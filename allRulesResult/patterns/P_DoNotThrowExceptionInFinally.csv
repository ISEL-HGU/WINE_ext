Pattern ID,Pattern,Context,"# of Eq list","# of Frq",complexity,Num of Warnings in Method,NCL
1,} finally {,"try {
  CompositeCache compositeCache=new CompositeCache(summaryCache,indexCache);
  CachableBuilder cb=new CachableBuilder().fsPath(fs,file).conf(conf).fileLen(fileLenCache).cacheProvider(new BasicCacheProvider(compositeCache,null)).cryptoService(cryptoService);
  bcReader=new CachableBlockFile.Reader(cb);
  return load(bcReader,summarySelector,factory);
}
 catch (FileNotFoundException fne) {
  return getEmptyReader(factory);
}
catch (IOException e) {
  try {
    if (!fs.exists(file)) {
      return getEmptyReader(factory);
    }
  }
 catch (  IOException e1) {
  }
  throw new UncheckedIOException(e);
}
 finally {
  if (bcReader != null) {
    try {
      bcReader.close();
    }
 catch (    IOException e) {
      throw new UncheckedIOException(e);
    }
  }
}
",0,0,0,829,
2,} finally {,"try {
  for (  TabletFile file : inFiles) {
    ns=context.getVolumeManager().getFileSystemByPath(file.getPath());
    reader=FileOperations.getInstance().newIndexReaderBuilder().forFile(file.getPathStr(),ns,ns.getConf(),context.getCryptoService()).withTableConfiguration(acuConf).build();
    iters.add(reader);
  }
  MultiIterator mmfi=new MultiIterator(iters,true);
  while (mmfi.hasTop()) {
    Key key=mmfi.getTopKey();
    boolean gtPrevEndRow=prevEndRow == null || key.compareRow(prevEndRow) > 0;
    boolean lteEndRow=endRow == null || key.compareRow(endRow) <= 0;
    if (gtPrevEndRow && lteEndRow)     writer.append(key,new Value());
    if (!lteEndRow)     break;
    mmfi.next();
  }
}
  finally {
  try {
    if (reader != null)     reader.close();
  }
 catch (  IOException e) {
    log.error(""{}"",e.getMessage(),e);
  }
  for (  SortedKeyValueIterator<Key,Value> r : iters)   try {
    if (r != null)     ((FileSKVIterator)r).close();
  }
 catch (  IOException e) {
    log.error(""{}"",e.getMessage(),e);
  }
  try {
    writer.close();
  }
 catch (  IOException e) {
    log.error(""{}"",e.getMessage(),e);
    throw e;
  }
}
",0,0,0,,
3,} finally {,"try {
  while (retry) {
    ManagerClientService.Iface client=null;
    try {
      client=ManagerClient.getConnection(context);
      if (client != null) {
        mmi=client.getManagerStats(TraceUtil.traceInfo(),context.rpcCreds());
        retry=false;
      }
 else {
        mmi=null;
        log.error(""Unable to get info from Manager"");
      }
      gcStatus=fetchGcStatus();
    }
 catch (    Exception e) {
      mmi=null;
      log.info(""Error fetching stats: "",e);
    }
 finally {
      if (client != null) {
        ManagerClient.close(client);
      }
    }
    if (mmi == null) {
      sleepUninterruptibly(1,TimeUnit.SECONDS);
    }
  }
  if (mmi != null) {
    int majorCompactions=0;
    int minorCompactions=0;
    lookupRateTracker.startingUpdates();
    indexCacheHitTracker.startingUpdates();
    indexCacheRequestTracker.startingUpdates();
    dataCacheHitTracker.startingUpdates();
    dataCacheRequestTracker.startingUpdates();
    for (    TabletServerStatus server : mmi.tServerInfo) {
      TableInfo summary=TableInfoUtil.summarizeTableStats(server);
      totalIngestRate+=summary.ingestRate;
      totalIngestByteRate+=summary.ingestByteRate;
      totalQueryRate+=summary.queryRate;
      totalScanRate+=summary.scanRate;
      totalQueryByteRate+=summary.queryByteRate;
      totalEntries+=summary.recs;
      totalHoldTime+=server.holdTime;
      totalLookups+=server.lookups;
      majorCompactions+=summary.majors.running;
      minorCompactions+=summary.minors.running;
      lookupRateTracker.updateTabletServer(server.name,server.lastContact,server.lookups);
      indexCacheHitTracker.updateTabletServer(server.name,server.lastContact,server.indexCacheHits);
      indexCacheRequestTracker.updateTabletServer(server.name,server.lastContact,server.indexCacheRequest);
      dataCacheHitTracker.updateTabletServer(server.name,server.lastContact,server.dataCacheHits);
      dataCacheRequestTracker.updateTabletServer(server.name,server.lastContact,server.dataCacheRequest);
    }
    lookupRateTracker.finishedUpdating();
    indexCacheHitTracker.finishedUpdating();
    indexCacheRequestTracker.finishedUpdating();
    dataCacheHitTracker.finishedUpdating();
    dataCacheRequestTracker.finishedUpdating();
    int totalTables=0;
    for (    TableInfo tInfo : mmi.tableMap.values()) {
      totalTabletCount+=tInfo.tablets;
      totalTables++;
    }
    this.totalIngestRate=totalIngestRate;
    this.totalTables=totalTables;
    totalIngestByteRate=totalIngestByteRate / 1000000.0;
    this.totalQueryRate=totalQueryRate;
    this.totalScanRate=totalScanRate;
    totalQueryByteRate=totalQueryByteRate / 1000000.0;
    this.totalEntries=totalEntries;
    this.totalTabletCount=totalTabletCount;
    this.totalHoldTime=totalHoldTime;
    this.totalLookups=totalLookups;
    ingestRateOverTime.add(new Pair<>(currentTime,totalIngestRate));
    ingestByteRateOverTime.add(new Pair<>(currentTime,totalIngestByteRate));
    double totalLoad=0.;
    for (    TabletServerStatus status : mmi.tServerInfo) {
      if (status != null) {
        totalLoad+=status.osLoad;
      }
    }
    loadOverTime.add(new Pair<>(currentTime,totalLoad));
    minorCompactionsOverTime.add(new Pair<>(currentTime,minorCompactions));
    majorCompactionsOverTime.add(new Pair<>(currentTime,majorCompactions));
    lookupsOverTime.add(new Pair<>(currentTime,lookupRateTracker.calculateRate()));
    queryRateOverTime.add(new Pair<>(currentTime,(long)totalQueryRate));
    queryByteRateOverTime.add(new Pair<>(currentTime,totalQueryByteRate));
    scanRateOverTime.add(new Pair<>(currentTime,(long)totalScanRate));
    calcCacheHitRate(indexCacheHitRateOverTime,currentTime,indexCacheHitTracker,indexCacheRequestTracker);
    calcCacheHitRate(dataCacheHitRateOverTime,currentTime,dataCacheHitTracker,dataCacheRequestTracker);
  }
  try {
    this.problemSummary=ProblemReports.getInstance(context).summarize();
    this.problemException=null;
  }
 catch (  Exception e) {
    log.info(""Failed to obtain problem reports "",e);
    this.problemSummary=Collections.emptyMap();
    this.problemException=e;
  }
}
  finally {
  lastRecalc.set(currentTime);
  if (!fetching.compareAndSet(true,false)) {
    throw new AssertionError(""Not supposed to happen; somebody broke this code"");
  }
}
",0,0,0,,
4,} finally {,"try {
  for (  ByteBuffer edit : data.getEdits()) {
    DataInputStream dis=new DataInputStream(ByteBufferUtil.toByteArrayInputStream(edit));
    try {
      key.readFields(dis);
      value.readFields(dis);
    }
 catch (    IOException e) {
      log.error(""Could not deserialize edit from stream"",e);
      throw new RemoteReplicationException(RemoteReplicationErrorCode.COULD_NOT_DESERIALIZE,""Could not deserialize edit from stream"");
    }
    if (bw == null) {
      BatchWriterConfig bwConfig=new BatchWriterConfig();
      bwConfig.setMaxMemory(memoryInBytes);
      try {
        bw=context.createBatchWriter(tableName,bwConfig);
      }
 catch (      TableNotFoundException e) {
        throw new RemoteReplicationException(RemoteReplicationErrorCode.TABLE_DOES_NOT_EXIST,""Table "" + tableName + "" does not exist"");
      }
    }
    log.info(""Applying {} mutations to table {} as part of batch"",value.mutations.size(),tableName);
    List<Mutation> mutationsCopy=new ArrayList<>(value.mutations.size());
    long mutationsCopied=0L;
    for (    Mutation orig : value.mutations) {
      if (orig instanceof ServerMutation) {
        mutationsCopied++;
        ServerMutation origServer=(ServerMutation)orig;
        Mutation copy=new Mutation(orig.getRow());
        for (        ColumnUpdate update : orig.getUpdates()) {
          long timestamp;
          if (update.hasTimestamp()) {
            timestamp=update.getTimestamp();
          }
 else {
            timestamp=origServer.getSystemTimestamp();
          }
          if (update.isDeleted()) {
            copy.putDelete(update.getColumnFamily(),update.getColumnQualifier(),new ColumnVisibility(update.getColumnVisibility()),timestamp);
          }
 else {
            copy.put(update.getColumnFamily(),update.getColumnQualifier(),new ColumnVisibility(update.getColumnVisibility()),timestamp,update.getValue());
          }
        }
        Set<String> replicationSources=orig.getReplicationSources();
        if (replicationSources != null && !replicationSources.isEmpty()) {
          for (          String replicationSource : replicationSources) {
            copy.addReplicationSource(replicationSource);
          }
        }
        mutationsCopy.add(copy);
      }
 else {
        mutationsCopy.add(orig);
      }
    }
    log.debug(""Copied {} mutations to ensure server-assigned timestamps are propagated"",mutationsCopied);
    try {
      bw.addMutations(mutationsCopy);
    }
 catch (    MutationsRejectedException e) {
      log.error(""Could not apply mutations to {}"",tableName);
      throw new RemoteReplicationException(RemoteReplicationErrorCode.COULD_NOT_APPLY,""Could not apply mutations to "" + tableName);
    }
    log.debug(""{} mutations added to the BatchScanner"",mutationsCopy.size());
    mutationsApplied+=mutationsCopy.size();
  }
}
  finally {
  if (bw != null) {
    try {
      bw.close();
    }
 catch (    MutationsRejectedException e) {
      log.error(""Could not apply mutations to {}"",tableName);
      throw new RemoteReplicationException(RemoteReplicationErrorCode.COULD_NOT_APPLY,""Could not apply mutations to "" + tableName);
    }
  }
}
",0,0,0,,
5,} finally {,"try {
  tabletServer.updateBulkImportState(files,BulkImportState.LOADING);
  var storedTabletFile=getDatafileManager().importMapFiles(tid,entries,setTime);
  lastMapFileImportTime=System.currentTimeMillis();
  if (needsSplit()) {
    getTabletServer().executeSplit(this);
  }
 else {
    compactable.filesAdded(false,storedTabletFile);
  }
}
  finally {
synchronized (this) {
    decrementWritesInProgress();
    if (!bulkImporting.removeAll(fileMap.keySet())) {
      throw new AssertionError(""Likely bug in code, always expect to remove something.  Please open an Accumulo issue."");
    }
    try {
      bulkImported.computeIfAbsent(tid,k -> new ArrayList<>()).addAll(fileMap.keySet());
    }
 catch (    Exception ex) {
      log.info(ex.toString(),ex);
    }
    tabletServer.removeBulkImportState(files);
  }
}
",0,0,0,,
6,} finally {,"try {
  deletingMemTable.delete(15000);
}
  finally {
synchronized (tablet) {
    if (otherMemTable != null) {
      throw new IllegalStateException();
    }
    if (deletingMemTable == null) {
      throw new IllegalStateException();
    }
    deletingMemTable=null;
    tablet.updateMemoryUsageStats(memTable.estimatedSizeInBytes(),0);
  }
}
",0,0,0,,
7,} finally {,"try {
  return super.startCoordinatorClientService();
}
  finally {
  try {
    metricServer=startHttpMetricServer();
  }
 catch (  Exception e1) {
    throw new RuntimeException(""Failed to start metric http server"",e1);
  }
}
",0,0,0,,
8,} finally {,"try {
  JAXBContext ctx=JAXBContext.newInstance(Results.class);
  Marshaller m=ctx.createMarshaller();
  m.marshal(results,xml);
  StringReader reader=new StringReader(xml.toString());
  TransformerFactory tf=TransformerFactory.newInstance();
  Templates xsl=tf.newTemplates(new StreamSource(xslContent));
  Transformer t=xsl.newTransformer();
  t.transform(new StreamSource(reader),new StreamResult(html));
}
 catch (Exception e) {
  throw new EJBException(""Error processing query results"",e);
}
 finally {
  try {
    xslContent.close();
  }
 catch (  IOException e) {
    throw new EJBException(""Unable to close input stream"",e);
  }
}
",0,0,0,,
9,finally {,"try {
  file=FileUtils.createTempFile(null);
  fileOut=new FileOutputStream(file);
  byte[] byteArray=new byte[12345];
  Random randomContentCreator=new Random();
  randomContentCreator.nextBytes(byteArray);
  fileOut.write(byteArray);
  return file;
}
  finally {
  try {
    if (fileOut != null) {
      fileOut.close();
    }
  }
 catch (  IOException e) {
    throw e;
  }
}
",0,0,0,,
10,finally {,"try {
  fileOut=new FileOutputStream(file);
  byte[] byteArray=new byte[size];
  Random randomContentCreator=new Random();
  randomContentCreator.nextBytes(byteArray);
  fileOut.write(byteArray);
  return file;
}
  finally {
  try {
    if (fileOut != null) {
      fileOut.close();
    }
  }
 catch (  IOException e) {
    throw e;
  }
}
",0,0,0,,
11,} finally {,"try {
  rollback();
}
  finally {
  LOG.warn(message);
  throw new TransactionRolledBackException(message);
}
",0,0,0,,
12,} finally {,"try {
  beforeEnd();
}
 catch (JMSException e) {
  throwingException=true;
  throw toXAException(e);
}
 finally {
  try {
    setXid(null);
  }
 catch (  XAException ignoreIfWillMask) {
    if (!throwingException) {
      throw ignoreIfWillMask;
    }
  }
}
",0,0,0,,
13,} finally {,"try {
  if (enableRecoveryFile) {
    Checksum checksum=new Adler32();
    recoveryFile.seek(RECOVERY_FILE_HEADER_SIZE);
    for (    PageWrite w : batch) {
      try {
        checksum.update(w.getDiskBound(tmpFilesForRemoval),0,pageSize);
      }
 catch (      Throwable t) {
        throw IOExceptionSupport.create(""Cannot create recovery file. Reason: "" + t,t);
      }
      recoveryFile.writeLong(w.page.getPageId());
      recoveryFile.write(w.getDiskBound(tmpFilesForRemoval),0,pageSize);
    }
    if (recoveryPageCount > recoveryFileMaxPageCount) {
      int t=Math.max(recoveryFileMinPageCount,batch.size());
      recoveryFile.setLength(recoveryFileSizeForPages(t));
    }
    recoveryFile.seek(0);
    recoveryFile.writeLong(nextTxid.get());
    recoveryFile.writeLong(checksum.getValue());
    recoveryFile.writeInt(batch.size());
    if (enableDiskSyncs) {
      recoveryFile.sync();
    }
  }
  for (  PageWrite w : batch) {
    writeFile.seek(toOffset(w.page.getPageId()));
    writeFile.write(w.getDiskBound(tmpFilesForRemoval),0,pageSize);
    w.done();
  }
  if (enableDiskSyncs) {
    writeFile.sync();
  }
}
 catch (IOException ioError) {
  LOG.info(""Unexpected io error on pagefile write of "" + batch.size() + "" pages."",ioError);
  loaded.set(false);
  throw ioError;
}
 finally {
synchronized (writes) {
    for (    PageWrite w : batch) {
      if (w.isDone()) {
        writes.remove(w.page.getPageId());
        if (w.tmpFile != null && tmpFilesForRemoval.containsKey(w.tmpFile)) {
          tmpFilesForRemoval.get(w.tmpFile).close();
          if (!w.tmpFile.delete()) {
            throw new IOException(""Can't delete temporary KahaDB transaction file:"" + w.tmpFile);
          }
          tmpFilesForRemoval.remove(w.tmpFile);
        }
      }
    }
  }
  if (checkpointLatch != null) {
    checkpointLatch.countDown();
  }
}
",0,0,0,,
14,} finally {,"try {
  transactionContext.commit();
}
 catch (JMSException e) {
  throw new ResourceException(""commit failed."",e);
}
 finally {
  try {
    setInManagedTx(false);
  }
 catch (  JMSException e) {
    throw new ResourceException(""commit failed."",e);
  }
}
",0,0,0,,
15,} finally {,"try {
  transactionContext.rollback();
}
 catch (JMSException e) {
  throw new ResourceException(""rollback failed."",e);
}
 finally {
  try {
    setInManagedTx(false);
  }
 catch (  JMSException e) {
    throw new ResourceException(""rollback failed."",e);
  }
}
",0,0,0,,
16,} finally {,"try {
  transactionContext.end(arg0,arg1);
}
  finally {
  try {
    setInManagedTx(false);
  }
 catch (  JMSException e) {
    throw (XAException)new XAException(XAException.XAER_PROTO).initCause(e);
  }
  if ((arg1 & TMFAIL) != 0) {
    LOG.debug(""Marking transaction: {} rollbackOnly"",this);
    transactionContext.setRollbackOnly(true);
  }
}
",0,0,0,,
17,} finally {,"try {
  connection=connectionFactory.getConnection();
  Statement statement=null;
  try {
    Set<Map<String,Object>> propertySet=request.getProperties();
    statement=connection.createStatement();
    for (    Map<String,Object> properties : propertySet) {
      String sql=getInsertSQL(properties);
      statement.execute(sql);
    }
  }
  finally {
    if (statement != null) {
      statement.close();
    }
  }
}
 catch (SQLException e) {
  throw new IllegalStateException(""DB error : "",e);
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException ex) {
      throw new IllegalStateException(""DB error : "",ex);
    }
  }
}
",0,0,0,,
18,} finally {,"try {
  connection=connectionFactory.getConnection();
  Statement statement=null;
  try {
    Set<Map<String,Object>> propertySet=request.getProperties();
    Map<String,Object> properties=propertySet.iterator().next();
    String sql=getUpdateSQL(properties,predicate);
    statement=connection.createStatement();
    statement.execute(sql);
  }
  finally {
    if (statement != null) {
      statement.close();
    }
  }
}
 catch (SQLException e) {
  throw new IllegalStateException(""DB error : "",e);
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException ex) {
      throw new IllegalStateException(""DB error : "",ex);
    }
  }
}
",0,0,0,,
19,} finally {,"try {
  connection=connectionFactory.getConnection();
  Statement statement=null;
  try {
    String sql=getDeleteSQL(predicate);
    statement=connection.createStatement();
    statement.execute(sql);
  }
  finally {
    if (statement != null) {
      statement.close();
    }
  }
}
 catch (SQLException e) {
  throw new IllegalStateException(""DB error : "",e);
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException ex) {
      throw new IllegalStateException(""DB error : "",ex);
    }
  }
}
",0,0,0,,
20,} finally {,"try {
  statement=dbAccessor.getConnection().createStatement();
  if (statement != null) {
    rs=statement.executeQuery(""SELECT "" + dbAccessor.quoteObjectName(""metainfo_value"") + "" from metainfo WHERE ""+ dbAccessor.quoteObjectName(""metainfo_key"")+ ""='version'"");
    if (rs != null && rs.next()) {
      return rs.getString(1);
    }
  }
}
 catch (SQLException e) {
  throw new RuntimeException(""Unable to read database version"",e);
}
 finally {
  if (rs != null) {
    try {
      rs.close();
    }
 catch (    SQLException e) {
      throw new RuntimeException(""Cannot close result set"");
    }
  }
  if (statement != null) {
    try {
      statement.close();
    }
 catch (    SQLException e) {
      throw new RuntimeException(""Cannot close statement"");
    }
  }
}
",0,0,0,,
21,} finally {,"try {
  addBuildListeners(project);
  addInputHandler(project);
  final PrintStream savedErr=System.err;
  final PrintStream savedOut=System.out;
  final InputStream savedIn=System.in;
  try {
    if (allowInput) {
      project.setDefaultInputStream(System.in);
    }
    System.setIn(new DemuxInputStream(project));
    System.setOut(new PrintStream(new DemuxOutputStream(project,false)));
    System.setErr(new PrintStream(new DemuxOutputStream(project,true)));
    if (!projectHelp) {
      project.fireBuildStarted();
    }
    if (threadPriority != null) {
      try {
        project.log(""Setting Ant's thread priority to "" + threadPriority,Project.MSG_VERBOSE);
        Thread.currentThread().setPriority(threadPriority);
      }
 catch (      final SecurityException swallowed) {
        project.log(""A security manager refused to set the -nice value"");
      }
    }
    setProperties(project);
    project.setKeepGoingMode(keepGoingMode);
    if (proxy) {
      final ProxySetup proxySetup=new ProxySetup(project);
      proxySetup.enableProxies();
    }
    for (    final ArgumentProcessor processor : processorRegistry.getProcessors()) {
      final List<String> extraArgs=extraArguments.get(processor.getClass());
      if (extraArgs != null) {
        processor.prepareConfigure(project,extraArgs);
      }
    }
    ProjectHelper.configureProject(project,buildFile);
    for (    final ArgumentProcessor processor : processorRegistry.getProcessors()) {
      final List<String> extraArgs=extraArguments.get(processor.getClass());
      if (extraArgs != null) {
        if (processor.handleArg(project,extraArgs)) {
          return;
        }
      }
    }
    if (projectHelp) {
      printDescription(project);
      printTargets(project,msgOutputLevel > Project.MSG_INFO,msgOutputLevel > Project.MSG_VERBOSE);
      return;
    }
    if (targets.isEmpty()) {
      if (project.getDefaultTarget() != null) {
        targets.addElement(project.getDefaultTarget());
      }
    }
    project.executeTargets(targets);
  }
  finally {
    System.setOut(savedOut);
    System.setErr(savedErr);
    System.setIn(savedIn);
  }
}
 catch (final RuntimeException|Error exc) {
  error=exc;
  throw exc;
}
 finally {
  if (!projectHelp) {
    try {
      project.fireBuildFinished(error);
    }
 catch (    final Throwable t) {
      System.err.println(""Caught an exception while logging the"" + "" end of the build.  Exception was:"");
      t.printStackTrace();
      if (error != null) {
        System.err.println(""There has been an error prior to"" + "" that:"");
        error.printStackTrace();
      }
      throw new BuildException(t);
    }
  }
 else   if (error != null) {
    project.log(error.toString(),Project.MSG_ERR);
  }
}
",0,0,0,,
22,} finally {,"try {
  r=new BufferedReader(new InputStreamReader(getInputStream()));
  do {
    System.err.println(prompt);
    System.err.flush();
    try {
      String input=r.readLine();
      if (input == null) {
        throw new BuildException(""unexpected end of stream while reading input"");
      }
      request.setInput(input);
    }
 catch (    IOException e) {
      throw new BuildException(""Failed to read input from"" + "" Console."",e);
    }
  }
 while (!request.isInputValid());
  success=true;
}
  finally {
  if (r != null) {
    try {
      r.close();
    }
 catch (    IOException e) {
      if (success) {
        throw new BuildException(""Failed to close input."",e);
      }
    }
  }
}
",0,0,0,,
23,} finally {,"try {
  result.exitCode=execute.execute();
  success=true;
}
 catch (final IOException e) {
  throw new BuildException(""Process fork failed."",e,getLocation());
}
 finally {
  String vmCrashString=""unknown"";
  BufferedReader br=null;
  try {
    if (vmWatcher.exists()) {
      br=new BufferedReader(new FileReader(vmWatcher));
      vmCrashString=br.readLine();
    }
 else {
      vmCrashString=""Monitor file ("" + vmWatcher.getAbsolutePath() + "") missing, location not writable,""+ "" testcase not started or mixing ant versions?"";
    }
  }
 catch (  final Exception e) {
    log(StringUtils.getStackTrace(e),Project.MSG_INFO);
  }
 finally {
    FileUtils.close(br);
    if (vmWatcher.exists()) {
      FILE_UTILS.tryHardToDelete(vmWatcher);
    }
  }
  final boolean crash=(watchdog != null && watchdog.killedProcess()) || !Constants.TERMINATED_SUCCESSFULLY.equals(vmCrashString);
  if (casesFile != null && crash) {
    test=createDummyTestForBatchTest(test);
  }
  if (watchdog != null && watchdog.killedProcess()) {
    result.timedOut=true;
    logTimeout(feArray,test,vmCrashString);
  }
 else   if (crash) {
    result.crashed=true;
    logVmCrash(feArray,test,vmCrashString);
  }
  if (!FILE_UTILS.tryHardToDelete(propsFile)) {
    String msg=""Could not delete temporary properties file '"" + propsFile.getAbsolutePath() + ""'."";
    if (success) {
      throw new BuildException(msg);
    }
    log(msg,Project.MSG_ERR);
  }
}
",0,0,0,,
24,} finally {,"try {
  write(String.format(""Tests run: %d, Failures: %d, Errors: %d, Skipped: %d, Time elapsed: %s sec%n"",suite.runCount(),suite.failureCount(),suite.errorCount(),suite.skipCount(),nf.format(suite.getRunTime() / ONE_SECOND)));
  if (systemOutput != null && !systemOutput.isEmpty()) {
    write(String.format(""------------- Standard Output ---------------%n""));
    write(systemOutput);
    write(String.format(""------------- ---------------- ---------------%n""));
  }
  if (systemError != null && !systemError.isEmpty()) {
    write(String.format(""------------- Standard Error -----------------%n""));
    write(systemError);
    write(String.format(""------------- ---------------- ---------------%n""));
  }
  write(System.lineSeparator());
  if (out != null) {
    try {
      wri.flush();
      write(inner.toString());
    }
 catch (    IOException ioex) {
      throw new BuildException(""Unable to write output"",ioex);
    }
  }
  success=true;
}
  finally {
  if (out != null) {
    try {
      wri.close();
    }
 catch (    IOException ioex) {
      if (success) {
        throw new BuildException(""Unable to flush output"",ioex);
      }
    }
 finally {
      if (out != System.out && out != System.err) {
        FileUtils.close(out);
      }
      wri=null;
      out=null;
    }
  }
}
",0,0,0,,
25,} finally {,"try {
  if (hasTestFailures && test.getFailureProperty() != null) {
    final TestExecutionContext testExecutionContext=this.testExecutionContext;
    if (testExecutionContext.getProject().isPresent()) {
      final Project project=testExecutionContext.getProject().get();
      project.setNewProperty(test.getFailureProperty(),""true"");
    }
  }
}
  finally {
  if (hasTestFailures && test.isHaltOnFailure()) {
    final String errorMessage;
    if (test instanceof NamedTest) {
      errorMessage=""Test "" + ((NamedTest)test).getName() + "" has ""+ summary.getTestsFailedCount()+ "" failure(s)"";
    }
 else {
      errorMessage=""Some test(s) have failure(s)"";
    }
    throw new BuildException(errorMessage);
  }
}
",0,0,0,,
26,} finally {,"try {
  if (test.getFailureProperty() != null) {
    this.getProject().setNewProperty(test.getFailureProperty(),""true"");
  }
}
  finally {
  if (test.isHaltOnFailure()) {
    final String errorMessage;
    if (test instanceof NamedTest) {
      errorMessage=""Test "" + ((NamedTest)test).getName() + "" has failure(s)"";
    }
 else {
      errorMessage=""Some test(s) have failure(s)"";
    }
    throw new BuildException(errorMessage);
  }
}
",0,0,0,,
27,} finally {,"try {
  getProject().log(""testing case sensitivity, attempting to cd to "" + target,Project.MSG_DEBUG);
  remoteSystemCaseSensitive=!ftp.changeWorkingDirectory(target);
}
 catch (IOException ioe) {
  remoteSystemCaseSensitive=true;
}
 finally {
  try {
    ftp.changeWorkingDirectory(directory);
  }
 catch (  IOException ioe) {
    throw new BuildException(ioe,getLocation());
  }
}
",0,0,0,,
28,} finally {,"try {
  comeback=ftp.changeWorkingDirectory(currentWorkingDir);
}
 catch (IOException ioe) {
  getProject().log(""could not cd back to "" + dir + "" while checking a symlink"",Project.MSG_ERR);
}
 finally {
  if (!comeback) {
    throw new BuildException(""could not cd back to %s while checking a symlink"",dir);
  }
}
",0,0,0,,
29,} finally {,"try {
  task.log(""testing case sensitivity, attempting to cd to "" + target,Project.MSG_DEBUG);
  remoteSystemCaseSensitive=!ftp.changeWorkingDirectory(target);
}
 catch (IOException ioe) {
  remoteSystemCaseSensitive=true;
}
 finally {
  try {
    ftp.changeWorkingDirectory(directory);
  }
 catch (  IOException ioe) {
    throw new BuildException(ioe,task.getLocation());
  }
}
",0,0,0,,
30,} finally {,"try {
  comeback=ftp.changeWorkingDirectory(currentWorkingDir);
}
 catch (IOException ioe) {
  task.log(""could not cd back to "" + dir + "" while checking a symlink"",Project.MSG_ERR);
}
 finally {
  if (!comeback) {
    throw new BuildException(""could not cd back to %s while checking a symlink"",dir);
  }
}
",0,0,0,,
31,} finally {,"try {
  rexec=new AntRExecClient();
  try {
    rexec.connect(server,port);
  }
 catch (  IOException e) {
    throw new BuildException(""Can't connect to "" + server);
  }
  if (userid != null && password != null && command != null && rexecTasks.isEmpty()) {
    rexec.rexec(userid,password,command);
  }
 else {
    handleMultipleTasks(rexec);
  }
  rexec.waitForEOF(defaultTimeout);
  success=true;
}
 catch (IOException e) {
  throw new BuildException(""Error r-executing command"",e);
}
 finally {
  if (rexec != null && rexec.isConnected()) {
    try {
      rexec.disconnect();
    }
 catch (    IOException e) {
      String msg=""Error disconnecting from "" + server;
      if (success) {
        throw new BuildException(msg);
      }
      log(msg,Project.MSG_ERR);
    }
  }
}
",0,0,0,,
32,} finally {,"try {
  telnet=new AntTelnetClient();
  try {
    telnet.connect(server,port);
  }
 catch (  IOException e) {
    throw new BuildException(""Can't connect to "" + server);
  }
  if (userid != null && password != null) {
    login(telnet);
  }
  for (  TelnetSubTask task : telnetTasks) {
    if (task instanceof TelnetRead && defaultTimeout != null) {
      ((TelnetRead)task).setDefaultTimeout(defaultTimeout);
    }
    task.execute(telnet);
  }
  success=true;
}
  finally {
  if (telnet != null && telnet.isConnected()) {
    try {
      telnet.disconnect();
    }
 catch (    IOException e) {
      String msg=""Error disconnecting from "" + server;
      if (success) {
        throw new BuildException(msg);
      }
 else {
        log(msg,Project.MSG_ERR);
      }
    }
  }
}
",0,0,0,,
33,} finally {,"try {
  Class<?> c=Class.forName(RMIC_CLASSNAME);
  Constructor<?> cons=c.getConstructor(OutputStream.class,String.class);
  Object rmic=cons.newInstance(logstr,""rmic"");
  Method doRmic=c.getMethod(""compile"",String[].class);
  boolean ok=Boolean.TRUE.equals(doRmic.invoke(rmic,(Object)cmd.getArguments()));
  success=true;
  return ok;
}
 catch (ClassNotFoundException ex) {
  if (JavaEnvUtils.isAtLeastJavaVersion(JavaEnvUtils.JAVA_9)) {
    throw new BuildException(ERROR_NO_RMIC_ON_CLASSPATH_JAVA_9,getRmic().getLocation());
  }
  throw new BuildException(ERROR_NO_RMIC_ON_CLASSPATH,getRmic().getLocation());
}
catch (Exception ex) {
  if (ex instanceof BuildException) {
    throw (BuildException)ex;
  }
  throw new BuildException(ERROR_RMIC_FAILED,ex,getRmic().getLocation());
}
 finally {
  try {
    logstr.close();
  }
 catch (  IOException e) {
    if (success) {
      throw new BuildException(e);
    }
  }
}
",0,0,0,,
34,} finally {,"try {
  try {
    FILE_UTILS.rename(target,temp);
    renamedTarget=true;
  }
 catch (  final IOException e) {
    throw new IOException(""Couldn't rename resource when "" + ""attempting to delete '"" + link + ""'.  Reason: ""+ e.getMessage());
  }
  if (!link.delete()) {
    throw new IOException(""Couldn't delete symlink: "" + link + "" (was it a real file? is this ""+ ""not a UNIX system?)"");
  }
  success=true;
}
  finally {
  if (renamedTarget) {
    try {
      FILE_UTILS.rename(temp,target);
    }
 catch (    final IOException e) {
      String msg=""Couldn't return resource "" + temp + "" to its original name: ""+ target.getAbsolutePath()+ "". Reason: ""+ e.getMessage()+ ""\n THE RESOURCE'S NAME ON DISK""+ "" HAS BEEN CHANGED BY THIS""+ "" ERROR!\n"";
      if (success) {
        throw new IOException(msg);
      }
 else {
        System.err.println(msg);
      }
    }
  }
}
",0,0,0,,
35,} finally {,"try {
  message+=LINE_SEPARATOR;
  String filename=file.getAbsolutePath();
  if (isNullOrEmpty(encoding)) {
    out=new FileWriter(filename,append);
  }
 else {
    out=new BufferedWriter(new OutputStreamWriter(new FileOutputStream(filename,append),encoding));
  }
  out.write(message,0,message.length());
}
 catch (IOException e) {
  throw new ResolveProcessException(e);
}
 finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException e) {
      throw new ResolveProcessException(e);
    }
  }
}
",0,0,0,,
36,} finally {,"try {
  if (!prototype) {
    FutureTask<Object> objectCreation=new FutureTask<Object>(new Callable<Object>(){
      public Object call() throws ComponentDefinitionException {
        return internalCreate();
      }
    }
);
    Future<Object> resultFuture=context.addFullObject(name,objectCreation);
    if (resultFuture == null) {
      didCreate=true;
      objectCreation.run();
      resultFuture=objectCreation;
    }
    try {
      result=resultFuture.get();
    }
 catch (    InterruptedException ie) {
      Thread.currentThread().interrupt();
    }
catch (    ExecutionException ee) {
      if (ee.getCause() instanceof ComponentDefinitionException)       throw (ComponentDefinitionException)ee.getCause();
 else       if (ee.getCause() instanceof RuntimeException)       throw (RuntimeException)ee.getCause();
 else       throw (Error)ee.getCause();
    }
  }
 else {
    result=internalCreate();
  }
}
  finally {
  if (didCreate)   context.removePartialObject(name);
  Recipe popped=context.pop();
  if (popped != this) {
    throw new IllegalStateException(""Internal Error: recipe stack is corrupt:"" + "" Expected "" + this + "" to be popped of the stack but was ""+ popped);
  }
}
",0,0,0,,
37,finally {,"try {
  TargetRegion region=new TargetRegion(parent);
  SubsystemResource ssr=new SubsystemResource(location,content,parent,coordination);
  result=Activator.getInstance().getSubsystems().getSubsystemByLocation(location);
  if (result != null) {
    if (!region.contains(result))     throw new SubsystemException(""Location already exists but existing subsystem is not part of target region: "" + location);
    if (!(result.getSymbolicName().equals(ssr.getSubsystemManifest().getSubsystemSymbolicNameHeader().getSymbolicName()) && result.getVersion().equals(ssr.getSubsystemManifest().getSubsystemVersionHeader().getVersion()) && result.getType().equals(ssr.getSubsystemManifest().getSubsystemTypeHeader().getType())))     throw new SubsystemException(""Location already exists but symbolic name, version, and type are not the same: "" + location);
  }
 else {
    result=(BasicSubsystem)region.find(ssr.getSubsystemManifest().getSubsystemSymbolicNameHeader().getSymbolicName(),ssr.getSubsystemManifest().getSubsystemVersionHeader().getVersion());
    if (result != null) {
      if (!result.getType().equals(ssr.getSubsystemManifest().getSubsystemTypeHeader().getType()))       throw new SubsystemException(""Subsystem already exists in target region but has a different type: "" + location);
    }
 else {
      result=new BasicSubsystem(ssr,deploymentManifest);
    }
  }
  checkLifecyclePermission(result);
  return (BasicSubsystem)ResourceInstaller.newInstance(coordination,result,parent).install();
}
 catch (Throwable t) {
  coordination.fail(t);
}
 finally {
  try {
    coordination.end();
  }
 catch (  CoordinationException e) {
    Throwable t=e.getCause();
    if (t instanceof SubsystemException)     throw (SubsystemException)t;
    if (t instanceof SecurityException)     throw (SecurityException)t;
    throw new SubsystemException(t);
  }
}
",0,0,0,,
38,finally {,"try {
  assertSymbolicName(""org.apache.aries.subsystem.itests.feature.empty"",emptyFeature);
  assertVersion(""1.1.2"",emptyFeature);
  assertType(SubsystemConstants.SUBSYSTEM_TYPE_FEATURE,emptyFeature);
  assertConstituents(0,emptyFeature);
  assertChildren(0,emptyFeature);
  startSubsystem(emptyFeature);
  stopSubsystem(emptyFeature);
}
 catch (AssertionError e) {
  error=e;
  throw e;
}
 finally {
  try {
    uninstallSubsystemSilently(emptyFeature);
  }
 catch (  AssertionError e) {
    if (error == null)     throw e;
    e.printStackTrace();
  }
}
",0,0,0,,
39,finally {,"try {
  assertSymbolicName(""org.apache.aries.subsystem.itests.subsystem.empty"",emptySubsystem);
  assertVersion(Version.emptyVersion,emptySubsystem);
  assertType(SubsystemConstants.SUBSYSTEM_TYPE_APPLICATION,emptySubsystem);
  assertConstituents(1,emptySubsystem);
  assertChildren(0,emptySubsystem);
  startSubsystem(emptySubsystem);
  stopSubsystem(emptySubsystem);
}
 catch (AssertionError e) {
  error=e;
  throw e;
}
 finally {
  try {
    uninstallSubsystemSilently(emptySubsystem);
  }
 catch (  AssertionError e) {
    if (error == null)     throw e;
    e.printStackTrace();
  }
}
",0,0,0,,
40,finally {,"try {
  assertSymbolicName(""org.apache.aries.subsystem.feature1"",feature1);
  assertVersion(""1.0.0"",feature1);
  assertConstituents(3,feature1);
  assertChildren(1,feature1);
  feature2=feature1.getChildren().iterator().next();
  assertEvent(feature2,Subsystem.State.INSTALLING,5000);
  assertEvent(feature2,Subsystem.State.INSTALLED,5000);
  assertSymbolicName(""org.apache.aries.subsystem.feature2"",feature2);
  assertVersion(""1.0.0"",feature2);
  assertConstituent(feature2,""org.apache.aries.subsystem.itests.tb2"",Version.parseVersion(""2.0.0""),IdentityNamespace.TYPE_BUNDLE);
  assertConstituent(feature2,""org.apache.aries.subsystem.itests.tb3"",Version.parseVersion(""1.0.0""),IdentityNamespace.TYPE_BUNDLE);
  assertConstituents(2,feature2);
  assertChildren(0,feature2);
  startSubsystem(feature1);
  assertEvent(feature2,Subsystem.State.RESOLVING,5000);
  assertEvent(feature2,Subsystem.State.RESOLVED,5000);
  assertEvent(feature2,Subsystem.State.STARTING,5000);
  assertEvent(feature2,Subsystem.State.ACTIVE,5000);
  stopSubsystem(feature1);
  assertEvent(feature2,Subsystem.State.STOPPING,5000);
  assertEvent(feature2,Subsystem.State.RESOLVED,5000);
}
 catch (AssertionError e) {
  error=e;
  throw e;
}
 finally {
  try {
    uninstallSubsystem(feature1);
    if (feature2 != null) {
      assertEvent(feature2,Subsystem.State.INSTALLED,5000);
      assertEvent(feature2,Subsystem.State.UNINSTALLING,5000);
      assertEvent(feature2,Subsystem.State.UNINSTALLED,5000);
      assertNotChild(feature1,feature2);
    }
  }
 catch (  AssertionError e) {
    if (error == null)     throw e;
    e.printStackTrace();
  }
}
",0,0,0,,
41,finally {,"try {
  assertFeature3(feature3Before);
  uninstallSubsystem(feature3Before);
  feature3Before=installSubsystemFromFile(""feature3.esa"");
  assertLastId(2);
  assertFeature3(feature3Before);
  Bundle bundle=getSubsystemCoreBundle();
  bundle.stop();
  resetLastId();
  bundle.start();
  Subsystem root=getRootSubsystem();
  assertChildren(1,root);
  feature3After=root.getChildren().iterator().next();
  assertLastId(2);
  assertFeature3(feature3After);
}
 catch (AssertionError e) {
  error=e;
  throw e;
}
 finally {
  try {
    if (feature3After != null) {
      uninstallSubsystem(feature3After);
    }
  }
 catch (  AssertionError e) {
    if (error == null)     throw e;
    e.printStackTrace();
  }
}
",0,0,0,,
42,finally {,"try {
  assertConstituent(feature1,""org.apache.aries.subsystem.itests.tb3"",Version.parseVersion(""1.0.0""),IdentityNamespace.TYPE_BUNDLE);
  Subsystem feature2=feature1.getChildren().iterator().next();
  while (!feature2.getState().equals(Subsystem.State.INSTALLED))   Thread.sleep(100);
  assertConstituent(feature2,""org.apache.aries.subsystem.itests.tb3"",Version.parseVersion(""1.0.0""),IdentityNamespace.TYPE_BUNDLE);
  uninstallSubsystem(feature2);
  assertNotChild(feature1,feature2);
  assertConstituent(feature1,""org.apache.aries.subsystem.itests.tb3"",Version.parseVersion(""1.0.0""),IdentityNamespace.TYPE_BUNDLE);
}
 catch (AssertionError e) {
  error=e;
  throw e;
}
 finally {
  try {
    uninstallSubsystem(feature1);
  }
 catch (  AssertionError e) {
    if (error == null)     throw e;
    e.printStackTrace();
  }
}
",0,0,0,,
43,} finally {,"try {
  frameTupleAccessor.reset(resultFrame.getBuffer());
  for (int tIndex=0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
    int start=frameTupleAccessor.getTupleStartOffset(tIndex);
    int length=frameTupleAccessor.getTupleEndOffset(tIndex) - start;
    bbis.setByteBuffer(resultFrame.getBuffer(),start);
    byte[] recordBytes=new byte[length];
    bbis.read(recordBytes,0,length);
    resultRecords.add(new String(recordBytes,0,length));
  }
}
  finally {
  try {
    bbis.close();
  }
 catch (  IOException e) {
    throw HyracksDataException.create(e);
  }
}
",0,0,0,,
44,} finally {,"try {
synchronized (opTracker) {
    try {
      if (opType == LSMOperationType.FLUSH) {
        opTracker.notifyAll();
        if (!failedOperation) {
          waitForLaggingMerge();
        }
      }
 else       if (opType == LSMOperationType.MERGE) {
        opTracker.notifyAll();
      }
      exitOperationalComponents(ctx,opType,failedOperation);
      ctx.setAccessingComponents(false);
      exitOperation(ctx,opType,newComponent,failedOperation);
    }
 catch (    Throwable e) {
      LOGGER.warn(""Failure exiting components"",e);
      throw e;
    }
 finally {
      if (failedOperation && (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION)) {
        opTracker.completeOperation(lsmIndex,opType,ctx.getSearchOperationCallback(),ctx.getModificationCallback());
      }
 else {
        opTracker.afterOperation(lsmIndex,opType,ctx.getSearchOperationCallback(),ctx.getModificationCallback());
      }
      List<ILSMDiskComponent> inactiveDiskComponents=lsmIndex.getInactiveDiskComponents();
      if (!inactiveDiskComponents.isEmpty()) {
        for (        ILSMDiskComponent inactiveComp : inactiveDiskComponents) {
          if (inactiveComp.getFileReferenceCount() == 1) {
            inactiveDiskComponentsToBeDeleted=inactiveDiskComponentsToBeDeleted == null ? new ArrayList<>() : inactiveDiskComponentsToBeDeleted;
            inactiveDiskComponentsToBeDeleted.add(inactiveComp);
          }
        }
        if (inactiveDiskComponentsToBeDeleted != null) {
          inactiveDiskComponents.removeAll(inactiveDiskComponentsToBeDeleted);
        }
      }
      List<ILSMMemoryComponent> inactiveMemoryComponents=lsmIndex.getInactiveMemoryComponents();
      if (!inactiveMemoryComponents.isEmpty()) {
        inactiveMemoryComponentsToBeCleanedUp=new ArrayList<>(inactiveMemoryComponents);
        inactiveMemoryComponents.clear();
      }
    }
  }
}
  finally {
  if (inactiveDiskComponentsToBeDeleted != null) {
    try {
      if (replicationEnabled) {
        lsmIndex.scheduleReplication(null,inactiveDiskComponentsToBeDeleted,ReplicationOperation.DELETE,opType);
      }
      for (      ILSMDiskComponent c : inactiveDiskComponentsToBeDeleted) {
        c.deactivateAndDestroy();
      }
    }
 catch (    Throwable e) {
      if (LOGGER.isWarnEnabled()) {
        LOGGER.log(Level.WARN,""Failure scheduling replication or destroying merged component"",e);
      }
      throw e;
    }
  }
  if (inactiveMemoryComponentsToBeCleanedUp != null) {
    for (    ILSMMemoryComponent c : inactiveMemoryComponentsToBeCleanedUp) {
      tracer.instant(c.toString(),traceCategory,Scope.p,lsmIndex.toString());
      c.cleanup();
synchronized (opTracker) {
        c.reset();
        opTracker.notifyAll();
      }
    }
  }
  if (opType == LSMOperationType.FLUSH) {
    ILSMMemoryComponent flushingComponent=(ILSMMemoryComponent)ctx.getComponentHolder().get(0);
    flushingComponent.flushed();
  }
}
",0,0,0,,
45,} finally {,"try {
  frameTupleAccessor.reset(resultFrame.getBuffer());
  for (int tIndex=0; tIndex < frameTupleAccessor.getTupleCount(); tIndex++) {
    int start=frameTupleAccessor.getTupleStartOffset(tIndex);
    int length=frameTupleAccessor.getTupleEndOffset(tIndex) - start;
    bbis.setByteBuffer(resultFrame.getBuffer(),start);
    byte[] recordBytes=new byte[length];
    bbis.read(recordBytes,0,length);
    resultRecords.put(new String(recordBytes,0,length));
  }
}
  finally {
  try {
    bbis.close();
  }
 catch (  IOException e) {
    throw new HyracksDataException(e);
  }
}
",0,0,0,,
46,} finally {,"try {
  writer.open();
  indexAccessor.diskOrderScan(cursor);
  int fieldCount=treeIndex.getFieldCount();
  FrameTupleAppender appender=new FrameTupleAppender(new VSizeFrame(ctx));
  ArrayTupleBuilder tb=new ArrayTupleBuilder(fieldCount);
  DataOutput dos=tb.getDataOutput();
  while (cursor.hasNext()) {
    tb.reset();
    cursor.next();
    ITupleReference frameTuple=cursor.getTuple();
    for (int i=0; i < frameTuple.getFieldCount(); i++) {
      dos.write(frameTuple.getFieldData(i),frameTuple.getFieldStart(i),frameTuple.getFieldLength(i));
      tb.addFieldEndOffset();
    }
    FrameUtils.appendToWriter(writer,appender,tb.getFieldEndOffsets(),tb.getByteArray(),0,tb.getSize());
  }
  appender.write(writer,true);
}
 catch (Throwable th) {
  writer.fail();
  throw new HyracksDataException(th);
}
 finally {
  try {
    cursor.close();
  }
 catch (  Exception cursorCloseException) {
    throw new IllegalStateException(cursorCloseException);
  }
 finally {
    writer.close();
  }
}
",0,0,0,,
47,} finally {,"try {
synchronized (opTracker) {
    try {
      int i=0;
      for (      ILSMComponent c : ctx.getComponentHolder()) {
        boolean isMutableComponent=i == 0 && c.getType() == LSMComponentType.MEMORY ? true : false;
        c.threadExit(opType,failedOperation,isMutableComponent);
        if (c.getType() == LSMComponentType.MEMORY) {
switch (c.getState()) {
case READABLE_UNWRITABLE:
            if (isMutableComponent && (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION)) {
              lsmIndex.changeFlushStatusForCurrentMutableCompoent(true);
            }
          break;
case INACTIVE:
        ((AbstractMemoryLSMComponent)c).reset();
      opTracker.notifyAll();
    break;
default :
  break;
}
}
 else {
switch (c.getState()) {
case INACTIVE:
lsmIndex.addInactiveDiskComponent(c);
break;
default :
break;
}
}
i++;
}
ctx.setAccessingComponents(false);
switch (opType) {
case FLUSH:
if (newComponent != null) {
lsmIndex.addComponent(newComponent);
if (replicationEnabled) {
componentsToBeReplicated.clear();
componentsToBeReplicated.add(newComponent);
triggerReplication(componentsToBeReplicated,false,opType);
}
mergePolicy.diskComponentAdded(lsmIndex,false);
}
break;
case MERGE:
if (newComponent != null) {
lsmIndex.subsumeMergedComponents(newComponent,ctx.getComponentHolder());
if (replicationEnabled) {
componentsToBeReplicated.clear();
componentsToBeReplicated.add(newComponent);
triggerReplication(componentsToBeReplicated,false,opType);
}
mergePolicy.diskComponentAdded(lsmIndex,fullMergeIsRequested.get());
}
break;
default :
break;
}
}
 catch (Throwable e) {
e.printStackTrace();
throw e;
}
 finally {
if (failedOperation && (opType == LSMOperationType.MODIFICATION || opType == LSMOperationType.FORCE_MODIFICATION)) {
opTracker.completeOperation(lsmIndex,opType,ctx.getSearchOperationCallback(),ctx.getModificationCallback());
}
 else {
opTracker.afterOperation(lsmIndex,opType,ctx.getSearchOperationCallback(),ctx.getModificationCallback());
}
inactiveDiskComponents=lsmIndex.getInactiveDiskComponents();
if (!inactiveDiskComponents.isEmpty()) {
for (ILSMComponent inactiveComp : inactiveDiskComponents) {
if (((AbstractDiskLSMComponent)inactiveComp).getFileReferenceCount() == 1) {
if (inactiveDiskComponentsToBeDeleted == null) {
inactiveDiskComponentsToBeDeleted=new LinkedList<ILSMComponent>();
}
inactiveDiskComponentsToBeDeleted.add(inactiveComp);
}
}
if (inactiveDiskComponentsToBeDeleted != null) {
inactiveDiskComponents.removeAll(inactiveDiskComponentsToBeDeleted);
}
}
}
}
}
  finally {
if (inactiveDiskComponentsToBeDeleted != null) {
try {
if (replicationEnabled) {
lsmIndex.scheduleReplication(null,inactiveDiskComponentsToBeDeleted,false,ReplicationOperation.DELETE,opType);
}
for (ILSMComponent c : inactiveDiskComponentsToBeDeleted) {
((AbstractDiskLSMComponent)c).destroy();
}
}
 catch (Throwable e) {
e.printStackTrace();
throw e;
}
}
}
",0,0,0,,
48,} finally {,"try {
  fileOutputStream=new FileOutputStream(new File(absolutePath));
  byte[] buffer=new byte[8 * 1024];
  int bytesRead;
  while ((bytesRead=inputStream.read(buffer)) != -1) {
    fileOutputStream.write(buffer,0,bytesRead);
  }
  IOUtils.closeQuietly(inputStream);
  IOUtils.closeQuietly(fileOutputStream);
}
 catch (Exception e) {
  LOG.error(""error writing to file"",e);
  throw new AtlasServiceException(e);
}
 finally {
  if (fileOutputStream != null) {
    try {
      fileOutputStream.close();
    }
 catch (    IOException e) {
      LOG.error(""error closing file"",e);
      throw new AtlasServiceException(e);
    }
  }
}
",0,0,0,,
49,} finally {,"try {
  table=connection.getTable(tableName);
  List<Put> puts=new ArrayList<>(events.size());
  for (int index=0; index < events.size(); index++) {
    EntityAuditEventV2 event=events.get(index);
    if (LOG.isDebugEnabled()) {
      LOG.debug(""Adding entity audit event {}"",event);
    }
    Put put=new Put(getKey(event.getEntityId(),event.getTimestamp(),index));
    addColumn(put,COLUMN_ACTION,event.getAction());
    addColumn(put,COLUMN_USER,event.getUser());
    addColumn(put,COLUMN_DETAIL,event.getDetails());
    if (persistEntityDefinition) {
      addColumn(put,COLUMN_DEFINITION,event.getEntityDefinitionString());
    }
    puts.add(put);
  }
  table.put(puts);
}
 catch (IOException e) {
  throw new AtlasBaseException(e);
}
 finally {
  try {
    close(table);
  }
 catch (  AtlasException e) {
    throw new AtlasBaseException(e);
  }
}
",0,0,0,,
50,} finally {,"try {
  table=connection.getTable(tableName);
  Scan scan=new Scan().setReversed(true).setCaching(DEFAULT_CACHING).setSmall(true);
  if (maxResultCount > -1) {
    scan.setFilter(new PageFilter(maxResultCount));
  }
  if (auditAction != null) {
    Filter filterAction=new SingleColumnValueFilter(COLUMN_FAMILY,COLUMN_ACTION,CompareFilter.CompareOp.EQUAL,new BinaryComparator(Bytes.toBytes(auditAction.toString())));
    scan.setFilter(filterAction);
  }
  if (StringUtils.isNotBlank(entityId)) {
    scan.setStopRow(Bytes.toBytes(entityId));
  }
  if (StringUtils.isEmpty(startKey)) {
    byte[] entityBytes=getKey(entityId,Long.MAX_VALUE,Integer.MAX_VALUE);
    scan=scan.setStartRow(entityBytes);
  }
 else {
    scan=scan.setStartRow(Bytes.toBytes(startKey));
  }
  scanner=table.getScanner(scan);
  List<EntityAuditEventV2> events=new ArrayList<>();
  Result result;
  while ((result=scanner.next()) != null && (maxResultCount == -1 || events.size() < maxResultCount)) {
    EntityAuditEventV2 event=fromKeyV2(result.getRow());
    if (StringUtils.isNotBlank(entityId) && !event.getEntityId().equals(entityId)) {
      continue;
    }
    event.setUser(getResultString(result,COLUMN_USER));
    event.setAction(EntityAuditActionV2.fromString(getResultString(result,COLUMN_ACTION)));
    event.setDetails(getResultString(result,COLUMN_DETAIL));
    if (persistEntityDefinition) {
      String colDef=getResultString(result,COLUMN_DEFINITION);
      if (colDef != null) {
        event.setEntityDefinition(colDef);
      }
    }
    events.add(event);
  }
  if (LOG.isDebugEnabled()) {
    LOG.debug(""Got events for entity id {}, operation {}, starting key{}, maximum result count {}, #records returned {}"",entityId,auditAction.toString(),startKey,maxResultCount,events.size());
  }
  return events;
}
 catch (IOException e) {
  throw new AtlasBaseException(e);
}
 finally {
  try {
    close(scanner);
    close(table);
    RequestContext.get().endMetricRecord(metric);
  }
 catch (  AtlasException e) {
    throw new AtlasBaseException(e);
  }
}
",0,0,0,,
51,} finally {,"try {
  Set<String> guids=new HashSet<>();
  table=connection.getTable(tableName);
  byte[] filterValue=Bytes.toBytes(classificationUpdatesAction);
  BinaryPrefixComparator binaryPrefixComparator=new BinaryPrefixComparator(filterValue);
  SingleColumnValueFilter filter=new SingleColumnValueFilter(COLUMN_FAMILY,COLUMN_ACTION,CompareFilter.CompareOp.EQUAL,binaryPrefixComparator);
  Scan scan=new Scan().setFilter(filter).setTimeRange(fromTimestamp,toTimestamp);
  Result result;
  scanner=table.getScanner(scan);
  while ((result=scanner.next()) != null) {
    EntityAuditEvent event=fromKey(result.getRow());
    if (event == null) {
      continue;
    }
    guids.add(event.getEntityId());
  }
  return guids;
}
 catch (IOException e) {
  throw new AtlasBaseException(e);
}
 finally {
  try {
    close(scanner);
    close(table);
  }
 catch (  AtlasException e) {
    throw new AtlasBaseException(e);
  }
}
",0,0,0,,
52,} finally {,"try {
  stream=fileContext.create(lPath,EnumSet.of(CreateFlag.CREATE,CreateFlag.OVERWRITE),Options.CreateOpts.CreateParent.createParent());
  InputStream in=null;
  try {
    in=new FileInputStream(srcFile);
    IOUtils.copyBytes(in,stream,conf,false);
  }
  finally {
    IOUtils.closeStream(in);
  }
  stateSaved=true;
}
 catch (Throwable t) {
  logger.debug(""while saving {} {}"",operatorId,window,t);
  stateSaved=false;
  throw Throwables.propagate(t);
}
 finally {
  try {
    if (stream != null) {
      stream.close();
    }
  }
 catch (  IOException ie) {
    stateSaved=false;
    throw new RuntimeException(ie);
  }
 finally {
    if (stateSaved) {
      fileContext.rename(lPath,new Path(path + Path.SEPARATOR + operatorIdStr+ Path.SEPARATOR+ window),Options.Rename.OVERWRITE);
    }
    FileUtil.fullyDelete(srcFile);
  }
}
",0,0,0,,
53,} finally {,"try {
  stream=fileContext.create(lPath,EnumSet.of(CreateFlag.CREATE,CreateFlag.OVERWRITE),Options.CreateOpts.CreateParent.createParent());
  store(stream,object);
  stateSaved=true;
}
 catch (Throwable t) {
  logger.debug(""while saving {} {}"",operatorId,window,t);
  stateSaved=false;
  throw Throwables.propagate(t);
}
 finally {
  try {
    if (stream != null) {
      stream.close();
    }
  }
 catch (  IOException ie) {
    stateSaved=false;
    throw new RuntimeException(ie);
  }
 finally {
    if (stateSaved) {
      logger.debug(""Saving {}: {}"",operatorId,window);
      fileContext.rename(lPath,new Path(path + Path.SEPARATOR + operatorIdStr+ Path.SEPARATOR+ window),Options.Rename.OVERWRITE);
    }
  }
}
",0,0,0,,
54,} finally {,"try {
  heartbeatLoop();
  hasError=false;
}
  finally {
  try {
    teardown();
  }
 catch (  Exception e) {
    if (!hasError) {
      throw e;
    }
  }
}
",0,0,0,,
55,} finally {,"try {
  for (  String path : pathsToScan) {
    File f=null;
    try {
      f=new File(path);
      if (!f.exists() || f.isDirectory() || (!f.getName().endsWith(""jar"") && !f.getName().endsWith(""class""))) {
        continue;
      }
      if (GENERATED_CLASSES_JAR.equals(f.getName())) {
        continue;
      }
      if (f.getName().endsWith(""class"")) {
        typeGraph.addNode(f);
        openClassFiles.put(path,f);
      }
 else {
        JarFile jar=new JarFile(path);
        openJarFiles.put(path,jar);
        java.util.Enumeration<JarEntry> entriesEnum=jar.entries();
        while (entriesEnum.hasMoreElements()) {
          final java.util.jar.JarEntry jarEntry=entriesEnum.nextElement();
          String entryName=jarEntry.getName();
          if (jarEntry.isDirectory()) {
            continue;
          }
          if (entryName.endsWith(""-javadoc.xml"")) {
            try {
              processJavadocXml(jar.getInputStream(jarEntry));
            }
 catch (            Exception ex) {
              LOG.warn(""Cannot process javadoc {} : "",entryName,ex);
            }
          }
 else           if (entryName.endsWith("".class"")) {
            TypeGraph.TypeGraphVertex newNode=typeGraph.addNode(jarEntry,jar);
            for (Iterator<String> iter=resourceCacheSet.iterator(); iter.hasNext(); ) {
              String entry=iter.next();
              if (entry.startsWith(entryName.substring(0,entryName.length() - 6))) {
                newNode.setHasResource(true);
                iter.remove();
              }
            }
          }
 else {
            String className=entryName;
            boolean foundClass=false;
            while (className.contains(""/"")) {
              className=className.substring(0,className.lastIndexOf('/'));
              TypeGraph.TypeGraphVertex tgv=typeGraph.getNode(className.replace('/','.'));
              if (tgv != null) {
                tgv.setHasResource(true);
                foundClass=true;
                break;
              }
            }
            if (!foundClass) {
              resourceCacheSet.add(entryName);
            }
          }
        }
      }
    }
 catch (    IOException ex) {
      LOG.warn(""Cannot process file {}"",f,ex);
    }
  }
  typeGraph.trim();
}
  finally {
  for (  Entry<String,JarFile> entry : openJarFiles.entrySet()) {
    try {
      entry.getValue().close();
    }
 catch (    IOException e) {
      throw Throwables.propagate(e);
    }
  }
}
",0,0,0,,
56,} finally {,"try {
  stream.close();
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    socket.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
57,} finally {,"try {
  super.stop();
}
  finally {
  try {
    if (client != null) {
      eventloop.disconnect(client);
      client=null;
    }
    eventloop.stop(server);
    eventloop.stop();
    if (codec instanceof Component) {
      @SuppressWarnings(""unchecked"") Component<com.datatorrent.api.Context> component=(Component<com.datatorrent.api.Context>)codec;
      component.teardown();
    }
    if (discovery instanceof Component) {
      @SuppressWarnings(""unchecked"") Component<com.datatorrent.api.Context> component=(Component<com.datatorrent.api.Context>)discovery;
      component.teardown();
    }
    if (storage instanceof Component) {
      @SuppressWarnings(""unchecked"") Component<com.datatorrent.api.Context> component=(Component<com.datatorrent.api.Context>)storage;
      component.teardown();
    }
  }
 catch (  Throwable cause) {
    throw new ServiceConfigurationError(""Failed Stop"",cause);
  }
}
",0,0,0,,
58,} finally {,"try {
  bytesOutStream.write(converter.convert(tuple));
  bytesOutStream.write(tupleSeparatorBytes);
  byteCount+=bytesOutStream.size();
  return bytesOutStream.toByteArray();
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    bytesOutStream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
59,} finally {,"try {
  output.writeInt(classNameBytes.length);
  output.write(className.replace('$','_').getBytes());
  output.writeInt(classBytes.length);
  output.write(classBytes);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    output.flush();
    output.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
60,} finally {,"try {
  scanner.teardown();
}
 catch (Throwable t) {
  DTThrowable.rethrow(t);
}
 finally {
  try {
    fs.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
61,} finally {,"try {
  _txManager.begin();
  if (__log.isDebugEnabled())   __log.debug(""Starting transaction."");
  _server.acquireTransactionLocks();
  String messageId=new GUID().toString();
  odeMex=_server.getEngine().createMessageExchange("""" + messageId,_serviceName,msgContext.getAxisOperation().getName().getLocalPart());
  __log.debug(""ODE routed to portType "" + odeMex.getPortType() + "" operation ""+ odeMex.getOperation()+ "" from service ""+ _serviceName);
  PortType portType=odeMex.getPortType();
  Operation operation=odeMex.getOperation();
  odeMex.setProperty(""isTwoWay"",Boolean.toString(msgContext.getAxisOperation() instanceof TwoChannelAxisOperation));
  if (odeMex.getOperation() != null) {
    Message odeRequest=odeMex.createMessage(odeMex.getOperation().getInput().getMessage().getQName());
    _converter.parseSoapRequest(odeRequest,msgContext.getEnvelope(),odeMex.getOperation());
    readHeader(msgContext,odeMex);
    if (__log.isDebugEnabled()) {
      __log.debug(""Invoking ODE using MEX "" + odeMex);
      __log.debug(""Message content:  "" + DOMUtils.domToString(odeRequest.getMessage()));
    }
    responseFuture=odeMex.invoke(odeRequest);
    __log.debug(""Commiting ODE MEX "" + odeMex);
    try {
      if (__log.isDebugEnabled())       __log.debug(""Commiting transaction."");
      _txManager.commit();
    }
 catch (    Exception e) {
      __log.error(""Commit failed"",e);
      success=false;
    }
  }
 else {
    success=false;
  }
}
 catch (Exception e) {
  __log.error(""Exception occured while invoking ODE"",e);
  success=false;
  String message=e.getMessage();
  if (message == null) {
    message=""An exception occured while invoking ODE."";
  }
  throw new OdeFault(message,e);
}
 finally {
  if (!success) {
    if (odeMex != null)     odeMex.release(success);
    try {
      _txManager.rollback();
    }
 catch (    Exception e) {
      throw new OdeFault(""Rollback failed"",e);
    }
  }
}
",0,0,0,,
62,} finally {,"try {
  odeMex=(MyRoleMessageExchange)_server.getEngine().getMessageExchange(odeMex.getMessageExchangeId());
  onResponse(odeMex,outMsgContext);
  commit=true;
}
 catch (AxisFault af) {
  __log.warn(""MEX produced a fault "" + odeMex,af);
  commit=true;
  throw af;
}
catch (Exception e) {
  __log.error(""Error processing response for MEX "" + odeMex,e);
  throw new OdeFault(""An exception occured when invoking ODE."",e);
}
 finally {
  odeMex.release(commit);
  if (commit) {
    try {
      if (__log.isDebugEnabled())       __log.debug(""Comitting transaction."");
      _txManager.commit();
    }
 catch (    Exception e) {
      throw new OdeFault(""Commit failed!"",e);
    }
  }
 else {
    try {
      _txManager.rollback();
    }
 catch (    Exception ex) {
      throw new OdeFault(""Rollback failed!"",ex);
    }
  }
}
",0,0,0,,
63,} finally {,"try {
  conn=_contexts.dao.getDataSource().getConnection();
  stmt=conn.prepareStatement(""SELECT VERSION FROM ODE_SCHEMA_VERSION"");
  rs=stmt.executeQuery();
  if (rs.next())   version=rs.getInt(""VERSION"");
}
 catch (Exception e) {
}
 finally {
  try {
    if (rs != null)     rs.close();
    if (stmt != null)     stmt.close();
    if (conn != null)     conn.close();
  }
 catch (  SQLException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
64,} finally {,"try {
  conn=_contexts.dao.getDataSource().getConnection();
  stmt=conn.createStatement();
  int res=stmt.executeUpdate(""UPDATE ODE_SCHEMA_VERSION SET VERSION = "" + version);
  if (res == 0)   throw new RuntimeException(""Couldn't update schema version."");
}
 catch (Exception e) {
}
 finally {
  try {
    if (stmt != null)     stmt.close();
    if (conn != null)     conn.close();
  }
 catch (  SQLException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
65,} finally {,"try {
  c=getConnection();
  s=c.createStatement();
  s.execute(""update ODE_JOB set jobid = '' where 1 = 0"");
}
 catch (Exception e) {
  throw new RuntimeException("""",e);
}
 finally {
  try {
    if (s != null)     s.close();
    if (c != null)     c.close();
  }
 catch (  Exception e) {
    throw new RuntimeException("""",e);
  }
}
",0,0,0,,
66,} finally {,"try {
  c=getConnection();
  s=c.createStatement();
  s.execute(""delete from ODE_JOB"");
}
 catch (Exception e) {
  throw new RuntimeException("""",e);
}
 finally {
  try {
    if (s != null)     s.close();
    if (c != null)     c.close();
  }
 catch (  Exception e) {
    throw new RuntimeException("""",e);
  }
}
",0,0,0,,
67,} finally {,"try {
  while (connectionStatus == ConnectionStatus.ReConnecting) {
    try {
      Thread.sleep(1000);
    }
 catch (    InterruptedException ignore) {
    }
  }
  if (connectionStatus == ConnectionStatus.ReConnected) {
    Thread.sleep(2000);
    connectionStatus=ConnectionStatus.Connected;
  }
  topicSession=newSession();
  Topic topic=lookupTopic(topicName);
  if (topic == null) {
    topic=topicSession.createTopic(topicName);
  }
  topicPublisher=topicSession.createPublisher(topic);
  TextMessage textMessage=topicSession.createTextMessage(message);
  topicPublisher.publish(textMessage);
  published=true;
}
 catch (Exception e) {
  String errorMessage=""Could not publish to topic: [topic-name] %s"";
  log.error(errorMessage,e);
  if (!retry) {
    throw new MessagingException(errorMessage,e);
  }
  reconnect();
}
 finally {
  try {
    if (topicSession != null) {
      topicSession.close();
    }
    if (topicPublisher != null) {
      topicPublisher.close();
    }
  }
 catch (  JMSException e) {
    message=""Error cleaning up pubisher"";
    log.error(message,e);
    throw new MessagingException(message,e);
  }
}
",0,0,0,,
68,} finally {,"try {
  fileOutStream=new FileOutputStream(lbInfoFilePath);
  ObjOutStream=new ObjectOutputStream(fileOutStream);
  ObjOutStream.writeObject(lbInfoDAO);
}
 catch (IOException e) {
  log.error(e.getMessage(),e);
  throw new PersistenceException(e.getMessage(),e);
}
 finally {
  try {
    if (ObjOutStream != null) {
      ObjOutStream.close();
    }
    if (fileOutStream != null) {
      fileOutStream.close();
    }
  }
 catch (  IOException e) {
    log.error(e.getMessage(),e);
    if (fileOutStream != null) {
      try {
        fileOutStream.close();
      }
 catch (      IOException e1) {
      }
    }
    throw new PersistenceException(e.getMessage(),e);
  }
}
",0,0,0,,
69,} finally {,"try {
  fileInStream=new FileInputStream(lbInfoFilePath);
  objInStream=new ObjectInputStream(fileInStream);
  return (LBInfoDAO)objInStream.readObject();
}
 catch (FileNotFoundException e) {
  log.warn(""File lbinformation.ser not found, any previously persisted LB information will not be reflected"");
  return null;
}
catch (IOException e) {
  log.error(e.getMessage(),e);
  throw new PersistenceException(e.getMessage(),e);
}
catch (ClassNotFoundException e) {
  log.error(e.getMessage(),e);
  throw new PersistenceException(e.getMessage(),e);
}
 finally {
  try {
    if (objInStream != null) {
      objInStream.close();
    }
    if (fileInStream != null) {
      fileInStream.close();
    }
  }
 catch (  IOException e) {
    log.error(e.getMessage(),e);
    if (fileInStream != null) {
      try {
        fileInStream.close();
      }
 catch (      IOException e1) {
      }
    }
    throw new PersistenceException(e.getMessage(),e);
  }
}
",0,0,0,,
70,finally {,"try {
  Message responseMsg=responseMsgCtx.getMessage();
  returnObj=getValueFromMessage(responseMsg);
}
  finally {
  try {
    responseMsgCtx.freeInputStream();
  }
 catch (  Throwable t) {
    throw ExceptionFactory.makeWebServiceException(t);
  }
}
",0,0,0,,
71,} finally {,"try {
  return JAXBDispatch.getValue(mc.getMessage(),mode,jaxbContext);
}
  finally {
  try {
    mc.freeInputStream();
  }
 catch (  Throwable t) {
    throw ExceptionFactory.makeWebServiceException(t);
  }
}
",0,0,0,,
72,} finally {,"try {
  return XMLDispatch.getValue(mc.getMessage(),mode,blockFactoryType);
}
  finally {
  try {
    mc.freeInputStream();
  }
 catch (  Throwable t) {
    throw ExceptionFactory.makeWebServiceException(t);
  }
}
",0,0,0,,
73,} finally {,"try {
  if (log.isDebugEnabled()) {
    log.debug(""Processing the response Message to create the return value(s)."");
  }
  if (hasFaultResponse(responseContext)) {
    Throwable t=getFaultResponse(responseContext,operationDesc);
    throw t;
  }
  ClassLoader cl=(ClassLoader)responseContext.getProperty(Constants.CACHE_CLASSLOADER);
  if (cl == null) {
    InvocationContext ic=responseContext.getInvocationContext();
    if (ic != null) {
      MessageContext requestMC=ic.getRequestMessageContext();
      if (requestMC != null) {
        cl=(ClassLoader)responseContext.getProperty(Constants.CACHE_CLASSLOADER);
        if (cl != null) {
          if (log.isDebugEnabled()) {
            log.debug(""Obtained ClassLoader for the request context: "" + cl);
          }
        }
      }
    }
  }
 else {
    if (log.isDebugEnabled()) {
      log.debug(""Obtained ClassLoader for the response context: "" + cl);
    }
  }
  Object object=MethodMarshallerFactory.getMarshaller(operationDesc,true,cl).demarshalResponse(responseMsg,args,operationDesc);
  if (log.isDebugEnabled()) {
    log.debug(""The response was processed and the return value created successfully."");
  }
  return object;
}
  finally {
  responseMsg.close();
  try {
    responseContext.freeInputStream();
  }
 catch (  Throwable t) {
    throw ExceptionFactory.makeWebServiceException(t);
  }
}
",0,0,0,,
74,} finally {,"try {
  if (opDesc.isJAXWSAsyncClientMethod()) {
    opDesc=opDesc.getSyncOperation();
  }
  if (msg != null && msg.isFault()) {
    ClassLoader cl=(ClassLoader)msgCtx.getProperty(Constants.CACHE_CLASSLOADER);
    Object object=MethodMarshallerFactory.getMarshaller(opDesc,true,cl).demarshalFaultResponse(msg,opDesc);
    if (log.isDebugEnabled() && object != null) {
      log.debug(""A fault was found and processed."");
      log.debug(""Throwing a fault of type: "" + object.getClass().getName() + "" back to the clent."");
    }
    if (msgCtx.getLocalException() != null) {
      ExceptionFactory.setInitialCause((Throwable)object,msgCtx.getLocalException());
    }
    return (Throwable)object;
  }
 else   if (msgCtx.getLocalException() != null) {
    return ExceptionFactory.makeWebServiceException(msgCtx.getLocalException());
  }
}
  finally {
  try {
    msgCtx.freeInputStream();
  }
 catch (  Throwable t) {
    throw ExceptionFactory.makeWebServiceException(t);
  }
}
",0,0,0,,
75,} finally {,"try {
  OMElement om=OMXMLBuilderFactory.createOMBuilder(bais).getDocumentElement();
  om.build();
  if (log.isDebugEnabled()) {
    log.debug(myClassName + "":readObject():  "" + "" EPR [""+ logCorrelationIDString+ ""]""+ "" EPR OM content [""+ om.toString()+ ""]"");
  }
  EndpointReferenceHelper.fromOM(this,om,AddressingConstants.Final.WSA_NAMESPACE);
}
 catch (Exception e) {
  IOException ioe=new IOException(""Unable to deserialize the EndpointReference with logCorrelationID ["" + logCorrelationIDString + ""]"");
  ioe.initCause(e);
  if (log.isDebugEnabled()) {
    log.debug(""readObject(): Unable to deserialize the EPR with logCorrelationID ["" + logCorrelationIDString + ""]   original error [""+ e.getClass().getName()+ ""]  message [""+ e.getMessage()+ ""]"",e);
  }
  throw ioe;
}
 finally {
  if (xmlReader != null) {
    try {
      xmlReader.close();
    }
 catch (    Exception e2) {
      IOException ioe2=new IOException(""Unable to close the XMLStreamReader for the EndpointReference with logCorrelationID ["" + logCorrelationIDString + ""]"");
      ioe2.initCause(e2);
      if (log.isDebugEnabled()) {
        log.debug(""readObject(): Unable to close the XMLStreamReader for the EPR with logCorrelationID ["" + logCorrelationIDString + ""]   original error [""+ e2.getClass().getName()+ ""]  message [""+ e2.getMessage()+ ""]"",e2);
      }
      throw ioe2;
    }
  }
}
",0,0,0,,
76,} finally {,"try {
  if (axis2xml != null && !"""".equals(axis2xml)) {
    configStream=new FileInputStream(axis2xml);
  }
 else {
    configStream=Loader.getResourceAsStream(DeploymentConstants.AXIS2_CONFIGURATION_RESOURCE);
  }
  axisConfig=populateAxisConfiguration(configStream);
}
 catch (FileNotFoundException e) {
  throw new AxisFault(""System can not find the given axis2.xml "" + axis2xml);
}
 finally {
  if (configStream != null) {
    try {
      configStream.close();
    }
 catch (    IOException e) {
      throw AxisFault.makeFault(e);
    }
  }
}
",0,0,0,,
77,} finally {,"try {
  MessageContext responseMsgCtx;
  try {
    requestMsgCtx.setEnvelope(envelope);
    opClient.addMessageContext(requestMsgCtx);
    opClient.execute(true);
    responseMsgCtx=opClient.getMessageContext(WSDLConstants.MESSAGE_LABEL_IN_VALUE);
  }
 catch (  AxisFault ex) {
    throw new SOAPException(ex.getMessage(),ex);
  }
  SOAPMessage response=getSOAPMessage(responseMsgCtx.getEnvelope());
  Attachments attachments=responseMsgCtx.getAttachmentMap();
  for (  String contentId : attachments.getAllContentIDs()) {
    if (!contentId.equals(attachments.getRootPartContentID())) {
      AttachmentPart ap=response.createAttachmentPart(attachments.getDataHandler(contentId));
      ap.setContentId(contentId);
      response.addAttachmentPart(ap);
    }
  }
  return response;
}
  finally {
  try {
    serviceClient.cleanupTransport();
    serviceClient.cleanup();
  }
 catch (  AxisFault ex) {
    throw new SOAPException(ex);
  }
}
",0,0,0,,
78,} finally {,"try {
  Reader reader=new InputStreamReader(is,""UTF-8"");
  char[] buffer=new char[1024];
  StringBuffer source=new StringBuffer();
  int count;
  while ((count=reader.read(buffer)) > 0) {
    source.append(buffer,0,count);
  }
  return source.toString();
}
 catch (IOException e) {
  throw new AxisFault(""IOException reading script: "" + scriptFile,e);
}
 finally {
  try {
    is.close();
  }
 catch (  IOException e) {
    throw new AxisFault(""IOException closing script: "" + scriptFile,e);
  }
}
",0,0,0,,
79,} finally {,"try {
  reader=new FileReader(scriptFile);
  char[] buffer=new char[1024];
  StringBuffer source=new StringBuffer();
  int count;
  while ((count=reader.read(buffer)) > 0) {
    source.append(buffer,0,count);
  }
  return source.toString();
}
 catch (IOException e) {
  throw new RuntimeException(""IOException reading script: "" + scriptName,e);
}
 finally {
  try {
    if (reader != null) {
      reader.close();
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(""IOException closing script: "" + scriptName,e);
  }
}
",0,0,0,,
80,} finally {,"try {
  Reader reader=new InputStreamReader(is,""UTF-8"");
  char[] buffer=new char[1024];
  StringBuffer source=new StringBuffer();
  int count;
  while ((count=reader.read(buffer)) > 0) {
    source.append(buffer,0,count);
  }
  return source.toString();
}
 catch (IOException e) {
  throw new AxisFault(""IOException reading script: "" + scriptName,e);
}
 finally {
  try {
    is.close();
  }
 catch (  IOException e) {
    throw new AxisFault(""IOException closing script: "" + scriptName,e);
  }
}
",0,0,0,,
81,} finally {,"try {
  while (!Thread.interrupted() && !isDestroyed() && this.conn.isOpen()) {
    this.httpservice.handleRequest(this.conn,context);
  }
}
 catch (ConnectionClosedException ex) {
  LOG.debug(""Client closed connection"");
}
catch (IOException ex) {
  if (ex instanceof SocketTimeoutException) {
    LOG.debug(ex.getMessage());
  }
 else   if (ex instanceof SocketException) {
    LOG.debug(ex.getMessage());
  }
 else {
    LOG.warn(ex.getMessage(),ex);
  }
}
catch (HttpException ex) {
  if (LOG.isWarnEnabled()) {
    LOG.warn(""HTTP protocol error: "" + ex.getMessage());
  }
}
 finally {
  destroy();
  if (this.callback == null) {
    throw new NullPointerException(""The callback object can't be null"");
  }
  this.callback.completed(this);
}
",0,0,0,,
82,} finally {,"try {
  if (checkpoint != null) {
    checkpoint.finalizeCheckpoint();
  }
}
 catch (final IOException finalizeCheckpointException) {
  ioe=finalizeCheckpointException;
}
 finally {
  try {
    UnboundedReader<?> toClose=reader;
    reader=null;
    toClose.close();
  }
 catch (  final IOException closeEx) {
    if (ioe != null) {
      ioe.addSuppressed(closeEx);
    }
 else {
      throw closeEx;
    }
  }
}
",0,0,0,,
83,} finally {,"try {
  result=delegate.run(pipeline);
  awaitWatermarksOrTimeout(testSparkOptions,result);
  result.stop();
  PipelineResult.State finishState=result.getState();
  assertThat(String.format(""Finish state %s is not allowed."",finishState),finishState,isOneOf(PipelineResult.State.STOPPED,PipelineResult.State.DONE));
}
  finally {
  try {
    FileUtils.deleteDirectory(new File(testSparkOptions.getCheckpointDir()));
  }
 catch (  IOException e) {
    throw new RuntimeException(""Failed to clear checkpoint tmp dir."",e);
  }
}
",0,0,0,,
84,} finally {,"try {
  Bundle bundle=getInstalledBundle(framework,localUrl);
  if (bundle != null) {
    return bundle;
  }
  LOG.debug(""Installing bundle into {} from url: {}"",framework,url);
  InputStream stream=getUrlStream(localUrl);
  Bundle installedBundle=framework.getBundleContext().installBundle(url,stream);
  return installedBundle;
}
  finally {
  if (!isLocal) {
    try {
      new File(new URI(localUrl)).delete();
    }
 catch (    URISyntaxException e) {
      throw Exceptions.propagate(e);
    }
  }
}
",0,0,0,,
85,} finally {,"try {
  if (log.isTraceEnabled())   log.trace(this + "" afterEnd, task: "" + task);
  if (startedInThisThread) {
    activeTaskCount.decrementAndGet();
  }
  if (isEndingAllIterations) {
    taskWasSubmittedAndNotYetEnded=incompleteTaskIds.remove(task.getId());
    if (flags != null && taskWasSubmittedAndNotYetEnded) {
      invokeCallback(flags.get(""newTaskEndCallback""),task);
    }
    ((TaskInternal<?>)task).setEndTimeUtc(System.currentTimeMillis());
  }
  if (startedInThisThread) {
    PerThreadCurrentTaskHolder.perThreadCurrentTask.remove();
    if (RENAME_THREADS) {
      Thread thread=task.getThread();
      if (thread == null) {
        log.warn(""BasicTask.afterEnd invoked without corresponding beforeStart"");
      }
 else {
        thread.setName(threadOriginalName.get());
        threadOriginalName.remove();
      }
    }
    ((TaskInternal<?>)task).setThread(null);
  }
}
  finally {
  try {
    if (error != null) {
      if (log.isDebugEnabled()) {
        if (error instanceof InterruptedException || error instanceof RuntimeInterruptedException) {
          log.debug(""Detected interruption on task "" + task + "" (rethrowing)""+ (Strings.isNonBlank(error.getMessage()) ? "": "" + error.getMessage() : """"));
        }
 else         if (error instanceof NullPointerException || error instanceof IndexOutOfBoundsException || error instanceof ClassCastException) {
          log.debug(""Exception running task "" + task + "" (rethrowing): ""+ error,error);
        }
 else {
          log.debug(""Exception running task "" + task + "" (rethrowing): ""+ error);
        }
        if (log.isTraceEnabled()) {
          log.trace(""Trace for exception running task "" + task + "" (rethrowing): ""+ error,error);
        }
      }
      throw Exceptions.propagate(error);
    }
  }
  finally {
synchronized (task) {
      task.notifyAll();
    }
    if (isEndingAllIterations && taskWasSubmittedAndNotYetEnded) {
      ((TaskInternal<?>)task).runListeners();
    }
  }
}
",0,0,0,,
86,} finally {,"try {
  log.trace(""Client logout"");
  client.logout();
}
 catch (IOException e) {
  throw new GenericFileOperationFailedException(client.getReplyCode(),client.getReplyString(),e.getMessage(),e);
}
 finally {
  try {
    log.trace(""Client disconnect"");
    client.disconnect();
  }
 catch (  IOException e) {
    throw new GenericFileOperationFailedException(client.getReplyCode(),client.getReplyString(),e.getMessage(),e);
  }
}
",0,0,0,,
87,} finally {,"try {
  while (!isInterrupted() && null != clientSocket && clientSocket.isConnected() && !clientSocket.isClosed()) {
    InputStream instream;
    try {
      instream=clientSocket.getInputStream();
    }
 catch (    IOException ioEx) {
      if (clientSocket.isClosed()) {
        log.debug(""Client socket was closed - ignoring exception"",clientSocket);
        break;
      }
 else {
        throw new MllpJUnitResourceException(""Unexpected IOException encounted getting input stream"",ioEx);
      }
    }
catch (    Exception unexpectedEx) {
      throw new MllpJUnitResourceException(""Unexpected exception encounted getting input stream"",unexpectedEx);
    }
    String parsedHL7Message;
    try {
      parsedHL7Message=getMessage(instream);
    }
 catch (    SocketTimeoutException timeoutEx) {
      log.info(""Waiting for message from client"");
      continue;
    }
    if (null != parsedHL7Message && parsedHL7Message.length() > 0) {
      ++messageCounter;
      if (closeSocketBeforeAcknowledgement(messageCounter)) {
        log.warn(""Closing socket before sending acknowledgement"");
        clientSocket.shutdownInput();
        clientSocket.shutdownOutput();
        clientSocket.close();
        break;
      }
      if (resetSocketBeforeAcknowledgement(messageCounter)) {
        log.warn(""Resetting socket before sending acknowledgement"");
        try {
          clientSocket.setSoLinger(true,0);
        }
 catch (        IOException ioEx) {
          log.warn(""Ignoring IOException encountered setting SO_LINGER when prepareing to reset socket"",ioEx);
        }
        clientSocket.shutdownInput();
        clientSocket.shutdownOutput();
        clientSocket.close();
        break;
      }
      String acknowledgmentMessage;
      if (acknowledgementString == null) {
        if (sendApplicationErrorAcknowledgement(messageCounter) || sendApplicationErrorAcknowledgement(parsedHL7Message)) {
          acknowledgmentMessage=generateAcknowledgementMessage(parsedHL7Message,""AE"");
        }
 else         if (sendApplicationRejectAcknowledgement(messageCounter) || sendApplicationRejectAcknowledgement(parsedHL7Message)) {
          acknowledgmentMessage=generateAcknowledgementMessage(parsedHL7Message,""AR"");
        }
 else {
          acknowledgmentMessage=generateAcknowledgementMessage(parsedHL7Message);
        }
      }
 else {
        acknowledgmentMessage=acknowledgementString;
      }
      BufferedOutputStream outstream=new BufferedOutputStream(clientSocket.getOutputStream());
      if (sendOutOfBandData(messageCounter)) {
        byte[] outOfBandDataBytes=""Out Of Band Hl7TestMessageGenerator"".getBytes();
        outstream.write(outOfBandDataBytes,0,outOfBandDataBytes.length);
      }
      if (excludeStartOfBlock(messageCounter)) {
        log.warn(""NOT sending START_OF_BLOCK"");
      }
 else {
        outstream.write(MllpProtocolConstants.START_OF_BLOCK);
        if (delayBeforeStartOfBlock > 0) {
          uncheckedSleep(delayBeforeStartOfBlock);
          uncheckedFlush(outstream);
        }
      }
      if (excludeAcknowledgement(messageCounter)) {
        log.info(""NOT sending Acknowledgement body"");
      }
 else {
        if (delayBeforeAcknowledgement > 0) {
          uncheckedSleep(delayBeforeAcknowledgement);
        }
        log.debug(""Buffering Acknowledgement\n\t{}"",acknowledgmentMessage.replace('\r','\n'));
        byte[] ackBytes=acknowledgmentMessage.getBytes();
        if (delayDuringAcknowledgement > 0) {
          int firstHalf=ackBytes.length / 2;
          outstream.write(ackBytes,0,firstHalf);
          uncheckedFlush(outstream);
          uncheckedSleep(delayDuringAcknowledgement);
          outstream.write(ackBytes,firstHalf,ackBytes.length - firstHalf);
          uncheckedFlush(outstream);
        }
 else {
          outstream.write(ackBytes,0,ackBytes.length);
        }
        if (delayAfterAcknowledgement > 0) {
          uncheckedFlush(outstream);
          uncheckedSleep(delayAfterAcknowledgement);
        }
      }
      if (excludeEndOfBlock(messageCounter)) {
        log.warn(""NOT sending END_OF_BLOCK"");
      }
 else {
        outstream.write(MllpProtocolConstants.END_OF_BLOCK);
        if (delayAfterEndOfBlock > 0) {
          uncheckedFlush(outstream);
          uncheckedSleep(delayAfterEndOfBlock);
        }
      }
      if (excludeEndOfData(messageCounter)) {
        log.warn(""NOT sending END_OF_DATA"");
      }
 else {
        outstream.write(MllpProtocolConstants.END_OF_DATA);
      }
      log.debug(""Writing Acknowledgement\n\t{}"",acknowledgmentMessage.replace('\r','\n'));
      uncheckedFlush(outstream);
      if (closeSocketAfterAcknowledgement(messageCounter)) {
        log.info(""Closing Client"");
        clientSocket.shutdownInput();
        clientSocket.shutdownOutput();
        clientSocket.close();
        break;
      }
    }
  }
}
 catch (IOException e) {
  String errorMessage=""Error while reading and writing from clientSocket"";
  log.error(errorMessage,e);
  throw new MllpJUnitResourceException(errorMessage,e);
}
 finally {
  if (clientSocket != null) {
    try {
      clientSocket.close();
    }
 catch (    IOException e) {
      String errorMessage=""Error while attempting to close to client Socket"";
      log.error(errorMessage,e);
      throw new MllpJUnitResourceException(errorMessage,e);
    }
  }
}
",0,0,0,,
88,} finally {,"try {
  writeManifest(analyzer,outputFile,niceManifest,exportScr,scrLocation,buildContext,getLog());
  if (supportIncrementalBuild) {
    writeIncrementalInfo(project);
  }
}
 catch (Exception e) {
  throw new MojoExecutionException(""Error trying to write Manifest to file "" + outputFile,e);
}
 finally {
  try {
    analyzer.close();
  }
 catch (  IOException e) {
    throw new MojoExecutionException(""Error trying to write Manifest to file "" + outputFile,e);
  }
}
",0,0,0,,
89,finally,"try {
  logger.info(""Submitting index {} of {} for data in {}"",isFullRebuild ? ""recovery"" : ""build"",indexes.stream().map(i -> i.getIndexMetadata().name).collect(Collectors.joining("","")),sstables.stream().map(SSTableReader::toString).collect(Collectors.joining("","")));
  Map<Index.IndexBuildingSupport,Set<Index>> byType=new HashMap<>();
  for (  Index index : indexes) {
    IndexBuildingSupport buildOrRecoveryTask=isFullRebuild ? index.getBuildTaskSupport() : index.getRecoveryTaskSupport();
    Set<Index> stored=byType.computeIfAbsent(buildOrRecoveryTask,i -> new HashSet<>());
    stored.add(index);
  }
  List<Future<?>> futures=new ArrayList<>(byType.size());
  byType.forEach((buildingSupport,groupedIndexes) -> {
    SecondaryIndexBuilder builder=buildingSupport.getIndexBuildTask(baseCfs,groupedIndexes,sstables);
    final SettableFuture build=SettableFuture.create();
    Futures.addCallback(CompactionManager.instance.submitIndexBuild(builder),new FutureCallback(){
      @Override public void onFailure(      Throwable t){
        logAndMarkIndexesFailed(groupedIndexes,t,false);
        unbuiltIndexes.addAll(groupedIndexes);
        build.setException(t);
      }
      @Override public void onSuccess(      Object o){
        groupedIndexes.forEach(i -> markIndexBuilt(i,isFullRebuild));
        logger.info(""Index build of {} completed"",getIndexNames(groupedIndexes));
        builtIndexes.addAll(groupedIndexes);
        build.set(o);
      }
    }
,MoreExecutors.directExecutor());
    futures.add(build);
  }
);
  FBUtilities.waitOnFutures(futures);
}
 catch (Exception e) {
  accumulatedFail=e;
  throw e;
}
 finally {
  try {
    Set<Index> failedIndexes=Sets.difference(indexes,Sets.union(builtIndexes,unbuiltIndexes));
    if (!failedIndexes.isEmpty()) {
      logAndMarkIndexesFailed(failedIndexes,accumulatedFail,false);
    }
    flushIndexesBlocking(builtIndexes,new FutureCallback(){
      String indexNames=StringUtils.join(builtIndexes.stream().map(i -> i.getIndexMetadata().name).collect(Collectors.toList()),',');
      @Override public void onFailure(      Throwable ignored){
        logger.info(""Index flush of {} failed"",indexNames);
      }
      @Override public void onSuccess(      Object ignored){
        logger.info(""Index flush of {} completed"",indexNames);
      }
    }
);
  }
 catch (  Exception e) {
    if (accumulatedFail != null) {
      accumulatedFail.addSuppressed(e);
    }
 else {
      throw e;
    }
  }
}
",0,0,0,,
90,finally,"try {
  redistributeSummaries(new IndexSummaryRedistribution(transactions,nonRedistributingOffHeapSize,this.memoryPoolBytes));
}
 catch (Exception e) {
  if (!(e instanceof CompactionInterruptedException))   logger.error(""Got exception during index summary redistribution"",e);
  throw e;
}
 finally {
  try {
    FBUtilities.closeAll(transactions.values());
  }
 catch (  Exception e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
91,finally,"try {
  onReadTimeout();
}
  finally {
  throw e;
}
",0,0,0,,
92,finally,"try {
  IndexSummaryManager.redistributeSummaries(redistribution);
  Assert.fail(""Should throw CompactionInterruptedException"");
}
 catch (CompactionInterruptedException e) {
}
catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    FBUtilities.closeAll(txns.values());
  }
 catch (  Exception e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
93,} finally {,"try {
  return getSession().createDocument(newProperties,targetFolderId,contentStream,versioningState,policies,addAces,removeAces);
}
  finally {
  if (contentStream != null) {
    InputStream stream=contentStream.getStream();
    if (stream != null) {
      try {
        stream.close();
      }
 catch (      IOException ioe) {
        throw new CmisRuntimeException(""Cannot close source stream!"",ioe);
      }
    }
  }
}
",0,0,0,,
94,} finally {,"try {
  success=_autoScaleService.configureAutoScaleVmGroup(this);
  if (success) {
    vmGroup=_entityMgr.findById(AutoScaleVmGroup.class,getEntityId());
    AutoScaleVmGroupResponse responseObject=_responseGenerator.createAutoScaleVmGroupResponse(vmGroup);
    setResponseObject(responseObject);
    responseObject.setResponseName(getCommandName());
  }
}
 catch (Exception ex) {
  s_logger.warn(""Failed to create autoscale vm group"",ex);
}
 finally {
  if (!success || vmGroup == null) {
    _autoScaleService.deleteAutoScaleVmGroup(getEntityId());
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create Autoscale Vm Group"");
  }
}
",0,0,0,,
95,} finally {,"try {
  CallContext.current().setEventDetails(""Rule Id: "" + getEntityId());
  success=_firewallService.applyEgressFirewallRules(rule,callerContext.getCallingAccount());
  rule=_entityMgr.findById(FirewallRule.class,getEntityId());
  FirewallResponse fwResponse=new FirewallResponse();
  if (rule != null) {
    fwResponse=_responseGenerator.createFirewallResponse(rule);
    setResponseObject(fwResponse);
  }
  fwResponse.setResponseName(getCommandName());
}
  finally {
  if (!success || rule == null) {
    _firewallService.revokeEgressFirewallRule(getEntityId(),true);
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create firewall rule"");
  }
}
",0,0,0,,
96,} finally {,"try {
  CallContext.current().setEventDetails(""Rule ID: "" + getEntityId());
  success=_firewallService.applyIngressFwRules(rule.getSourceIpAddressId(),callerContext.getCallingAccount());
  rule=_entityMgr.findById(FirewallRule.class,getEntityId());
  FirewallResponse fwResponse=new FirewallResponse();
  if (rule != null) {
    fwResponse=_responseGenerator.createFirewallResponse(rule);
    setResponseObject(fwResponse);
  }
  fwResponse.setResponseName(getCommandName());
}
  finally {
  if (!success || rule == null) {
    _firewallService.revokeIngressFwRule(getEntityId(),true);
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create firewall rule"");
  }
}
",0,0,0,,
97,} finally {,"try {
  CallContext.current().setEventDetails(""Rule Id: "" + getEntityId());
  if (getOpenFirewall()) {
    success=success && _firewallService.applyIngressFirewallRules(ipAddressId,callerContext.getCallingAccount());
  }
  success=success && _rulesService.applyPortForwardingRules(ipAddressId,callerContext.getCallingAccount());
  rule=_entityMgr.findById(PortForwardingRule.class,getEntityId());
  FirewallRuleResponse fwResponse=new FirewallRuleResponse();
  if (rule != null) {
    fwResponse=_responseGenerator.createPortForwardingRuleResponse(rule);
    setResponseObject(fwResponse);
  }
  fwResponse.setResponseName(getCommandName());
}
  finally {
  if (!success || rule == null) {
    if (getOpenFirewall()) {
      _firewallService.revokeRelatedFirewallRule(getEntityId(),true);
    }
    try {
      _rulesService.revokePortForwardingRule(getEntityId(),true);
    }
 catch (    Exception ex) {
    }
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to apply port forwarding rule"");
  }
}
",0,0,0,,
98,} finally {,"try {
  CallContext.current().setEventDetails(""Load Balancer Id: "" + getEntityId());
  rule=_entityMgr.findById(ApplicationLoadBalancerRule.class,getEntityId());
  ApplicationLoadBalancerResponse lbResponse=_responseGenerator.createLoadBalancerContainerReponse(rule,_lbService.getLbInstances(getEntityId()));
  setResponseObject(lbResponse);
  lbResponse.setResponseName(getCommandName());
}
 catch (Exception ex) {
  s_logger.warn(""Failed to create load balancer due to exception "",ex);
}
 finally {
  if (rule == null) {
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create load balancer"");
  }
}
",0,0,0,,
99,} finally {,"try {
  CallContext.current().setEventDetails(""Load balancer health check policy ID : "" + getEntityId());
  success=_lbService.applyLBHealthCheckPolicy(this);
  if (success) {
    policy=_entityMgr.findById(HealthCheckPolicy.class,getEntityId());
    LoadBalancer lb=_lbService.findById(policy.getLoadBalancerId());
    LBHealthCheckResponse hcResponse=_responseGenerator.createLBHealthCheckPolicyResponse(policy,lb);
    setResponseObject(hcResponse);
    hcResponse.setResponseName(getCommandName());
  }
}
  finally {
  if (!success || (policy == null)) {
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create health check policy"");
  }
}
",0,0,0,,
100,} finally {,"try {
  CallContext.current().setEventDetails(""Rule Id: "" + getEntityId());
  success=_lbService.applyLBStickinessPolicy(this);
  if (success) {
    policy=_entityMgr.findById(StickinessPolicy.class,getEntityId());
    LoadBalancer lb=_lbService.findById(policy.getLoadBalancerId());
    LBStickinessResponse spResponse=_responseGenerator.createLBStickinessPolicyResponse(policy,lb);
    setResponseObject(spResponse);
    spResponse.setResponseName(getCommandName());
  }
}
  finally {
  if (!success || (policy == null)) {
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create stickiness policy"");
  }
}
",0,0,0,,
101,} finally {,"try {
  CallContext.current().setEventDetails(""Rule Id: "" + getEntityId());
  if (getOpenFirewall()) {
    success=success && _firewallService.applyIngressFirewallRules(getSourceIpAddressId(),callerContext.getCallingAccount());
  }
  rule=_entityMgr.findById(LoadBalancer.class,getEntityId());
  LoadBalancerResponse lbResponse=new LoadBalancerResponse();
  if (rule != null) {
    lbResponse=_responseGenerator.createLoadBalancerResponse(rule);
    setResponseObject(lbResponse);
  }
  lbResponse.setResponseName(getCommandName());
}
 catch (Exception ex) {
  s_logger.warn(""Failed to create LB rule due to exception "",ex);
}
 finally {
  if (!success || rule == null) {
    if (getOpenFirewall()) {
      _firewallService.revokeRelatedFirewallRule(getEntityId(),true);
    }
    _lbService.deleteLoadBalancerRule(getEntityId(),false);
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create load balancer rule"");
  }
}
",0,0,0,,
102,} finally {,"try {
  CallContext.current().setEventDetails(""Rule ID: "" + getEntityId());
  if (getOpenFirewall()) {
    result=result && _firewallService.applyIngressFirewallRules(ipAddressId,CallContext.current().getCallingAccount());
  }
  result=result && _rulesService.applyStaticNatRules(ipAddressId,CallContext.current().getCallingAccount());
  rule=_entityMgr.findById(FirewallRule.class,getEntityId());
  StaticNatRule staticNatRule=_rulesService.buildStaticNatRule(rule,false);
  IpForwardingRuleResponse fwResponse=_responseGenerator.createIpForwardingRuleResponse(staticNatRule);
  fwResponse.setResponseName(getCommandName());
  setResponseObject(fwResponse);
}
  finally {
  if (!result || rule == null) {
    if (getOpenFirewall()) {
      _firewallService.revokeRelatedFirewallRule(getEntityId(),true);
    }
    _rulesService.revokeStaticNatRule(getEntityId(),true);
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Error in creating IP forwarding rule on the domr"");
  }
}
",0,0,0,,
103,} finally {,"try {
  CallContext.current().setEventDetails(""Rule ID: "" + getEntityId());
  success=_networkACLService.applyNetworkACL(rule.getAclId());
  rule=_networkACLService.getNetworkACLItem(getEntityId());
  NetworkACLItemResponse aclResponse=new NetworkACLItemResponse();
  if (rule != null) {
    aclResponse=_responseGenerator.createNetworkACLItemResponse(rule);
    setResponseObject(aclResponse);
  }
  aclResponse.setResponseName(getCommandName());
}
  finally {
  if (!success || rule == null) {
    _networkACLService.revokeNetworkACLItem(getEntityId());
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create network ACL Item"");
  }
}
",0,0,0,,
104,} finally {,"try {
  CallContext.current().setEventDetails(""Static route Id: "" + getEntityId());
  success=_vpcService.applyStaticRoute(getEntityId());
  route=_entityMgr.findById(StaticRoute.class,getEntityId());
  StaticRouteResponse routeResponse=new StaticRouteResponse();
  if (route != null) {
    routeResponse=_responseGenerator.createStaticRouteResponse(route);
    setResponseObject(routeResponse);
  }
  routeResponse.setResponseName(getCommandName());
}
  finally {
  if (!success || route == null) {
    _entityMgr.remove(StaticRoute.class,getEntityId());
    throw new ServerApiException(ApiErrorCode.INTERNAL_ERROR,""Failed to create static route"");
  }
}
",0,0,0,,
105,} finally {,"try {
  final Journal journal=start.second().getJournal();
  if (planToDeploy != null) {
    avoids=planToDeploy.getAvoids();
  }
  if (avoids == null) {
    avoids=new ExcludeList();
  }
  if (s_logger.isDebugEnabled()) {
    s_logger.debug(""Deploy avoids pods: "" + avoids.getPodsToAvoid() + "", clusters: ""+ avoids.getClustersToAvoid()+ "", hosts: ""+ avoids.getHostsToAvoid());
  }
  boolean planChangedByVolume=false;
  boolean reuseVolume=true;
  final DataCenterDeployment originalPlan=plan;
  int retry=StartRetry.value();
  while (retry-- != 0) {
    s_logger.debug(""VM start attempt #"" + (StartRetry.value() - retry));
    if (reuseVolume) {
      final List<VolumeVO> vols=_volsDao.findReadyRootVolumesByInstance(vm.getId());
      for (      final VolumeVO vol : vols) {
        final Long volTemplateId=vol.getTemplateId();
        if (volTemplateId != null && volTemplateId.longValue() != template.getId()) {
          if (s_logger.isDebugEnabled()) {
            s_logger.debug(vol + "" of "" + vm+ "" is READY, but template ids don't match, let the planner reassign a new pool"");
          }
          continue;
        }
        final StoragePool pool=(StoragePool)dataStoreMgr.getPrimaryDataStore(vol.getPoolId());
        if (!pool.isInMaintenance()) {
          if (s_logger.isDebugEnabled()) {
            s_logger.debug(""Root volume is ready, need to place VM in volume's cluster"");
          }
          final long rootVolDcId=pool.getDataCenterId();
          final Long rootVolPodId=pool.getPodId();
          final Long rootVolClusterId=pool.getClusterId();
          if (planToDeploy != null && planToDeploy.getDataCenterId() != 0) {
            final Long clusterIdSpecified=planToDeploy.getClusterId();
            if (clusterIdSpecified != null && rootVolClusterId != null) {
              if (rootVolClusterId.longValue() != clusterIdSpecified.longValue()) {
                if (s_logger.isDebugEnabled()) {
                  s_logger.debug(""Cannot satisfy the deployment plan passed in since the ready Root volume is in different cluster. volume's cluster: "" + rootVolClusterId + "", cluster specified: ""+ clusterIdSpecified);
                }
                throw new ResourceUnavailableException(""Root volume is ready in different cluster, Deployment plan provided cannot be satisfied, unable to create a deployment for "" + vm,Cluster.class,clusterIdSpecified);
              }
            }
            plan=new DataCenterDeployment(planToDeploy.getDataCenterId(),planToDeploy.getPodId(),planToDeploy.getClusterId(),planToDeploy.getHostId(),vol.getPoolId(),null,ctx);
          }
 else {
            plan=new DataCenterDeployment(rootVolDcId,rootVolPodId,rootVolClusterId,null,vol.getPoolId(),null,ctx);
            if (s_logger.isDebugEnabled()) {
              s_logger.debug(vol + "" is READY, changing deployment plan to use this pool's dcId: "" + rootVolDcId+ "" , podId: ""+ rootVolPodId+ "" , and clusterId: ""+ rootVolClusterId);
            }
            planChangedByVolume=true;
          }
        }
      }
    }
    final VirtualMachineProfileImpl vmProfile=new VirtualMachineProfileImpl(vm,template,offering,owner,params);
    logBootModeParameters(params);
    DeployDestination dest=null;
    try {
      dest=_dpMgr.planDeployment(vmProfile,plan,avoids,planner);
    }
 catch (    final AffinityConflictException e2) {
      s_logger.warn(""Unable to create deployment, affinity rules associted to the VM conflict"",e2);
      throw new CloudRuntimeException(""Unable to create deployment, affinity rules associted to the VM conflict"");
    }
    if (dest == null) {
      if (planChangedByVolume) {
        plan=originalPlan;
        planChangedByVolume=false;
        reuseVolume=false;
        continue;
      }
      throw new InsufficientServerCapacityException(""Unable to create a deployment for "" + vmProfile,DataCenter.class,plan.getDataCenterId(),areAffinityGroupsAssociated(vmProfile));
    }
    if (dest != null) {
      avoids.addHost(dest.getHost().getId());
      if (!template.isDeployAsIs()) {
        journal.record(""Deployment found - Attempt #"" + (StartRetry.value() - retry),vmProfile,dest);
      }
    }
    long destHostId=dest.getHost().getId();
    vm.setPodIdToDeployIn(dest.getPod().getId());
    final Long cluster_id=dest.getCluster().getId();
    final ClusterDetailsVO cluster_detail_cpu=_clusterDetailsDao.findDetail(cluster_id,VmDetailConstants.CPU_OVER_COMMIT_RATIO);
    final ClusterDetailsVO cluster_detail_ram=_clusterDetailsDao.findDetail(cluster_id,VmDetailConstants.MEMORY_OVER_COMMIT_RATIO);
    if (userVmDetailsDao.findDetail(vm.getId(),VmDetailConstants.CPU_OVER_COMMIT_RATIO) == null && (Float.parseFloat(cluster_detail_cpu.getValue()) > 1f || Float.parseFloat(cluster_detail_ram.getValue()) > 1f)) {
      userVmDetailsDao.addDetail(vm.getId(),VmDetailConstants.CPU_OVER_COMMIT_RATIO,cluster_detail_cpu.getValue(),true);
      userVmDetailsDao.addDetail(vm.getId(),VmDetailConstants.MEMORY_OVER_COMMIT_RATIO,cluster_detail_ram.getValue(),true);
    }
 else     if (userVmDetailsDao.findDetail(vm.getId(),VmDetailConstants.CPU_OVER_COMMIT_RATIO) != null) {
      userVmDetailsDao.addDetail(vm.getId(),VmDetailConstants.CPU_OVER_COMMIT_RATIO,cluster_detail_cpu.getValue(),true);
      userVmDetailsDao.addDetail(vm.getId(),VmDetailConstants.MEMORY_OVER_COMMIT_RATIO,cluster_detail_ram.getValue(),true);
    }
    vmProfile.setCpuOvercommitRatio(Float.parseFloat(cluster_detail_cpu.getValue()));
    vmProfile.setMemoryOvercommitRatio(Float.parseFloat(cluster_detail_ram.getValue()));
    StartAnswer startAnswer=null;
    try {
      if (!changeState(vm,Event.OperationRetry,destHostId,work,Step.Prepare)) {
        throw new ConcurrentOperationException(""Unable to update the state of the Virtual Machine "" + vm.getUuid() + "" oldstate: ""+ vm.getState()+ ""Event :""+ Event.OperationRetry);
      }
    }
 catch (    final NoTransitionException e1) {
      throw new ConcurrentOperationException(e1.getMessage());
    }
    try {
      resetVmNicsDeviceId(vm.getId());
      _networkMgr.prepare(vmProfile,dest,ctx);
      if (vm.getHypervisorType() != HypervisorType.BareMetal) {
        volumeMgr.prepare(vmProfile,dest);
      }
      if (!reuseVolume) {
        reuseVolume=true;
      }
      Commands cmds=null;
      vmGuru.finalizeVirtualMachineProfile(vmProfile,dest,ctx);
      final VirtualMachineTO vmTO=hvGuru.implement(vmProfile);
      checkAndSetEnterSetupMode(vmTO,params);
      handlePath(vmTO.getDisks(),vm.getHypervisorType());
      cmds=new Commands(Command.OnError.Stop);
      cmds.addCommand(new StartCommand(vmTO,dest.getHost(),getExecuteInSequence(vm.getHypervisorType())));
      vmGuru.finalizeDeployment(cmds,vmProfile,dest,ctx);
      addExtraConfig(vmTO);
      work=_workDao.findById(work.getId());
      if (work == null || work.getStep() != Step.Prepare) {
        throw new ConcurrentOperationException(""Work steps have been changed: "" + work);
      }
      _workDao.updateStep(work,Step.Starting);
      _agentMgr.send(destHostId,cmds);
      _workDao.updateStep(work,Step.Started);
      startAnswer=cmds.getAnswer(StartAnswer.class);
      if (startAnswer != null && startAnswer.getResult()) {
        handlePath(vmTO.getDisks(),startAnswer.getIqnToData());
        final String host_guid=startAnswer.getHost_guid();
        if (host_guid != null) {
          final HostVO finalHost=_resourceMgr.findHostByGuid(host_guid);
          if (finalHost == null) {
            throw new CloudRuntimeException(""Host Guid "" + host_guid + "" doesn't exist in DB, something went wrong while processing start answer: ""+ startAnswer);
          }
          destHostId=finalHost.getId();
        }
        if (vmGuru.finalizeStart(vmProfile,destHostId,cmds,ctx)) {
          syncDiskChainChange(startAnswer);
          if (!changeState(vm,Event.OperationSucceeded,destHostId,work,Step.Done)) {
            s_logger.error(""Unable to transition to a new state. VM uuid: "" + vm.getUuid() + ""VM oldstate:""+ vm.getState()+ ""Event:""+ Event.OperationSucceeded);
            throw new ConcurrentOperationException(""Failed to deploy VM"" + vm.getUuid());
          }
          final GPUDeviceTO gpuDevice=startAnswer.getVirtualMachine().getGpuDevice();
          if (gpuDevice != null) {
            _resourceMgr.updateGPUDetails(destHostId,gpuDevice.getGroupDetails());
          }
          if (userVmDetailsDao.findDetail(vm.getId(),VmDetailConstants.DEPLOY_VM) != null) {
            userVmDetailsDao.removeDetail(vm.getId(),VmDetailConstants.DEPLOY_VM);
          }
          startedVm=vm;
          if (s_logger.isDebugEnabled()) {
            s_logger.debug(""Start completed for VM "" + vm);
          }
          final Host vmHost=_hostDao.findById(destHostId);
          if (vmHost != null && (VirtualMachine.Type.ConsoleProxy.equals(vm.getType()) || VirtualMachine.Type.SecondaryStorageVm.equals(vm.getType())) && caManager.canProvisionCertificates()) {
            final Map<String,String> sshAccessDetails=_networkMgr.getSystemVMAccessDetails(vm);
            for (int retries=3; retries > 0; retries--) {
              try {
                setupAgentSecurity(vmHost,sshAccessDetails,vm);
                return;
              }
 catch (              final Exception e) {
                s_logger.error(""Retrying after catching exception while trying to secure agent for systemvm id="" + vm.getId(),e);
              }
            }
            throw new CloudRuntimeException(""Failed to setup and secure agent for systemvm id="" + vm.getId());
          }
          return;
        }
 else {
          if (s_logger.isDebugEnabled()) {
            s_logger.info(""The guru did not like the answers so stopping "" + vm);
          }
          StopCommand stopCmd=new StopCommand(vm,getExecuteInSequence(vm.getHypervisorType()),false);
          stopCmd.setControlIp(getControlNicIpForVM(vm));
          Map<String,Boolean> vlanToPersistenceMap=getVlanToPersistenceMapForVM(vm.getId());
          if (MapUtils.isNotEmpty(vlanToPersistenceMap)) {
            stopCmd.setVlanToPersistenceMap(vlanToPersistenceMap);
          }
          final StopCommand cmd=stopCmd;
          final Answer answer=_agentMgr.easySend(destHostId,cmd);
          if (answer != null && answer instanceof StopAnswer) {
            final StopAnswer stopAns=(StopAnswer)answer;
            if (vm.getType() == VirtualMachine.Type.User) {
              final String platform=stopAns.getPlatform();
              if (platform != null) {
                final Map<String,String> vmmetadata=new HashMap<String,String>();
                vmmetadata.put(vm.getInstanceName(),platform);
                syncVMMetaData(vmmetadata);
              }
            }
          }
          if (answer == null || !answer.getResult()) {
            s_logger.warn(""Unable to stop "" + vm + "" due to ""+ (answer != null ? answer.getDetails() : ""no answers""));
            _haMgr.scheduleStop(vm,destHostId,WorkType.ForceStop);
            throw new ExecutionException(""Unable to stop this VM, "" + vm.getUuid() + "" so we are unable to retry the start operation"");
          }
          throw new ExecutionException(""Unable to start  VM:"" + vm.getUuid() + "" due to error in finalizeStart, not retrying"");
        }
      }
      s_logger.info(""Unable to start VM on "" + dest.getHost() + "" due to ""+ (startAnswer == null ? "" no start answer"" : startAnswer.getDetails()));
      if (startAnswer != null && startAnswer.getContextParam(""stopRetry"") != null) {
        break;
      }
    }
 catch (    OperationTimedoutException e) {
      s_logger.debug(""Unable to send the start command to host "" + dest.getHost() + "" failed to start VM: ""+ vm.getUuid());
      if (e.isActive()) {
        _haMgr.scheduleStop(vm,destHostId,WorkType.CheckStop);
      }
      canRetry=false;
      throw new AgentUnavailableException(""Unable to start "" + vm.getHostName(),destHostId,e);
    }
catch (    final ResourceUnavailableException e) {
      s_logger.info(""Unable to contact resource."",e);
      if (!avoids.add(e)) {
        if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
          throw e;
        }
 else {
          s_logger.warn(""unexpected ResourceUnavailableException : "" + e.getScope().getName(),e);
          throw e;
        }
      }
    }
catch (    final InsufficientCapacityException e) {
      s_logger.info(""Insufficient capacity "",e);
      if (!avoids.add(e)) {
        if (e.getScope() == Volume.class || e.getScope() == Nic.class) {
          throw e;
        }
 else {
          s_logger.warn(""unexpected InsufficientCapacityException : "" + e.getScope().getName(),e);
        }
      }
    }
catch (    final ExecutionException e) {
      s_logger.error(""Failed to start instance "" + vm,e);
      throw new AgentUnavailableException(""Unable to start instance due to "" + e.getMessage(),destHostId,e);
    }
catch (    final NoTransitionException e) {
      s_logger.error(""Failed to start instance "" + vm,e);
      throw new AgentUnavailableException(""Unable to start instance due to "" + e.getMessage(),destHostId,e);
    }
catch (    final StorageAccessException e) {
      s_logger.warn(""Unable to access storage on host"",e);
    }
 finally {
      if (startedVm == null && canRetry) {
        final Step prevStep=work.getStep();
        _workDao.updateStep(work,Step.Release);
        if ((prevStep == Step.Started || prevStep == Step.Starting) && startAnswer != null && startAnswer.getResult()) {
          cleanup(vmGuru,vmProfile,work,Event.OperationFailed,false);
        }
 else {
          cleanup(vmGuru,vmProfile,work,Event.OperationFailed,true);
        }
      }
    }
  }
}
  finally {
  if (startedVm == null) {
    if (VirtualMachine.Type.User.equals(vm.type) && ResoureCountRunningVMsonly.value()) {
      resourceCountDecrement(owner.getAccountId(),new Long(offering.getCpu()),new Long(offering.getRamSize()));
    }
    if (canRetry) {
      try {
        changeState(vm,Event.OperationFailed,null,work,Step.Done);
      }
 catch (      final NoTransitionException e) {
        throw new ConcurrentOperationException(e.getMessage());
      }
    }
  }
  if (planToDeploy != null) {
    planToDeploy.setAvoids(avoids);
  }
}
",0,0,0,,
106,} finally {,"try {
  answer=_agentMgr.send(vm.getHostId(),stop);
  if (answer != null) {
    if (answer instanceof StopAnswer) {
      final StopAnswer stopAns=(StopAnswer)answer;
      if (vm.getType() == VirtualMachine.Type.User) {
        final String platform=stopAns.getPlatform();
        if (platform != null) {
          final UserVmVO userVm=_userVmDao.findById(vm.getId());
          _userVmDao.loadDetails(userVm);
          userVm.setDetail(VmDetailConstants.PLATFORM,platform);
          _userVmDao.saveDetails(userVm);
        }
      }
    }
    stopped=answer.getResult();
    if (!stopped) {
      throw new CloudRuntimeException(""Unable to stop the virtual machine due to "" + answer.getDetails());
    }
    vmGuru.finalizeStop(profile,answer);
    final GPUDeviceTO gpuDevice=stop.getGpuDevice();
    if (gpuDevice != null) {
      _resourceMgr.updateGPUDetails(vm.getHostId(),gpuDevice.getGroupDetails());
    }
  }
 else {
    throw new CloudRuntimeException(""Invalid answer received in response to a StopCommand on "" + vm.instanceName);
  }
}
 catch (final AgentUnavailableException e) {
  s_logger.warn(""Unable to stop vm, agent unavailable: "" + e.toString());
}
catch (final OperationTimedoutException e) {
  s_logger.warn(""Unable to stop vm, operation timed out: "" + e.toString());
}
 finally {
  if (!stopped) {
    if (!cleanUpEvenIfUnableToStop) {
      s_logger.warn(""Unable to stop vm "" + vm);
      try {
        stateTransitTo(vm,Event.OperationFailed,vm.getHostId());
      }
 catch (      final NoTransitionException e) {
        s_logger.warn(""Unable to transition the state "" + vm);
      }
      throw new CloudRuntimeException(""Unable to stop "" + vm);
    }
 else {
      s_logger.warn(""Unable to actually stop "" + vm + "" but continue with release because it's a force stop"");
      vmGuru.finalizeStop(profile,answer);
    }
  }
 else {
    if (VirtualMachine.systemVMs.contains(vm.getType())) {
      HostVO systemVmHost=ApiDBUtils.findHostByTypeNameAndZoneId(vm.getDataCenterId(),vm.getHostName(),VirtualMachine.Type.SecondaryStorageVm.equals(vm.getType()) ? Host.Type.SecondaryStorageVM : Host.Type.ConsoleProxy);
      if (systemVmHost != null) {
        _agentMgr.agentStatusTransitTo(systemVmHost,Status.Event.ShutdownRequested,_nodeId);
      }
    }
  }
}
",0,0,0,,
107,} finally {,"try {
  if (s_logger.isDebugEnabled()) {
    s_logger.debug(String.format(""Offline migration of %s vm %s with volumes"",vm.getHypervisorType().toString(),vm.getInstanceName()));
  }
  migrateThroughHypervisorOrStorage(vm,volumeToPoolMap);
}
 catch (ConcurrentOperationException|InsufficientCapacityException|StorageUnavailableException e) {
  String msg=String.format(""Failed to migrate VM: %s"",vmUuid);
  s_logger.debug(msg);
  throw new CloudRuntimeException(msg,e);
}
 finally {
  try {
    stateTransitTo(vm,Event.AgentReportStopped,null);
  }
 catch (  final NoTransitionException e) {
    String anotherMEssage=String.format(""failed to change vm state of VM: %s"",vmUuid);
    s_logger.debug(anotherMEssage);
    throw new CloudRuntimeException(anotherMEssage,e);
  }
}
",0,0,0,,
108,} finally {,"try {
  s_logger.debug(""Updating domain_router table"");
  pstmt=conn.prepareStatement(""UPDATE domain_router, virtual_router_providers vrp LEFT JOIN (physical_network_service_providers pnsp INNER JOIN physical_network pntwk INNER JOIN vm_instance vm INNER JOIN domain_router vr) ON (vrp.nsp_id = pnsp.id AND pnsp.physical_network_id = pntwk.id AND pntwk.data_center_id = vm.data_center_id AND vm.id=vr.id) SET vr.element_id=vrp.id;"");
  pstmt.executeUpdate();
}
 catch (SQLException e) {
  throw new CloudRuntimeException(""Unable to update router table. "",e);
}
 finally {
  try {
    if (pstmt != null) {
      pstmt.close();
    }
  }
 catch (  SQLException e) {
    throw new CloudRuntimeException(""Unable to close statement for router table. "",e);
  }
}
",0,0,0,,
109,} finally {,"try {
  conn=LibvirtConnection.getConnectionByVmName(vmName);
  secondaryStoragePool=storagePoolMgr.getStoragePoolByURI(secondaryStoragePoolUrl);
  final String ssPmountPath=secondaryStoragePool.getLocalPath();
  snapshotRelPath=destSnapshot.getPath();
  snapshotDestPath=ssPmountPath + File.separator + snapshotRelPath;
  snapshotDisk=storagePoolMgr.getPhysicalDisk(primaryStore.getPoolType(),primaryStore.getUuid(),volumePath);
  primaryPool=snapshotDisk.getPool();
  long size=0;
  if (primaryPool.getType() == StoragePoolType.RBD) {
    final String rbdSnapshot=snapshotDisk.getPath() + ""@"" + snapshotName;
    final String snapshotFile=snapshotDestPath + ""/"" + snapshotName;
    try {
      s_logger.debug(""Attempting to backup RBD snapshot "" + rbdSnapshot);
      final File snapDir=new File(snapshotDestPath);
      s_logger.debug(""Attempting to create "" + snapDir.getAbsolutePath() + "" recursively for snapshot storage"");
      FileUtils.forceMkdir(snapDir);
      final QemuImgFile srcFile=new QemuImgFile(KVMPhysicalDisk.RBDStringBuilder(primaryPool.getSourceHost(),primaryPool.getSourcePort(),primaryPool.getAuthUserName(),primaryPool.getAuthSecret(),rbdSnapshot));
      srcFile.setFormat(snapshotDisk.getFormat());
      final QemuImgFile destFile=new QemuImgFile(snapshotFile);
      destFile.setFormat(PhysicalDiskFormat.QCOW2);
      s_logger.debug(""Backing up RBD snapshot "" + rbdSnapshot + "" to ""+ snapshotFile);
      final QemuImg q=new QemuImg(cmd.getWaitInMillSeconds());
      q.convert(srcFile,destFile);
      final File snapFile=new File(snapshotFile);
      if (snapFile.exists()) {
        size=snapFile.length();
      }
      s_logger.debug(""Finished backing up RBD snapshot "" + rbdSnapshot + "" to ""+ snapshotFile+ "" Snapshot size: ""+ toHumanReadableSize(size));
    }
 catch (    final FileNotFoundException e) {
      s_logger.error(""Failed to open "" + snapshotDestPath + "". The error was: ""+ e.getMessage());
      return new CopyCmdAnswer(e.toString());
    }
catch (    final IOException e) {
      s_logger.error(""Failed to create "" + snapshotDestPath + "". The error was: ""+ e.getMessage());
      return new CopyCmdAnswer(e.toString());
    }
catch (    final QemuImgException|LibvirtException e) {
      s_logger.error(""Failed to backup the RBD snapshot from "" + rbdSnapshot + "" to ""+ snapshotFile+ "" the error was: ""+ e.getMessage());
      return new CopyCmdAnswer(e.toString());
    }
  }
 else {
    final Script command=new Script(_manageSnapshotPath,cmd.getWaitInMillSeconds(),s_logger);
    command.add(""-b"",snapshotDisk.getPath());
    command.add(NAME_OPTION,snapshotName);
    command.add(""-p"",snapshotDestPath);
    if (isCreatedFromVmSnapshot) {
      descName=UUID.randomUUID().toString();
    }
    command.add(""-t"",descName);
    final String result=command.execute();
    if (result != null) {
      s_logger.debug(""Failed to backup snaptshot: "" + result);
      return new CopyCmdAnswer(result);
    }
    final File snapFile=new File(snapshotDestPath + ""/"" + descName);
    if (snapFile.exists()) {
      size=snapFile.length();
    }
  }
  final SnapshotObjectTO newSnapshot=new SnapshotObjectTO();
  newSnapshot.setPath(snapshotRelPath + File.separator + descName);
  newSnapshot.setPhysicalSize(size);
  return new CopyCmdAnswer(newSnapshot);
}
 catch (final LibvirtException e) {
  s_logger.debug(""Failed to backup snapshot: "",e);
  return new CopyCmdAnswer(e.toString());
}
catch (final CloudRuntimeException e) {
  s_logger.debug(""Failed to backup snapshot: "",e);
  return new CopyCmdAnswer(e.toString());
}
 finally {
  if (isCreatedFromVmSnapshot) {
    s_logger.debug(""Ignoring removal of vm snapshot on primary as this snapshot is created from vm snapshot"");
  }
 else {
    try {
      DomainInfo.DomainState state=null;
      Domain vm=null;
      if (vmName != null) {
        try {
          vm=resource.getDomain(conn,vmName);
          state=vm.getInfo().state;
        }
 catch (        final LibvirtException e) {
          s_logger.trace(""Ignoring libvirt error."",e);
        }
      }
      final KVMStoragePool primaryStorage=storagePoolMgr.getStoragePool(primaryStore.getPoolType(),primaryStore.getUuid());
      if (state == DomainInfo.DomainState.VIR_DOMAIN_RUNNING && !primaryStorage.isExternalSnapshot()) {
        final DomainSnapshot snap=vm.snapshotLookupByName(snapshotName);
        try {
          s_logger.info(String.format(""Suspending VM '%s' to delete snapshot,"",vm.getName()));
          vm.suspend();
        }
 catch (        final LibvirtException e) {
          s_logger.error(""Failed to suspend the VM"",e);
          throw e;
        }
        snap.delete(0);
        vm=resource.getDomain(conn,vmName);
        state=vm.getInfo().state;
        if (state == DomainInfo.DomainState.VIR_DOMAIN_PAUSED) {
          vm.resume();
        }
      }
 else {
        if (primaryPool.getType() != StoragePoolType.RBD) {
          deleteSnapshotViaManageSnapshotScript(snapshotName,snapshotDisk);
        }
      }
    }
 catch (    final Exception ex) {
      s_logger.error(""Failed to delete snapshots on primary"",ex);
    }
  }
  try {
    if (secondaryStoragePool != null) {
      secondaryStoragePool.delete();
    }
  }
 catch (  final Exception ex) {
    s_logger.debug(""Failed to delete secondary storage"",ex);
  }
}
",0,0,0,,
110,} finally {,"try {
  loadBalancer.setState(FirewallRule.State.Add);
  _lbDao.persist(loadBalancer);
  applyLoadBalancerConfig(loadBalancerId);
  success=true;
}
 catch (ResourceUnavailableException e) {
  s_logger.warn(""Unable to apply the load balancer config because resource is unavaliable."",e);
  success=false;
}
 finally {
  if (!success) {
    final List<Long> vmInstanceIds=new ArrayList<Long>();
    Transaction.execute(new TransactionCallbackNoReturn(){
      @Override public void doInTransactionWithoutResult(      TransactionStatus status){
        for (        Long vmId : vmIds) {
          vmInstanceIds.add(vmId);
        }
      }
    }
);
    if (!vmInstanceIds.isEmpty()) {
      _lb2VmMapDao.remove(loadBalancer.getId(),vmInstanceIds,null);
      s_logger.debug(""LB Rollback rule id: "" + loadBalancer.getId() + ""  while attaching VM: ""+ vmInstanceIds);
    }
    loadBalancer.setState(backupState);
    _lbDao.persist(loadBalancer);
    CloudRuntimeException ex=new CloudRuntimeException(""Failed to add specified loadbalancerruleid for vms "" + vmInstanceIds);
    ex.addProxyObject(loadBalancer.getUuid(),""loadBalancerId"");
    throw ex;
  }
}
",0,0,0,,
111,} finally {,"try {
  guestNic=_itMgr.addVmToNetwork(vmInstance,network,profile);
  saveExtraDhcpOptions(guestNic.getId(),cmd.getDhcpOptionsMap());
  _networkMgr.configureExtraDhcpOptions(network,guestNic.getId(),cmd.getDhcpOptionsMap());
  cleanUp=false;
}
 catch (ResourceUnavailableException e) {
  throw new CloudRuntimeException(""Unable to add NIC to "" + vmInstance + "": ""+ e);
}
catch (InsufficientCapacityException e) {
  throw new CloudRuntimeException(""Insufficient capacity when adding NIC to "" + vmInstance + "": ""+ e);
}
catch (ConcurrentOperationException e) {
  throw new CloudRuntimeException(""Concurrent operations on adding NIC to "" + vmInstance + "": ""+ e);
}
 finally {
  if (cleanUp) {
    try {
      _itMgr.removeVmFromNetwork(vmInstance,network,null);
    }
 catch (    ResourceUnavailableException e) {
      throw new CloudRuntimeException(""Error while cleaning up NIC "" + e);
    }
  }
}
",0,0,0,,
112,} finally {,"try {
  URI uri=new URI(_httpProxy);
  String uriScheme=uri.getScheme();
  if (!""http"".equalsIgnoreCase(uriScheme)) {
    errMsg=String.format(""[%s] is not supported, it only supports HTTP proxy"",uriScheme);
    valid=false;
  }
 else   if (uri.getHost() == null) {
    errMsg=""host can not be null"";
    valid=false;
  }
 else   if (uri.getPort() == -1) {
    _httpProxy=_httpProxy + "":3128"";
  }
}
 catch (URISyntaxException e) {
  errMsg=e.toString();
  valid=false;
  s_logger.error(String.format(""Unable to configure HTTP proxy [%s] on secondary storage VM manager [%s] due to [%s]."",_httpProxy,name,errMsg),e);
}
 finally {
  if (!valid) {
    String message=String.format(""Unable to configure HTTP proxy [%s] on secondary storage VM manager [%s] due to [%s]."",_httpProxy,name,errMsg);
    s_logger.warn(message);
    throw new ConfigurationException(message);
  }
}
",0,0,0,,
113,} finally {,"try {
  if (state == HttpNfcLeaseState.READY) {
    final long totalBytes=HttpNfcLeaseMO.calcTotalBytes(ovfImportResult);
    File ovfFile=new File(ovfFilePath);
    HttpNfcLeaseInfo httpNfcLeaseInfo=null;
    try {
      httpNfcLeaseInfo=leaseMo.getLeaseInfo();
    }
 catch (    Exception e) {
      throw new CloudRuntimeException(""error waiting for lease info"",e);
    }
    List<HttpNfcLeaseDeviceUrl> deviceUrls=httpNfcLeaseInfo.getDeviceUrl();
    long bytesAlreadyWritten=0;
    final HttpNfcLeaseMO.ProgressReporter progressReporter=leaseMo.createProgressReporter();
    try {
      for (      HttpNfcLeaseDeviceUrl deviceUrl : deviceUrls) {
        String deviceKey=deviceUrl.getImportKey();
        for (        OvfFileItem ovfFileItem : ovfImportResult.getFileItem()) {
          if (deviceKey.equals(ovfFileItem.getDeviceId())) {
            String absoluteFile=ovfFile.getParent() + File.separator + ovfFileItem.getPath();
            s_logger.info(""Uploading file: "" + absoluteFile);
            File f=new File(absoluteFile);
            if (f.exists()) {
              String urlToPost=deviceUrl.getUrl();
              urlToPost=resolveHostNameInUrl(dcMo,urlToPost);
              context.uploadVmdkFile(ovfFileItem.isCreate() ? ""PUT"" : ""POST"",urlToPost,absoluteFile,bytesAlreadyWritten,new ActionDelegate<Long>(){
                @Override public void action(                Long param){
                  progressReporter.reportProgress((int)(param * 100 / totalBytes));
                }
              }
);
              bytesAlreadyWritten+=ovfFileItem.getSize();
            }
          }
        }
      }
    }
 catch (    Exception e) {
      String erroMsg=""File upload task failed to complete due to: "" + e.getMessage();
      s_logger.error(erroMsg);
      importSuccess=false;
      throw new CloudRuntimeException(erroMsg,e);
    }
catch (    Throwable th) {
      String errorMsg=""throwable caught during file upload task: "" + th.getMessage();
      s_logger.error(errorMsg);
      importSuccess=false;
      throw new CloudRuntimeException(errorMsg,th);
    }
 finally {
      progressReporter.close();
    }
    if (bytesAlreadyWritten == totalBytes) {
      try {
        leaseMo.updateLeaseProgress(100);
      }
 catch (      Exception e) {
        throw new CloudRuntimeException(""error while waiting for lease update"",e);
      }
    }
  }
 else   if (state == HttpNfcLeaseState.ERROR) {
    LocalizedMethodFault error=null;
    try {
      error=leaseMo.getLeaseError();
    }
 catch (    Exception e) {
      throw new CloudRuntimeException(""error getting lease error"",e);
    }
    MethodFault fault=error.getFault();
    String erroMsg=""Object creation on vCenter failed due to: Exception: "" + fault.getClass().getName() + "", message: ""+ error.getLocalizedMessage();
    s_logger.error(erroMsg);
    throw new CloudRuntimeException(erroMsg);
  }
}
  finally {
  try {
    if (!importSuccess) {
      s_logger.error(""Aborting the lease on "" + vmName + "" after import operation failed."");
      leaseMo.abortLease();
    }
 else {
      leaseMo.completeLease();
    }
  }
 catch (  Exception e) {
    throw new CloudRuntimeException(""error completing lease"",e);
  }
}
",0,0,0,,
114,} finally {,"try {
  HttpNfcLeaseInfo leaseInfo=leaseMo.getLeaseInfo();
  final long totalBytes=leaseInfo.getTotalDiskCapacityInKB() * 1024;
  long totalBytesDownloaded=0;
  List<HttpNfcLeaseDeviceUrl> deviceUrls=leaseInfo.getDeviceUrl();
  s_logger.info(""volss: copy vmdk and ovf file starts "" + System.currentTimeMillis());
  if (deviceUrls != null) {
    OvfFile[] ovfFiles=new OvfFile[deviceUrls.size()];
    for (int i=0; i < deviceUrls.size(); i++) {
      String deviceId=deviceUrls.get(i).getKey();
      String deviceUrlStr=deviceUrls.get(i).getUrl();
      String orgDiskFileName=deviceUrlStr.substring(deviceUrlStr.lastIndexOf(""/"") + 1);
      String diskFileName=String.format(""%s-disk%d%s"",exportName,i,VmwareHelper.getFileExtension(orgDiskFileName,"".vmdk""));
      String diskUrlStr=deviceUrlStr.replace(""*"",hostName);
      diskUrlStr=HypervisorHostHelper.resolveHostNameInUrl(dcMo,diskUrlStr);
      String diskLocalPath=exportDir + File.separator + diskFileName;
      fileNames.add(diskLocalPath);
      if (s_logger.isInfoEnabled()) {
        s_logger.info(""Download VMDK file for export. url: "" + deviceUrlStr);
      }
      long lengthOfDiskFile=_context.downloadVmdkFile(diskUrlStr,diskLocalPath,totalBytesDownloaded,new ActionDelegate<Long>(){
        @Override public void action(        Long param){
          if (s_logger.isTraceEnabled()) {
            s_logger.trace(""Download progress "" + param + ""/""+ toHumanReadableSize(totalBytes));
          }
          progressReporter.reportProgress((int)(param * 100 / totalBytes));
        }
      }
);
      totalBytesDownloaded+=lengthOfDiskFile;
      OvfFile ovfFile=new OvfFile();
      ovfFile.setPath(diskFileName);
      ovfFile.setDeviceId(deviceId);
      ovfFile.setSize(lengthOfDiskFile);
      ovfFiles[i]=ovfFile;
    }
    OvfCreateDescriptorParams ovfDescParams=new OvfCreateDescriptorParams();
    ovfDescParams.getOvfFiles().addAll(Arrays.asList(ovfFiles));
    OvfCreateDescriptorResult ovfCreateDescriptorResult=_context.getService().createDescriptor(morOvf,getMor(),ovfDescParams);
    String ovfPath=exportDir + File.separator + exportName+ "".ovf"";
    fileNames.add(ovfPath);
    OutputStreamWriter out=new OutputStreamWriter(new FileOutputStream(ovfPath),""UTF-8"");
    out.write(ovfCreateDescriptorResult.getOvfDescriptor());
    out.close();
    if (packToOva) {
      s_logger.info(""Sync file system before we package OVA..."");
      Script commandSync=new Script(true,""sync"",0,s_logger);
      commandSync.execute();
      Script command=new Script(false,""tar"",0,s_logger);
      command.setWorkDir(exportDir);
      command.add(""-cf"",exportName + "".ova"");
      command.add(exportName + "".ovf"");
      for (      String name : fileNames) {
        command.add((new File(name).getName()));
      }
      s_logger.info(""Package OVA with command: "" + command.toString());
      command.execute();
      if ((new File(exportDir + File.separator + exportName+ "".ova"")).exists()) {
        success=true;
      }
 else {
        s_logger.error(exportDir + File.separator + exportName+ "".ova is not created as expected"");
      }
    }
 else {
      success=true;
    }
  }
  s_logger.info(""volss: copy vmdk and ovf file finished "" + System.currentTimeMillis());
}
 catch (Throwable e) {
  s_logger.error(""Unexpected exception "",e);
}
 finally {
  progressReporter.close();
  if (leaveOvaFileOnly) {
    for (    String name : fileNames) {
      new File(name).delete();
    }
  }
  if (!success)   throw new Exception(""Unable to finish the whole process to package as a OVA file"");
}
",0,0,0,,
115,} finally {,"try {
  boolean append=getLogger().isInfoEnabled();
  resolver=(SourceResolver)this.manager.lookup(SourceResolver.ROLE);
  src=resolver.resolveURI(""cocoon://"" + pipeline);
  is=src.getInputStream();
  reader=new InputStreamReader(is);
  StringBuffer sb=new StringBuffer();
  char[] b=new char[8192];
  int n;
  while ((n=reader.read(b)) > 0) {
    if (append) {
      sb.append(b,0,n);
    }
  }
  reader.close();
  if (append) {
    getLogger().info(""CocoonPipelineCronJob: "" + name + "", called pipeline: ""+ pipeline+ "", and received following content:\n""+ sb.toString());
  }
}
 catch (Exception e) {
  throw new CascadingRuntimeException(""CocoonPipelineCronJob: "" + name + "", raised an exception: "",e);
}
 finally {
  try {
    if (reader != null)     reader.close();
    if (is != null)     is.close();
  }
 catch (  IOException e) {
    throw new CascadingRuntimeException(""CocoonPipelineCronJob: "" + name + "", raised an exception: "",e);
  }
  if (resolver != null) {
    resolver.release(src);
    this.manager.release(resolver);
    resolver=null;
    src=null;
  }
}
",0,0,0,,
116,} finally {,"try {
  NekoHtmlSaxParser parser=new NekoHtmlSaxParser(this.properties);
  DOMBuilder builder=new DOMBuilder();
  parser.setContentHandler(builder);
  parser.parse(new InputSource(reader));
  Document doc=builder.getDocument();
  IncludeXMLConsumer.includeNode(doc,this.contentHandler,this.lexicalHandler);
}
 catch (Exception e) {
  throw new ProcessingException(""Exception in NekoHTMLTransformer.normalize()"",e);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException e) {
    throw new ProcessingException(e);
  }
}
",0,0,0,,
117,} finally {,"try {
  if (this.context == null) {
    initialize();
  }
  if (getLogger().isDebugEnabled()) {
    getLogger().debug(""Creating new Context: "" + name);
  }
  newContext=context.createSubcontext(name,map2Attributes(attributes));
}
 catch (Exception e) {
  throw new ProcessingException(e);
}
 finally {
  try {
    if (newContext != null) {
      newContext.close();
    }
  }
 catch (  NamingException e) {
    throw new ProcessingException(e);
  }
}
",0,0,0,,
118,} finally {,"try {
  stmt=connection.prepareStatement(sql);
  Scriptable array=(Scriptable)params;
  if (array != Undefined.instance) {
    int len=(int)Context.toNumber(ScriptableObject.getProperty(array,""length""));
    for (int i=0; i < len; i++) {
      Object val=ScriptableObject.getProperty(array,i);
      if (val instanceof Wrapper) {
        val=((Wrapper)val).unwrap();
      }
      if (val == Scriptable.NOT_FOUND) {
        val=null;
      }
      stmt.setObject(i + 1,val);
    }
  }
  ResultSet rs=stmt.executeQuery();
  if (maxRows == 0) {
    maxRows=-1;
  }
  if (funObj instanceof Function) {
    Context cx=Context.getCurrentContext();
    Function fun=(Function)funObj;
    ResultSetMetaData rsmd=rs.getMetaData();
    int noOfColumns=rsmd.getColumnCount();
    for (int i=0; i < startRow; i++) {
      rs.next();
    }
    int processedRows=0;
    Scriptable scope=getTopLevelScope(this);
    Scriptable proto=getObjectPrototype(scope);
    Object[] args;
    while (rs.next()) {
      if ((maxRows != -1) && (processedRows == maxRows)) {
        break;
      }
      Scriptable row=new ScriptableResult.Row();
      row.setParentScope(scope);
      row.setPrototype(proto);
      for (int i=1; i <= noOfColumns; i++) {
        Object value=rs.getObject(i);
        if (rs.wasNull()) {
          value=null;
        }
        row.put(rsmd.getColumnName(i),row,value);
      }
      args=new Object[1];
      args[0]=row;
      fun.call(cx,scope,scope,args);
    }
    return Undefined.instance;
  }
 else {
    ScriptableResult s=new ScriptableResult(this,rs,startRow,maxRows);
    s.setParentScope(getTopLevelScope(this));
    s.setPrototype(getClassPrototype(this,s.getClassName()));
    return s;
  }
}
 catch (JavaScriptException e) {
  throw e;
}
catch (Exception e) {
  throw new JavaScriptException(e);
}
 finally {
  try {
    if (stmt != null) {
      stmt.close();
    }
  }
 catch (  SQLException sqle) {
    throw new JavaScriptException(sqle);
  }
}
",0,0,0,,
119,} finally {,"try {
  stmt=connection.prepareStatement(sql);
  Scriptable array=(Scriptable)params;
  if (array != Undefined.instance) {
    int len=(int)Context.toNumber(ScriptableObject.getProperty(array,""length""));
    for (int i=0; i < len; i++) {
      Object val=ScriptableObject.getProperty(array,i);
      if (val instanceof Wrapper) {
        val=((Wrapper)val).unwrap();
      }
      if (val == Scriptable.NOT_FOUND) {
        val=null;
      }
      stmt.setObject(i + 1,val);
    }
  }
  stmt.execute();
  return stmt.getUpdateCount();
}
 catch (Exception e) {
  throw new JavaScriptException(e);
}
 finally {
  try {
    if (stmt != null) {
      stmt.close();
    }
  }
 catch (  SQLException sqle) {
    throw new JavaScriptException(sqle);
  }
}
",0,0,0,,
120,} finally {,"try {
  selector=(ServiceSelector)manager.lookup(Serializer.ROLE + ""Selector"");
  serializer=(Serializer)selector.select(localSerializer);
  oStream=ws.getOutputStream();
  serializer.setOutputStream(oStream);
  DOMStreamer streamer=new DOMStreamer(serializer);
  streamer.stream(resource);
}
  finally {
  if (oStream != null) {
    oStream.flush();
    try {
      oStream.close();
      failed=false;
    }
 catch (    Throwable t) {
      if (getLogger().isDebugEnabled()) {
        getLogger().debug(""FAIL (oStream.close) exception"" + t,t);
      }
      throw new ProcessingException(""Could not process your document."",t);
    }
 finally {
      if (selector != null) {
        selector.release(serializer);
        this.manager.release(selector);
      }
    }
  }
}
",0,0,0,,
121,} finally {,"try {
  connectPipeline(environment);
  return processXMLPipeline(environment);
}
 catch (ProcessingException e) {
  buffer=null;
  return processErrorHandler(environment,e,consumer);
}
 finally {
  if (buffer != null) {
    try {
      buffer.toSAX(consumer);
    }
 catch (    SAXException e) {
      throw new ProcessingException(""Failed to execute pipeline."",e);
    }
  }
}
",0,0,0,,
122,} finally {,"try {
  ByteArrayOutputStream os=new ByteArrayOutputStream();
  this.environment.setOutputStream(os);
  EnvironmentHelper.enterProcessor(this.pipelineDescription.processor,this.environment);
  try {
    this.pipelineDescription.processingPipeline.process(this.environment);
  }
  finally {
    EnvironmentHelper.leaveProcessor();
  }
  return new ByteArrayInputStream(os.toByteArray());
}
 catch (ResourceNotFoundException e) {
  throw new SourceNotFoundException(""Exception during processing of "" + this.systemId,e);
}
catch (Exception e) {
  throw new SourceException(""Exception during processing of "" + this.systemId,e);
}
 finally {
  if (touchedOM) {
    ObjectModel newObjectModel;
    try {
      newObjectModel=(ObjectModel)manager.lookup(ObjectModel.ROLE);
    }
 catch (    ServiceException e) {
      throw new RuntimeException(""Couldn't look up Object Model"",e);
    }
    newObjectModel.cleanupLocalContext();
    touchedOM=false;
  }
  this.environment.setOutputStream(null);
  this.needsRefresh=true;
}
",0,0,0,,
123,} finally {,"try {
  if (this.redirectSource != null) {
    SourceUtil.parse(this.manager,this.redirectSource,contentHandler);
  }
 else {
    XMLConsumer consumer;
    if (contentHandler instanceof XMLConsumer) {
      consumer=(XMLConsumer)contentHandler;
    }
 else     if (contentHandler instanceof LexicalHandler) {
      consumer=new ContentHandlerWrapper(contentHandler,(LexicalHandler)contentHandler);
    }
 else {
      consumer=new ContentHandlerWrapper(contentHandler);
    }
    EnvironmentHelper.enterProcessor(this.pipelineDescription.processor,this.environment);
    try {
      this.pipelineDescription.processingPipeline.process(this.environment,EnvironmentHelper.createEnvironmentAwareConsumer(consumer));
    }
  finally {
      EnvironmentHelper.leaveProcessor();
    }
  }
}
 catch (SAXException e) {
  throw e;
}
catch (Exception e) {
  throw new SAXException(""Exception during processing of "" + this.systemId,e);
}
 finally {
  if (touchedOM) {
    ObjectModel newObjectModel;
    try {
      newObjectModel=(ObjectModel)manager.lookup(ObjectModel.ROLE);
    }
 catch (    ServiceException e) {
      throw new SAXException(""Couldn't look up Object Model"",e);
    }
    newObjectModel.cleanupLocalContext();
    touchedOM=false;
  }
  this.needsRefresh=true;
}
",0,0,0,,
124,} finally {,"try {
  if (connection != null) {
    connection.removeTrace(this);
    connection=null;
  }
  final List<AbandonedTrace> resultSetList=getTrace();
  if (resultSetList != null) {
    final ResultSet[] resultSets=resultSetList.toArray(Utils.EMPTY_RESULT_SET_ARRAY);
    for (    final ResultSet resultSet : resultSets) {
      if (resultSet != null) {
        try {
          resultSet.close();
        }
 catch (        final Exception e) {
          if (connection != null) {
            connection.handleExceptionNoThrow(e);
          }
          thrownList.add(e);
        }
      }
    }
    clearTrace();
  }
  if (statement != null) {
    try {
      statement.close();
    }
 catch (    final Exception e) {
      if (connection != null) {
        connection.handleExceptionNoThrow(e);
      }
      thrownList.add(e);
    }
  }
}
  finally {
  closed=true;
  statement=null;
  if (!thrownList.isEmpty()) {
    throw new SQLExceptionList(thrownList);
  }
}
",0,0,0,,
125,finally,"try {
  final RuleLoader loader=new LoaderFromStream(is);
  return loader;
}
 catch (final Exception e) {
  throw new PluginException(""Unable to load xmlrules from file ["" + rulesFileName + ""]"",e);
}
 finally {
  try {
    is.close();
  }
 catch (  final IOException ioe) {
    throw new PluginException(""Unable to close stream for file ["" + rulesFileName + ""]"",ioe);
  }
}
",0,0,0,,
126,finally,"try {
  final RuleLoader loader=new LoaderFromStream(is);
  return loader;
}
 catch (final Exception e) {
  throw new PluginException(""Unable to load xmlrules from resource ["" + resourceName + ""]"",e);
}
 finally {
  try {
    is.close();
  }
 catch (  final IOException ioe) {
    throw new PluginException(""Unable to close stream for resource ["" + resourceName + ""]"",ioe);
  }
}
",0,0,0,,
127,} finally {,"try {
  super.onClose();
}
  finally {
  try {
    endOutput();
  }
 catch (  final Exception e) {
    throw new FileSystemException(""vfs.provider/close-outstr.error"",file,e);
  }
}
",0,0,0,,
128,} finally {,"try {
  vector=channel.ls(""."");
}
 catch (final SftpException ex) {
  lsEx=ex;
}
 finally {
  try {
    if (relPath != null) {
      channel.cd(workingDirectory);
    }
  }
 catch (  final SftpException xe) {
    throw new FileSystemException(""vfs.provider.sftp/change-work-directory-back.error"",workingDirectory,lsEx);
  }
}
",0,0,0,,
129,} finally {,"try {
  URI uri=new URI(dotFileDir);
  FileSystem fs=FileSystem.get(uri,getConfiguration());
  SimpleDateFormat dateFormat=new SimpleDateFormat(""yyyy-MM-dd_HH.mm.ss.SSS"");
  String filenameSuffix=String.format(""_%s_%s.dot"",dateFormat.format(new Date()),fileName);
  String encodedName=URLEncoder.encode(getName(),""UTF-8"");
  final int maxPipeNameLength=150;
  String filenamePrefix=encodedName.substring(0,Math.min(maxPipeNameLength,encodedName.length()));
  Path jobPlanPath=new Path(uri.getPath(),filenamePrefix + filenameSuffix);
  LOG.info(""Writing jobplan to {}"",jobPlanPath);
  outputStream=fs.create(jobPlanPath,true);
  outputStream.write(dotFileContents.getBytes(Charsets.UTF_8));
}
 catch (URISyntaxException e) {
  thrownException=e;
  throw new CrunchRuntimeException(""Invalid dot file dir URI, job plan will not be written: "" + dotFileDir,e);
}
catch (IOException e) {
  thrownException=e;
  throw new CrunchRuntimeException(""Error writing dotfile contents to "" + dotFileDir,e);
}
catch (RuntimeException e) {
  thrownException=e;
  throw e;
}
 finally {
  if (outputStream != null) {
    try {
      outputStream.close();
    }
 catch (    IOException e) {
      if (thrownException == null)       throw new CrunchRuntimeException(""Error closing dotfile"",e);
    }
  }
}
",0,0,0,,
130,} finally {,"try {
  for (  BaseToken baseToken : JCasUtil.select(systemView,BaseToken.class)) {
    String tokenText=baseToken.getCoveredText().toLowerCase();
    String output=String.format(""%s|%s\n"",tokenText,getAnnotationContext(baseToken,contextSize));
    try {
      tokenWriter.write(output);
    }
 catch (    IOException e) {
      throw new AnalysisEngineProcessException(e);
    }
  }
  for (  EventMention eventMention : JCasUtil.select(goldView,EventMention.class)) {
    String eventText=eventMention.getCoveredText().toLowerCase();
    String output=String.format(""%s|%s\n"",eventText,getAnnotationContext(eventMention,contextSize));
    try {
      eventWriter.write(output);
    }
 catch (    IOException e) {
      throw new AnalysisEngineProcessException(e);
    }
  }
}
  finally {
  try {
    tokenWriter.close();
    eventWriter.close();
  }
 catch (  IOException e) {
    throw new AnalysisEngineProcessException(e);
  }
}
",0,0,0,,
131,} finally {,"try {
  for (  EventMention eventMention : JCasUtil.select(goldView,EventMention.class)) {
    List<EventMention> coveringSystemEventMentions=JCasUtil.selectCovered(systemView,EventMention.class,eventMention.getBegin(),eventMention.getEnd());
    for (    EventMention systemEventMention : coveringSystemEventMentions) {
      if (systemEventMention.getTypeID() == umlsSemanticType) {
        String output=String.format(""%s|%s\n"",systemEventMention.getCoveredText().toLowerCase(),expandToNP(systemView,eventMention).toLowerCase());
        try {
          eventWriter.write(output);
        }
 catch (        IOException e) {
          throw new AnalysisEngineProcessException(e);
        }
      }
    }
  }
}
  finally {
  try {
    eventWriter.close();
  }
 catch (  IOException e) {
    throw new AnalysisEngineProcessException(e);
  }
}
",0,0,0,,
132,} finally {,"try {
  for (  BinaryTextRelation binaryTextRelation : JCasUtil.select(goldView,BinaryTextRelation.class)) {
    boolean sameSentence=false;
    Annotation arg1=binaryTextRelation.getArg1().getArgument();
    Annotation arg2=binaryTextRelation.getArg2().getArgument();
    String category=binaryTextRelation.getCategory();
    String text=getTextBetweenAnnotations(systemView,arg1,arg2);
    List<Sentence> sents1=JCasUtil.selectCovering(systemView,Sentence.class,arg1.getBegin(),arg1.getEnd());
    List<Sentence> sents2=JCasUtil.selectCovering(systemView,Sentence.class,arg2.getBegin(),arg2.getEnd());
    if (sents1.size() == 1 && sents2.size() == 1) {
      if (sents1.get(0) == sents2.get(0)) {
        sameSentence=true;
      }
    }
 else {
      System.err.println(""Could not find covering sent for relation: "" + String.format(""%s|%s|%s|%s\n"",category,arg1.getCoveredText(),arg2.getCoveredText(),text));
    }
    String output=String.format(""%s|%s|%s|%s|%s|%s|%s\n"",category,arg1.getCoveredText(),arg2.getCoveredText(),text,arg1.getType().toString(),arg2.getType().toString(),sameSentence ? ""same"" : ""different"");
    try {
      writer.write(output);
    }
 catch (    IOException e) {
      throw new AnalysisEngineProcessException(e);
    }
  }
}
  finally {
  try {
    writer.close();
  }
 catch (  IOException e) {
    throw new AnalysisEngineProcessException(e);
  }
}
",0,0,0,,
133,finally,"try {
  while (hasAcquired && shouldRun) {
    operation.call();
  }
}
  finally {
  if (activeClient.compareAndSet(this,null)) {
    throw new Exception(""Bad release"");
  }
}
",0,0,0,,
134,} finally {,"try {
  JAXBElement<TLSClientParametersType> type=JAXBUtils.unmarshall(getContext(),data,TLSClientParametersType.class);
  TLSClientParametersType cpt=type.getValue();
  return createTLSClientParametersFromType(cpt);
}
 catch (RuntimeException e) {
  throw e;
}
catch (Exception e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    StaxUtils.close(data);
  }
 catch (  XMLStreamException ex) {
    throw new RuntimeException(ex);
  }
}
",0,0,0,,
135,} finally {,"try {
  u=ctx.createUnmarshaller();
  JAXBElement<?> obj=u.unmarshal(data,cls);
  return cls.cast(obj.getValue());
}
 catch (RuntimeException e) {
  throw e;
}
catch (Exception e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    StaxUtils.close(data);
  }
 catch (  XMLStreamException ex) {
    throw new RuntimeException(ex);
  }
  JAXBUtils.closeUnmarshaller(u);
}
",0,0,0,,
136,} finally {,"try {
  T obj=null;
  if (c != null) {
    obj=JAXBUtils.unmarshall(context,data,c).getValue();
  }
 else {
    Object o=JAXBUtils.unmarshall(context,data);
    if (o instanceof JAXBElement<?>) {
      JAXBElement<?> el=(JAXBElement<?>)o;
      @SuppressWarnings(""unchecked"") T ot=(T)el.getValue();
      obj=ot;
    }
  }
  return obj;
}
 catch (JAXBException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    StaxUtils.close(data);
  }
 catch (  XMLStreamException ex) {
    throw new RuntimeException(ex);
  }
}
",0,0,0,,
137,} finally {,"try {
  StaxUtils.copy(xReader,cachedOS);
  InputStream transformedIS=XSLTUtils.transform(getXSLTTemplate(),cachedOS.getInputStream());
  XMLStreamReader transformedReader=StaxUtils.createXMLStreamReader(transformedIS);
  message.setContent(XMLStreamReader.class,transformedReader);
}
 catch (XMLStreamException e) {
  throw new Fault(""STAX_COPY"",LOG,e,e.getMessage());
}
catch (IOException e) {
  throw new Fault(""GET_CACHED_INPUT_STREAM"",LOG,e,e.getMessage());
}
 finally {
  try {
    StaxUtils.close(xReader);
  }
 catch (  XMLStreamException ex) {
    throw new Fault(ex);
  }
  try {
    cachedOS.close();
  }
 catch (  IOException e) {
    LOG.warning(""Cannot close stream after transformation: "" + e.getMessage());
  }
}
",0,0,0,,
138,} finally {,"try {
  if (xmlReader.getEventType() == XMLStreamConstants.START_ELEMENT || xmlReader.nextTag() == XMLStreamConstants.START_ELEMENT) {
    SoapVersion soapVersion=readVersion(xmlReader,message);
    if (soapVersion == Soap12.getInstance() && version == Soap11.getInstance()) {
      message.setVersion(version);
      throw new SoapFault(new Message(""INVALID_11_VERSION"",LOG),version.getVersionMismatch());
    }
    XMLStreamReader filteredReader=new PartialXMLStreamReader(xmlReader,message.getVersion().getBody());
    Node nd=message.getContent(Node.class);
    W3CDOMStreamWriter writer=message.get(W3CDOMStreamWriter.class);
    final Document doc;
    if (writer != null) {
      StaxUtils.copy(filteredReader,writer);
      doc=writer.getDocument();
    }
 else     if (nd instanceof Document) {
      doc=(Document)nd;
      StaxUtils.readDocElements(doc,doc,filteredReader,false,false);
    }
 else {
      final boolean addNC=MessageUtils.getContextualBoolean(message,""org.apache.cxf.binding.soap.addNamespaceContext"",false);
      Map<String,String> bodyNC=addNC ? new HashMap<String,String>() : null;
      if (addNC) {
        addCurrentNamespaceDecls(xmlReader,bodyNC);
      }
      HeadersProcessor processor=new HeadersProcessor(soapVersion);
      doc=processor.process(filteredReader);
      if (doc != null) {
        message.setContent(Node.class,doc);
      }
 else {
        message.put(ENVELOPE_EVENTS,processor.getEnvAttributeAndNamespaceEvents());
        message.put(BODY_EVENTS,processor.getBodyAttributeAndNamespaceEvents());
        message.put(ENVELOPE_PREFIX,processor.getEnvelopePrefix());
        message.put(BODY_PREFIX,processor.getBodyPrefix());
      }
      if (addNC) {
        addCurrentNamespaceDecls(xmlReader,bodyNC);
        message.put(""soap.body.ns.context"",bodyNC);
      }
    }
    List<Element> soapBody=null;
    if (doc != null) {
      Element element=doc.getDocumentElement();
      QName header=soapVersion.getHeader();
      QName body=soapVersion.getBody();
      List<Element> elemList=DOMUtils.findAllElementsByTagNameNS(element,header.getNamespaceURI(),header.getLocalPart());
      soapBody=DOMUtils.getChildrenWithName(element,body.getNamespaceURI(),body.getLocalPart());
      for (      Element elem : elemList) {
        Element hel=DOMUtils.getFirstElement(elem);
        while (hel != null) {
          if (elem.hasAttributes()) {
            NamedNodeMap nnp=elem.getAttributes();
            for (int ct=0; ct < nnp.getLength(); ct++) {
              Node attr=nnp.item(ct);
              Node headerAttrNode=hel.hasAttributes() ? hel.getAttributes().getNamedItemNS(attr.getNamespaceURI(),attr.getLocalName()) : null;
              if (headerAttrNode == null) {
                Attr attribute=hel.getOwnerDocument().createAttributeNS(attr.getNamespaceURI(),attr.getNodeName());
                attribute.setNodeValue(attr.getNodeValue());
                hel.setAttributeNodeNS(attribute);
              }
            }
          }
          HeaderProcessor p=bus == null ? null : bus.getExtension(HeaderManager.class).getHeaderProcessor(hel.getNamespaceURI());
          Object obj;
          DataBinding dataBinding=null;
          if (p == null || p.getDataBinding() == null) {
            obj=hel;
          }
 else {
            dataBinding=p.getDataBinding();
            DataReader<Node> dataReader=dataBinding.createReader(Node.class);
            dataReader.setAttachments(message.getAttachments());
            dataReader.setProperty(DataReader.ENDPOINT,message.getExchange().getEndpoint());
            dataReader.setProperty(Message.class.getName(),message);
            obj=dataReader.read(hel);
          }
          SoapHeader shead=new SoapHeader(new QName(hel.getNamespaceURI(),hel.getLocalName()),obj,dataBinding);
          String mu=hel.getAttributeNS(soapVersion.getNamespace(),soapVersion.getAttrNameMustUnderstand());
          String act=hel.getAttributeNS(soapVersion.getNamespace(),soapVersion.getAttrNameRole());
          if (!StringUtils.isEmpty(act)) {
            shead.setActor(act);
          }
          shead.setMustUnderstand(Boolean.valueOf(mu) || ""1"".equals(mu));
          shead.setDirection(SoapHeader.Direction.DIRECTION_IN);
          message.getHeaders().add(shead);
          hel=DOMUtils.getNextElement(hel);
        }
      }
    }
    if (ServiceUtils.isSchemaValidationEnabled(SchemaValidationType.IN,message)) {
      message.getInterceptorChain().add(new CheckClosingTagsInterceptor());
    }
    if (ServiceUtils.isSchemaValidationEnabled(SchemaValidationType.IN,message) && soapBody != null && soapBody.isEmpty()) {
      throw new SoapFault(new Message(""NO_SOAP_BODY"",LOG,""no soap body""),soapVersion.getSender());
    }
  }
}
 catch (XMLStreamException e) {
  throw new SoapFault(new Message(""XML_STREAM_EXC"",LOG,e.getMessage()),e,message.getVersion().getSender());
}
 finally {
  if (closeNeeded) {
    try {
      StaxUtils.close(xmlReader);
    }
 catch (    XMLStreamException e) {
      throw new SoapFault(new Message(""XML_STREAM_EXC"",LOG,e.getMessage()),e,message.getVersion().getSender());
    }
  }
}
",0,0,0,,
139,} finally {,"try {
  xmlStreamReader=createStreamReader(typeToRead,is);
  return type.cast(aegisReader.read(xmlStreamReader,typeToRead));
}
 catch (Exception e) {
  throw ExceptionUtils.toBadRequestException(e,null);
}
 finally {
  try {
    StaxUtils.close(xmlStreamReader);
  }
 catch (  XMLStreamException e) {
    throw ExceptionUtils.toBadRequestException(e,null);
  }
}
",0,0,0,,
140,} finally {,"try {
  InputStream realStream=getInputStream(type,genericType,is);
  if (Document.class.isAssignableFrom(type)) {
    W3CDOMStreamWriter writer=new W3CDOMStreamWriter();
    reader=createReader(type,realStream,false,enc);
    copyReaderToWriter(reader,writer);
    return type.cast(writer.getDocument());
  }
  boolean isCollection=InjectionUtils.isSupportedCollectionOrArray(type);
  Class<?> theGenericType=isCollection ? InjectionUtils.getActualType(genericType) : type;
  Class<?> theType=getActualType(theGenericType,genericType,anns);
  unmarshaller=createUnmarshaller(theType,genericType,isCollection);
  XMLStreamReader xsr=createReader(type,realStream,isCollection,enc);
  Object response;
  if (JAXBElement.class.isAssignableFrom(type) || !isCollection && (unmarshalAsJaxbElement || jaxbElementClassMap != null && jaxbElementClassMap.containsKey(theType.getName()))) {
    response=unmarshaller.unmarshal(xsr,theType);
  }
 else {
    response=unmarshaller.unmarshal(xsr);
  }
  if (response instanceof JAXBElement && !JAXBElement.class.isAssignableFrom(type)) {
    response=((JAXBElement<?>)response).getValue();
  }
  if (isCollection) {
    response=((CollectionWrapper)response).getCollectionOrArray(unmarshaller,theType,type,genericType,org.apache.cxf.jaxrs.utils.JAXBUtils.getAdapter(theGenericType,anns));
  }
 else {
    response=checkAdapter(response,type,anns,false);
  }
  return type.cast(response);
}
 catch (JAXBException e) {
  handleJAXBException(e,true);
}
catch (XMLStreamException e) {
  if (e.getCause() instanceof JSONSequenceTooLargeException) {
    throw new WebApplicationException(413);
  }
  handleXMLStreamException(e,true);
}
catch (WebApplicationException e) {
  throw e;
}
catch (Exception e) {
  throw ExceptionUtils.toBadRequestException(e,null);
}
 finally {
  try {
    StaxUtils.close(reader);
  }
 catch (  XMLStreamException e) {
    throw ExceptionUtils.toBadRequestException(e,null);
  }
  JAXBUtils.closeUnmarshaller(unmarshaller);
}
",0,0,0,,
141,} finally {,"try {
  reader=StaxUtils.createXMLStreamReader(inputSource);
  return deserialize(ctx,reader,true);
}
  finally {
  try {
    StaxUtils.close(reader);
  }
 catch (  final XMLStreamException ex) {
    throw new XMLEncryptionException(ex);
  }
}
",0,0,0,,
142,} finally {,"try {
  u=createUnmarshaller();
  Object o;
  if (namespace == null) {
    o=u.unmarshal(element,extensionClass);
  }
 else {
    reader=StaxUtils.createXMLStreamReader(element);
    reader=new MappingReaderDelegate(reader);
    o=u.unmarshal(reader,extensionClass);
  }
  if (o != null) {
    o=((JAXBElement<?>)o).getValue();
  }
  ExtensibilityElement el=o instanceof ExtensibilityElement ? (ExtensibilityElement)o : new JAXBExtensibilityElement(o);
  el.setElementType(qname);
  return el;
}
 catch (Exception ex) {
  throw new WSDLException(WSDLException.PARSER_ERROR,""Error reading element "" + qname,ex);
}
 finally {
  try {
    StaxUtils.close(reader);
  }
 catch (  XMLStreamException ex) {
    throw new WSDLException(WSDLException.PARSER_ERROR,ex.getMessage(),ex);
  }
  JAXBUtils.closeUnmarshaller(u);
}
",0,0,0,,
143,} finally {,"try {
  xmlReader=StaxUtils.createXMLStreamReader(src);
  if (xmlStreamReaderWrapper != null) {
    xmlReader=xmlStreamReaderWrapper.wrap(xmlReader);
  }
  doc=StaxUtils.read(xmlReader,true);
  if (src.getSystemId() != null) {
    try {
      doc.setDocumentURI(new String(src.getSystemId()));
    }
 catch (    Exception e) {
    }
  }
}
 catch (Exception e) {
  throw new WSDLException(WSDLException.PARSER_ERROR,e.getMessage(),e);
}
 finally {
  try {
    StaxUtils.close(xmlReader);
  }
 catch (  XMLStreamException ex) {
    throw new WSDLException(WSDLException.PARSER_ERROR,ex.getMessage(),ex);
  }
}
",0,0,0,,
144,} finally {,"try (InputStream input=url.openStream()){
  StreamSource src=new StreamSource(input,url.toExternalForm());
  reader=StaxUtils.createXMLStreamReader(src);
  return StaxUtils.read(reader,true);
}
 catch (Exception e) {
  throw new ToolException(e);
}
 finally {
  try {
    StaxUtils.close(reader);
  }
 catch (  XMLStreamException e1) {
    throw new ToolException(e1);
  }
}
",0,0,0,,
145,} finally {,"try {
  StreamSource source=new StreamSource(wsdl);
  reader=StaxUtils.createXMLStreamReader(source);
  return StaxUtils.read(reader,true);
}
 catch (Exception e) {
  throw new ToolException(e);
}
 finally {
  try {
    if (reader != null) {
      try {
        reader.getClass().getMethod(""closeCompletely"").invoke(reader);
      }
 catch (      Throwable t) {
      }
      reader.close();
    }
  }
 catch (  XMLStreamException e) {
    throw new ToolException(e);
  }
}
",0,0,0,,
146,finally {,"try {
  runQueryReadingPCPointInstances(READ_TIMEOUT);
  runGetObjectByIdReadingPCPointInstance(READ_TIMEOUT);
  runNavigationalReadPCPointInstance(READ_TIMEOUT);
}
  finally {
  t.join();
  Throwable problem=group.getUncaughtException(t);
  if (problem != null) {
    if (problem instanceof AssertionFailedError)     throw (AssertionFailedError)problem;
 else     throw new JDOFatalException(""Thread "" + t.getName() + "" results in exception "",problem);
  }
}
",0,0,0,,
147,finally {,"try {
  runUpdatePCointInstance(WRITE_TIMEOUT);
  runDeletePCPointInstance(WRITE_TIMEOUT);
  runDeletePCPointInstancesByQuery(WRITE_TIMEOUT);
}
  finally {
  t.join();
  Throwable problem=group.getUncaughtException(t);
  if (problem != null) {
    if (problem instanceof AssertionFailedError)     throw (AssertionFailedError)problem;
 else     throw new JDOFatalException(""Thread "" + t.getName() + "" results in exception "",problem);
  }
}
",0,0,0,,
148,finally {,"try {
  runQueryReadingPCPointInstances(ZERO_TIMEOUT);
}
  finally {
  t.join();
  Throwable problem=group.getUncaughtException(t);
  if (problem != null) {
    if (problem instanceof AssertionFailedError)     throw (AssertionFailedError)problem;
 else     throw new JDOFatalException(""Thread "" + t.getName() + "" results in exception "",problem);
  }
}
",0,0,0,,
149,finally {,"try {
  runUpdatePCointInstance(ZERO_TIMEOUT);
}
  finally {
  t.join();
  Throwable problem=group.getUncaughtException(t);
  if (problem != null) {
    if (problem instanceof AssertionFailedError)     throw (AssertionFailedError)problem;
 else     throw new JDOFatalException(""Thread "" + t.getName() + "" results in exception "",problem);
  }
}
",0,0,0,,
150,} finally {,"try {
  stream=new FileInputStream(name);
  return JDOHelper.getPersistenceManagerFactory(stream);
}
 catch (FileNotFoundException e) {
  throw new RuntimeException("""",e);
}
 finally {
  if (stream != null) {
    try {
      stream.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
151,} finally {,"try {
  stream=new FileInputStream(name);
  return JDOHelper.getPersistenceManagerFactory(stream,Thread.currentThread().getContextClassLoader());
}
 catch (FileNotFoundException e) {
  throw new RuntimeException("""",e);
}
 finally {
  if (stream != null) {
    try {
      stream.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
152,} finally {,"try {
  oos=new ObjectOutputStream(new ByteArrayOutputStream());
  oos.writeObject(obj);
}
 catch (IOException e) {
  throw new JDOFatalException(e.getMessage(),e);
}
 finally {
  if (oos != null) {
    try {
      oos.close();
    }
 catch (    IOException e) {
      throw new JDOFatalException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
153,} finally {,"try {
  oos=new ObjectOutputStream(new ByteArrayOutputStream());
  oos.writeObject(obj);
}
 catch (IOException e) {
  throw new JDOFatalException(e.getMessage(),e);
}
 finally {
  if (oos != null) {
    try {
      oos.close();
    }
 catch (    IOException e) {
      throw new JDOFatalException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
154,} finally {,"try {
  ByteArrayOutputStream byteArrayOutputStream=new ByteArrayOutputStream();
  oos=new ObjectOutputStream(byteArrayOutputStream);
  oos.writeObject(obj);
  ois=new ObjectInputStream(new ByteArrayInputStream(byteArrayOutputStream.toByteArray()));
  result=ois.readObject();
}
 catch (IOException e) {
  throw new JDOFatalException(e.getMessage(),e);
}
catch (ClassNotFoundException e) {
  throw new JDOFatalException(e.getMessage(),e);
}
 finally {
  try {
    if (oos != null) {
      oos.close();
    }
    if (ois != null) {
      ois.close();
    }
  }
 catch (  IOException e) {
    throw new JDOFatalException(e.getMessage(),e);
  }
}
",0,0,0,,
155,finally,"try {
  propertiesFW=new FileWriter(targetProperties);
  propertiesPW=new PrintWriter(propertiesFW);
  ditaWriter=new XMLWriter(targetDita);
  processMessages(source,propertiesPW,ditaWriter);
}
 catch (Exception e) {
  throw new BuildException(""Could not generate English properties from message descriptors: "" + e.getMessage(),e);
}
 finally {
  try {
    finishWriting(propertiesFW,propertiesPW);
    if (ditaWriter != null) {
      ditaWriter.flush();
      ditaWriter.close();
    }
  }
 catch (  Exception ex) {
    throw new BuildException(""Error closing file writers."",ex);
  }
}
",0,0,0,,
156,finally,"try {
  int drdaMaintID=readDRDAMaintID(target);
  VersionID versionID=new VersionID(_releaseID);
  if (_bump) {
    versionID.bump();
  }
  int major=versionID.getMajor();
  int minor=versionID.getMinor();
  int currentYear=getCurrentYear();
  propertiesFW=new FileWriter(target);
  propertiesPW=new PrintWriter(propertiesFW);
  propertiesPW.println(APACHE_LICENSE_HEADER);
  propertiesPW.println(DRDA_MAINT + ""="" + drdaMaintID);
  propertiesPW.println(""maint="" + encodeFixpackAndPoint(versionID));
  propertiesPW.println(""major="" + major);
  propertiesPW.println(""minor="" + minor);
  propertiesPW.println(""eversion="" + versionID.getBranchName());
  propertiesPW.println(""beta="" + versionID.isBeta());
  propertiesPW.println(""copyright.comment=Copyright 1997, "" + currentYear + "" The Apache Software Foundation or its licensors, as applicable."");
  propertiesPW.println(""vendor=The Apache Software Foundation"");
  propertiesPW.println(""copyright.year="" + currentYear);
  propertiesPW.println(""release.id.long="" + versionID.toString());
  setProperty(NEW_RELEASE_ID,versionID.toString());
}
 catch (Exception e) {
  throw new BuildException(""Could not generate release properties: "" + e.getMessage(),e);
}
 finally {
  try {
    finishWriting(propertiesFW,propertiesPW);
  }
 catch (  Exception ex) {
    throw new BuildException(""Error closing file writers."",ex);
  }
}
",0,0,0,,
157,finally,"try {
  SecurityUtil.authorize(Securable.CHECK_TABLE);
  dd=lcc.getDataDictionary();
  dvf=lcc.getDataValueFactory();
  ExecutionFactory ef=lcc.getLanguageConnectionFactory().getExecutionFactory();
  sd=dd.getSchemaDescriptor(schemaName,tc,true);
  td=dd.getTableDescriptor(tableName,sd,tc);
  if (td == null) {
    throw StandardException.newException(SQLState.LANG_TABLE_NOT_FOUND,schemaName + ""."" + tableName);
  }
  if (td.getTableType() == TableDescriptor.VIEW_TYPE) {
    return true;
  }
  baseCC=tc.openConglomerate(td.getHeapConglomerateId(),false,0,TransactionController.MODE_TABLE,TransactionController.ISOLATION_SERIALIZABLE);
  baseCC.checkConsistency();
  heapCD=td.getConglomerateDescriptor(td.getHeapConglomerateId());
  baseRow=ef.getValueRow(td.getNumberOfColumns());
  ColumnDescriptorList cdl=td.getColumnDescriptorList();
  int cdlSize=cdl.size();
  for (int index=0; index < cdlSize; index++) {
    ColumnDescriptor cd=(ColumnDescriptor)cdl.elementAt(index);
    baseRow.setColumn(cd.getPosition(),cd.getType().getNull());
  }
  ConglomerateDescriptor[] cds=td.getConglomerateDescriptors();
  for (int index=0; index < cds.length; index++) {
    indexCD=cds[index];
    if (!indexCD.isIndex())     continue;
    indexCC=tc.openConglomerate(indexCD.getConglomerateNumber(),false,0,TransactionController.MODE_TABLE,TransactionController.ISOLATION_SERIALIZABLE);
    indexCC.checkConsistency();
    indexCC.close();
    indexCC=null;
    if (indexCD.isConstraint()) {
      constraintDesc=dd.getConstraintDescriptor(td,indexCD.getUUID());
      if (constraintDesc == null) {
        throw StandardException.newException(SQLState.LANG_OBJECT_NOT_FOUND,""CONSTRAINT for INDEX"",indexCD.getConglomerateName());
      }
    }
    if (baseRowCount < 0) {
      scan=tc.openScan(heapCD.getConglomerateNumber(),false,0,TransactionController.MODE_TABLE,TransactionController.ISOLATION_SERIALIZABLE,RowUtil.EMPTY_ROW_BITSET,null,0,null,null,0);
      rl=scan.newRowLocationTemplate();
      scanRL=scan.newRowLocationTemplate();
      for (baseRowCount=0; scan.next(); baseRowCount++)       ;
      scan.close();
      scan=null;
    }
    baseColumnPositions=indexCD.getIndexDescriptor().baseColumnPositions();
    baseColumns=baseColumnPositions.length;
    FormatableBitSet indexColsBitSet=new FormatableBitSet();
    for (int i=0; i < baseColumns; i++) {
      indexColsBitSet.grow(baseColumnPositions[i]);
      indexColsBitSet.set(baseColumnPositions[i] - 1);
    }
    indexRow=ef.getValueRow(baseColumns + 1);
    for (int column=0; column < baseColumns; column++) {
      ColumnDescriptor cd=td.getColumnDescriptor(baseColumnPositions[column]);
      indexRow.setColumn(column + 1,cd.getType().getNull());
    }
    indexRow.setColumn(baseColumns + 1,rl);
    scan=tc.openScan(indexCD.getConglomerateNumber(),false,0,TransactionController.MODE_TABLE,TransactionController.ISOLATION_SERIALIZABLE,(FormatableBitSet)null,null,0,null,null,0);
    DataValueDescriptor[] baseRowIndexOrder=new DataValueDescriptor[baseColumns];
    DataValueDescriptor[] baseObjectArray=baseRow.getRowArray();
    for (int i=0; i < baseColumns; i++) {
      baseRowIndexOrder[i]=baseObjectArray[baseColumnPositions[i] - 1];
    }
    for (indexRows=0; scan.fetchNext(indexRow.getRowArray()); indexRows++) {
      RowLocation baseRL=(RowLocation)indexRow.getColumn(baseColumns + 1);
      boolean base_row_exists=baseCC.fetch(baseRL,baseObjectArray,indexColsBitSet);
      if (!base_row_exists) {
        String indexName=indexCD.getConglomerateName();
        throw StandardException.newException(SQLState.LANG_INCONSISTENT_ROW_LOCATION,(schemaName + ""."" + tableName),indexName,baseRL.toString(),indexRow.toString());
      }
      for (int column=0; column < baseColumns; column++) {
        DataValueDescriptor indexColumn=indexRow.getColumn(column + 1);
        DataValueDescriptor baseColumn=baseRowIndexOrder[column];
        if (indexColumn.compare(baseColumn) != 0) {
          ColumnDescriptor cd=td.getColumnDescriptor(baseColumnPositions[column]);
          throw StandardException.newException(SQLState.LANG_INDEX_COLUMN_NOT_EQUAL,indexCD.getConglomerateName(),td.getSchemaName(),td.getName(),baseRL.toString(),cd.getColumnName(),indexColumn.toString(),baseColumn.toString(),indexRow.toString());
        }
      }
    }
    scan.close();
    scan=null;
    if (indexRows != baseRowCount) {
      throw StandardException.newException(SQLState.LANG_INDEX_ROW_COUNT_MISMATCH,indexCD.getConglomerateName(),td.getSchemaName(),td.getName(),Long.toString(indexRows),Long.toString(baseRowCount));
    }
  }
  ConstraintDescriptorList constraintDescList=dd.getConstraintDescriptors(td);
  for (int index=0; index < constraintDescList.size(); index++) {
    constraintDesc=constraintDescList.elementAt(index);
    if (constraintDesc.hasBackingIndex()) {
      ConglomerateDescriptor conglomDesc;
      conglomDesc=td.getConglomerateDescriptor(constraintDesc.getConglomerateId());
      if (conglomDesc == null) {
        throw StandardException.newException(SQLState.LANG_OBJECT_NOT_FOUND,""INDEX for CONSTRAINT"",constraintDesc.getConstraintName());
      }
    }
  }
}
 catch (StandardException se) {
  throw PublicAPI.wrapStandardException(se);
}
 finally {
  try {
    if (baseCC != null) {
      baseCC.close();
      baseCC=null;
    }
    if (indexCC != null) {
      indexCC.close();
      indexCC=null;
    }
    if (scan != null) {
      scan.close();
      scan=null;
    }
  }
 catch (  StandardException se) {
    throw PublicAPI.wrapStandardException(se);
  }
}
",0,0,0,,
158,finally,"try {
  if (create) {
    getSecureRandom().nextBytes(data);
    byte[] checksum=getMD5Checksum(data);
    CipherProvider tmpCipherProvider=createNewCipher(ENCRYPT,mainSecretKey,mainIV);
    tmpCipherProvider.encrypt(data,0,data.length,data,0);
    verifyKeyFile=privAccessFile(sf,Attribute.CRYPTO_EXTERNAL_KEY_VERIFY_FILE,""rw"");
    verifyKeyFile.writeInt(checksum.length);
    verifyKeyFile.write(checksum);
    verifyKeyFile.write(data);
    verifyKeyFile.sync();
  }
 else {
    verifyKeyInputStream=privAccessGetInputStream(sf,Attribute.CRYPTO_EXTERNAL_KEY_VERIFY_FILE);
    DataInputStream dis=new DataInputStream(verifyKeyInputStream);
    int checksumLen=dis.readInt();
    byte[] originalChecksum=new byte[checksumLen];
    dis.readFully(originalChecksum);
    dis.readFully(data);
    CipherProvider tmpCipherProvider=createNewCipher(DECRYPT,mainSecretKey,mainIV);
    tmpCipherProvider.decrypt(data,0,data.length,data,0);
    byte[] verifyChecksum=getMD5Checksum(data);
    if (!MessageDigest.isEqual(originalChecksum,verifyChecksum)) {
      throw StandardException.newException(SQLState.ENCRYPTION_BAD_EXTERNAL_KEY);
    }
  }
}
 catch (IOException ioe) {
  throw StandardException.newException(SQLState.ENCRYPTION_UNABLE_KEY_VERIFICATION,ioe);
}
 finally {
  try {
    if (verifyKeyFile != null)     verifyKeyFile.close();
    if (verifyKeyInputStream != null)     verifyKeyInputStream.close();
  }
 catch (  IOException ioee) {
    throw StandardException.newException(SQLState.ENCRYPTION_UNABLE_KEY_VERIFICATION,ioee);
  }
}
",0,0,0,,
159,} finally {,"try {
  Control gc=entry.control;
  if (gc == null) {
    Lock gl=new Lock(compatibilitySpace,ref,qualifier);
    gl.grant();
    entry.control=gl;
    return gl;
  }
  control=gc.getLockControl();
  if (control != gc) {
    entry.control=control;
  }
  if (SanityManager.DEBUG) {
    SanityManager.ASSERT(ref.equals(control.getLockable()));
    SanityManager.ASSERT(locks.get(control.getLockable()).control == control);
  }
  lockItem=control.addLock(this,compatibilitySpace,qualifier);
  if (lockItem.getCount() != 0) {
    return lockItem;
  }
  blockedByParent=(timeout == 0) && compatibilitySpace.getOwner().isNestedOwner() && control.blockedByParent(lockItem);
  if (AbstractPool.noLockWait(timeout,compatibilitySpace) || blockedByParent) {
    control.giveUpWait(lockItem,this);
    if (SanityManager.DEBUG) {
      if (SanityManager.DEBUG_ON(""DeadlockTrace"")) {
        SanityManager.showTrace(new Throwable());
        lockDebug=DiagnosticUtil.toDiagString(lockItem) + ""\nCould not grant lock with zero timeout, "" + ""here's the table"";
        entry.unlock();
        try {
          lockDebug+=toDebugString();
        }
  finally {
          entry.lock();
        }
      }
    }
    return null;
  }
}
  finally {
  entry.unlock();
  if (blockedByParent) {
    throw StandardException.newException(SQLState.SELF_DEADLOCK);
  }
}
",0,0,0,,
160,} finally {,"try {
  indexSC=tc.openScan(indexCID,false,0,TransactionController.MODE_RECORD,TransactionController.ISOLATION_READ_COMMITTED_NOHOLDLOCK,(FormatableBitSet)null,key,ScanController.GE,null,key,ScanController.GT);
  if (indexSC.next()) {
    if (indexSC.next()) {
      throw StandardException.newException(rollbackOnError ? SQLState.LANG_DEFERRED_DUPLICATE_KEY_CONSTRAINT_T : SQLState.LANG_DEFERRED_DUPLICATE_KEY_CONSTRAINT_S,cd.getConstraintName(),cd.getTableDescriptor().getName());
    }
  }
 else {
  }
}
 catch (StandardException se) {
  sawException=true;
  throw se;
}
 finally {
  try {
    if (indexSC != null) {
      indexSC.close();
    }
  }
 catch (  StandardException ie) {
    if (!sawException) {
      throw ie;
    }
  }
}
",0,0,0,,
161,} finally {,"try {
  indexSC=tc.openScan(cids[idx],false,0,TransactionController.MODE_RECORD,TransactionController.ISOLATION_READ_COMMITTED,(FormatableBitSet)null,key,ScanController.GE,null,key,ScanController.GT);
  if (idx == 0) {
    if (indexSC.next()) {
    }
 else {
      break;
    }
  }
 else {
    if (indexSC.next()) {
    }
 else {
      violation=true;
    }
  }
}
 catch (StandardException se) {
  sawException=true;
  throw se;
}
 finally {
  try {
    if (indexSC != null) {
      indexSC.close();
    }
  }
 catch (  StandardException ie) {
    if (!sawException) {
      throw ie;
    }
  }
}
",0,0,0,,
162,finally,"try {
  StorageFile dbase=storageFactory.newStorageFile(null);
  String canonicalDbName=storageFactory.getCanonicalName();
  String dbname=StringUtil.shortDBName(canonicalDbName,storageFactory.getSeparator());
  historyFile=privFileWriter(storageFactory.newStorageFile(BACKUP_HISTORY),true);
  backupcopy=new File(backupDir,dbname);
  logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_BACKUP_STARTED,canonicalDbName,getFilePath(backupcopy)));
  if (privExists(backupcopy)) {
    oldbackup=new File(backupDir,dbname + "".OLD"");
    if (privExists(oldbackup)) {
      if (privIsDirectory(oldbackup))       privRemoveDirectory(oldbackup);
 else       privDelete(oldbackup);
    }
    if (!privRenameTo(backupcopy,oldbackup)) {
      renameFailed=true;
      throw StandardException.newException(SQLState.RAWSTORE_ERROR_RENAMING_FILE,backupcopy,oldbackup);
    }
 else {
      logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_MOVED_BACKUP,getFilePath(backupcopy),getFilePath(oldbackup)));
      renamed=true;
    }
  }
  createBackupDirectory(backupcopy);
  dbHistoryFile=storageFactory.newStorageFile(BACKUP_HISTORY);
  backupHistoryFile=new File(backupcopy,BACKUP_HISTORY);
  if (!privCopyFile(dbHistoryFile,backupHistoryFile))   throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,dbHistoryFile,backupHistoryFile);
  StorageFile jarDir=storageFactory.newStorageFile(FileResource.JAR_DIRECTORY_NAME);
  if (privExists(jarDir)) {
    String[] jarDirContents=privList(jarDir);
    File backupJarDir=new File(backupcopy,FileResource.JAR_DIRECTORY_NAME);
    createBackupDirectory(backupJarDir);
    LanguageConnectionContext lcc=(LanguageConnectionContext)getContextOrNull(LanguageConnectionContext.CONTEXT_ID);
    boolean uuidSupported=lcc.getDataDictionary().checkVersion(DataDictionary.DD_VERSION_DERBY_10_9,null);
    if (uuidSupported) {
      for (int i=0; i < jarDirContents.length; i++) {
        StorageFile jar=storageFactory.newStorageFile(jarDir,jarDirContents[i]);
        File backupJar=new File(backupJarDir,jarDirContents[i]);
        if (privIsDirectory(new File(jar.getPath()))) {
          continue;
        }
        if (!privCopyFile(jar,backupJar)) {
          throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,jar,backupJar);
        }
      }
    }
 else {
      for (int i=0; i < jarDirContents.length; i++) {
        StorageFile jarSchemaDir=storageFactory.newStorageFile(jarDir,jarDirContents[i]);
        File backupJarSchemaDir=new File(backupJarDir,jarDirContents[i]);
        if (!privCopyDirectory(jarSchemaDir,backupJarSchemaDir,(byte[])null,null,false)) {
          throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,jarSchemaDir,backupJarSchemaDir);
        }
      }
    }
  }
  StorageFile logdir=logFactory.getLogDirectory();
  try {
    String name=getServiceName(this);
    PersistentService ps=getMonitor().getServiceType(this);
    String fullName=ps.getCanonicalServiceName(name);
    Properties prop=ps.getServiceProperties(fullName,(Properties)null);
    StorageFile defaultLogDir=storageFactory.newStorageFile(LogFactory.LOG_DIRECTORY_NAME);
    if (!logdir.equals(defaultLogDir)) {
      prop.remove(Attribute.LOG_DEVICE);
      if (SanityManager.DEBUG) {
        SanityManager.ASSERT(prop.getProperty(Attribute.LOG_DEVICE) == null,""cannot get rid of logDevice property"");
      }
      logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_EDITED_SERVICEPROPS));
    }
    ps.saveServiceProperties(backupcopy.getPath(),prop);
  }
 catch (  StandardException se) {
    logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_ERROR_EDIT_SERVICEPROPS) + se);
    return;
  }
  StorageFile verifyKeyFile=storageFactory.newStorageFile(Attribute.CRYPTO_EXTERNAL_KEY_VERIFY_FILE);
  if (privExists(verifyKeyFile)) {
    File backupVerifyKeyFile=new File(backupcopy,Attribute.CRYPTO_EXTERNAL_KEY_VERIFY_FILE);
    if (!privCopyFile(verifyKeyFile,backupVerifyKeyFile))     throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,verifyKeyFile,backupVerifyKeyFile);
  }
  File logBackup=new File(backupcopy,LogFactory.LOG_DIRECTORY_NAME);
  if (privExists(logBackup)) {
    privRemoveDirectory(logBackup);
  }
  createBackupDirectory(logBackup);
  logFactory.checkpoint(this,dataFactory,xactFactory,true);
  logFactory.startLogBackup(logBackup);
  File segBackup=new File(backupcopy,""seg0"");
  createBackupDirectory(segBackup);
  dataFactory.backupDataFiles(t,segBackup);
  logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_DATA_SEG_BACKUP_COMPLETED,getFilePath(segBackup)));
  logFactory.endLogBackup(logBackup);
  logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_COPIED_LOG,getFilePath(logdir),getFilePath(logBackup)));
  error=false;
}
 catch (IOException ioe) {
  throw StandardException.newException(SQLState.RAWSTORE_UNEXPECTED_EXCEPTION,ioe);
}
 finally {
  try {
    if (error) {
      logFactory.abortLogBackup();
      if (!renameFailed)       privRemoveDirectory(backupcopy);
      if (renamed)       privRenameTo(oldbackup,backupcopy);
      logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_BACKUP_ABORTED));
    }
 else {
      if (renamed && privExists(oldbackup)) {
        privRemoveDirectory(oldbackup);
        logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_REMOVED_BACKUP,getFilePath(oldbackup)));
      }
      logHistory(historyFile,MessageService.getTextMessage(MessageId.STORE_BACKUP_COMPLETED,backupInstant));
      if (!privCopyFile(dbHistoryFile,backupHistoryFile))       throw StandardException.newException(SQLState.RAWSTORE_ERROR_COPYING_FILE,dbHistoryFile,backupHistoryFile);
    }
    historyFile.close();
  }
 catch (  IOException ioe) {
    try {
      historyFile.close();
    }
 catch (    IOException ioe2) {
    }
    ;
    throw StandardException.newException(SQLState.RAWSTORE_UNEXPECTED_EXCEPTION,ioe);
  }
}
",0,0,0,,
163,} finally {,"try {
synchronized (this) {
    while (inRemove) {
      try {
        wait();
      }
 catch (      InterruptedException ie) {
        InterruptStatus.setInterrupted();
      }
    }
    if (getCommittedDropState())     isStub=true;
    inBackup=true;
  }
  if (isStub) {
    StorageFile file=getFileName((ContainerKey)getIdentity(),true,false,true);
    backupFile=new File(backupLocation,file.getName());
    copyFile(file,backupFile);
  }
 else {
    long lastPageNumber=getLastPageNumber(handle);
    if (lastPageNumber == ContainerHandle.INVALID_PAGE_NUMBER) {
      return;
    }
    StorageFile file=getFileName((ContainerKey)getIdentity(),false,false,true);
    backupFile=new File(backupLocation,file.getName());
    backupRaf=getRandomAccessFile(backupFile);
    byte[] encryptionBuf=null;
    if (dataFactory.databaseEncrypted()) {
      encryptionBuf=new byte[pageSize];
    }
    for (long pageNumber=FIRST_ALLOC_PAGE_NUMBER; pageNumber <= lastPageNumber; pageNumber++) {
      page=getLatchedPage(handle,pageNumber);
      byte[] dataToWrite=updatePageArray(pageNumber,page.getPageArray(),encryptionBuf,false);
      backupRaf.write(dataToWrite,0,pageSize);
      page.unlatch();
      page=null;
synchronized (this) {
        if (inRemove) {
          break;
        }
      }
    }
  }
  if (!isStub) {
    backupRaf.getFD().sync();
    backupRaf.close();
    backupRaf=null;
  }
  backupCompleted=true;
}
 catch (IOException ioe) {
  throw StandardException.newException(SQLState.BACKUP_FILE_IO_ERROR,ioe,backupFile);
}
 finally {
synchronized (this) {
    inBackup=false;
    notifyAll();
  }
  if (page != null) {
    page.unlatch();
    page=null;
  }
  if (!backupCompleted && backupFile != null) {
    if (backupRaf != null) {
      try {
        backupRaf.close();
        backupRaf=null;
      }
 catch (      IOException ioe) {
        throw StandardException.newException(SQLState.BACKUP_FILE_IO_ERROR,ioe,backupFile);
      }
    }
    removeFile(backupFile);
  }
}
",0,0,0,,
164,} finally {,"try {
  long lastPageNumber=getLastPageNumber(handle);
  newRaf=getRandomAccessFile(newFile);
  byte[] encryptionBuf=null;
  if (doEncrypt) {
    encryptionBuf=new byte[pageSize];
  }
  for (long pageNumber=FIRST_ALLOC_PAGE_NUMBER; pageNumber <= lastPageNumber; pageNumber++) {
    page=getLatchedPage(handle,pageNumber);
    byte[] dataToWrite=updatePageArray(pageNumber,page.getPageArray(),encryptionBuf,true);
    newRaf.write(dataToWrite,0,pageSize);
    page.unlatch();
    page=null;
  }
  newRaf.sync();
  newRaf.close();
  newRaf=null;
}
 catch (IOException ioe) {
  throw StandardException.newException(SQLState.FILE_CONTAINER_EXCEPTION,ioe,getIdentity() != null ? getIdentity().toString() : ""unknown"",doEncrypt ? ""encrypt"" : ""decrypt"",newFilePath);
}
 finally {
  if (page != null) {
    page.unlatch();
    page=null;
  }
  if (newRaf != null) {
    try {
      newRaf.close();
    }
 catch (    IOException ioe) {
      newRaf=null;
      throw StandardException.newException(SQLState.FILE_CONTAINER_EXCEPTION,ioe,getIdentity() != null ? getIdentity().toString() : ""unknown"",doEncrypt ? ""encrypt-close"" : ""decrypt-close"",newFilePath);
    }
  }
}
",0,0,0,,
165,finally,"try {
  StreamLogScan scanLog;
  if (prepareStartAt == null) {
    scanLog=(StreamLogScan)logFactory.openBackwardsScan(prepareStopAt);
  }
 else {
    if (prepareStartAt.lessThan(prepareStopAt)) {
      return;
    }
    scanLog=(StreamLogScan)logFactory.openBackwardsScan(((LogCounter)prepareStartAt).getValueAsLong(),prepareStopAt);
  }
  if (SanityManager.DEBUG)   SanityManager.ASSERT(scanLog != null,""cannot open log for prepare"");
  rawInput=new ArrayInputStream(new byte[4096]);
  LogRecord record;
  while ((record=scanLog.getNextRecord(rawInput,prepareId,0)) != null) {
    if (SanityManager.DEBUG) {
      SanityManager.ASSERT(record.getTransactionId().equals(prepareId),""getNextRecord return unqualified log rec for prepare"");
    }
    logrecordseen++;
    if (record.isCLR()) {
      clrskipped++;
      record.skipLoggable();
      long prepareInstant=rawInput.readLong();
      if (SanityManager.DEBUG) {
        if (SanityManager.DEBUG_ON(LogToFile.DBG_FLAG)) {
          SanityManager.DEBUG(LogToFile.DBG_FLAG,""Skipping over CLRs, reset scan to "" + LogCounter.toDebugString(prepareInstant));
        }
      }
      scanLog.resetPosition(new LogCounter(prepareInstant));
      continue;
    }
    if (record.requiresPrepareLocks()) {
      lop=record.getRePreparable();
    }
 else {
      continue;
    }
    if (lop != null) {
      lop.reclaimPrepareLocks(t,t.newLockingPolicy(LockingPolicy.MODE_RECORD,TransactionController.ISOLATION_REPEATABLE_READ,true));
      if (SanityManager.DEBUG) {
        if (SanityManager.DEBUG_ON(LogToFile.DBG_FLAG)) {
          SanityManager.DEBUG(LogToFile.DBG_FLAG,""Reprepare log record at instant "" + scanLog.getInstant() + "" : ""+ lop);
        }
      }
    }
  }
}
 catch (ClassNotFoundException cnfe) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_CORRUPTED,cnfe));
}
catch (IOException ioe) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_READ_LOG_FOR_UNDO,ioe));
}
catch (StandardException se) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_UNDO_FAILED,se,prepareId,lop,(Object)null));
}
 finally {
  if (rawInput != null) {
    try {
      rawInput.close();
    }
 catch (    IOException ioe) {
      throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_READ_LOG_FOR_UNDO,ioe,prepareId));
    }
  }
}
",0,0,0,,
166,finally,"try {
  if (undoStartAt == null) {
    scanLog=(StreamLogScan)logFactory.openBackwardsScan(undoStopAt);
  }
 else {
    if (undoStartAt.lessThan(undoStopAt)) {
      return;
    }
    long undoStartInstant=((LogCounter)undoStartAt).getValueAsLong();
    scanLog=(StreamLogScan)logFactory.openBackwardsScan(undoStartInstant,undoStopAt);
  }
  if (SanityManager.DEBUG)   SanityManager.ASSERT(scanLog != null,""cannot open log for undo"");
  rawInput=new ArrayInputStream(new byte[4096]);
  LogRecord record;
  while ((record=scanLog.getNextRecord(rawInput,undoId,0)) != null) {
    if (SanityManager.DEBUG) {
      SanityManager.ASSERT(record.getTransactionId().equals(undoId),""getNextRecord return unqualified log record for undo"");
    }
    logrecordseen++;
    if (record.isCLR()) {
      clrskipped++;
      record.skipLoggable();
      long undoInstant=rawInput.readLong();
      if (SanityManager.DEBUG) {
        if (SanityManager.DEBUG_ON(LogToFile.DBG_FLAG)) {
          SanityManager.DEBUG(LogToFile.DBG_FLAG,""Skipping over CLRs, reset scan to "" + LogCounter.toDebugString(undoInstant));
        }
      }
      scanLog.resetPosition(new LogCounter(undoInstant));
      continue;
    }
    lop=record.getUndoable();
    if (lop != null) {
      int optionalDataLength=rawInput.readInt();
      int savePosition=rawInput.getPosition();
      rawInput.setLimit(optionalDataLength);
      compensation=lop.generateUndo(t,rawInput);
      if (SanityManager.DEBUG) {
        if (SanityManager.DEBUG_ON(LogToFile.DBG_FLAG)) {
          SanityManager.DEBUG(LogToFile.DBG_FLAG,""Rollback log record at instant "" + LogCounter.toDebugString(scanLog.getInstant()) + "" : ""+ lop);
        }
      }
      clrgenerated++;
      if (compensation != null) {
        rawInput.setLimit(savePosition,optionalDataLength);
        t.logAndUndo(compensation,new LogCounter(scanLog.getInstant()),rawInput);
        compensation.releaseResource(t);
        compensation=null;
      }
    }
  }
}
 catch (ClassNotFoundException cnfe) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_CORRUPTED,cnfe));
}
catch (IOException ioe) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_READ_LOG_FOR_UNDO,ioe));
}
catch (StandardException se) {
  throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_UNDO_FAILED,se,undoId,lop,compensation));
}
 finally {
  if (compensation != null) {
    compensation.releaseResource(t);
  }
  if (rawInput != null) {
    try {
      rawInput.close();
    }
 catch (    IOException ioe) {
      throw logFactory.markCorrupt(StandardException.newException(SQLState.LOG_READ_LOG_FOR_UNDO,ioe,undoId));
    }
  }
}
",0,0,0,,
167,finally,"try {
  if (approxLogLength > logSwitchInterval) {
    switchLogFile();
    logWrittenFromLastCheckPoint=0;
  }
 else {
    logWrittenFromLastCheckPoint=-endPosition;
  }
  if (SanityManager.DEBUG) {
    if (SanityManager.DEBUG_ON(TEST_LOG_SWITCH_LOG))     return false;
  }
  if (needCPTran)   cptran=tf.startInternalTransaction(rsf,getContextService().getCurrentContextManager());
  long undoLWM_long;
  long redoLWM_long;
synchronized (this) {
    redoLWM_long=currentInstant();
    redoLWM=new LogCounter(redoLWM_long);
    LogCounter undoLWM=(LogCounter)(tf.firstUpdateInstant());
    if (undoLWM == null)     undoLWM_long=redoLWM_long;
 else     undoLWM_long=undoLWM.getValueAsLong();
  }
  df.checkpoint();
  Formatable transactionTable=tf.getTransactionTable();
  CheckpointOperation nextCheckpoint=new CheckpointOperation(redoLWM_long,undoLWM_long,transactionTable);
  cptran.logAndDo(nextCheckpoint);
  LogCounter checkpointInstant=(LogCounter)(cptran.getLastLogInstant());
  if (checkpointInstant != null) {
    flush(checkpointInstant);
  }
 else {
    throw StandardException.newException(SQLState.LOG_CANNOT_LOG_CHECKPOINT);
  }
  cptran.commit();
  if (needCPTran) {
    cptran.close();
    cptran=null;
  }
  if (!writeControlFile(getControlFileName(),checkpointInstant.getValueAsLong())) {
    throw StandardException.newException(SQLState.LOG_CONTROL_FILE,getControlFileName());
  }
  currentCheckpoint=nextCheckpoint;
  if (!logArchived()) {
    truncateLog(currentCheckpoint);
  }
  if (!backupInProgress)   df.removeDroppedContainerFileStubs(redoLWM);
}
 catch (IOException ioe) {
  throw markCorrupt(StandardException.newException(SQLState.LOG_IO_ERROR,ioe));
}
 finally {
synchronized (this) {
    inCheckpoint=false;
    notifyAll();
  }
  if (cptran != null && needCPTran) {
    try {
      cptran.commit();
      cptran.close();
    }
 catch (    StandardException se) {
      throw markCorrupt(StandardException.newException(SQLState.LOG_CORRUPTED,se));
    }
  }
}
",0,0,0,,
168,finally,"try {
  return readArray(new InputStreamReader(inputStream,characterSetName));
}
 catch (UnsupportedEncodingException uee) {
  throw ToolUtilities.wrap(uee);
}
 finally {
  try {
    inputStream.close();
  }
 catch (  IOException ioe) {
    throw ToolUtilities.wrap(ioe);
  }
}
",0,0,0,,
169,} finally {,"try {
  closeSession();
}
 catch (Throwable t) {
  try {
    session.clientSocket.close();
  }
 catch (  IOException ioe) {
  }
}
 finally {
  throw error;
}
",0,0,0,,
170,finally {,"try {
  copyFileToFail(LOGFILESDIR);
  nullFields();
  deleteFile(LOGFILESDIR);
  copyFileToFail(""derby-0.log"");
  copyFileToFail(""derby-0.log.lck"");
  for (int i=0; i < 3; i++) {
    copyFileToFail(""db-"" + i + "".log"");
    deleteFile(""db-"" + i + "".log"");
  }
}
 catch (IOException ioe) {
  BaseTestCase.printStackTrace(ioe);
  if (stackOut != null) {
    stackOut.println(""Copying derby.log or database failed:"");
    ioe.printStackTrace(stackOut);
    stackOut.println();
  }
}
 finally {
  if (stackOut != null) {
    stackOut.close();
  }
  if (stopAfterFirstFail) {
    running.printStackTrace(out);
    System.exit(1);
  }
 else   throw running;
}
",0,0,0,,
171,} finally {,"try {
  statement=connection.createStatement();
  statement.execute(queryString);
}
 catch (SQLException e) {
  String sqlState=e.getSQLState();
  if (!ignoreExceptions.contains(sqlState)) {
    throw new TestFailedException(e);
  }
}
 finally {
  if (statement != null) {
    try {
      statement.close();
    }
 catch (    SQLException ee) {
      throw new TestFailedException(ee);
    }
  }
}
",0,0,0,,
172,} finally {,"try {
  rs=stmt.executeQuery();
  System.out.println(""Execute returned a ResultSet"");
  rs.close();
}
 catch (SQLException e) {
  throw new TestFailedException(""Should not happen"",e);
}
 finally {
  try {
    stmt.close();
  }
 catch (  SQLException e) {
    throw new TestFailedException(""close should not throw"",e);
  }
}
",0,0,0,,
173,} finally {,"try {
  String failPath=PrivilegedFileOpsForTests.getAbsolutePath(getFailureFolder());
  stackOut=new PrintWriter(PrivilegedFileOpsForTests.getFileOutputStream(new File(failPath,ERRORSTACKTRACEFILE),true));
  String[] replPaths=new String[]{masterDbSubPath,slaveDbSubPath};
  for (int i=0; i < 2; i++) {
    File origLog=new File(replPaths[i],DERBY_LOG);
    File newLog=new File(failPath,replPaths[i] + ""-"" + DERBY_LOG);
    PrivilegedFileOpsForTests.copy(origLog,newLog);
    String dbName=TestConfiguration.getCurrent().getDefaultDatabaseName();
    File dbDir=new File(replPaths[i],dbName);
    File newDbDir=new File(failPath,replPaths[i] + ""-"" + dbName);
    PrivilegedFileOpsForTests.copy(dbDir,newDbDir);
  }
}
 catch (IOException ioe) {
  BaseTestCase.printStackTrace(ioe);
  if (stackOut != null) {
    stackOut.println(""Copying db_slave/db_master's "" + DERBY_LOG + "" or database failed:"");
    ioe.printStackTrace(stackOut);
    stackOut.println();
  }
}
 finally {
  if (stackOut != null) {
    stackOut.close();
  }
  throw running;
}
",0,0,0,,
174,finally,"try {
  int value;
  Statement s=DriverManager.getConnection(""jdbc:default:connection"").createStatement();
  rs=s.executeQuery(""SELECT s FROM t1"");
  if (rs.next()) {
    System.out.println(""Value of t1.s is "" + rs.getShort(1));
  }
}
 catch (SQLException se) {
  if (!se.getSQLState().equals(""38001"")) {
    throw new ExceptionInInitializerError(se);
  }
}
 finally {
  try {
    if (rs != null)     rs.close();
  }
 catch (  SQLException se) {
    if (!se.getSQLState().equals(""38001"")) {
      throw new ExceptionInInitializerError(se);
    }
  }
}
",0,0,0,,
175,finally,"try {
  int value;
  Statement s=DriverManager.getConnection(""jdbc:default:connection"").createStatement();
  boolean b=s.execute(""INSERT into t1 values (1)"");
}
 catch (SQLException se) {
  if (!se.getSQLState().equals(""38001"")) {
    throw new ExceptionInInitializerError(se);
  }
}
 finally {
  try {
    if (rs != null)     rs.close();
  }
 catch (  SQLException se) {
    if (!se.getSQLState().equals(""38001""))     throw new ExceptionInInitializerError(se);
  }
}
",0,0,0,,
176,finally {,"try {
  String failPath=PrivilegedFileOpsForTests.getAbsolutePath(getFailureFolder());
  stackOut=new PrintWriter(PrivilegedFileOpsForTests.getFileOutputStream(new File(failPath,ERRORSTACKTRACEFILE),true));
  stackOut.println(""[Error/failure logged at "" + new java.util.Date() + ""]"");
  running.printStackTrace(stackOut);
  stackOut.println();
  File origLog=new File(DEFAULT_DB_DIR,DERBY_LOG);
  File newLog=new File(failPath,DERBY_LOG);
  PrivilegedFileOpsForTests.copy(origLog,newLog);
  for (int i=0; i < 10; i++) {
    String logName=""derby-"" + i + "".log"";
    File origRolLog=new File(DEFAULT_DB_DIR,logName);
    File newRolLog=new File(failPath,logName);
    PrivilegedFileOpsForTests.copy(origRolLog,newRolLog);
  }
  String dbName=TestConfiguration.getCurrent().getDefaultDatabaseName();
  File dbDir=new File(DEFAULT_DB_DIR,dbName);
  File newDbDir=new File(failPath,dbName);
  PrivilegedFileOpsForTests.copy(dbDir,newDbDir);
}
 catch (IOException ioe) {
  BaseTestCase.printStackTrace(ioe);
  if (stackOut != null) {
    stackOut.println(""Copying derby.log or database failed:"");
    ioe.printStackTrace(stackOut);
    stackOut.println();
  }
}
 finally {
  if (stackOut != null) {
    stackOut.close();
  }
  if (stopAfterFirstFail) {
    running.printStackTrace(out);
    System.exit(1);
  }
 else   throw running;
}
",0,0,0,,
177,finally,"try {
  List<Modification> mods=new ArrayList<Modification>();
  if (StringUtils.isNotEmpty(entity.getDescription())) {
    mods.add(new DefaultModification(ModificationOperation.REPLACE_ATTRIBUTE,SchemaConstants.DESCRIPTION_AT,entity.getDescription()));
  }
  if (entity.isTemporalSet()) {
    String szRawData=ConstraintUtil.setConstraint(entity);
    if (StringUtils.isNotEmpty(szRawData)) {
      mods.add(new DefaultModification(ModificationOperation.REPLACE_ATTRIBUTE,GlobalIds.CONSTRAINT,szRawData));
    }
  }
  loadAttrs(entity.getParents(),mods,GlobalIds.PARENT_NODES);
  if (IS_RFC2307 && StringUtils.isNotEmpty(entity.getGidNumber())) {
    mods.add(new DefaultModification(ModificationOperation.REPLACE_ATTRIBUTE,GlobalIds.GID_NUMBER,entity.getGidNumber()));
  }
  if (mods.size() > 0) {
    ld=getAdminConnection();
    modify(ld,dn,mods,entity);
  }
}
 catch (LdapException e) {
  String error=""update name ["" + entity.getName() + ""] caught LdapException=""+ e;
  throw new UpdateException(GlobalErrIds.ROLE_UPDATE_FAILED,error,e);
}
catch (Exception e) {
  String error=""update name ["" + entity.getName() + ""] caught LdapException=""+ e.getMessage();
  throw new UpdateException(GlobalErrIds.ROLE_UPDATE_FAILED,error,e);
}
 finally {
  try {
    closeAdminConnection(ld);
  }
 catch (  Exception e) {
    String error=""update name ["" + entity.getName() + ""] caught LdapException=""+ e;
    throw new UpdateException(GlobalErrIds.ROLE_UPDATE_FAILED,error,e);
  }
}
",0,0,0,,
178,} finally {,"try {
  writer=new FileWriterWithEncoding(cacheFile,StandardCharsets.UTF_8);
  writer.write(token);
  writer.flush();
  cacheFile.setReadable(false,false);
  cacheFile.setReadable(true,true);
  if (!cacheFile.setWritable(true,true)) {
    throw new KrbException(""Cache file is not readable."");
  }
}
 catch (IOException ioe) {
  if (cacheFile.delete()) {
    System.err.println(""Cache file is deleted."");
  }
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    IOException e) {
      throw new KrbException(e.getMessage());
    }
  }
}
",0,0,0,,
179,} finally {,"try {
  while ((tempString=reader.readLine()) != null) {
    sb.append(tempString);
  }
}
 catch (IOException e1) {
  throw new HasException(""Failed to read file. "" + e1.getMessage());
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException e) {
    throw new HasException(e.getMessage());
  }
}
",0,0,0,,
180,} finally {,"try {
  trustStore=KeyStore.getInstance(""JKS"");
  in=new FileInputStream(truststoreFile);
  trustStore.load(in,truststoreSecret.toCharArray());
}
 catch (Exception e2) {
  throw new HasException(""Failed to get truststore from the file: "" + truststoreFile + "". ""+ e2.getMessage());
}
 finally {
  if (in != null) {
    try {
      in.close();
    }
 catch (    IOException e) {
      throw new HasException(e.getMessage());
    }
  }
}
",0,0,0,,
181,} finally {,"try {
  while ((tempString=reader.readLine()) != null) {
    sb.append(tempString);
  }
}
 catch (IOException e) {
  throw new HasException(""Failed to read file: "" + e.getMessage());
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException e) {
    throw new HasException(e.getMessage());
  }
}
",0,0,0,,
182,} finally {,"try {
  while ((tempString=reader.readLine()) != null) {
    sb.append(tempString);
  }
}
 catch (IOException e) {
  throw new KrbException(""Errors occurred when read line. "",e);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException e) {
    throw new KrbException(e.getMessage());
  }
}
",0,0,0,,
183,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
184,finally,"try {
  oIn=new ObjectInputStream(in);
  DefaultAttribute value=new DefaultAttribute(at);
  value.readExternal(oIn);
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
185,finally,"try {
  oOut=new ObjectOutputStream(out);
  oOut.writeObject(value);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
186,finally,"try {
  oIn=new ObjectInputStream(in);
  Entry value=(Entry)oIn.readObject();
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
187,finally,"try {
  oOut=new ObjectOutputStream(out);
  modification.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
188,finally,"try {
  oIn=new ObjectInputStream(in);
  Modification modification=new DefaultModification();
  modification.readExternal(oIn);
  Attribute attribute=modification.getAttribute();
  if ((attribute != null) && (schemaManager != null)) {
    AttributeType attributeType=schemaManager.getAttributeType(attribute.getId());
    modification.apply(attributeType);
  }
  return modification;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
189,finally,"try {
  if (!wasConnected) {
    connection.connect();
  }
  Entry rootDse=connection.lookup(Dn.ROOT_DSE,SchemaConstants.SUBSCHEMA_SUBENTRY_AT,SchemaConstants.VENDOR_NAME_AT);
  if (rootDse != null) {
    if (isApacheDs(rootDse)) {
      Attribute subschemaSubentryAttribute=rootDse.get(SchemaConstants.SUBSCHEMA_SUBENTRY_AT);
      if ((subschemaSubentryAttribute != null) && (subschemaSubentryAttribute.size() > 0)) {
        subschemaSubentryDn=new Dn(connection.getSchemaManager(),subschemaSubentryAttribute.getString());
        loadSchemas();
      }
    }
 else {
      try {
        Attribute subschemaSubentryAttribute=rootDse.get(SchemaConstants.SUBSCHEMA_SUBENTRY_AT);
        if ((subschemaSubentryAttribute != null) && (subschemaSubentryAttribute.size() > 0)) {
          subschemaSubentryDn=new Dn(connection.getSchemaManager(),subschemaSubentryAttribute.getString());
          loadSchemas();
        }
      }
 catch (      LdapException le) {
        throw le;
      }
    }
  }
}
  finally {
  if ((!wasConnected) && (connection.isConnected())) {
    try {
      connection.close();
    }
 catch (    IOException e) {
      throw new LdapException(e);
    }
  }
}
",0,0,0,,
190,finally,"try {
  readLines();
  Attributes attributes=parseAttributes();
  if (LOG.isDebugEnabled()) {
    if (attributes == null) {
      LOG.debug(I18n.msg(I18n.MSG_13401_PARSED_NO_ENTRY));
    }
 else {
      LOG.debug(I18n.msg(I18n.MSG_13402_PARSED_ONE_ENTRY));
    }
  }
  return attributes;
}
 catch (LdapLdifException ne) {
  LOG.error(I18n.err(I18n.ERR_13403_CANNOT_PARSE_LDIF_BUFFER,ne.getLocalizedMessage()));
  throw new LdapLdifException(I18n.err(I18n.ERR_13442_ERROR_PARSING_LDIF_BUFFER),ne);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException ioe) {
    throw new LdapLdifException(I18n.err(I18n.ERR_13450_CANNOT_CLOSE_FILE),ioe);
  }
}
",0,0,0,,
191,finally,"try {
  readLines();
  Entry entry=parseEntry((SchemaManager)null);
  if (LOG.isDebugEnabled()) {
    if (entry == null) {
      LOG.debug(I18n.msg(I18n.MSG_13401_PARSED_NO_ENTRY));
    }
 else {
      LOG.debug(I18n.msg(I18n.MSG_13402_PARSED_ONE_ENTRY));
    }
  }
  return entry;
}
 catch (LdapLdifException ne) {
  LOG.error(I18n.err(I18n.ERR_13403_CANNOT_PARSE_LDIF_BUFFER,ne.getLocalizedMessage()));
  throw new LdapLdifException(I18n.err(I18n.ERR_13442_ERROR_PARSING_LDIF_BUFFER),ne);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException ioe) {
    throw new LdapLdifException(I18n.err(I18n.ERR_13450_CANNOT_CLOSE_FILE),ioe);
  }
}
",0,0,0,,
192,finally,"try {
  readLines();
  Entry entry=parseEntry(schemaManager);
  if (LOG.isDebugEnabled()) {
    if (entry == null) {
      LOG.debug(I18n.msg(I18n.MSG_13401_PARSED_NO_ENTRY));
    }
 else {
      LOG.debug(I18n.msg(I18n.MSG_13402_PARSED_ONE_ENTRY));
    }
  }
  return entry;
}
 catch (LdapLdifException ne) {
  LOG.error(I18n.err(I18n.ERR_13403_CANNOT_PARSE_LDIF_BUFFER,ne.getLocalizedMessage()));
  throw new LdapLdifException(I18n.err(I18n.ERR_13442_ERROR_PARSING_LDIF_BUFFER),ne);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException ioe) {
    throw new LdapLdifException(I18n.err(I18n.ERR_13450_CANNOT_CLOSE_FILE),ioe);
  }
}
",0,0,0,,
193,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
194,finally,"try {
  oIn=new ObjectInputStream(in);
  DefaultAttribute value=new DefaultAttribute();
  value.readExternal(oIn);
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
195,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
196,finally,"try {
  oIn=new ObjectInputStream(in);
  Value value=Value.createValue((AttributeType)null);
  value.readExternal(oIn);
  return value;
}
  finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
197,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
198,finally,"try {
  oIn=new ObjectInputStream(in);
  Value value=Value.createValue(at);
  value.readExternal(oIn);
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
199,finally,"try {
  oOut=new ObjectOutputStream(out);
  modification.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
200,finally,"try {
  Modification modification=new DefaultModification();
  oIn=new ObjectInputStream(in);
  modification.readExternal(oIn);
  return modification;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
201,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
202,finally,"try {
  oIn=new ObjectInputStream(in);
  Value value=Value.createValue(at);
  value.readExternal(oIn);
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
203,finally,"try {
  oIn=new ObjectInputStream(in);
  Value value=Value.createValue(at);
  value.readExternal(oIn);
  return value;
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oIn != null) {
      oIn.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
204,finally,"try {
  this.reader=reader;
  version=parseVersion();
  return parseEntry();
}
 catch (LdapLdifException ne) {
  LOG.error(I18n.err(I18n.ERR_12069,ne.getLocalizedMessage()));
  throw new LdapLdifException(I18n.err(I18n.ERR_12070),ne);
}
catch (LdapException le) {
  throw new LdapLdifException(le.getMessage(),le);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException ioe) {
    throw new LdapLdifException(I18n.err(I18n.ERR_13450_CANNOT_CLOSE_FILE),ioe);
  }
}
",0,0,0,,
205,finally,"try {
  doInit();
  initialized=true;
}
 catch (Exception e) {
  throw new LdapOtherException(e.getMessage(),e);
}
 finally {
  if (!initialized) {
    try {
      destroy(null);
    }
 catch (    Exception e) {
      throw new LdapOtherException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
206,finally,"try {
  oOut=new ObjectOutputStream(out);
  value.writeExternal(oOut);
  oOut.flush();
}
 catch (IOException ioe) {
  throw ioe;
}
 finally {
  try {
    if (oOut != null) {
      oOut.flush();
      oOut.close();
    }
  }
 catch (  IOException ioe) {
    throw ioe;
  }
}
",0,0,0,,
207,finally,"try {
  LOG.warn(PARTIAL_IMPL_WARNING);
  cursor.afterLast();
  while (cursor.previous()) {
    ChangeLogEvent event=cursor.get();
    List<LdifEntry> reverses=event.getReverseLdifs();
    for (    LdifEntry reverse : reverses) {
switch (reverse.getChangeType().getChangeType()) {
case ChangeType.ADD_ORDINAL:
        adminSession.add(new DefaultEntry(schemaManager,reverse.getEntry()),true);
      break;
case ChangeType.DELETE_ORDINAL:
    adminSession.delete(reverse.getDn(),true);
  break;
case ChangeType.MODIFY_ORDINAL:
List<Modification> mods=reverse.getModifications();
adminSession.modify(reverse.getDn(),mods,true);
break;
case ChangeType.MODDN_ORDINAL:
case ChangeType.MODRDN_ORDINAL:
Dn forwardDn=event.getForwardLdif().getDn();
Dn reverseDn=reverse.getDn();
moddn(reverseDn,forwardDn,reverse.isDeleteOldRdn());
break;
default :
LOG.error(I18n.err(I18n.ERR_75));
throw new NotImplementedException(I18n.err(I18n.ERR_76,reverse.getChangeType()));
}
}
adminSession.endSessionTransaction(true);
}
}
 catch (Exception e) {
try {
adminSession.endSessionTransaction(false);
}
 catch (IOException ioe) {
throw new LdapOperationException(ioe.getMessage(),ioe);
}
throw new LdapOperationException(e.getMessage(),e);
}
 finally {
try {
cursor.close();
}
 catch (Exception e) {
throw new LdapOperationException(e.getMessage(),e);
}
}
",0,0,0,,
208,finally,"try {
  partitionTxn=partition.beginReadTransaction();
  renameContext.setTransaction(partitionTxn);
  eagerlyPopulateFields(renameContext);
}
  finally {
  try {
    if (partitionTxn != null) {
      partitionTxn.close();
    }
  }
 catch (  IOException ioe) {
    throw new LdapOtherException(ioe.getMessage(),ioe);
  }
}
",0,0,0,,
209,finally,"try {
  Dn baseDn=new Dn(opContext.getSession().getDirectoryService().getSchemaManager(),entryName.getRdn(entryName.size() - 1));
  SearchOperationContext searchContext=new SearchOperationContext(opContext.getSession(),baseDn,childrenFilter,childrenSearchControls);
  searchContext.setAliasDerefMode(AliasDerefMode.DEREF_ALWAYS);
  searchContext.setPartition(opContext.getPartition());
  searchContext.setTransaction(opContext.getTransaction());
  results=opContext.getSession().getDirectoryService().getPartitionNexus().search(searchContext);
  try {
    while (results.next()) {
      results.get();
      cnt++;
    }
  }
 catch (  Exception e) {
    throw new LdapOtherException(e.getMessage(),e);
  }
}
  finally {
  if (results != null) {
    try {
      results.close();
    }
 catch (    Exception e) {
      throw new LdapOperationException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
210,finally,"try {
  try (PartitionTxn partitionTxn=configPartition.beginReadTransaction()){
    SearchOperationContext searchContext=new SearchOperationContext(null);
    searchContext.setAliasDerefMode(AliasDerefMode.NEVER_DEREF_ALIASES);
    searchContext.setDn(baseDn);
    searchContext.setFilter(filter);
    searchContext.setScope(scope);
    searchContext.setPartition(configPartition);
    searchContext.setTransaction(partitionTxn);
    PartitionSearchResult searchResult=se.computeResult(partitionTxn,schemaManager,searchContext);
    cursor=searchResult.getResultSet();
    if (!cursor.next()) {
      if (mandatory) {
        cursor.close();
        String message=""No instance was configured under the DN '"" + baseDn + ""' for the objectClass '""+ name+ ""'."";
        LOG.error(message);
        throw new ConfigurationException(message);
      }
 else {
        return null;
      }
    }
    do {
      IndexEntry<String,String> forwardEntry=cursor.get();
      Entry entry=configPartition.fetch(partitionTxn,forwardEntry.getId());
      LOG.debug(""Entry read : {}"",entry);
      AdsBaseBean bean=readConfig(entry);
      beansList.add(bean);
    }
 while (cursor.next());
  }
 }
 catch (ConfigurationException ce) {
  throw ce;
}
catch (Exception e) {
  String message=""An error occured while reading the configuration DN '"" + baseDn + ""' for the objectClass '""+ name+ ""':\n""+ e.getMessage();
  LOG.error(message);
  throw new ConfigurationException(message,e);
}
 finally {
  if (cursor != null) {
    try {
      cursor.close();
    }
 catch (    Exception e) {
      throw new ConfigurationException(e.getMessage(),e.getCause());
    }
  }
}
",0,0,0,,
211,} finally {,"try {
  return Collectors.toList(threadPool.invokeAll(tasks,timeout,TimeUnit.MILLISECONDS),futureMapper);
}
 catch (InterruptedException e) {
  final String errMsg=String.format(""Interrupted while waiting for activity '%s' tasks to be done."",activity);
  logger.error(errMsg,e);
  throw UserException.resourceError(e).message(errMsg).build(logger);
}
catch (RejectedExecutionException e) {
  final String errMsg=String.format(""Failure while submitting activity '%s' tasks for execution."",activity);
  logger.error(errMsg,e);
  throw UserException.internalError(e).message(errMsg).build(logger);
}
 finally {
  List<Runnable> notStartedTasks=threadPool.shutdownNow();
  if (!notStartedTasks.isEmpty()) {
    logger.error(""{} activity '{}' tasks never commenced execution."",notStartedTasks.size(),activity);
  }
  try {
    if (!threadPool.awaitTermination(5000,TimeUnit.MILLISECONDS)) {
      logger.error(""Detected run away tasks in activity '{}'."",activity);
    }
  }
 catch (  final InterruptedException e) {
    logger.warn(""Interrupted while waiting for pending threads in activity '{}' to terminate."",activity);
  }
  if (statistics != null) {
    statistics.collect(tasks).log(activity,logger,parallelism);
  }
  if (futureMapper.count != tasks.size()) {
    final String errMsg=String.format(""Waited for %d ms, but only %d tasks for '%s' are complete."" + "" Total number of tasks %d, parallelism %d."",timeout,futureMapper.count,activity,tasks.size(),parallelism);
    logger.error(errMsg,futureMapper.throwable);
    throw UserException.resourceError(futureMapper.throwable).message(errMsg).build(logger);
  }
  if (futureMapper.throwable != null) {
    throw (futureMapper.throwable instanceof IOException) ? (IOException)futureMapper.throwable : new IOException(futureMapper.throwable);
  }
}
",0,0,0,,
212,finally {,"try {
  log.info(""Renaming jar to path[%s]"",hdfsPath);
  fs.rename(intermediateHdfsPath,hdfsPath);
  if (!fs.exists(hdfsPath)) {
    throw new IOE(""File does not exist even after moving from[%s] to [%s]"",intermediateHdfsPath,hdfsPath);
  }
}
 catch (IOException e) {
  try {
    if (!fs.exists(hdfsPath)) {
      log.error(e,""IOException while Renaming jar file"");
      exception=e;
    }
  }
 catch (  IOException e1) {
    e.addSuppressed(e1);
    exception=e;
  }
}
 finally {
  try {
    if (fs.exists(intermediateHdfsPath)) {
      fs.delete(intermediateHdfsPath,false);
    }
  }
 catch (  IOException e) {
    if (exception == null) {
      exception=e;
    }
 else {
      exception.addSuppressed(e);
    }
  }
  if (exception != null) {
    throw exception;
  }
}
",0,0,0,,
213,finally {,"try {
  new File(baseDir,""dir1"").mkdir();
  new File(baseDir,""dir1/file1"").createNewFile();
  new File(baseDir,""dir1/file2"").createNewFile();
  new File(baseDir,""dir2/subDir1"").mkdirs();
  new File(baseDir,""dir2/subDir1/file3"").createNewFile();
  new File(baseDir,""dir2/subDir2"").mkdirs();
  new File(baseDir,""dir2/subDir2/file4"").createNewFile();
  new File(baseDir,""dir2/subDir2/file5"").createNewFile();
  List<String> files=Lists.newArrayList(Iterables.transform(FSSpideringIterator.spiderIterable(FileSystem.getLocal(new Configuration()),new Path(baseDir.toString())),new Function<FileStatus,String>(){
    @Override public String apply(    @Nullable FileStatus input){
      return input.getPath().getName();
    }
  }
));
  for (  String testFile : testFiles) {
    Assert.assertTrue(files.remove(testFile));
  }
  Assert.assertTrue(files.isEmpty());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    FileUtils.deleteDirectory(baseDir);
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
214,finally {,"try {
  new File(baseDir,""dir1"").mkdir();
  new File(baseDir,""dir2/subDir1"").mkdirs();
  new File(baseDir,""dir2/subDir2"").mkdirs();
  new File(baseDir,""dir3/subDir1"").mkdirs();
  List<String> files=Lists.newArrayList(Iterables.transform(FSSpideringIterator.spiderIterable(FileSystem.getLocal(new Configuration()),new Path(baseDir.toString())),new Function<FileStatus,String>(){
    @Override public String apply(    @Nullable FileStatus input){
      return input.getPath().getName();
    }
  }
));
  Assert.assertTrue(files.isEmpty());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    FileUtils.deleteDirectory(baseDir);
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
215,finally {,"try {
  toolbox.getDataSegmentServerAnnouncer().announce();
  toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);
  plumber.startJob();
  toolbox.addMonitor(metricsMonitor);
  final FirehoseFactory firehoseFactory=spec.getIOConfig().getFirehoseFactory();
  final boolean firehoseDrainableByClosing=isFirehoseDrainableByClosing(firehoseFactory);
synchronized (this) {
    if (!gracefullyStopped) {
      firehose=firehoseFactory.connect(Preconditions.checkNotNull(spec.getDataSchema().getParser(),""inputRowParser""),toolbox.getIndexingTmpDir());
    }
  }
  while (firehose != null && (!gracefullyStopped || firehoseDrainableByClosing) && firehose.hasMore()) {
    Plumbers.addNextRow(committerSupplier,firehose,plumber,tuningConfig.isReportParseExceptions(),metrics);
  }
}
 catch (Throwable e) {
  normalExit=false;
  log.makeAlert(e,""Exception aborted realtime processing[%s]"",dataSchema.getDataSource()).emit();
  throw e;
}
 finally {
  if (normalExit) {
    try {
      if (firehose != null) {
        log.info(""Persisting remaining data."");
        final Committer committer=committerSupplier.get();
        final CountDownLatch persistLatch=new CountDownLatch(1);
        plumber.persist(new Committer(){
          @Override public Object getMetadata(){
            return committer.getMetadata();
          }
          @Override public void run(){
            try {
              committer.run();
            }
  finally {
              persistLatch.countDown();
            }
          }
        }
);
        persistLatch.await();
      }
      if (gracefullyStopped) {
        log.info(""Gracefully stopping."");
      }
 else {
        log.info(""Finishing the job."");
synchronized (this) {
          if (gracefullyStopped) {
            log.info(""Gracefully stopping."");
          }
 else {
            finishingJob=true;
          }
        }
        if (finishingJob) {
          plumber.finishJob();
        }
      }
    }
 catch (    InterruptedException e) {
      log.debug(e,""Interrupted while finishing the job"");
    }
catch (    Exception e) {
      log.makeAlert(e,""Failed to finish realtime task"").emit();
      throw e;
    }
 finally {
      if (firehose != null) {
        CloseQuietly.close(firehose);
      }
      toolbox.removeMonitor(metricsMonitor);
    }
  }
  toolbox.getDataSegmentServerAnnouncer().unannounce();
  toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);
}
",0,0,0,,
216,finally {,"try {
  while (stillReading) {
    if (possiblyPause()) {
      assignment=assignPartitions(recordSupplier);
      possiblyResetDataSourceMetadata(toolbox,recordSupplier,assignment);
      if (assignment.isEmpty()) {
        log.debug(""All partitions have been fully read."");
        publishOnStop.set(true);
        stopRequested.set(true);
      }
    }
    if (stopRequested.get() || sequences.size() == 0 || getLastSequenceMetadata().isCheckpointed()) {
      status=Status.PUBLISHING;
    }
    if (stopRequested.get()) {
      break;
    }
    if (backgroundThreadException != null) {
      throw new RuntimeException(backgroundThreadException);
    }
    checkPublishAndHandoffFailure();
    maybePersistAndPublishSequences(committerSupplier);
    List<OrderedPartitionableRecord<PartitionIdType,SequenceOffsetType,RecordType>> records=getRecords(recordSupplier,toolbox);
    stillReading=!assignment.isEmpty();
    SequenceMetadata<PartitionIdType,SequenceOffsetType> sequenceToCheckpoint=null;
    for (    OrderedPartitionableRecord<PartitionIdType,SequenceOffsetType,RecordType> record : records) {
      final boolean shouldProcess=verifyRecordInRange(record.getPartitionId(),record.getSequenceNumber());
      log.trace(""Got stream[%s] partition[%s] sequenceNumber[%s], shouldProcess[%s]."",record.getStream(),record.getPartitionId(),record.getSequenceNumber(),shouldProcess);
      if (shouldProcess) {
        final List<InputRow> rows=parser.parse(record.getData(),isEndOfShard(record.getSequenceNumber()));
        boolean isPersistRequired=false;
        final SequenceMetadata<PartitionIdType,SequenceOffsetType> sequenceToUse=sequences.stream().filter(sequenceMetadata -> sequenceMetadata.canHandle(this,record)).findFirst().orElse(null);
        if (sequenceToUse == null) {
          throw new ISE(""Cannot find any valid sequence for record with partition [%s] and sequenceNumber [%s]. Current sequences: %s"",record.getPartitionId(),record.getSequenceNumber(),sequences);
        }
        for (        InputRow row : rows) {
          final AppenderatorDriverAddResult addResult=driver.add(row,sequenceToUse.getSequenceName(),committerSupplier,true,false);
          if (addResult.isOk()) {
            final boolean isPushRequired=addResult.isPushRequired(tuningConfig.getPartitionsSpec().getMaxRowsPerSegment(),tuningConfig.getPartitionsSpec().getMaxTotalRowsOr(DynamicPartitionsSpec.DEFAULT_MAX_TOTAL_ROWS));
            if (isPushRequired && !sequenceToUse.isCheckpointed()) {
              sequenceToCheckpoint=sequenceToUse;
            }
            isPersistRequired|=addResult.isPersistRequired();
          }
 else {
            throw new ISE(""Could not allocate segment for row with timestamp[%s]"",row.getTimestamp());
          }
        }
        if (isPersistRequired) {
          Futures.addCallback(driver.persistAsync(committerSupplier.get()),new FutureCallback<Object>(){
            @Override public void onSuccess(            @Nullable Object result){
              log.debug(""Persist completed with metadata: %s"",result);
            }
            @Override public void onFailure(            Throwable t){
              log.error(""Persist failed, dying"");
              backgroundThreadException=t;
            }
          }
);
        }
        lastReadOffsets.put(record.getPartitionId(),record.getSequenceNumber());
        currOffsets.put(record.getPartitionId(),getNextStartOffset(record.getSequenceNumber()));
      }
      final boolean moreToReadAfterThisRecord=isMoreToReadAfterReadingRecord(record.getSequenceNumber(),endOffsets.get(record.getPartitionId()));
      if (!moreToReadAfterThisRecord && assignment.remove(record.getStreamPartition())) {
        log.info(""Finished reading stream[%s], partition[%s]."",record.getStream(),record.getPartitionId());
        recordSupplier.assign(assignment);
        stillReading=!assignment.isEmpty();
      }
    }
    if (!stillReading) {
      fireDepartmentMetrics.markProcessingDone();
    }
    if (System.currentTimeMillis() > nextCheckpointTime) {
      sequenceToCheckpoint=getLastSequenceMetadata();
    }
    if (sequenceToCheckpoint != null && stillReading) {
      Preconditions.checkArgument(getLastSequenceMetadata().getSequenceName().equals(sequenceToCheckpoint.getSequenceName()),""Cannot checkpoint a sequence [%s] which is not the latest one, sequences %s"",sequenceToCheckpoint,sequences);
      requestPause();
      final CheckPointDataSourceMetadataAction checkpointAction=new CheckPointDataSourceMetadataAction(task.getDataSource(),ioConfig.getTaskGroupId(),null,createDataSourceMetadata(new SeekableStreamStartSequenceNumbers<>(stream,sequenceToCheckpoint.getStartOffsets(),sequenceToCheckpoint.getExclusiveStartPartitions())));
      if (!toolbox.getTaskActionClient().submit(checkpointAction)) {
        throw new ISE(""Checkpoint request with sequences [%s] failed, dying"",currOffsets);
      }
    }
  }
  ingestionState=IngestionState.COMPLETED;
}
 catch (Exception e) {
  caughtExceptionInner=e;
  log.error(e,""Encountered exception in run() before persisting."");
  throw e;
}
 finally {
  try {
    driver.persist(committerSupplier.get());
  }
 catch (  Exception e) {
    if (caughtExceptionInner != null) {
      caughtExceptionInner.addSuppressed(e);
    }
 else {
      throw e;
    }
  }
}
",0,0,0,,
217,finally {,"try (final RecordSupplier<PartitionIdType,SequenceOffsetType,RecordType> recordSupplier=task.newTaskRecordSupplier()){
  if (toolbox.getAppenderatorsManager().shouldTaskMakeNodeAnnouncements()) {
    toolbox.getDataSegmentServerAnnouncer().announce();
    toolbox.getDruidNodeAnnouncer().announce(discoveryDruidNode);
  }
  appenderator=task.newAppenderator(toolbox,fireDepartmentMetrics,rowIngestionMeters,parseExceptionHandler);
  driver=task.newDriver(appenderator,toolbox,fireDepartmentMetrics);
  final Object restoredMetadata=driver.startJob(segmentId -> {
    try {
      if (lockGranularityToUse == LockGranularity.SEGMENT) {
        return toolbox.getTaskActionClient().submit(new SegmentLockAcquireAction(TaskLockType.EXCLUSIVE,segmentId.getInterval(),segmentId.getVersion(),segmentId.getShardSpec().getPartitionNum(),1000L)).isOk();
      }
 else {
        return toolbox.getTaskActionClient().submit(new TimeChunkLockAcquireAction(TaskLockType.EXCLUSIVE,segmentId.getInterval(),1000L)) != null;
      }
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
);
  if (restoredMetadata == null) {
    Preconditions.checkState(sequences.get(0).startOffsets.entrySet().stream().allMatch(partitionOffsetEntry -> createSequenceNumber(partitionOffsetEntry.getValue()).compareTo(createSequenceNumber(ioConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(partitionOffsetEntry.getKey()))) >= 0),""Sequence sequences are not compatible with start sequences of task"");
    currOffsets.putAll(sequences.get(0).startOffsets);
  }
 else {
    @SuppressWarnings(""unchecked"") final Map<String,Object> restoredMetadataMap=(Map)restoredMetadata;
    final SeekableStreamEndSequenceNumbers<PartitionIdType,SequenceOffsetType> restoredNextPartitions=deserializePartitionsFromMetadata(toolbox.getJsonMapper(),restoredMetadataMap.get(METADATA_NEXT_PARTITIONS));
    currOffsets.putAll(restoredNextPartitions.getPartitionSequenceNumberMap());
    if (!restoredNextPartitions.getStream().equals(ioConfig.getStartSequenceNumbers().getStream())) {
      throw new ISE(""Restored stream[%s] but expected stream[%s]"",restoredNextPartitions.getStream(),ioConfig.getStartSequenceNumbers().getStream());
    }
    if (!currOffsets.keySet().equals(ioConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().keySet())) {
      throw new ISE(""Restored partitions[%s] but expected partitions[%s]"",currOffsets.keySet(),ioConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().keySet());
    }
    if (sequences.size() == 0 || getLastSequenceMetadata().isCheckpointed()) {
      this.endOffsets.putAll(sequences.size() == 0 ? currOffsets : getLastSequenceMetadata().getEndOffsets());
    }
  }
  log.info(""Initialized sequences: %s"",sequences.stream().map(SequenceMetadata::toString).collect(Collectors.joining("", "")));
  int numPreFilterPartitions=currOffsets.size();
  if (currOffsets.entrySet().removeIf(x -> isEndOfShard(x.getValue()))) {
    log.info(""Removed [%d] partitions from assignment which have already been closed."",numPreFilterPartitions - currOffsets.size());
  }
  if (!isEndOffsetExclusive()) {
    for (    Map.Entry<PartitionIdType,SequenceOffsetType> entry : currOffsets.entrySet()) {
      final boolean isAtStart=entry.getValue().equals(ioConfig.getStartSequenceNumbers().getPartitionSequenceNumberMap().get(entry.getKey()));
      if (!isAtStart || ioConfig.getStartSequenceNumbers().getExclusivePartitions().contains(entry.getKey())) {
        lastReadOffsets.put(entry.getKey(),entry.getValue());
      }
    }
  }
  final Supplier<Committer> committerSupplier=() -> {
    final Map<PartitionIdType,SequenceOffsetType> snapshot=ImmutableMap.copyOf(currOffsets);
    lastPersistedOffsets.clear();
    lastPersistedOffsets.putAll(snapshot);
    return new Committer(){
      @Override public Object getMetadata(){
        return ImmutableMap.of(METADATA_NEXT_PARTITIONS,new SeekableStreamEndSequenceNumbers<>(stream,snapshot));
      }
      @Override public void run(){
      }
    }
;
  }
;
  maybePersistAndPublishSequences(committerSupplier);
  Set<StreamPartition<PartitionIdType>> assignment=assignPartitions(recordSupplier);
  possiblyResetDataSourceMetadata(toolbox,recordSupplier,assignment);
  seekToStartingSequence(recordSupplier,assignment);
  ingestionState=IngestionState.BUILD_SEGMENTS;
  boolean stillReading=!assignment.isEmpty();
  status=Status.READING;
  Throwable caughtExceptionInner=null;
  try {
    while (stillReading) {
      if (possiblyPause()) {
        assignment=assignPartitions(recordSupplier);
        possiblyResetDataSourceMetadata(toolbox,recordSupplier,assignment);
        if (assignment.isEmpty()) {
          log.debug(""All partitions have been fully read."");
          publishOnStop.set(true);
          stopRequested.set(true);
        }
      }
      if (stopRequested.get() || sequences.size() == 0 || getLastSequenceMetadata().isCheckpointed()) {
        status=Status.PUBLISHING;
      }
      if (stopRequested.get()) {
        break;
      }
      if (backgroundThreadException != null) {
        throw new RuntimeException(backgroundThreadException);
      }
      checkPublishAndHandoffFailure();
      maybePersistAndPublishSequences(committerSupplier);
      List<OrderedPartitionableRecord<PartitionIdType,SequenceOffsetType,RecordType>> records=getRecords(recordSupplier,toolbox);
      stillReading=!assignment.isEmpty();
      SequenceMetadata<PartitionIdType,SequenceOffsetType> sequenceToCheckpoint=null;
      for (      OrderedPartitionableRecord<PartitionIdType,SequenceOffsetType,RecordType> record : records) {
        final boolean shouldProcess=verifyRecordInRange(record.getPartitionId(),record.getSequenceNumber());
        log.trace(""Got stream[%s] partition[%s] sequenceNumber[%s], shouldProcess[%s]."",record.getStream(),record.getPartitionId(),record.getSequenceNumber(),shouldProcess);
        if (shouldProcess) {
          final List<InputRow> rows=parser.parse(record.getData(),isEndOfShard(record.getSequenceNumber()));
          boolean isPersistRequired=false;
          final SequenceMetadata<PartitionIdType,SequenceOffsetType> sequenceToUse=sequences.stream().filter(sequenceMetadata -> sequenceMetadata.canHandle(this,record)).findFirst().orElse(null);
          if (sequenceToUse == null) {
            throw new ISE(""Cannot find any valid sequence for record with partition [%s] and sequenceNumber [%s]. Current sequences: %s"",record.getPartitionId(),record.getSequenceNumber(),sequences);
          }
          for (          InputRow row : rows) {
            final AppenderatorDriverAddResult addResult=driver.add(row,sequenceToUse.getSequenceName(),committerSupplier,true,false);
            if (addResult.isOk()) {
              final boolean isPushRequired=addResult.isPushRequired(tuningConfig.getPartitionsSpec().getMaxRowsPerSegment(),tuningConfig.getPartitionsSpec().getMaxTotalRowsOr(DynamicPartitionsSpec.DEFAULT_MAX_TOTAL_ROWS));
              if (isPushRequired && !sequenceToUse.isCheckpointed()) {
                sequenceToCheckpoint=sequenceToUse;
              }
              isPersistRequired|=addResult.isPersistRequired();
            }
 else {
              throw new ISE(""Could not allocate segment for row with timestamp[%s]"",row.getTimestamp());
            }
          }
          if (isPersistRequired) {
            Futures.addCallback(driver.persistAsync(committerSupplier.get()),new FutureCallback<Object>(){
              @Override public void onSuccess(              @Nullable Object result){
                log.debug(""Persist completed with metadata: %s"",result);
              }
              @Override public void onFailure(              Throwable t){
                log.error(""Persist failed, dying"");
                backgroundThreadException=t;
              }
            }
);
          }
          lastReadOffsets.put(record.getPartitionId(),record.getSequenceNumber());
          currOffsets.put(record.getPartitionId(),getNextStartOffset(record.getSequenceNumber()));
        }
        final boolean moreToReadAfterThisRecord=isMoreToReadAfterReadingRecord(record.getSequenceNumber(),endOffsets.get(record.getPartitionId()));
        if (!moreToReadAfterThisRecord && assignment.remove(record.getStreamPartition())) {
          log.info(""Finished reading stream[%s], partition[%s]."",record.getStream(),record.getPartitionId());
          recordSupplier.assign(assignment);
          stillReading=!assignment.isEmpty();
        }
      }
      if (!stillReading) {
        fireDepartmentMetrics.markProcessingDone();
      }
      if (System.currentTimeMillis() > nextCheckpointTime) {
        sequenceToCheckpoint=getLastSequenceMetadata();
      }
      if (sequenceToCheckpoint != null && stillReading) {
        Preconditions.checkArgument(getLastSequenceMetadata().getSequenceName().equals(sequenceToCheckpoint.getSequenceName()),""Cannot checkpoint a sequence [%s] which is not the latest one, sequences %s"",sequenceToCheckpoint,sequences);
        requestPause();
        final CheckPointDataSourceMetadataAction checkpointAction=new CheckPointDataSourceMetadataAction(task.getDataSource(),ioConfig.getTaskGroupId(),null,createDataSourceMetadata(new SeekableStreamStartSequenceNumbers<>(stream,sequenceToCheckpoint.getStartOffsets(),sequenceToCheckpoint.getExclusiveStartPartitions())));
        if (!toolbox.getTaskActionClient().submit(checkpointAction)) {
          throw new ISE(""Checkpoint request with sequences [%s] failed, dying"",currOffsets);
        }
      }
    }
    ingestionState=IngestionState.COMPLETED;
  }
 catch (  Exception e) {
    caughtExceptionInner=e;
    log.error(e,""Encountered exception in run() before persisting."");
    throw e;
  }
 finally {
    try {
      driver.persist(committerSupplier.get());
    }
 catch (    Exception e) {
      if (caughtExceptionInner != null) {
        caughtExceptionInner.addSuppressed(e);
      }
 else {
        throw e;
      }
    }
  }
synchronized (statusLock) {
    if (stopRequested.get() && !publishOnStop.get()) {
      throw new InterruptedException(""Stopping without publishing"");
    }
    status=Status.PUBLISHING;
  }
  List<SequenceMetadata<PartitionIdType,SequenceOffsetType>> sequencesSnapshot=new ArrayList<>(sequences);
  for (int i=0; i < sequencesSnapshot.size(); i++) {
    final SequenceMetadata<PartitionIdType,SequenceOffsetType> sequenceMetadata=sequencesSnapshot.get(i);
    if (!publishingSequences.contains(sequenceMetadata.getSequenceName())) {
      final boolean isLast=i == (sequencesSnapshot.size() - 1);
      if (isLast) {
        sequenceMetadata.setEndOffsets(currOffsets);
      }
      sequenceMetadata.updateAssignments(currOffsets,this::isMoreToReadAfterReadingRecord);
      publishingSequences.add(sequenceMetadata.getSequenceName());
      publishAndRegisterHandoff(sequenceMetadata);
    }
  }
  if (backgroundThreadException != null) {
    throw new RuntimeException(backgroundThreadException);
  }
  Futures.allAsList(publishWaitList).get();
  List<SegmentsAndCommitMetadata> handedOffList=Collections.emptyList();
  if (tuningConfig.getHandoffConditionTimeout() == 0) {
    handedOffList=Futures.allAsList(handOffWaitList).get();
  }
 else {
    try {
      handedOffList=Futures.allAsList(handOffWaitList).get(tuningConfig.getHandoffConditionTimeout(),TimeUnit.MILLISECONDS);
    }
 catch (    TimeoutException e) {
      log.makeAlert(""Timeout waiting for handoff"").addData(""taskId"",task.getId()).addData(""handoffConditionTimeout"",tuningConfig.getHandoffConditionTimeout()).emit();
    }
  }
  for (  SegmentsAndCommitMetadata handedOff : handedOffList) {
    log.info(""Handoff complete for segments: %s"",String.join("", "",Lists.transform(handedOff.getSegments(),DataSegment::toString)));
  }
  appenderator.close();
}
 catch (InterruptedException|RejectedExecutionException e) {
  caughtExceptionOuter=e;
  try {
    Futures.allAsList(publishWaitList).cancel(true);
    Futures.allAsList(handOffWaitList).cancel(true);
    if (appenderator != null) {
      appenderator.closeNow();
    }
  }
 catch (  Exception e2) {
    e.addSuppressed(e2);
  }
  if (e instanceof RejectedExecutionException && (e.getCause() == null || !(e.getCause() instanceof InterruptedException))) {
    throw e;
  }
  if (!stopRequested.get()) {
    Thread.currentThread().interrupt();
    throw e;
  }
}
catch (Exception e) {
  caughtExceptionOuter=e;
  try {
    Futures.allAsList(publishWaitList).cancel(true);
    Futures.allAsList(handOffWaitList).cancel(true);
    if (appenderator != null) {
      appenderator.closeNow();
    }
  }
 catch (  Exception e2) {
    e.addSuppressed(e2);
  }
  throw e;
}
 finally {
  try {
    if (driver != null) {
      driver.close();
    }
    toolbox.getChatHandlerProvider().unregister(task.getId());
    if (toolbox.getAppenderatorsManager().shouldTaskMakeNodeAnnouncements()) {
      toolbox.getDruidNodeAnnouncer().unannounce(discoveryDruidNode);
      toolbox.getDataSegmentServerAnnouncer().unannounce();
    }
  }
 catch (  Throwable e) {
    if (caughtExceptionOuter != null) {
      caughtExceptionOuter.addSuppressed(e);
    }
 else {
      throw e;
    }
  }
}
",0,0,0,,
218,} finally {,"try {
  registry.register(url);
}
  finally {
  if (CollectionUtils.isNotEmpty(listeners) && !UrlUtils.isConsumer(url)) {
    RuntimeException exception=null;
    for (    RegistryServiceListener listener : listeners) {
      if (listener != null) {
        try {
          listener.onRegister(url,registry);
        }
 catch (        RuntimeException t) {
          logger.error(t.getMessage(),t);
          exception=t;
        }
      }
    }
    if (exception != null) {
      throw exception;
    }
  }
}
",0,0,0,,
219,} finally {,"try {
  registry.unregister(url);
}
  finally {
  if (CollectionUtils.isNotEmpty(listeners) && !UrlUtils.isConsumer(url)) {
    RuntimeException exception=null;
    for (    RegistryServiceListener listener : listeners) {
      if (listener != null) {
        try {
          listener.onUnregister(url,registry);
        }
 catch (        RuntimeException t) {
          logger.error(t.getMessage(),t);
          exception=t;
        }
      }
    }
    if (exception != null) {
      throw exception;
    }
  }
}
",0,0,0,,
220,} finally {,"try {
  registry.subscribe(url,listener);
}
  finally {
  if (CollectionUtils.isNotEmpty(listeners)) {
    RuntimeException exception=null;
    for (    RegistryServiceListener registryListener : listeners) {
      if (registryListener != null) {
        try {
          registryListener.onSubscribe(url,registry);
        }
 catch (        RuntimeException t) {
          logger.error(t.getMessage(),t);
          exception=t;
        }
      }
    }
    if (exception != null) {
      throw exception;
    }
  }
}
",0,0,0,,
221,} finally {,"try {
  registry.unsubscribe(url,listener);
}
  finally {
  if (CollectionUtils.isNotEmpty(listeners)) {
    RuntimeException exception=null;
    for (    RegistryServiceListener registryListener : listeners) {
      if (registryListener != null) {
        try {
          registryListener.onUnsubscribe(url,registry);
        }
 catch (        RuntimeException t) {
          logger.error(t.getMessage(),t);
          exception=t;
        }
      }
    }
    if (exception != null) {
      throw exception;
    }
  }
}
",0,0,0,,
222,} finally {,"try {
  exporter.unexport();
}
  finally {
  if (CollectionUtils.isNotEmpty(listeners)) {
    RuntimeException exception=null;
    for (    ExporterListener listener : listeners) {
      if (listener != null) {
        try {
          listener.unexported(this);
        }
 catch (        RuntimeException t) {
          logger.error(t.getMessage(),t);
          exception=t;
        }
      }
    }
    if (exception != null) {
      throw exception;
    }
  }
}
",0,0,0,,
223,} finally,"try {
  rs=executeQuery(""SELECT systimestamp FROM DUAL"",null,false,conn);
  return (rs.next() ? rs.getTimestamp(1) : null);
}
 catch (SQLException e) {
  throw new EmpireSQLException(this,e);
}
 finally {
  try {
    Statement stmt=(rs != null) ? rs.getStatement() : null;
    if (rs != null)     rs.close();
    if (stmt != null)     stmt.close();
  }
 catch (  SQLException e) {
    throw new EmpireSQLException(this,e);
  }
}
",0,0,0,,
224,finally,"try {
  out=m_action.getFileOutputStream(tmp);
  Properties store=new Properties();
  int count=0;
  for (Iterator iter=data.entrySet().iterator(); iter.hasNext(); ) {
    Entry entry=(Entry)iter.next();
    store.setProperty(count++ + ""-"" + (String)entry.getKey(),getEncoded(entry.getValue()));
  }
  store.store(out,null);
}
 catch (IOException ex) {
  org=ex;
  throw ex;
}
 finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException ex) {
      if (org == null) {
        throw ex;
      }
    }
  }
}
",0,0,0,,
225,finally,"try {
  in=m_action.getFileInputStream(m_file);
  Properties store=new Properties();
  store.load(in);
  for (Iterator iter=store.entrySet().iterator(); iter.hasNext(); ) {
    Entry entry=(Entry)iter.next();
    result.put(entry.getKey(),getUnencoded((String)entry.getValue(),target));
  }
}
 catch (IOException ex) {
  other=ex;
  throw ex;
}
 finally {
  if (in != null) {
    try {
      in.close();
    }
 catch (    IOException ex) {
      if (other == null) {
        throw ex;
      }
    }
  }
}
",0,0,0,,
226,finally,"try {
  output=Felix.m_secureAction.getOutputStream(target);
  input=new BundleInputStream(content);
  byte[] buffer=new byte[64 * 1024];
  for (int i=input.read(buffer); i != -1; i=input.read(buffer)) {
    output.write(buffer,0,i);
  }
}
 catch (IOException ex) {
  rethrow=ex;
}
 finally {
  if (output != null) {
    try {
      output.close();
    }
 catch (    IOException ex) {
      if (rethrow == null) {
        rethrow=ex;
      }
    }
  }
  if (input != null) {
    try {
      input.close();
    }
 catch (    IOException ex) {
      if (rethrow == null) {
        rethrow=ex;
      }
    }
  }
  if (rethrow != null) {
    throw rethrow;
  }
}
",0,0,0,,
227,finally,"try {
  for (int i=input.read(result,0,size); i != -1 && i < size; i+=input.read(result,i,size - i)) {
  }
}
 catch (Exception ex) {
  exception=ex;
}
 finally {
  try {
    input.close();
  }
 catch (  Exception ex) {
    throw exception != null ? exception : ex;
  }
}
",0,0,0,,
228,finally,"try {
  writeManifest(analyzer,outputFile,niceManifest,exportScr,scrLocation,buildContext,getLog());
}
 catch (Exception e) {
  throw new MojoExecutionException(""Error trying to write Manifest to file "" + outputFile,e);
}
 finally {
  try {
    analyzer.close();
  }
 catch (  IOException e) {
    throw new MojoExecutionException(""Error trying to write Manifest to file "" + outputFile,e);
  }
}
",0,0,0,,
229,finally,"try {
  bundle=doRun();
  if (bundle != null) {
    refreshPackages(fw,plugin.getBundle().getBundleContext(),5000L,bundle);
  }
}
 catch (Exception ex) {
  rethrow=ex;
  throw ex;
}
 finally {
  if ((state & (Bundle.ACTIVE | Bundle.STARTING)) != 0) {
    try {
      bundle.start(startFlags);
    }
 catch (    Exception ex) {
      if (rethrow == null) {
        throw ex;
      }
 else {
        try {
          getLog().log(LogService.LOG_ERROR,""Cannot restart bundle: "" + bundle + "" after exception during update!"",ex);
        }
 catch (        Exception secondary) {
          System.err.println(""Cannot restart bundle: "" + bundle + "" after exception during update!"");
          ex.printStackTrace(System.err);
        }
      }
    }
  }
}
",0,0,0,,
230,} finally {,"try {
  try {
    manifest=jar.getManifest();
  }
 catch (  IOException ioex) {
    throw new ProgramInvocationException(""The Manifest in the jar file could not be accessed '"" + jarFile.getPath() + ""'. ""+ ioex.getMessage(),ioex);
  }
  if (manifest == null) {
    throw new ProgramInvocationException(""No manifest found in jar file '"" + jarFile.getPath() + ""'. The manifest is need to point to the program's main class."");
  }
  Attributes attributes=manifest.getMainAttributes();
  className=attributes.getValue(PackagedProgram.MANIFEST_ATTRIBUTE_ASSEMBLER_CLASS);
  if (className != null) {
    return className;
  }
  className=attributes.getValue(PackagedProgram.MANIFEST_ATTRIBUTE_MAIN_CLASS);
  if (className != null) {
    return className;
  }
 else {
    throw new ProgramInvocationException(""Neither a '"" + MANIFEST_ATTRIBUTE_MAIN_CLASS + ""', nor a '""+ MANIFEST_ATTRIBUTE_ASSEMBLER_CLASS+ ""' entry was found in the jar file."");
  }
}
  finally {
  try {
    jar.close();
  }
 catch (  Throwable t) {
    throw new ProgramInvocationException(""Could not close the JAR file: "" + t.getMessage(),t);
  }
}
",0,0,0,,
231,} finally {,"try {
  if (resourceStream != null) {
    URL root=cl.getResource(""web"");
    URL requested=cl.getResource(""web"" + requestPath);
    if (root != null && requested != null) {
      URI rootURI=new URI(root.getPath()).normalize();
      URI requestedURI=new URI(requested.getPath()).normalize();
      if (!rootURI.relativize(requestedURI).equals(requestedURI)) {
        LOG.debug(""Loading missing file from classloader: {}"",requestPath);
        file.getParentFile().mkdirs();
        Files.copy(resourceStream,file.toPath());
        success=true;
      }
    }
  }
}
 catch (Throwable t) {
  LOG.error(""error while responding"",t);
}
 finally {
  if (!success) {
    LOG.debug(""Unable to load requested file {} from classloader"",requestPath);
    throw new NotFoundException(""File not found."");
  }
}
",0,0,0,,
232,} finally {,"try {
  if (resourceStream != null) {
    URL root=cl.getResource(""web"");
    URL requested=cl.getResource(""web"" + requestPath);
    if (root != null && requested != null) {
      URI rootURI=new URI(root.getPath()).normalize();
      URI requestedURI=new URI(requested.getPath()).normalize();
      if (!rootURI.relativize(requestedURI).equals(requestedURI)) {
        logger.debug(""Loading missing file from classloader: {}"",requestPath);
        file.getParentFile().mkdirs();
        Files.copy(resourceStream,file.toPath());
        success=true;
      }
    }
  }
}
 catch (Throwable t) {
  logger.error(""error while responding"",t);
}
 finally {
  if (!success) {
    logger.debug(""Unable to load requested file {} from classloader"",requestPath);
    throw new NotFoundException(String.format(""Unable to load requested file %s."",requestPath));
  }
}
",0,0,0,,
233,} finally {,"try {
  cancelTask();
}
  finally {
  FlinkSecurityManager.unmonitorUserSystemExitForCurrentThread();
  getCompletionFuture().whenComplete((unusedResult,unusedError) -> {
    mailboxProcessor.allActionsCompleted();
    try {
      cancelables.close();
    }
 catch (    IOException e) {
      throw new CompletionException(e);
    }
  }
);
}
",0,0,0,,
234,} finally {,"try {
  if (totalBytes <= MAX_ALLOC_BUFFER_SIZE) {
    checkpointFile.write(new byte[(int)totalBytes]);
  }
 else {
    byte[] initBuffer=new byte[MAX_ALLOC_BUFFER_SIZE];
    long remainingBytes=totalBytes;
    while (remainingBytes >= MAX_ALLOC_BUFFER_SIZE) {
      checkpointFile.write(initBuffer);
      remainingBytes-=MAX_ALLOC_BUFFER_SIZE;
    }
    if (remainingBytes > 0) {
      checkpointFile.write(initBuffer,0,(int)remainingBytes);
    }
  }
  success=true;
}
  finally {
  try {
    checkpointFile.close();
  }
 catch (  IOException e) {
    if (success) {
      throw e;
    }
  }
}
",0,0,0,,
235,} finally {,"try {
  transaction.begin();
  T value=transactor.call();
  transaction.commit();
  committed=true;
  return value;
}
 catch (Throwable e) {
  interrupted=Thread.currentThread().isInterrupted();
  try {
    transaction.rollback();
  }
 catch (  Throwable e2) {
    logger.error(""Failed to roll back transaction, exception follows:"",e2);
  }
  if (e instanceof InterruptedException) {
    interrupted=true;
  }
 else   if (e instanceof Error) {
    throw (Error)e;
  }
 else   if (e instanceof RuntimeException) {
    throw (RuntimeException)e;
  }
  throw new ChannelException(e);
}
 finally {
  interrupted=interrupted || Thread.currentThread().isInterrupted();
  try {
    transaction.close();
  }
 catch (  Throwable e) {
    if (committed) {
      if (e instanceof Error) {
        throw (Error)e;
      }
 else       if (e instanceof RuntimeException) {
        throw (RuntimeException)e;
      }
 else {
        throw new ChannelException(e);
      }
    }
 else {
      logger.error(""Failed to close transaction after error, exception follows:"",e);
    }
  }
 finally {
    if (interrupted) {
      Thread.currentThread().interrupt();
    }
  }
}
",0,0,0,,
236,} finally {,"try {
  reader=new BufferedReader(new InputStreamReader(process.getInputStream()));
  List<String> result=Lists.newArrayList();
  String line;
  while ((line=reader.readLine()) != null) {
    result.add(line);
  }
  return result;
}
  finally {
  process.destroy();
  if (reader != null) {
    reader.close();
  }
  int exit=process.waitFor();
  if (exit != 0) {
    throw new IllegalStateException(""Command ["" + command + ""] exited with ""+ exit);
  }
}
",0,0,0,,
237,} finally {,"try {
  out=new ObjectOutputStream(bos);
  out.writeObject(object);
  event.setBody(bos.toByteArray());
}
 catch (IOException e) {
  throw new FlumeException(""Error serializing object"",e);
}
 finally {
  try {
    if (out != null) {
      out.close();
    }
  }
 catch (  IOException e) {
    throw new FlumeException(""Error closing ObjectOutputStream"",e);
  }
  try {
    if (bos != null) {
      bos.close();
    }
  }
 catch (  IOException e) {
    throw new FlumeException(""Error closing ByteArrayOutputStream"",e);
  }
}
",0,0,0,,
238,} finally {,"try {
  try (BufferedReader contR=new BufferedReader(new InputStreamReader(contIn,""UTF-8""))){
    String contLine;
    while ((contLine=contR.readLine()) != null) {
      processLine(contLine,resolverClass,srcDirResourcePath,dstRootDir,contResource);
    }
  }
   jarMarkedSubdirectories(dstRootDir);
  deleteDstRootDir=false;
}
  finally {
  if (deleteDstRootDir) {
    try {
      if (dstRootDir.getParentFile() == null) {
        throw new IOException(""Won't delete the root directory"");
      }
      FileUtils.deleteDirectory(dstRootDir);
    }
 catch (    IOException e) {
      LOG.error(""Failed to delete destination directory: "" + dstRootDir,e);
    }
  }
}
",0,0,0,,
239,} finally {,"try {
  try {
    ip.ee.notify(EvaluationEvent.ENTER_MAP,ip,null,res);
    done=true;
  }
 catch (  Throwable e) {
    throw ip.newWrappedError(e);
  }
  return ip.fetchMapInner(res,(char)0x20,forceStringValues);
}
  finally {
  if (done) {
    try {
      ip.ee.notify(EvaluationEvent.LEAVE_MAP,ip,null,res);
    }
 catch (    Throwable e) {
      throw ip.newWrappedError(e);
    }
  }
}
",0,0,0,,
240,} finally {,"try {
  try {
    ip.ee.notify(EvaluationEvent.ENTER_LIST,ip,null,res);
    done=true;
  }
 catch (  Throwable e) {
    throw ip.newWrappedError(e);
  }
  return ip.fetchListInner(res,(char)0x20,forceStringValues);
}
  finally {
  if (done) {
    try {
      ip.ee.notify(EvaluationEvent.LEAVE_LIST,ip,null,res);
    }
 catch (    Throwable e) {
      throw ip.newWrappedError(e);
    }
  }
}
",0,0,0,,
241,} finally {,"try {
  Object nr;
  try {
    nr=ee.notify(EvaluationEvent.ENTER_MAP_KEY,this,(String)o1,null);
    done=true;
  }
 catch (  Throwable e) {
    throw newWrappedError(e,keyP);
  }
  if (nr == null) {
    o2=fetchExpression(forceStringValues,false);
    map.put((String)o1,o2);
  }
 else {
    p2=p;
    skipExpression();
    if (nr == EvaluationEnvironment.RETURN_FRAGMENT) {
      map.put((String)o1,new Fragment(tx,p2,p,fileName));
    }
  }
}
  finally {
  if (done) {
    try {
      ee.notify(EvaluationEvent.LEAVE_MAP_KEY,this,(String)o1,null);
    }
 catch (    Throwable e) {
      throw newWrappedError(e);
    }
  }
}
",0,0,0,,
242,} finally {,"try {
  Object nr;
  try {
    nr=ee.notify(EvaluationEvent.ENTER_MAP_KEY,this,(String)o1,null);
    done=true;
  }
 catch (  Throwable e) {
    throw newWrappedError(e,keyP);
  }
  if (nr == null || nr == EvaluationEnvironment.RETURN_FRAGMENT) {
    map.put((String)o1,Boolean.TRUE);
  }
}
  finally {
  if (done) {
    try {
      ee.notify(EvaluationEvent.LEAVE_MAP_KEY,this,(String)o1,null);
    }
 catch (    Throwable e) {
      throw newWrappedError(e);
    }
  }
}
",0,0,0,,
243,} finally {,"try {
  try {
    nr=ee.notify(EvaluationEvent.ENTER_MAP,this,null,map);
    done=true;
  }
 catch (  Throwable e) {
    throw newWrappedError(e);
  }
  if (nr == null) {
    fetchMapInner(map,'}',forceStr);
    res=map;
  }
 else {
    p--;
    int p2=p;
    skipExpression();
    res=new Fragment(tx,p2,p,fileName);
    p--;
  }
}
  finally {
  if (done) {
    try {
      ee.notify(EvaluationEvent.LEAVE_MAP,this,null,map);
    }
 catch (    Throwable e) {
      throw newWrappedError(e);
    }
  }
}
",0,0,0,,
244,} finally {,"try {
  try {
    ee.notify(EvaluationEvent.ENTER_LIST,this,null,res);
    done=true;
  }
 catch (  Throwable e) {
    throw newWrappedError(e);
  }
  fetchListInner(res,']',forceStr);
}
  finally {
  if (done) {
    try {
      ee.notify(EvaluationEvent.LEAVE_LIST,this,null,res);
    }
 catch (    Throwable e) {
      throw newWrappedError(e);
    }
  }
}
",0,0,0,,
245,} finally {,"try {
  try {
    ee.notify(EvaluationEvent.ENTER_FUNCTION_PARAMS,this,s,null);
  }
 catch (  Throwable e) {
    throw newWrappedError(e,funcP);
  }
  done=true;
  params=fetchListInner(new ArrayList<Object>(),')',forceStr);
}
  finally {
  if (done) {
    try {
      ee.notify(EvaluationEvent.LEAVE_FUNCTION_PARAMS,this,s,null);
    }
 catch (    Throwable e) {
      throw newWrappedError(e);
    }
  }
}
",0,0,0,,
246,} finally {,"try {
  CacheSerializableRunnable destroyDynRegn=new CacheSerializableRunnable(""Destroy Dynamic regions""){
    @Override public void run2() throws CacheException {
      Region dr=getCache().getRegion(""__DynamicRegions"");
      if (dr != null) {
        dr.localDestroyRegion();
      }
    }
  }
;
  getOtherVm().invoke(destroyDynRegn);
  Region dr=getCache().getRegion(""__DynamicRegions"");
  if (dr != null) {
    dr.localDestroyRegion();
  }
}
 catch (VirtualMachineError e) {
  SystemFailure.initiateFailure(e);
  throw e;
}
catch (Throwable t) {
  LogWriterUtils.getLogWriter().severe(""tearDown in "" + this + "" failed due to ""+ t);
}
 finally {
  try {
    disconnectAllFromDS();
  }
 catch (  VirtualMachineError e) {
    SystemFailure.initiateFailure(e);
    throw e;
  }
catch (  Throwable t) {
    LogWriterUtils.getLogWriter().severe(""tearDown in "" + this + "" failed to disconnect all DS due to ""+ t);
  }
}
",0,0,0,,
247,} finally {,"try {
  doTestSuspendLockingBehaves();
}
  finally {
  Invoke.invokeInEveryVM(new SerializableRunnable(){
    @Override public void run(){
      try {
        if (suspendClientSuspendLockingBehaves != null) {
          suspendClientSuspendLockingBehaves.stop();
          suspendClientSuspendLockingBehaves=null;
        }
      }
 catch (      VirtualMachineError e) {
        SystemFailure.initiateFailure(e);
        throw e;
      }
catch (      Throwable t) {
        logger.error(""Error in testSuspendLockingBehaves finally"",t);
      }
      try {
        if (lockClientSuspendLockingBehaves != null) {
          lockClientSuspendLockingBehaves.stop();
          lockClientSuspendLockingBehaves=null;
        }
      }
 catch (      VirtualMachineError e) {
        SystemFailure.initiateFailure(e);
        throw e;
      }
catch (      Throwable t) {
        logger.error(""Error in testSuspendLockingBehaves finally"",t);
      }
    }
  }
);
}
",0,0,0,,
248,} finally {,"try {
  if (cache != null && !cache.isClosed()) {
    for (Iterator itr=cache.rootRegions().iterator(); itr.hasNext(); ) {
      Region root=(Region)itr.next();
      if (root.isDestroyed() || root instanceof HARegion) {
        continue;
      }
      try {
        root.localDestroyRegion(""teardown"");
      }
 catch (      VirtualMachineError e) {
        SystemFailure.initiateFailure(e);
        throw e;
      }
catch (      Throwable t) {
        cache.getLogger().error(t);
      }
    }
  }
}
  finally {
  try {
    closeCache();
  }
 catch (  VirtualMachineError e) {
    SystemFailure.initiateFailure(e);
    throw e;
  }
catch (  Throwable t) {
    cache.getLogger().error(""Error in closing the cache "",t);
  }
}
",0,0,0,,
249,} finally {,"try {
  if (interrupted) {
    throw new InterruptedException();
  }
  if (stillWaiting()) {
    preWait();
    try {
      result=basicWait(msecs,latch);
    }
 catch (    InterruptedException e) {
      interrupted=true;
    }
 finally {
      if (doCleanUp) {
        postWait();
      }
    }
  }
  if (this.exception != null) {
    throw this.exception;
  }
}
  finally {
  if (doCleanUp) {
    try {
      cleanup();
    }
  finally {
      if (interrupted) {
        throw new InterruptedException();
      }
    }
  }
  MessageDependencyMonitor.doneWaiting(this);
}
",0,0,0,,
250,} finally {,"try {
  cleanup();
}
  finally {
  if (interrupted) {
    throw new InterruptedException();
  }
}
",0,0,0,,
251,} finally {,"try {
  startTime=0;
  if (ackTimeout > 0) {
    startTime=System.currentTimeMillis();
  }
  ms.reserveConnections(startTime,ackTimeout,ackSDTimeout);
  int result=ms.writeMessage();
  if (bytesWritten == 0) {
    bytesWritten=result;
  }
  ce=ms.getConnectExceptions();
  sentCons=ms.getSentConnections();
  totalSentCons.addAll(sentCons);
}
 catch (NotSerializableException e) {
  throw e;
}
catch (IOException ex) {
  throw new InternalGemFireException(""Unknown error serializing message"",ex);
}
 finally {
  try {
    ms.close();
  }
 catch (  IOException e) {
    throw new InternalGemFireException(""Unknown error serializing message"",e);
  }
}
",0,0,0,,
252,} finally {,"try {
  ThreadRequestState requestState=(ThreadRequestState)this.threadRequestState.get();
  if (requestState == null) {
    requestState=new ThreadRequestState(incThreadSequence(),interruptible);
    this.threadRequestState.set(requestState);
  }
 else {
    requestState.interruptible=interruptible;
  }
  final int threadId=requestState.threadId;
  long leaseExpireTime=0;
  boolean keepTrying=true;
  int lockId=-1;
  incActiveLocks();
  while (keepTrying) {
    checkDestroyed();
    interrupted=Thread.interrupted() || interrupted;
    if (interrupted && interruptible) {
      throw new InterruptedException();
    }
    boolean reentrant=false;
    int recursionBefore=-1;
synchronized (token) {
      token.checkForExpiration();
      if (token.isLeaseHeldByCurrentThread()) {
        if (logger.isTraceEnabled(LogMarker.DLS_VERBOSE)) {
          logger.trace(LogMarker.DLS_VERBOSE,""{} , name: {} - lock() is reentrant: {}"",this,name,token);
        }
        reentrant=true;
        if (reentrant && disallowReentrant) {
          throw new IllegalStateException(String.format(""%s attempted to reenter non-reentrant lock %s"",new Object[]{Thread.currentThread(),token}));
        }
        recursionBefore=token.getRecursion();
        lockId=token.getLeaseId();
        if (lockId < 0) {
          continue;
        }
      }
    }
    LockGrantorId theLockGrantorId=getLockGrantorId();
    if (reentrant) {
      Assert.assertTrue(lockId > -1,""Reentrant lock must have lockId > -1"");
    }
 else {
      lockId=-1;
    }
    DLockRequestProcessor processor=createRequestProcessor(theLockGrantorId,name,threadId,startTime,requestLeaseTime,requestWaitTime,reentrant,tryLock,disableAlerts);
    if (reentrant) {
synchronized (token) {
        if (!token.isLeaseHeldByCurrentThread()) {
          reentrant=false;
          recursionBefore=-1;
          token.checkForExpiration();
        }
      }
    }
 else {
      lockId=processor.getProcessorId();
    }
    gotLock=processor.requestLock(interruptible,lockId);
    if (logger.isTraceEnabled(LogMarker.DLS_VERBOSE)) {
      logger.trace(LogMarker.DLS_VERBOSE,""Grantor {} replied {}"",theLockGrantorId,processor.getResponseCodeString());
    }
    if (gotLock) {
      leaseExpireTime=processor.getLeaseExpireTime();
      int recursion=recursionBefore + 1;
      if (!grantLocalDLockAfterObtainingRemoteLock(name,token,threadId,leaseExpireTime,lockId,theLockGrantorId,processor,recursion)) {
        continue;
      }
      if (logger.isTraceEnabled(LogMarker.DLS_VERBOSE)) {
        logger.trace(LogMarker.DLS_VERBOSE,""{}, name: {} - granted lock: {}"",this,name,token);
      }
      keepTrying=false;
    }
 else     if (processor.repliedDestroyed()) {
      checkDestroyed();
      Assert.assertTrue(isDestroyed(),""Grantor reports service "" + this + "" is destroyed: ""+ name);
    }
 else     if (processor.repliedNotGrantor() || processor.hadNoResponse()) {
      long waitForGrantorTime=waitLimit - token.getCurrentTime();
      if (waitForGrantorTime <= 0) {
        waitForGrantorTime=100;
      }
      notLockGrantorId(theLockGrantorId,waitForGrantorTime,TimeUnit.MILLISECONDS);
    }
 else     if (processor.repliedNotHolder()) {
      reentrant=false;
      recursionBefore=-1;
synchronized (token) {
        token.checkForExpiration();
        if (token.isLeaseHeldByCurrentThread()) {
          logger.warn(LogMarker.DLS_MARKER,""Grantor reports reentrant lock not held: {}"",token);
          RemoteThread rThread=new RemoteThread(getDistributionManager().getId(),threadId);
          token.releaseLock(lockId,rThread,false);
        }
      }
    }
 else {
      if (waitLimit > token.getCurrentTime() + 20) {
        sleep(20,interruptible);
      }
      keepTrying=waitLimit > token.getCurrentTime();
    }
  }
}
  finally {
  getStats().endLockWait(statStart,gotLock);
  if (!gotLock) {
synchronized (token) {
      token.decUsage();
    }
    freeResources(token.getName());
  }
  if (interrupted) {
    Thread.currentThread().interrupt();
  }
  if (!gotLock && interruptible && Thread.interrupted()) {
    throw new InterruptedException();
  }
  blockedOn.set(null);
}
",0,0,0,,
253,} finally {,"try {
  checkForProblem(dm);
}
  finally {
  throw e;
}
",0,0,0,,
254,} finally {,"try {
  if (forceNewEntry || forceCallbacks) {
    boolean opCompleted=false;
    RegionEntry newRe=getEntryFactory().createEntry(owner,event.getKey(),Token.REMOVED_PHASE1);
synchronized (newRe) {
      try {
        RegionEntry oldRe=putEntryIfAbsent(event.getKey(),newRe);
        while (!opCompleted && oldRe != null) {
synchronized (oldRe) {
            if (oldRe.isRemovedPhase2()) {
              owner.getCachePerfStats().incRetries();
              getEntryMap().remove(event.getKey(),oldRe);
              oldRe=putEntryIfAbsent(event.getKey(),newRe);
            }
 else {
              opCompleted=true;
              event.setRegionEntry(oldRe);
              if (oldRe.isDestroyed()) {
                if (isDebugEnabled) {
                  logger.debug(""mapInvalidate: Found DESTROYED token, not invalidated; key={}"",event.getKey());
                }
              }
 else               if (oldRe.isInvalid()) {
                handleAlreadyInvalidEntry(event,owner,oldRe);
                try {
                  oldRe.setValue(owner,oldRe.getValueInVM(owner));
                }
 catch (                RegionClearedException e) {
                }
              }
 else {
                owner.serverInvalidate(event);
                if (owner.getConcurrencyChecksEnabled() && event.noVersionReceivedFromServer()) {
                  return false;
                }
                final int oldSize=owner.calculateRegionEntryValueSize(oldRe);
                FilterProfile fp=owner.getFilterProfile();
                if (!oldRe.isRemoved() && (fp != null && fp.getCqCount() > 0)) {
                  Object oldValue=oldRe.getValueInVM(owner);
                  if (oldValue == Token.NOT_AVAILABLE) {
                    event.setOldValue(oldRe.getValueOnDiskOrBuffer(owner));
                  }
 else {
                    event.setOldValue(oldValue);
                  }
                }
                boolean isCreate=false;
                try {
                  if (oldRe.isRemoved()) {
                    processVersionTag(oldRe,event);
                    event.putNewEntry(owner,oldRe);
                    EntryLogger.logInvalidate(event);
                    owner.recordEvent(event);
                    if (!oldRe.isTombstone()) {
                      owner.updateSizeOnPut(event.getKey(),oldSize,event.getNewValueBucketSize());
                    }
 else {
                      owner.updateSizeOnCreate(event.getKey(),event.getNewValueBucketSize());
                      isCreate=true;
                    }
                  }
 else {
                    processVersionTag(oldRe,event);
                    event.putExistingEntry(owner,oldRe);
                    EntryLogger.logInvalidate(event);
                    owner.recordEvent(event);
                    owner.updateSizeOnPut(event.getKey(),oldSize,event.getNewValueBucketSize());
                  }
                }
 catch (                RegionClearedException e) {
                  EntryLogger.logInvalidate(event);
                  owner.recordEvent(event);
                  clearOccured=true;
                }
                owner.basicInvalidatePart2(oldRe,event,clearOccured,invokeCallbacks);
                if (!clearOccured) {
                  if (isCreate) {
                    lruEntryCreate(oldRe);
                  }
 else {
                    lruEntryUpdate(oldRe);
                  }
                }
                didInvalidate=true;
                invalidatedRe=oldRe;
              }
            }
          }
        }
        if (!opCompleted) {
          if (forceNewEntry && event.isFromServer()) {
            if (!FORCE_INVALIDATE_EVENT) {
              event.inhibitCacheListenerNotification(true);
            }
          }
          event.setRegionEntry(newRe);
          owner.serverInvalidate(event);
          if (!forceNewEntry && event.noVersionReceivedFromServer()) {
            return false;
          }
          try {
            ownerIsInitialized=owner.isInitialized();
            if (!ownerIsInitialized && owner.getDataPolicy().withReplication()) {
              final int oldSize=owner.calculateRegionEntryValueSize(newRe);
              invalidateEntry(event,newRe,oldSize);
            }
 else {
              invalidateNewEntry(event,owner,newRe);
            }
          }
 catch (          RegionClearedException e) {
            owner.recordEvent(event);
            clearOccured=true;
          }
          owner.basicInvalidatePart2(newRe,event,clearOccured,invokeCallbacks);
          if (!clearOccured) {
            lruEntryCreate(newRe);
            incEntryCount(1);
          }
          opCompleted=true;
          didInvalidate=true;
          invalidatedRe=newRe;
          if (!forceNewEntry) {
            removeEntry(event.getKey(),newRe,false);
          }
        }
      }
 catch (      ConcurrentCacheModificationException ccme) {
        VersionTag tag=event.getVersionTag();
        if (tag != null && tag.isTimeStampUpdated()) {
          owner.notifyTimestampsToGateways(event);
        }
        throw ccme;
      }
 finally {
        if (!opCompleted) {
          removeEntry(event.getKey(),newRe,false);
        }
      }
    }
  }
 else {
    boolean retry=true;
    while (retry) {
      retry=false;
      boolean entryExisted=false;
      RegionEntry re=getEntry(event.getKey());
      RegionEntry tombstone=null;
      boolean haveTombstone=false;
      if (re != null && re.isTombstone()) {
        tombstone=re;
        haveTombstone=true;
        re=null;
      }
      if (re == null) {
        ownerIsInitialized=owner.isInitialized();
        if (!ownerIsInitialized) {
          RegionEntry newRe=haveTombstone ? tombstone : getEntryFactory().createEntry(owner,event.getKey(),Token.INVALID);
synchronized (newRe) {
            if (haveTombstone && !tombstone.isTombstone()) {
              retry=true;
              continue;
            }
            re=putEntryIfAbsent(event.getKey(),newRe);
            if (re == tombstone) {
              re=null;
            }
          }
        }
 else         if (owner.getServerProxy() != null) {
          Object sync=haveTombstone ? tombstone : new Object();
synchronized (sync) {
            if (haveTombstone && !tombstone.isTombstone()) {
              retry=true;
              continue;
            }
            owner.serverInvalidate(event);
            if (owner.getConcurrencyChecksEnabled()) {
              if (event.getVersionTag() == null) {
                return false;
              }
 else               if (tombstone != null) {
                processVersionTag(tombstone,event);
                try {
                  tombstone.setValue(owner,Token.TOMBSTONE);
                }
 catch (                RegionClearedException e) {
                }
catch (                ConcurrentCacheModificationException ccme) {
                  VersionTag tag=event.getVersionTag();
                  if (tag != null && tag.isTimeStampUpdated()) {
                    owner.notifyTimestampsToGateways(event);
                  }
                  throw ccme;
                }
                owner.rescheduleTombstone(tombstone,event.getVersionTag());
              }
            }
          }
          entryExisted=true;
        }
      }
      if (re != null) {
synchronized (re) {
          if (!event.isOriginRemote() && event.getOperation().isExpiration()) {
            if (re.isInUseByTransaction()) {
              return false;
            }
          }
          if (re.isTombstone() || (!re.isRemoved() && !re.isDestroyed())) {
            entryExisted=true;
            if (re.isInvalid()) {
              handleAlreadyInvalidEntry(event,owner,re);
            }
 else {
              event.setRegionEntry(re);
              owner.serverInvalidate(event);
              if (owner.getConcurrencyChecksEnabled() && event.noVersionReceivedFromServer()) {
                if (isDebugEnabled) {
                  logger.debug(""returning early because server did not generate a version stamp for this event:{}"",event);
                }
                return false;
              }
              if (owner.getFilterProfile().getCqCount() > 0) {
                if (re.isValueNull()) {
                  event.setOldValue(re.getValueOnDiskOrBuffer(owner));
                }
 else {
                  Object v=re.getValueInVM(owner);
                  event.setOldValue(v);
                }
              }
              final boolean oldWasTombstone=re.isTombstone();
              final int oldSize=_getOwner().calculateRegionEntryValueSize(re);
              try {
                invalidateEntry(event,re,oldSize);
              }
 catch (              RegionClearedException rce) {
                EntryLogger.logInvalidate(event);
                _getOwner().recordEvent(event);
                clearOccured=true;
              }
catch (              ConcurrentCacheModificationException ccme) {
                VersionTag tag=event.getVersionTag();
                if (tag != null && tag.isTimeStampUpdated()) {
                  owner.notifyTimestampsToGateways(event);
                }
                throw ccme;
              }
              owner.basicInvalidatePart2(re,event,clearOccured,invokeCallbacks);
              if (!clearOccured) {
                if (oldWasTombstone) {
                  lruEntryCreate(re);
                }
 else {
                  lruEntryUpdate(re);
                }
              }
              didInvalidate=true;
              invalidatedRe=re;
            }
          }
        }
      }
 else {
      }
      if (!entryExisted) {
        owner.checkEntryNotFound(event.getKey());
      }
    }
  }
}
 catch (DiskAccessException dae) {
  invalidatedRe=null;
  didInvalidate=false;
  this._getOwner().handleDiskAccessException(dae);
  throw dae;
}
 finally {
  if (oqlIndexManager != null) {
    oqlIndexManager.countDownIndexUpdaters();
  }
  if (invalidatedRe != null) {
    owner.basicInvalidatePart3(invalidatedRe,event,invokeCallbacks);
  }
  if (didInvalidate && !clearOccured) {
    try {
      lruUpdateCallback();
    }
 catch (    DiskAccessException dae) {
      this._getOwner().handleDiskAccessException(dae);
      throw dae;
    }
  }
 else   if (!didInvalidate) {
    resetThreadLocals();
  }
}
",0,0,0,,
255,} finally {,"try {
synchronized (re) {
    if (!re.isRemoved()) {
      runner.run();
    }
  }
}
  finally {
  if (disabled) {
    enableLruUpdateCallback();
  }
  try {
    lruUpdateCallback();
  }
 catch (  DiskAccessException dae) {
    this._getOwner().handleDiskAccessException(dae);
    throw dae;
  }
}
",0,0,0,,
256,} finally {,"try {
  openRAF();
  writeLiveData();
  success=true;
  if (!tmpFile.delete()) {
    throw new DiskAccessException(""could not delete temporary file "" + tmpFile,parent);
  }
}
 catch (DiskAccessException e) {
  if (logger.isDebugEnabled()) {
    logger.debug(""Exception compacting init file {}"",this,e);
  }
}
 finally {
  if (!success) {
    try {
      ifRAF.close();
    }
 catch (    IOException ignore2) {
    }
    if (!ifFile.delete()) {
      throw new DiskAccessException(""could not delete file "" + ifFile,parent);
    }
    if (!tmpFile.renameTo(ifFile)) {
      throw new DiskAccessException(""could not rename file "" + tmpFile + "" to ""+ ifFile,parent);
    }
    openRAF();
    ifLiveRecordCount=0;
    ifTotalRecordCount=0;
  }
}
",0,0,0,,
257,} finally {,"try {
  RegionEntry re=getRegionEntry(event.getKey());
  if (re != null) {
synchronized (re) {
      if (clientEvent != null) {
        clientEvent.setVersionTag(re.getVersionStamp().asVersionTag());
      }
      event.setNewValue(re.getValue(this));
    }
  }
}
  finally {
  if (disabled) {
    entries.enableLruUpdateCallback();
  }
  try {
    entries.lruUpdateCallback();
  }
 catch (  DiskAccessException dae) {
    handleDiskAccessException(dae);
    throw dae;
  }
}
",0,0,0,,
258,} finally {,"try {
  setRegionByPath(region.getFullPath(),region);
  region.preInitialize();
  region.initialize(snapshotInputStream,imageTarget,internalRegionArgs);
  success=true;
}
 catch (CancelException|RedundancyAlreadyMetException e) {
  throw e;
}
catch (RuntimeException validationException) {
  logger.warn(String.format(""Initialization failed for Region %s"",region.getFullPath()),validationException);
  throw validationException;
}
 finally {
  if (!success) {
    try {
      region.cleanupFailedInitialization();
    }
 catch (    VirtualMachineError e) {
      SystemFailure.initiateFailure(e);
      throw e;
    }
catch (    Throwable t) {
      SystemFailure.checkFailure();
      stopper.checkCancelInProgress(t);
      logger.warn(String.format(""Initialization failed for Region %s"",region.getFullPath()),t);
    }
 finally {
      setRegionByPath(region.getFullPath(),null);
      rootRegions.remove(name,region);
    }
  }
}
",0,0,0,,
259,} finally {,"try {
synchronized (regionEntry) {
    clientEvent.setVersionTag(regionEntry.getVersionStamp().asVersionTag());
    value=getDeserialized(regionEntry,updateStats,disableCopyOnRead,preferCachedDeserializable,retainResult);
  }
}
  finally {
  if (disabled) {
    entries.enableLruUpdateCallback();
  }
  try {
    entries.lruUpdateCallback();
  }
 catch (  DiskAccessException dae) {
    handleDiskAccessException(dae);
    throw dae;
  }
}
",0,0,0,,
260,} finally {,"try {
  refreshEntriesFromServerKeys(null,serverKeys,interestResultPolicy);
  finishedRefresh=true;
}
  finally {
  if (!finishedRefresh) {
switch (interestType) {
case InterestType.FILTER_CLASS:
      proxy.unregisterInterest(key,interestType,false,false);
    break;
case InterestType.KEY:
  if (key instanceof String && key.equals(""ALL_KEYS"")) {
    proxy.unregisterInterest("".*"",InterestType.REGULAR_EXPRESSION,false,false);
  }
 else   if (key instanceof List) {
    proxy.unregisterInterestList((List)key,false,false);
  }
 else {
    proxy.unregisterInterest(key,InterestType.KEY,false,false);
  }
break;
case InterestType.OQL_QUERY:
proxy.unregisterInterest(key,InterestType.OQL_QUERY,false,false);
break;
case InterestType.REGULAR_EXPRESSION:
{
proxy.unregisterInterest(key,InterestType.REGULAR_EXPRESSION,false,false);
break;
}
default :
throw new InternalGemFireError(""unknown interest type"");
}
}
}
",0,0,0,,
261,} finally {,"try {
  this.closed=true;
  this.seenEvents.clear();
  this.seenResults.clear();
  freePendingCallbacks();
  if (this.locks != null) {
    final long conflictStart=statisticsClock.getTime();
    try {
      this.locks.cleanup(getCache().getInternalDistributedSystem());
    }
 catch (    IllegalArgumentException|IllegalMonitorStateException e) {
      exception=e;
    }
    if (statisticsClock.isEnabled()) {
      this.proxy.getTxMgr().getCachePerfStats().incTxConflictCheckTime(statisticsClock.getTime() - conflictStart);
    }
  }
  Iterator<Map.Entry<InternalRegion,TXRegionState>> it=this.regions.entrySet().iterator();
  while (it.hasNext()) {
    Map.Entry<InternalRegion,TXRegionState> me=it.next();
    InternalRegion r=me.getKey();
    TXRegionState txrs=me.getValue();
    if (gotBucketLocks) {
      if (r instanceof BucketRegion && (((BucketRegion)r).getBucketAdvisor().isPrimary())) {
        try {
          ((BucketRegion)r).doUnlockForPrimary();
        }
 catch (        RegionDestroyedException rde) {
          if (logger.isDebugEnabled()) {
            logger.debug(""RegionDestroyedException while unlocking bucket region {}"",r.getFullPath(),rde);
          }
        }
catch (        Exception rde) {
          if (logger.isDebugEnabled()) {
            logger.debug(""Exception while unlocking bucket region {} this is probably because the bucket was destroyed and never locked initially."",r.getFullPath(),rde);
          }
        }
      }
    }
    txrs.cleanup(r);
  }
}
  finally {
synchronized (this.completionGuard) {
    this.completionGuard.notifyAll();
  }
  if (exception != null && !this.proxy.getCache().isClosed()) {
    throw exception;
  }
}
",0,0,0,,
262,} finally {,"try {
  ms.writeMessage();
  ConnectExceptions ce=ms.getConnectExceptions();
  if (ce != null && !ce.getMembers().isEmpty()) {
    Assert.assertTrue(ce.getMembers().size() == 1);
    logger.warn(""Failed sending a direct reply to {}"",ce.getMembers().iterator().next());
    return Collections.singleton(ce.getMembers().iterator().next());
  }
  sentReply=true;
  return Collections.emptySet();
}
 catch (NotSerializableException e) {
  throw new InternalGemFireException(e);
}
catch (IOException ex) {
  throw new InternalGemFireException(""Unknown error serializing message"",ex);
}
 finally {
  try {
    ms.close();
  }
 catch (  IOException e) {
    throw new InternalGemFireException(""Unknown error serializing message"",e);
  }
}
",0,0,0,,
263,} finally {,"try {
  HashMap<String,CqQueryImpl> cqMap=cqQueryMap;
  if (!cqMap.containsKey(serverCqName)) {
    return;
  }
  cQuery=(ServerCQImpl)getCq(serverCqName);
}
 catch (CacheLoaderException e1) {
  errMsg=""CQ not found in the cq meta region, CqName: %s"";
  ex=e1;
}
catch (TimeoutException e2) {
  errMsg=""Timeout while trying to get CQ from meta region, CqName: %s"";
  ex=e2;
}
 finally {
  if (ex != null) {
    String s=String.format(errMsg,cqName);
    if (logger.isDebugEnabled()) {
      logger.debug(s);
    }
    throw new CqException(s,ex);
  }
}
",0,0,0,,
264,} finally {,"try {
  HashMap<String,CqQueryImpl> cqMap=cqQueryMap;
  if (!cqMap.containsKey(serverCqName)) {
    return;
  }
  cQuery=(ServerCQImpl)cqMap.get(serverCqName);
}
 catch (CacheLoaderException e1) {
  errMsg=""CQ not found in the cq meta region, CqName: %s"";
  ex=e1;
}
catch (TimeoutException e2) {
  errMsg=""Timeout while trying to get CQ from meta region, CqName: %s"";
  ex=e2;
}
 finally {
  if (ex != null) {
    String s=String.format(errMsg,cqName);
    if (logger.isDebugEnabled()) {
      logger.debug(s);
    }
    throw new CqException(s,ex);
  }
}
",0,0,0,,
265,} finally {,"try {
  this.query=constructServerSideQuery();
  if (isDebugEnabled) {
    logger.debug(""Server side query for the cq: {} is: {}"",cqName,this.query.getQueryString());
  }
}
 catch (Exception ex) {
  t=ex;
  if (ex instanceof ClassNotFoundException) {
    msg=""Class not found exception. The antlr.jar or the spcified class may be missing from server side classpath. Error : %s"";
  }
 else {
    msg=""Error while parsing the query. Error : %s"";
  }
}
 finally {
  if (t != null) {
    String s=String.format(msg,t);
    if (isDebugEnabled) {
      logger.debug(s,t);
    }
    throw new CqException(s);
  }
}
",0,0,0,,
266,} finally {,"try {
  Collection<String> manifestcp=module.getClassPath();
  JarFile warFile=module.getModuleFile();
  Enumeration<JarEntry> entries=warFile.entries();
  List<ZipEntry> libs=new ArrayList<ZipEntry>();
  while (entries.hasMoreElements()) {
    ZipEntry entry=entries.nextElement();
    URI targetPath=module.resolve(entry.getName());
    if (entry.getName().equals(""WEB-INF/web.xml"")) {
      moduleContext.addFile(targetPath,module.getOriginalSpecDD());
    }
 else     if (entry.getName().startsWith(""WEB-INF/lib"") && entry.getName().endsWith("".jar"")) {
      libs.add(entry);
    }
 else {
      moduleContext.addFile(targetPath,warFile,entry);
    }
  }
  moduleContext.addToClassPath(module.resolve(""WEB-INF/classes"").getPath());
  manifestcp.add(""WEB-INF/classes"");
  for (  ZipEntry entry : libs) {
    URI targetPath=module.resolve(entry.getName());
    moduleContext.addInclude(targetPath,warFile,entry);
    manifestcp.add(entry.getName());
  }
  moduleContext.addManifestClassPath(warFile,RELATIVE_MODULE_BASE_URI,manifestcp);
  for (  String classpath : manifestcp) {
    earContext.addToClassPath(module.resolve(classpath).toString());
  }
}
 catch (IOException e) {
  throw new DeploymentException(""Problem deploying war"",e);
}
 finally {
  if (!module.isStandAlone()) {
    try {
      moduleContext.flush();
    }
 catch (    IOException e) {
      throw new DeploymentException(""Problem closing war context"",e);
    }
  }
}
",0,0,0,,
267,} finally {,"try {
  if (next != null) {
    next.after(beforeAfterContext,httpRequest,httpResponse,dispatch);
  }
}
  finally {
  if (beforeAfterContext.clearRequiredFlags[index]) {
    boolean active=(Boolean)beforeAfterContext.contexts[index];
    beforeAfterContext.clearRequiredFlags[index]=false;
    if ((!active && isMarkedRollback()) || (dispatch == EDGE_SERVLET && isActive())) {
      try {
        userTransaction.rollback();
      }
 catch (      SystemException e) {
        throw new RuntimeException(""Error rolling back transaction left open by user program"",e);
      }
    }
  }
}
",0,0,0,,
268,} finally {,"try {
  ssh.start();
  System.setProperty(""MavenTest.jsch.port"",Integer.toString(ssh.getPort()));
  invocation.run();
}
 catch (final IOException e) {
  fail(e);
}
 finally {
  System.clearProperty(""MavenTest.jsch.port"");
  if (ssh.isStarted()) {
    try {
      ssh.close(true).await();
    }
 catch (    final IOException e) {
      throw new IllegalStateException(e);
    }
  }
}
",0,0,0,,
269,} finally {,"try {
  try {
    doClose();
  }
 catch (  Exception e) {
  }
  transactionManager.setRollbackOnly();
  if (t instanceof Exception) {
    Exception e=(Exception)t;
    for (    ChunkListener chunkProxy : chunkListeners) {
      try {
        chunkProxy.onError(e);
      }
 catch (      final Exception e1) {
        logger.log(Level.SEVERE,e1.getMessage(),e1);
      }
    }
  }
  stepContext.getMetric(MetricImpl.MetricType.ROLLBACK_COUNT).incValue();
}
  finally {
  int txStatus=transactionManager.getStatus();
  if (txStatus == Status.STATUS_ACTIVE || txStatus == Status.STATUS_MARKED_ROLLBACK) {
    transactionManager.rollback();
  }
  throw new BatchContainerRuntimeException(""Failure in Read-Process-Write Loop"",t);
}
",0,0,0,,
270,} finally {,"try {
  return internalCreate(expectedType,lazyRefAllowed);
}
  finally {
  Recipe popped=context.pop();
  if (popped != this) {
    throw new IllegalStateException(""Internal Error: recipe stack is corrupt:"" + "" Expected "" + this + "" to be popped of the stack but ""+ popped+ "" was"");
  }
}
",0,0,0,,
271,} finally {,"try {
  ExecutionContext context=ExecutionContext.getContext();
  if (getName() != null && context.containsObject(getName()) && !(context.getObject(getName()) instanceof Recipe)) {
    return context.getObject(getName());
  }
  context.push(this);
  try {
    return internalCreate(expectedType,lazyRefAllowed);
  }
  finally {
    Recipe popped=context.pop();
    if (popped != this) {
      throw new IllegalStateException(""Internal Error: recipe stack is corrupt:"" + "" Expected "" + this + "" to be popped of the stack but ""+ popped+ "" was"");
    }
  }
}
  finally {
  if (createNewContext) {
    ExecutionContext context=ExecutionContext.getContext();
    ExecutionContext.setContext(null);
    Map<String,List<Reference>> unresolvedRefs=context.getUnresolvedRefs();
    if (!unresolvedRefs.isEmpty()) {
      throw new UnresolvedReferencesException(unresolvedRefs);
    }
  }
  if (oldClassLoader == null) {
    Thread.currentThread().setContextClassLoader(null);
  }
}
",0,0,0,,
272,} finally {,"try {
  return state;
}
  finally {
  state=newState;
switch (newState) {
case UNINITIALISED:
    throw new IllegalStateException();
case BEFORE_CUSTOM_DATA:
  delegateTo(new DefaultWriteObjectReader(objectReader));
break;
case IN_CUSTOM_DATA:
delegateTo(objectReader);
break;
case CLOSED:
delegateTo(ClosedObjectReader.INSTANCE);
break;
}
}
",0,0,0,,
273,} finally {,"try {
  LOG.info(""Start HBase mini cluster."");
  hbaseCluster=htu.startMiniCluster(numServers);
  LOG.info(""After cluster start-up."");
  hbaseCluster.waitForActiveAndReadyMaster();
  LOG.info(""After active and ready."");
  conf=hbaseCluster.getConfiguration();
}
 catch (Exception ex) {
  throw new RuntimeException(""Minicluster not starting."");
}
 finally {
  Runtime.getRuntime().addShutdownHook(new Thread(new Runnable(){
    @Override public void run(){
      try {
        if (hbaseCluster != null) {
          hbaseCluster.shutdown();
        }
      }
 catch (      IOException e) {
        throw new RuntimeException(""Exception shutting down cluster."");
      }
    }
  }
));
}
",0,0,0,,
274,} finally {,"try {
  final Method fireTaskStarted=Project.class.getDeclaredMethod(""fireTaskStarted"",Task.class);
  ReflectionUtils.trySetAccessible(fireTaskStarted);
  fireTaskStarted.invoke(project,task);
  Object realThing;
  realThing=task;
  task.maybeConfigure();
  if (task instanceof UnknownElement) {
    realThing=((UnknownElement)task).getRealThing();
  }
  DispatchUtils.execute(task);
  return realThing != null ? realThing : task;
}
 catch (BuildException ex) {
  if (ex.getLocation() == Location.UNKNOWN_LOCATION) {
    ex.setLocation(task.getLocation());
  }
  reason=ex;
  throw ex;
}
catch (Exception ex) {
  reason=ex;
  BuildException be=new BuildException(ex);
  be.setLocation(task.getLocation());
  throw be;
}
catch (Error ex) {
  reason=ex;
  throw ex;
}
 finally {
  try {
    final Method fireTaskFinished=Project.class.getDeclaredMethod(""fireTaskFinished"",Task.class,Throwable.class);
    ReflectionUtils.trySetAccessible(fireTaskFinished);
    fireTaskFinished.invoke(project,task,reason);
  }
 catch (  Exception e) {
    BuildException be=new BuildException(e);
    be.setLocation(task.getLocation());
    throw be;
  }
}
",0,0,0,,
275,} finally {,"try {
  String output=FileUtil.execCommand(new File(getPath().toUri()),Shell.getGetPermissionCommand());
  StringTokenizer t=new StringTokenizer(output,Shell.TOKEN_SEPARATOR_REGEX);
  String permission=t.nextToken();
  if (permission.length() > FsPermission.MAX_PERMISSION_LENGTH) {
    permission=permission.substring(0,FsPermission.MAX_PERMISSION_LENGTH);
  }
  setPermission(FsPermission.valueOf(permission));
  t.nextToken();
  String owner=t.nextToken();
  String group=t.nextToken();
  if (Shell.WINDOWS) {
    owner=removeDomain(owner);
    group=removeDomain(group);
  }
  setOwner(owner);
  setGroup(group);
}
 catch (Shell.ExitCodeException ioe) {
  if (ioe.getExitCode() != 1) {
    e=ioe;
  }
 else {
    setPermission(null);
    setOwner(null);
    setGroup(null);
  }
}
catch (IOException ioe) {
  e=ioe;
}
 finally {
  if (e != null) {
    throw new RuntimeException(""Error while running command to get "" + ""file permissions : "" + StringUtils.stringifyException(e));
  }
}
",0,0,0,,
276,} finally {,"try {
  client=connect();
  Path homeDir=new Path(client.printWorkingDirectory());
  return homeDir;
}
 catch (IOException ioe) {
  throw new FTPException(""Failed to get home directory"",ioe);
}
 finally {
  try {
    disconnect(client);
  }
 catch (  IOException ioe) {
    throw new FTPException(""Failed to disconnect"",ioe);
  }
}
",0,0,0,,
277,} finally {,"try {
  if (!dir.isDirectory()) {
    metric.diskCheckFailed();
    throw new DiskErrorException(dir + "" is not a directory!"");
  }
  DiskChecker.checkDir(dir);
  tmpFile=Files.createTempFile(dir.toPath(),""test"",""tmp"");
  byte[] inputBytes=new byte[16];
  RANDOM.nextBytes(inputBytes);
  long startTime=System.nanoTime();
  Files.write(tmpFile,inputBytes);
  long writeLatency=TimeUnit.MICROSECONDS.convert(System.nanoTime() - startTime,TimeUnit.NANOSECONDS);
  metric.addWriteFileLatency(writeLatency);
  startTime=System.nanoTime();
  byte[] outputBytes=Files.readAllBytes(tmpFile);
  long readLatency=TimeUnit.MICROSECONDS.convert(System.nanoTime() - startTime,TimeUnit.NANOSECONDS);
  metric.addReadFileLatency(readLatency);
  if (!Arrays.equals(inputBytes,outputBytes)) {
    metric.diskCheckFailed();
    throw new DiskErrorException(""Data in file has been corrupted."");
  }
}
 catch (IOException e) {
  metric.diskCheckFailed();
  throw new DiskErrorException(""Disk Check failed!"",e);
}
 finally {
  if (tmpFile != null) {
    try {
      Files.delete(tmpFile);
    }
 catch (    IOException e) {
      metric.diskCheckFailed();
      throw new DiskErrorException(""File deletion failed!"",e);
    }
  }
}
",0,0,0,,
278,} finally {,"try {
  TEST_JETTY_TL.set(TestJettyHelper.this);
  statement.evaluate();
}
  finally {
  TEST_JETTY_TL.remove();
  if (server != null && server.isRunning()) {
    try {
      server.stop();
    }
 catch (    Exception ex) {
      throw new RuntimeException(""Could not stop embedded servlet container, "" + ex.getMessage(),ex);
    }
  }
}
",0,0,0,,
279,} finally {,"try {
  zookeeper=zkClient.getZookeeperClient().getZooKeeper();
}
 catch (Exception e) {
  LOG.info(""Cannot get zookeeper client "",e);
}
 finally {
  if (zookeeper == null) {
    throw new IOException(""Zookeeper client is null"");
  }
}
",0,0,0,,
280,} finally {,"try {
  aliasMapSnapshot=createSnapshot(aliasMap);
  compressedAliasMap=getCompressedAliasMap(new File(aliasMapSnapshot,aliasMap.blockPoolID));
  try (FileInputStream fis=new FileInputStream(compressedAliasMap)){
    ImageServlet.setVerificationHeadersForGet(response,compressedAliasMap);
    ImageServlet.setFileNameHeaders(response,compressedAliasMap);
    DataTransferThrottler throttler=ImageServlet.getThrottlerForBootstrapStandby(conf);
    TransferFsImage.copyFileToStream(response.getOutputStream(),compressedAliasMap,fis,throttler);
  }
 }
  finally {
  StringBuilder errMessage=new StringBuilder();
  if (compressedAliasMap != null && !FileUtil.fullyDelete(compressedAliasMap)) {
    errMessage.append(""Failed to fully delete compressed aliasmap "").append(compressedAliasMap.getAbsolutePath()).append(""\n"");
  }
  if (aliasMapSnapshot != null && !FileUtil.fullyDelete(aliasMapSnapshot)) {
    errMessage.append(""Failed to fully delete the aliasmap snapshot "").append(aliasMapSnapshot.getAbsolutePath()).append(""\n"");
  }
  if (errMessage.length() > 0) {
    throw new IOException(errMessage.toString());
  }
}
",0,0,0,,
281,} finally {,"try {
  if (localPaths != null) {
    for (    File f : localPaths) {
      try {
        if (f.exists()) {
          LOG.warn(""Overwriting existing file "" + f + "" with file downloaded from ""+ url);
        }
        FileOutputStream fos=new FileOutputStream(f);
        outputStreams.add(fos);
        streamPathMap.put(fos,f);
      }
 catch (      IOException ioe) {
        LOG.warn(""Unable to download file "" + f,ioe);
        if (dstStorage != null && (dstStorage instanceof StorageErrorReporter)) {
          ((StorageErrorReporter)dstStorage).reportErrorOnFile(f);
        }
      }
    }
    if (outputStreams.isEmpty()) {
      throw new IOException(""Unable to download to any storage directory"");
    }
  }
  byte[] buf=new byte[IO_FILE_BUFFER_SIZE];
  while (num > 0) {
    num=stream.read(buf);
    if (num > 0) {
      received+=num;
      for (      FileOutputStream fos : outputStreams) {
        fos.write(buf,0,num);
      }
      if (throttler != null) {
        throttler.throttle(num);
      }
    }
  }
  finishedReceiving=true;
  double xferSec=Math.max(((float)(Time.monotonicNow() - startTime)) / 1000.0,0.001);
  long xferKb=received / 1024;
  xferCombined+=xferSec;
  xferStats.append(String.format("" The file download took %.2fs at %.2f KB/s."",xferSec,xferKb / xferSec));
}
  finally {
  stream.close();
  for (  FileOutputStream fos : outputStreams) {
    long flushStartTime=Time.monotonicNow();
    fos.getChannel().force(true);
    fos.close();
    double writeSec=Math.max(((float)(flushStartTime - Time.monotonicNow())) / 1000.0,0.001);
    xferCombined+=writeSec;
    xferStats.append(String.format("" Synchronous (fsync) write to disk of "" + streamPathMap.get(fos).getAbsolutePath() + "" took %.2fs."",writeSec));
  }
  if (!finishedReceiving) {
    deleteTmpFiles(localPaths);
  }
  if (finishedReceiving && received != advertisedSize) {
    deleteTmpFiles(localPaths);
    throw new IOException(""File "" + url + "" received length ""+ received+ "" is not of the advertised size ""+ advertisedSize+ "". Fsimage name: ""+ fsImageName+ "" lastReceived: ""+ num);
  }
}
",0,0,0,,
282,} finally {,"try {
  if (isClient && !isTransfer) {
    responder=new Daemon(datanode.threadGroup,new PacketResponder(replyOut,mirrIn,downstreams));
    responder.start();
  }
  while (receivePacket() >= 0) {
  }
  if (responder != null) {
    ((PacketResponder)responder.getRunnable()).close();
    responderClosed=true;
  }
  if (isDatanode || isTransfer) {
    try (ReplicaHandler handler=claimReplicaHandler()){
      close();
      block.setNumBytes(replicaInfo.getNumBytes());
      if (stage == BlockConstructionStage.TRANSFER_RBW) {
        datanode.data.convertTemporaryToRbw(block);
      }
 else {
        datanode.data.finalizeBlock(block,dirSyncOnFinalize);
      }
    }
     datanode.metrics.incrBlocksWritten();
  }
}
 catch (IOException ioe) {
  replicaInfo.releaseAllBytesReserved();
  if (datanode.isRestarting()) {
    LOG.info(""Shutting down for restart ("" + block + "")."");
  }
 else {
    LOG.info(""Exception for "" + block,ioe);
    throw ioe;
  }
}
 finally {
  Thread.interrupted();
  if (!responderClosed) {
    if (responder != null) {
      if (datanode.isRestarting() && isClient && !isTransfer) {
        try (Writer out=new OutputStreamWriter(replicaInfo.createRestartMetaStream(),""UTF-8"")){
          out.write(Long.toString(Time.now() + restartBudget));
          out.flush();
        }
 catch (        IOException ioe) {
        }
 finally {
          IOUtils.closeStream(streams.getDataOut());
        }
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
      }
      responder.interrupt();
    }
    IOUtils.closeStream(this);
    cleanupBlock();
  }
  if (responder != null) {
    try {
      responder.interrupt();
      long joinTimeout=datanode.getDnConf().getXceiverStopTimeout();
      joinTimeout=joinTimeout > 1 ? joinTimeout * 8 / 10 : joinTimeout;
      responder.join(joinTimeout);
      if (responder.isAlive()) {
        String msg=""Join on responder thread "" + responder + "" timed out"";
        LOG.warn(msg + ""\n"" + StringUtils.getStackTrace(responder));
        throw new IOException(msg);
      }
    }
 catch (    InterruptedException e) {
      responder.interrupt();
      if (!datanode.isRestarting()) {
        throw new InterruptedIOException(""Interrupted receiveBlock"");
      }
    }
    responder=null;
  }
}
",0,0,0,,
283,} finally {,"try {
  LOG.info(""Reconfiguring {} to {}"",property,newVal);
  this.refreshVolumes(newVal);
  return getConf().get(DFS_DATANODE_DATA_DIR_KEY);
}
 catch (IOException e) {
  rootException=e;
}
 finally {
  try {
    triggerBlockReport(new BlockReportOptions.Factory().setIncremental(false).build());
  }
 catch (  IOException e) {
    LOG.warn(""Exception while sending the block report after refreshing"" + "" volumes {} to {}"",property,newVal,e);
    if (rootException == null) {
      rootException=e;
    }
  }
 finally {
    if (rootException != null) {
      throw new ReconfigurationException(property,newVal,getConf().get(property),rootException);
    }
  }
}
",0,0,0,,
284,} finally {,"try {
  triggerBlockReport(new BlockReportOptions.Factory().setIncremental(false).build());
}
 catch (IOException e) {
  LOG.warn(""Exception while sending the block report after refreshing"" + "" volumes {} to {}"",property,newVal,e);
  if (rootException == null) {
    rootException=e;
  }
}
 finally {
  if (rootException != null) {
    throw new ReconfigurationException(property,newVal,getConf().get(property),rootException);
  }
}
",0,0,0,,
285,} finally {,"try {
  LOG.info(""Reconfiguring {} to {}"",property,newVal);
  int movers;
  if (newVal == null) {
    movers=DFS_DATANODE_BALANCE_MAX_NUM_CONCURRENT_MOVES_DEFAULT;
  }
 else {
    movers=Integer.parseInt(newVal);
    if (movers <= 0) {
      rootException=new ReconfigurationException(property,newVal,getConf().get(property),new IllegalArgumentException(""balancer max concurrent movers must be larger than 0""));
    }
  }
  boolean success=xserver.updateBalancerMaxConcurrentMovers(movers);
  if (!success) {
    rootException=new ReconfigurationException(property,newVal,getConf().get(property),new IllegalArgumentException(""Could not modify concurrent moves thread count""));
  }
  return Integer.toString(movers);
}
 catch (NumberFormatException nfe) {
  rootException=new ReconfigurationException(property,newVal,getConf().get(property),nfe);
}
 finally {
  if (rootException != null) {
    LOG.warn(String.format(""Exception in updating balancer max concurrent movers %s to %s"",property,newVal),rootException);
    throw rootException;
  }
}
",0,0,0,,
286,} finally {,"try {
  flush();
  ((FileOutputStream)out).getChannel().force(true);
  triedToClose=true;
  super.close();
  success=true;
}
  finally {
  if (success) {
    boolean renamed=tmpFile.renameTo(origFile);
    if (!renamed) {
      if (origFile.exists()) {
        try {
          Files.delete(origFile.toPath());
        }
 catch (        IOException e) {
          throw new IOException(""Could not delete original file "" + origFile,e);
        }
      }
      try {
        NativeIO.renameTo(tmpFile,origFile);
      }
 catch (      NativeIOException e) {
        throw new IOException(""Could not rename temporary file "" + tmpFile + "" to ""+ origFile+ "" due to failure in native rename. ""+ e.toString());
      }
    }
  }
 else {
    if (!triedToClose) {
      IOUtils.closeStream(out);
    }
    if (!tmpFile.delete()) {
      LOG.warn(""Unable to delete tmp file "" + tmpFile);
    }
  }
}
",0,0,0,,
287,} finally {,"try {
  DatanodeInfo[] nodes=lblock.getLocations();
  targetAddr=NetUtils.createSocketAddr(nodes[0].getXferAddr());
  blockReader=new BlockReaderFactory(new DfsClientConf(conf)).setFileName(BlockReaderFactory.getFileName(targetAddr,""test-blockpoolid"",block.getBlockId())).setBlock(block).setBlockToken(lblock.getBlockToken()).setInetSocketAddress(targetAddr).setStartOffset(0).setLength(0).setVerifyChecksum(true).setClientName(""TestBlockTokenWithDFS"").setDatanodeInfo(nodes[0]).setCachingStrategy(CachingStrategy.newDefaultStrategy()).setClientCacheContext(ClientContext.getFromConf(conf)).setConfiguration(conf).setRemotePeerFactory(new RemotePeerFactory(){
    @Override public Peer newConnectedPeer(    InetSocketAddress addr,    Token<BlockTokenIdentifier> blockToken,    DatanodeID datanodeId) throws IOException {
      Peer peer=null;
      Socket sock=NetUtils.getDefaultSocketFactory(conf).createSocket();
      try {
        sock.connect(addr,HdfsConstants.READ_TIMEOUT);
        sock.setSoTimeout(HdfsConstants.READ_TIMEOUT);
        peer=DFSUtilClient.peerFromSocket(sock);
      }
  finally {
        if (peer == null) {
          IOUtils.closeSocket(sock);
        }
      }
      return peer;
    }
  }
).build();
}
 catch (IOException ex) {
  ioe=ex;
}
 finally {
  if (blockReader != null) {
    try {
      blockReader.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
288,} finally {,"try {
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final NamenodeProtocols nn=cluster.getNameNode().getRpcServer();
  FSImage fsimage=cluster.getNamesystem().getFSImage();
  StorageDirectory sd=fsimage.getStorage().getStorageDir(0);
  startTransactionWorkers(cluster,caughtErr);
  long previousLogTxId=1;
  for (int i=0; i < NUM_ROLLS && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException e) {
    }
    LOG.info(""Starting roll "" + i + ""."");
    CheckpointSignature sig=nn.rollEditLog();
    long nextLog=sig.curSegmentTxId;
    String logFileName=NNStorage.getFinalizedEditsFileName(previousLogTxId,nextLog - 1);
    previousLogTxId+=verifyEditLogs(cluster.getNamesystem(),fsimage,logFileName,previousLogTxId);
    assertEquals(previousLogTxId,nextLog);
    File expectedLog=NNStorage.getInProgressEditsFile(sd,previousLogTxId);
    assertTrue(""Expect "" + expectedLog + "" to exist"",expectedLog.exists());
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
289,} finally {,"try {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  FSEditLog editLog=fsimage.getEditLog();
  startTransactionWorkers(cluster,caughtErr);
  for (int i=0; i < NUM_SAVE_IMAGE && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException ignored) {
    }
    LOG.info(""Save "" + i + "": entering safe mode"");
    namesystem.enterSafeMode(false);
    long logStartTxId=fsimage.getStorage().getMostRecentCheckpointTxId() + 1;
    verifyEditLogs(namesystem,fsimage,NNStorage.getInProgressEditsFileName(logStartTxId),logStartTxId);
    LOG.info(""Save "" + i + "": saving namespace"");
    namesystem.saveNamespace(0,0);
    LOG.info(""Save "" + i + "": leaving safemode"");
    long savedImageTxId=fsimage.getStorage().getMostRecentCheckpointTxId();
    verifyEditLogs(namesystem,fsimage,NNStorage.getFinalizedEditsFileName(logStartTxId,savedImageTxId),logStartTxId);
    assertEquals(fsimage.getStorage().getMostRecentCheckpointTxId(),editLog.getLastWrittenTxId() - 1);
    namesystem.leaveSafeMode(false);
    LOG.info(""Save "" + i + "": complete"");
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
290,} finally {,"try {
  Configuration conf=new HdfsConfiguration();
  int dataBlocks=StripedFileTestUtil.getDefaultECPolicy().getNumDataUnits();
  int parityBlocks=StripedFileTestUtil.getDefaultECPolicy().getNumParityUnits();
  int cellSize=StripedFileTestUtil.getDefaultECPolicy().getCellSize();
  int totalSize=dataBlocks + parityBlocks;
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(totalSize).build();
  fs=cluster.getFileSystem();
  fs.enableErasureCodingPolicy(StripedFileTestUtil.getDefaultECPolicy().getName());
  Path ecDirPath=new Path(""/striped"");
  fs.mkdir(ecDirPath,FsPermission.getDirDefault());
  fs.getClient().setErasureCodingPolicy(ecDirPath.toString(),StripedFileTestUtil.getDefaultECPolicy().getName());
  Path file=new Path(ecDirPath,""corrupted"");
  final int length=cellSize * dataBlocks;
  final byte[] bytes=StripedFileTestUtil.generateBytes(length);
  DFSTestUtil.writeFile(fs,file,bytes);
  LocatedStripedBlock lsb=(LocatedStripedBlock)fs.getClient().getLocatedBlocks(file.toString(),0,cellSize * dataBlocks).get(0);
  final LocatedBlock[] blks=StripedBlockUtil.parseStripedBlockGroup(lsb,cellSize,dataBlocks,parityBlocks);
  for (int i=0; i < parityBlocks + 1; i++) {
    int ipcPort=blks[i].getLocations()[0].getIpcPort();
    cluster.corruptReplica(cluster.getDataNode(ipcPort),blks[i].getBlock());
  }
  for (  DataNode dn : cluster.getDataNodes()) {
    DataNodeTestUtils.setHeartbeatsDisabledForTests(dn,true);
  }
  try {
    IOUtils.copyBytes(fs.open(file),new IOUtils.NullOutputStream(),conf,true);
  }
 catch (  IOException ie) {
    assertTrue(ie.getMessage().contains(""missingChunksNum="" + (parityBlocks + 1)));
  }
  MBeanServer mbs=ManagementFactory.getPlatformMBeanServer();
  ObjectName replStateMBeanName=new ObjectName(""Hadoop:service=NameNode,name=ReplicatedBlocksState"");
  ObjectName ecBlkGrpStateMBeanName=new ObjectName(""Hadoop:service=NameNode,name=ECBlockGroupsState"");
  ObjectName namenodeMXBeanName=new ObjectName(""Hadoop:service=NameNode,name=NameNodeInfo"");
  long expectedMissingBlockCount=1L;
  long expectedCorruptBlockCount=1L;
  GenericTestUtils.waitFor(new Supplier<Boolean>(){
    @Override public Boolean get(){
      try {
        Long numMissingBlocks=(Long)mbs.getAttribute(namenodeMXBeanName,""NumberOfMissingBlocks"");
        if (numMissingBlocks == expectedMissingBlockCount) {
          return true;
        }
      }
 catch (      Exception e) {
        Assert.fail(""Caught unexpected exception."");
      }
      return false;
    }
  }
,1000,60000);
  BlockManagerTestUtil.updateState(cluster.getNamesystem().getBlockManager());
  long totalMissingBlocks=cluster.getNamesystem().getMissingBlocksCount();
  Long replicaMissingBlocks=(Long)mbs.getAttribute(replStateMBeanName,""MissingReplicatedBlocks"");
  Long ecMissingBlocks=(Long)mbs.getAttribute(ecBlkGrpStateMBeanName,""MissingECBlockGroups"");
  assertEquals(""Unexpected total missing blocks!"",expectedMissingBlockCount,totalMissingBlocks);
  assertEquals(""Unexpected total missing blocks!"",totalMissingBlocks,(replicaMissingBlocks + ecMissingBlocks));
  assertEquals(""Unexpected total ec missing blocks!"",expectedMissingBlockCount,ecMissingBlocks.longValue());
  long totalCorruptBlocks=cluster.getNamesystem().getCorruptReplicaBlocks();
  Long replicaCorruptBlocks=(Long)mbs.getAttribute(replStateMBeanName,""CorruptReplicatedBlocks"");
  Long ecCorruptBlocks=(Long)mbs.getAttribute(ecBlkGrpStateMBeanName,""CorruptECBlockGroups"");
  assertEquals(""Unexpected total corrupt blocks!"",expectedCorruptBlockCount,totalCorruptBlocks);
  assertEquals(""Unexpected total corrupt blocks!"",totalCorruptBlocks,(replicaCorruptBlocks + ecCorruptBlocks));
  assertEquals(""Unexpected total ec corrupt blocks!"",expectedCorruptBlockCount,ecCorruptBlocks.longValue());
  String corruptFiles=(String)(mbs.getAttribute(namenodeMXBeanName,""CorruptFiles""));
  int numCorruptFiles=((Object[])JSON.parse(corruptFiles)).length;
  assertEquals(1,numCorruptFiles);
}
  finally {
  if (fs != null) {
    try {
      fs.close();
    }
 catch (    Exception e) {
      throw e;
    }
  }
  if (cluster != null) {
    cluster.shutdown();
  }
}
",0,0,0,,
291,} finally {,"try {
  Configuration conf=new HdfsConfiguration();
  int dataBlocks=StripedFileTestUtil.getDefaultECPolicy().getNumDataUnits();
  int parityBlocks=StripedFileTestUtil.getDefaultECPolicy().getNumParityUnits();
  int totalSize=dataBlocks + parityBlocks;
  int cellSize=StripedFileTestUtil.getDefaultECPolicy().getCellSize();
  int stripesPerBlock=2;
  int blockSize=stripesPerBlock * cellSize;
  conf.setLong(DFSConfigKeys.DFS_BLOCK_SIZE_KEY,blockSize);
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(totalSize).build();
  namesystem=cluster.getNamesystem();
  fs=cluster.getFileSystem();
  fs.enableErasureCodingPolicy(StripedFileTestUtil.getDefaultECPolicy().getName());
  verifyTotalBlocksMetrics(0L,0L,namesystem.getTotalBlocks());
  Path replDirPath=new Path(""/replicated"");
  Path replFileSmall=new Path(replDirPath,""replfile_small"");
  final short factor=3;
  DFSTestUtil.createFile(fs,replFileSmall,blockSize,factor,0);
  DFSTestUtil.waitReplication(fs,replFileSmall,factor);
  Path ecDirPath=new Path(""/striped"");
  fs.mkdir(ecDirPath,FsPermission.getDirDefault());
  fs.getClient().setErasureCodingPolicy(ecDirPath.toString(),StripedFileTestUtil.getDefaultECPolicy().getName());
  Path ecFileSmall=new Path(ecDirPath,""ecfile_small"");
  final int smallLength=cellSize * dataBlocks;
  final byte[] smallBytes=StripedFileTestUtil.generateBytes(smallLength);
  DFSTestUtil.writeFile(fs,ecFileSmall,smallBytes);
  verifyTotalBlocksMetrics(1L,1L,namesystem.getTotalBlocks());
  Path replFileLarge=new Path(replDirPath,""replfile_large"");
  DFSTestUtil.createFile(fs,replFileLarge,2 * blockSize,factor,0);
  DFSTestUtil.waitReplication(fs,replFileLarge,factor);
  Path ecFileLarge=new Path(ecDirPath,""ecfile_large"");
  final int largeLength=blockSize * totalSize + smallLength;
  final byte[] largeBytes=StripedFileTestUtil.generateBytes(largeLength);
  DFSTestUtil.writeFile(fs,ecFileLarge,largeBytes);
  verifyTotalBlocksMetrics(3L,3L,namesystem.getTotalBlocks());
  fs.delete(replDirPath,true);
  verifyTotalBlocksMetrics(0L,3L,namesystem.getTotalBlocks());
  fs.delete(ecDirPath,true);
  verifyTotalBlocksMetrics(0L,0L,namesystem.getTotalBlocks());
}
  finally {
  if (fs != null) {
    try {
      fs.close();
    }
 catch (    Exception e) {
      throw e;
    }
  }
  if (namesystem != null) {
    try {
      namesystem.close();
    }
 catch (    Exception e) {
      throw e;
    }
  }
  if (cluster != null) {
    cluster.shutdown();
  }
}
",0,0,0,,
292,} finally {,"try {
  statement.executeBatch();
  connection.commit();
}
 catch (SQLException e) {
  try {
    connection.rollback();
  }
 catch (  SQLException ex) {
    LOG.warn(StringUtils.stringifyException(ex));
  }
  throw new IOException(e.getMessage());
}
 finally {
  try {
    statement.close();
    connection.close();
  }
 catch (  SQLException ex) {
    throw new IOException(ex.getMessage());
  }
}
",0,0,0,,
293,} finally {,"try {
  out=create(f,permission,overwrite,false,bufferSize,replication,blockSize,progress,lease);
}
  finally {
  try {
    if (lease != null) {
      lease.free();
    }
  }
 catch (  Exception e) {
    NativeAzureFileSystemHelper.cleanup(LOG,out);
    String msg=""Unable to free lease on "" + parent.toUri();
    LOG.error(msg);
    throw new IOException(msg,e);
  }
}
",0,0,0,,
294,} finally {,"try {
  flush();
}
 catch (IOException e) {
  ioeFromFlush=e;
  throw e;
}
 finally {
  try {
    this.out.close();
  }
 catch (  IOException e) {
    if (ioeFromFlush == e) {
      LOG.debug(""flush() and close() throwing back same Exception. Just swallowing the latter"",e);
    }
 else {
      throw e;
    }
  }
}
",0,0,0,,
295,} finally {,"try {
  if (srcNames != null) {
    Iterator iter=srcNames.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      File fsource=new File(source);
      String base=getBasePathInJarOut(source);
      if (!fsource.exists()) {
        throwing=true;
        throw new FileNotFoundException(fsource.getAbsolutePath());
      }
      if (fsource.isDirectory()) {
        addDirectory(jarOut,base,fsource,0);
      }
 else {
        addFileStream(jarOut,base,fsource);
      }
    }
  }
  if (srcUnjar != null) {
    Iterator iter=srcUnjar.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      jarSource=new JarFile(source);
      addJarEntries(jarOut,jarSource);
      jarSource.close();
    }
  }
}
  finally {
  try {
    jarOut.close();
  }
 catch (  ZipException z) {
    if (!throwing) {
      throw new IOException(z.toString());
    }
  }
}
",0,0,0,,
296,} finally {,"try {
  String stringType=resp.getEntity(String.class);
  msg=""Server response:\n"" + stringType;
}
 catch (ClientHandlerException|UniformInterfaceException chuie) {
  msg=""Error getting entity from the HTTP response."" + chuie.getLocalizedMessage();
}
catch (Throwable t) {
  msg=""Error getting entity from the HTTP response."" + t.getLocalizedMessage();
}
 finally {
  msg=""Response from the timeline server is not successful"" + "", HTTP error code: "" + resp.getStatus() + "", ""+ msg;
  LOG.error(msg);
  throw new YarnException(msg);
}
",0,0,0,,
297,} finally {,"try {
  if (writer != null) {
    writer.close();
  }
}
 catch (Exception e) {
  LOG.warn(""Exception closing writer"",e);
}
 finally {
  try {
    this.fsDataOStream.close();
  }
 catch (  DSQuotaExceededException e) {
    LOG.error(""Exception in closing {}"",this.fsDataOStream.getClass(),e);
    throw e;
  }
catch (  Throwable e) {
    LOG.error(""Exception in closing {}"",this.fsDataOStream.getClass(),e);
  }
}
",0,0,0,,
298,} finally {,"try {
  File file=new File(cGroupParamPath);
  Writer w=new OutputStreamWriter(new FileOutputStream(file),""UTF-8"");
  pw=new PrintWriter(w);
  pw.write(value);
}
 catch (IOException e) {
  throw new ResourceHandlerException(String.format(""Unable to write to %s with value: %s"",cGroupParamPath,value),e);
}
 finally {
  if (pw != null) {
    boolean hasError=pw.checkError();
    pw.close();
    if (hasError) {
      throw new ResourceHandlerException(String.format(""PrintWriter unable to write to %s with value: %s"",cGroupParamPath,value));
    }
    if (pw.checkError()) {
      throw new ResourceHandlerException(String.format(""Error while closing cgroup file %s"",cGroupParamPath));
    }
  }
}
",0,0,0,,
299,} finally {,"try {
  try {
    logAggregationFileController.initializeWriter(logControllerContext);
  }
 catch (  IOException e1) {
    logAggregationSucceedInThisCycle=false;
    LOG.error(""Cannot create writer for app "" + this.applicationId + "". Skip log upload this time. "",e1);
    return;
  }
  boolean uploadedLogsInThisCycle=false;
  for (  ContainerId container : pendingContainerInThisCycle) {
    ContainerLogAggregator aggregator=null;
    if (containerLogAggregators.containsKey(container)) {
      aggregator=containerLogAggregators.get(container);
    }
 else {
      aggregator=new ContainerLogAggregator(container);
      containerLogAggregators.put(container,aggregator);
    }
    Set<Path> uploadedFilePathsInThisCycle=aggregator.doContainerLogAggregation(logAggregationFileController,appFinished,finishedContainers.contains(container));
    if (uploadedFilePathsInThisCycle.size() > 0) {
      uploadedLogsInThisCycle=true;
      LOG.trace(""Uploaded the following files for {}: {}"",container,uploadedFilePathsInThisCycle.toString());
      List<Path> uploadedFilePathsInThisCycleList=new ArrayList<>();
      uploadedFilePathsInThisCycleList.addAll(uploadedFilePathsInThisCycle);
      if (LOG.isDebugEnabled()) {
        for (        Path uploadedFilePath : uploadedFilePathsInThisCycleList) {
          try {
            long fileSize=lfs.getFileStatus(uploadedFilePath).getLen();
            if (fileSize >= logFileSizeThreshold) {
              LOG.debug(""Log File "" + uploadedFilePath + "" size is ""+ fileSize+ "" bytes"");
            }
          }
 catch (          Exception e1) {
            LOG.error(""Failed to get log file size "" + e1);
          }
        }
      }
      deletionTask=new FileDeletionTask(delService,this.userUgi.getShortUserName(),null,uploadedFilePathsInThisCycleList);
    }
    if (finishedContainers.contains(container)) {
      containerLogAggregators.remove(container);
    }
  }
  logControllerContext.setUploadedLogsInThisCycle(uploadedLogsInThisCycle);
  logControllerContext.setLogUploadTimeStamp(System.currentTimeMillis());
  logControllerContext.increLogAggregationTimes();
  try {
    this.logAggregationFileController.postWrite(logControllerContext);
    diagnosticMessage=""Log uploaded successfully for Application: "" + appId + "" in NodeManager: ""+ LogAggregationUtils.getNodeString(nodeId)+ "" at ""+ Times.format(logControllerContext.getLogUploadTimeStamp())+ ""\n"";
  }
 catch (  Exception e) {
    diagnosticMessage=e.getMessage();
    renameTemporaryLogFileFailed=true;
    logAggregationSucceedInThisCycle=false;
  }
}
  finally {
  LogAggregationDFSException exc=null;
  try {
    this.logAggregationFileController.closeWriter();
  }
 catch (  LogAggregationDFSException e) {
    diagnosticMessage=e.getMessage();
    renameTemporaryLogFileFailed=true;
    logAggregationSucceedInThisCycle=false;
    exc=e;
  }
  if (logAggregationSucceedInThisCycle && deletionTask != null) {
    delService.delete(deletionTask);
  }
  if (diagnosticMessage != null && !diagnosticMessage.isEmpty()) {
    LOG.debug(""Sending log aggregation report along with the "" + ""following diagnostic message:\""{}\"""",diagnosticMessage);
  }
  if (!logAggregationSucceedInThisCycle) {
    LOG.warn(""Log aggregation did not succeed in this cycle"");
  }
  sendLogAggregationReport(logAggregationSucceedInThisCycle,diagnosticMessage,appFinished);
  if (exc != null) {
    throw exc;
  }
}
",0,0,0,,
300,} finally {,"try {
  File file=new File(path + ""/"" + param);
  Writer w=new OutputStreamWriter(new FileOutputStream(file),""UTF-8"");
  pw=new PrintWriter(w);
  pw.write(value);
}
 catch (IOException e) {
  throw new IOException(""Unable to set "" + param + ""=""+ value+ "" for cgroup at: ""+ path,e);
}
 finally {
  if (pw != null) {
    boolean hasError=pw.checkError();
    pw.close();
    if (hasError) {
      throw new IOException(""Unable to set "" + param + ""=""+ value+ "" for cgroup at: ""+ path);
    }
    if (pw.checkError()) {
      throw new IOException(""Error while closing cgroup file "" + path);
    }
  }
}
",0,0,0,,
301,} finally {,"try {
  String output=FileUtil.execCommand(new File(getPath().toUri()),Shell.getGetPermissionCommand());
  StringTokenizer t=new StringTokenizer(output,Shell.TOKEN_SEPARATOR_REGEX);
  String permission=t.nextToken();
  if (permission.length() > FsPermission.MAX_PERMISSION_LENGTH) {
    permission=permission.substring(0,FsPermission.MAX_PERMISSION_LENGTH);
  }
  setPermission(FsPermission.valueOf(permission));
  t.nextToken();
  String owner=t.nextToken();
  if (Shell.WINDOWS) {
    int i=owner.indexOf('\\');
    if (i != -1)     owner=owner.substring(i + 1);
  }
  setOwner(owner);
  setGroup(t.nextToken());
}
 catch (Shell.ExitCodeException ioe) {
  if (ioe.getExitCode() != 1) {
    e=ioe;
  }
 else {
    setPermission(null);
    setOwner(null);
    setGroup(null);
  }
}
catch (IOException ioe) {
  e=ioe;
}
 finally {
  if (e != null) {
    throw new RuntimeException(""Error while running command to get "" + ""file permissions : "" + StringUtils.stringifyException(e));
  }
}
",0,0,0,,
302,} finally {,"try {
  client=connect();
  Path homeDir=new Path(client.printWorkingDirectory());
  return homeDir;
}
 catch (IOException ioe) {
  throw new FTPException(""Failed to get home directory"",ioe);
}
 finally {
  try {
    disconnect(client);
  }
 catch (  IOException ioe) {
    throw new FTPException(""Failed to disconnect"",ioe);
  }
}
",0,0,0,,
303,} finally {,"try {
  ClassLoader cl=Thread.currentThread().getContextClassLoader();
  URL url=cl.getResource(""webapp"");
  if (url == null) {
    throw new RuntimeException(""Could not find webapp/ dir in test classpath"");
  }
  WebAppContext context=new WebAppContext(url.getPath(),""/kms"");
  jetty.addHandler(context);
  jetty.start();
  url=new URL(getJettyURL(jetty),""kms"");
  System.out.println(""Test KMS running at: "" + url);
  callable.kmsUrl=url;
  callable.call();
}
  finally {
  if (jetty != null && jetty.isRunning()) {
    try {
      jetty.stop();
    }
 catch (    Exception ex) {
      throw new RuntimeException(""Could not stop embedded Jetty, "" + ex.getMessage(),ex);
    }
  }
}
",0,0,0,,
304,} finally {,"try {
  TEST_JETTY_TL.set(TestJettyHelper.this);
  statement.evaluate();
}
  finally {
  TEST_JETTY_TL.remove();
  if (server != null && server.isRunning()) {
    try {
      server.stop();
    }
 catch (    Exception ex) {
      throw new RuntimeException(""Could not stop embedded servlet container, "" + ex.getMessage(),ex);
    }
  }
}
",0,0,0,,
305,} finally {,"try {
  if (isClient && !isTransfer) {
    responder=new Daemon(datanode.threadGroup,new PacketResponder(replyOut,mirrIn,downstreams));
    responder.start();
  }
  while (receivePacket() >= 0) {
  }
  if (responder != null) {
    ((PacketResponder)responder.getRunnable()).close();
    responderClosed=true;
  }
  if (isDatanode || isTransfer) {
    close();
    block.setNumBytes(replicaInfo.getNumBytes());
    if (stage == BlockConstructionStage.TRANSFER_RBW) {
      datanode.data.convertTemporaryToRbw(block);
    }
 else {
      datanode.data.finalizeBlock(block);
    }
    datanode.metrics.incrBlocksWritten();
  }
}
 catch (IOException ioe) {
  if (datanode.isRestarting()) {
    LOG.info(""Shutting down for restart ("" + block + "")."");
  }
 else {
    LOG.info(""Exception for "" + block,ioe);
    throw ioe;
  }
}
 finally {
  Thread.interrupted();
  if (!responderClosed) {
    if (responder != null) {
      if (datanode.isRestarting() && isClient && !isTransfer) {
        File blockFile=((ReplicaInPipeline)replicaInfo).getBlockFile();
        File restartMeta=new File(blockFile.getParent() + File.pathSeparator + "".""+ blockFile.getName()+ "".restart"");
        if (restartMeta.exists() && !restartMeta.delete()) {
          LOG.warn(""Failed to delete restart meta file: "" + restartMeta.getPath());
        }
        try {
          FileWriter out=new FileWriter(restartMeta);
          out.write(Long.toString(Time.now() + restartBudget));
          out.flush();
          out.close();
        }
 catch (        IOException ioe) {
        }
        try {
          Thread.sleep(1000);
        }
 catch (        InterruptedException ie) {
        }
      }
      responder.interrupt();
    }
    IOUtils.closeStream(this);
    cleanupBlock();
  }
  if (responder != null) {
    try {
      responder.interrupt();
      long joinTimeout=datanode.getDnConf().getXceiverStopTimeout();
      joinTimeout=joinTimeout > 1 ? joinTimeout * 8 / 10 : joinTimeout;
      responder.join(joinTimeout);
      if (responder.isAlive()) {
        String msg=""Join on responder thread "" + responder + "" timed out"";
        LOG.warn(msg + ""\n"" + StringUtils.getStackTrace(responder));
        throw new IOException(msg);
      }
    }
 catch (    InterruptedException e) {
      responder.interrupt();
      if (!datanode.isRestarting()) {
        throw new IOException(""Interrupted receiveBlock"");
      }
    }
    responder=null;
  }
}
",0,0,0,,
306,} finally {,"try {
  if (localPaths != null) {
    for (    File f : localPaths) {
      try {
        if (f.exists()) {
          LOG.warn(""Overwriting existing file "" + f + "" with file downloaded from ""+ url);
        }
        outputStreams.add(new FileOutputStream(f));
      }
 catch (      IOException ioe) {
        LOG.warn(""Unable to download file "" + f,ioe);
        if (dstStorage != null && (dstStorage instanceof StorageErrorReporter)) {
          ((StorageErrorReporter)dstStorage).reportErrorOnFile(f);
        }
      }
    }
    if (outputStreams.isEmpty()) {
      throw new IOException(""Unable to download to any storage directory"");
    }
  }
  int num=1;
  byte[] buf=new byte[HdfsConstants.IO_FILE_BUFFER_SIZE];
  while (num > 0) {
    num=stream.read(buf);
    if (num > 0) {
      received+=num;
      for (      FileOutputStream fos : outputStreams) {
        fos.write(buf,0,num);
      }
      if (throttler != null) {
        throttler.throttle(num);
      }
    }
  }
  finishedReceiving=true;
}
  finally {
  stream.close();
  for (  FileOutputStream fos : outputStreams) {
    fos.getChannel().force(true);
    fos.close();
  }
  if (finishedReceiving && received != advertisedSize) {
    throw new IOException(""File "" + url + "" received length ""+ received+ "" is not of the advertised size ""+ advertisedSize);
  }
}
",0,0,0,,
307,} finally {,"try {
  flush();
  ((FileOutputStream)out).getChannel().force(true);
  triedToClose=true;
  super.close();
  success=true;
}
  finally {
  if (success) {
    boolean renamed=tmpFile.renameTo(origFile);
    if (!renamed) {
      if (!origFile.delete() || !tmpFile.renameTo(origFile)) {
        throw new IOException(""Could not rename temporary file "" + tmpFile + "" to ""+ origFile);
      }
    }
  }
 else {
    if (!triedToClose) {
      IOUtils.closeStream(out);
    }
    if (!tmpFile.delete()) {
      LOG.warn(""Unable to delete tmp file "" + tmpFile);
    }
  }
}
",0,0,0,,
308,} finally {,"try {
  DatanodeInfo[] nodes=lblock.getLocations();
  targetAddr=NetUtils.createSocketAddr(nodes[0].getXferAddr());
  blockReader=new BlockReaderFactory(new DFSClient.Conf(conf)).setFileName(BlockReaderFactory.getFileName(targetAddr,""test-blockpoolid"",block.getBlockId())).setBlock(block).setBlockToken(lblock.getBlockToken()).setInetSocketAddress(targetAddr).setStartOffset(0).setLength(-1).setVerifyChecksum(true).setClientName(""TestBlockTokenWithDFS"").setDatanodeInfo(nodes[0]).setCachingStrategy(CachingStrategy.newDefaultStrategy()).setClientCacheContext(ClientContext.getFromConf(conf)).setConfiguration(conf).setRemotePeerFactory(new RemotePeerFactory(){
    @Override public Peer newConnectedPeer(    InetSocketAddress addr,    Token<BlockTokenIdentifier> blockToken,    DatanodeID datanodeId) throws IOException {
      Peer peer=null;
      Socket sock=NetUtils.getDefaultSocketFactory(conf).createSocket();
      try {
        sock.connect(addr,HdfsServerConstants.READ_TIMEOUT);
        sock.setSoTimeout(HdfsServerConstants.READ_TIMEOUT);
        peer=TcpPeerServer.peerFromSocket(sock);
      }
  finally {
        if (peer == null) {
          IOUtils.closeSocket(sock);
        }
      }
      return peer;
    }
  }
).build();
}
 catch (IOException ex) {
  ioe=ex;
}
 finally {
  if (blockReader != null) {
    try {
      blockReader.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
309,} finally {,"try {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  StorageDirectory sd=fsimage.getStorage().getStorageDir(0);
  startTransactionWorkers(namesystem,caughtErr);
  long previousLogTxId=1;
  for (int i=0; i < NUM_ROLLS && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException e) {
    }
    LOG.info(""Starting roll "" + i + ""."");
    CheckpointSignature sig=namesystem.rollEditLog();
    long nextLog=sig.curSegmentTxId;
    String logFileName=NNStorage.getFinalizedEditsFileName(previousLogTxId,nextLog - 1);
    previousLogTxId+=verifyEditLogs(namesystem,fsimage,logFileName,previousLogTxId);
    assertEquals(previousLogTxId,nextLog);
    File expectedLog=NNStorage.getInProgressEditsFile(sd,previousLogTxId);
    assertTrue(""Expect "" + expectedLog + "" to exist"",expectedLog.exists());
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
310,} finally {,"try {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  FSEditLog editLog=fsimage.getEditLog();
  startTransactionWorkers(namesystem,caughtErr);
  for (int i=0; i < NUM_SAVE_IMAGE && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException e) {
    }
    LOG.info(""Save "" + i + "": entering safe mode"");
    namesystem.enterSafeMode(false);
    long logStartTxId=fsimage.getStorage().getMostRecentCheckpointTxId() + 1;
    verifyEditLogs(namesystem,fsimage,NNStorage.getInProgressEditsFileName(logStartTxId),logStartTxId);
    LOG.info(""Save "" + i + "": saving namespace"");
    namesystem.saveNamespace();
    LOG.info(""Save "" + i + "": leaving safemode"");
    long savedImageTxId=fsimage.getStorage().getMostRecentCheckpointTxId();
    verifyEditLogs(namesystem,fsimage,NNStorage.getFinalizedEditsFileName(logStartTxId,savedImageTxId),logStartTxId);
    assertEquals(fsimage.getStorage().getMostRecentCheckpointTxId(),editLog.getLastWrittenTxId() - 1);
    namesystem.leaveSafeMode();
    LOG.info(""Save "" + i + "": complete"");
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
311,} finally {,"try {
  statement.executeBatch();
  connection.commit();
}
 catch (SQLException e) {
  try {
    connection.rollback();
  }
 catch (  SQLException ex) {
    LOG.warn(StringUtils.stringifyException(ex));
  }
  throw new IOException(e.getMessage());
}
 finally {
  try {
    statement.close();
    connection.close();
  }
 catch (  SQLException ex) {
    throw new IOException(ex.getMessage());
  }
}
",0,0,0,,
312,} finally {,"try {
  if (srcNames != null) {
    Iterator iter=srcNames.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      File fsource=new File(source);
      String base=getBasePathInJarOut(source);
      if (!fsource.exists()) {
        throwing=true;
        throw new FileNotFoundException(fsource.getAbsolutePath());
      }
      if (fsource.isDirectory()) {
        addDirectory(jarOut,base,fsource,0);
      }
 else {
        addFileStream(jarOut,base,fsource);
      }
    }
  }
  if (srcUnjar != null) {
    Iterator iter=srcUnjar.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      jarSource=new JarFile(source);
      addJarEntries(jarOut,jarSource);
      jarSource.close();
    }
  }
}
  finally {
  try {
    jarOut.close();
  }
 catch (  ZipException z) {
    if (!throwing) {
      throw new IOException(z.toString());
    }
  }
}
",0,0,0,,
313,} finally {,"try {
  if (isClient && !isTransfer) {
    responder=new Daemon(datanode.threadGroup,new PacketResponder(replyOut,mirrIn,downstreams));
    responder.start();
  }
  while (receivePacket() >= 0) {
  }
  if (responder != null) {
    ((PacketResponder)responder.getRunnable()).close();
    responderClosed=true;
  }
  if (isDatanode || isTransfer) {
    close();
    block.setNumBytes(replicaInfo.getNumBytes());
    if (stage == BlockConstructionStage.TRANSFER_RBW) {
      datanode.data.convertTemporaryToRbw(block);
    }
 else {
      datanode.data.finalizeBlock(block);
    }
    datanode.metrics.incrBlocksWritten();
  }
}
 catch (IOException ioe) {
  LOG.info(""Exception in receiveBlock for "" + block,ioe);
  throw ioe;
}
 finally {
  if (!responderClosed) {
    IOUtils.closeStream(this);
    if (responder != null) {
      responder.interrupt();
    }
    cleanupBlock();
  }
  if (responder != null) {
    try {
      responder.join();
    }
 catch (    InterruptedException e) {
      throw new IOException(""Interrupted receiveBlock"");
    }
    responder=null;
  }
}
",0,0,0,,
314,} finally {,"try {
  if (localPath != null) {
    output=new FileOutputStream[localPath.length];
    for (int i=0; i < output.length; i++) {
      output[i]=new FileOutputStream(localPath[i]);
    }
  }
  int num=1;
  while (num > 0) {
    num=stream.read(buf);
    if (num > 0 && localPath != null) {
      received+=num;
      for (int i=0; i < output.length; i++) {
        output[i].write(buf,0,num);
      }
    }
  }
  finishedReceiving=true;
}
  finally {
  stream.close();
  if (output != null) {
    for (int i=0; i < output.length; i++) {
      if (output[i] != null) {
        output[i].getChannel().force(true);
        output[i].close();
      }
    }
  }
  if (finishedReceiving && received != advertisedSize) {
    throw new IOException(""File "" + str + "" received length ""+ received+ "" is not of the advertised size ""+ advertisedSize);
  }
}
",0,0,0,,
315,} finally {,"try {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  FSEditLog editLog=fsimage.getEditLog();
  editLog.setBufferCapacity(2048);
  editLog.close();
  editLog.open();
  startTransactionWorkers(namesystem,caughtErr);
  for (int i=0; i < NUM_ROLLS && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException e) {
    }
    LOG.info(""Starting roll "" + i + ""."");
    editLog.rollEditLog();
    LOG.info(""Roll complete "" + i + ""."");
    verifyEditLogs(namesystem,fsimage);
    LOG.info(""Starting purge "" + i + ""."");
    editLog.purgeEditLog();
    LOG.info(""Complete purge "" + i + ""."");
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
316,} finally {,"try {
  cluster=new MiniDFSCluster.Builder(conf).numDataNodes(NUM_DATA_NODES).build();
  cluster.waitActive();
  fileSys=cluster.getFileSystem();
  final FSNamesystem namesystem=cluster.getNamesystem();
  FSImage fsimage=namesystem.getFSImage();
  FSEditLog editLog=fsimage.getEditLog();
  editLog.setBufferCapacity(2048);
  editLog.close();
  editLog.open();
  startTransactionWorkers(namesystem,caughtErr);
  for (int i=0; i < NUM_SAVE_IMAGE && caughtErr.get() == null; i++) {
    try {
      Thread.sleep(20);
    }
 catch (    InterruptedException e) {
    }
    LOG.info(""Save "" + i + "": entering safe mode"");
    namesystem.enterSafeMode(false);
    verifyEditLogs(namesystem,fsimage);
    LOG.info(""Save "" + i + "": saving namespace"");
    namesystem.saveNamespace();
    LOG.info(""Save "" + i + "": leaving safemode"");
    verifyEditLogs(namesystem,fsimage);
    namesystem.leaveSafeMode(false);
    LOG.info(""Save "" + i + "": complete"");
  }
}
  finally {
  stopTransactionWorkers();
  if (caughtErr.get() != null) {
    throw new RuntimeException(caughtErr.get());
  }
  if (fileSys != null)   fileSys.close();
  if (cluster != null)   cluster.shutdown();
}
",0,0,0,,
317,} finally {,"try {
  if (srcNames != null) {
    Iterator iter=srcNames.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      File fsource=new File(source);
      String base=getBasePathInJarOut(source);
      if (!fsource.exists()) {
        throwing=true;
        throw new FileNotFoundException(fsource.getAbsolutePath());
      }
      if (fsource.isDirectory()) {
        addDirectory(jarOut,base,fsource,0);
      }
 else {
        addFileStream(jarOut,base,fsource);
      }
    }
  }
  if (srcUnjar != null) {
    Iterator iter=srcUnjar.iterator();
    while (iter.hasNext()) {
      source=(String)iter.next();
      jarSource=new JarFile(source);
      addJarEntries(jarOut,jarSource);
      jarSource.close();
    }
  }
}
  finally {
  try {
    jarOut.close();
  }
 catch (  ZipException z) {
    if (!throwing) {
      throw new IOException(z.toString());
    }
  }
}
",0,0,0,,
318,} finally {,"try {
  Connection conn=vtconfig.getConnection(true);
  DatabaseMetaData dbmd=conn.getMetaData();
  ResultSet rs=dbmd.getTables(null,schema,table,null);
  boolean tableExists=rs.next();
  stmt=conn.createStatement();
  if (tableExists && dropTable) {
    if (verticaVersion(conf,true) >= 305) {
      stmt=conn.createStatement();
      stmt.execute(""TRUNCATE TABLE "" + writerTable);
    }
 else {
      if (def == null) {
        rs=dbmd.getColumns(null,schema,table,null);
        ArrayList<String> defs=new ArrayList<String>();
        while (rs.next())         defs.add(rs.getString(4) + "" "" + rs.getString(5));
        def=defs.toArray(new String[0]);
      }
      stmt=conn.createStatement();
      stmt.execute(""DROP TABLE "" + writerTable + "" CASCADE"");
      tableExists=false;
    }
  }
  if (!tableExists) {
    if (def == null)     throw new RuntimeException(""Table "" + writerTable + "" does not exist and no table definition provided"");
    if (schema != null) {
      rs=dbmd.getSchemas(null,schema);
      if (!rs.next())       stmt.execute(""CREATE SCHEMA "" + schema);
    }
    StringBuffer tabledef=new StringBuffer(""CREATE TABLE "").append(writerTable).append("" ("");
    for (    String column : def)     tabledef.append(column).append("","");
    tabledef.replace(tabledef.length() - 1,tabledef.length(),"")"");
    stmt.execute(tabledef.toString());
    stmt.execute(""select implement_temp_design('"" + writerTable + ""')"");
  }
}
 catch (Exception e) {
  throw new RuntimeException(e);
}
 finally {
  if (stmt != null)   try {
    stmt.close();
  }
 catch (  SQLException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
319,} finally {,"try {
  conn=config.getConnection(false);
  stmt=conn.createStatement();
  ResultSet rs=stmt.executeQuery(paramsQuery);
  ResultSetMetaData rsmd=rs.getMetaData();
  while (rs.next()) {
    limitOffset=false;
    List<Object> segmentParams=new ArrayList<Object>();
    for (int j=1; j <= rsmd.getColumnCount(); j++) {
      segmentParams.add(rs.getObject(j));
    }
    splits.add(new VerticaInputSplit(inputQuery,segmentParams,start,end));
  }
}
 catch (Exception e) {
  throw new IOException(e);
}
 finally {
  try {
    if (stmt != null)     stmt.close();
  }
 catch (  SQLException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
320,} finally {,"try {
  conn=config.getConnection(false);
  stmt=conn.createStatement();
  ResultSet rs=stmt.executeQuery(countQuery);
  rs.next();
  count=rs.getLong(1);
}
 catch (Exception e) {
  throw new IOException(e);
}
 finally {
  try {
    if (stmt != null)     stmt.close();
  }
 catch (  SQLException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
321,} finally {,"try {
  statement.executeBatch();
  connection.commit();
}
 catch (SQLException e) {
  try {
    connection.rollback();
  }
 catch (  SQLException ex) {
    LOG.warn(StringUtils.stringifyException(ex));
  }
  throw new IOException(e.getMessage());
}
 finally {
  try {
    statement.close();
    connection.close();
  }
 catch (  SQLException ex) {
    throw new IOException(ex.getMessage());
  }
}
",0,0,0,,
322,} finally {,"try {
  try {
    store=BlockUtils.getUncachedDatanodeStore(kvContainerData,config,true);
  }
 catch (  IOException e) {
    cachedDB=BlockUtils.getDB(kvContainerData,config);
    store=cachedDB.getStore();
    LOG.warn(""Attempt to get an uncached RocksDB handle failed and an "" + ""instance was retrieved from the cache. This should only happen "" + ""in tests"");
  }
  Table<String,Long> metadataTable=store.getMetadataTable();
  Long pendingDeleteBlockCount=metadataTable.get(OzoneConsts.PENDING_DELETE_BLOCK_COUNT);
  if (pendingDeleteBlockCount != null) {
    kvContainerData.incrPendingDeletionBlocks(pendingDeleteBlockCount);
  }
 else {
    MetadataKeyFilters.KeyPrefixFilter filter=MetadataKeyFilters.getDeletingKeyFilter();
    int numPendingDeletionBlocks=store.getBlockDataTable().getSequentialRangeKVs(null,Integer.MAX_VALUE,filter).size();
    kvContainerData.incrPendingDeletionBlocks(numPendingDeletionBlocks);
  }
  Long delTxnId=metadataTable.get(OzoneConsts.DELETE_TRANSACTION_KEY);
  if (delTxnId != null) {
    kvContainerData.updateDeleteTransactionId(delTxnId);
  }
  Long bcsId=metadataTable.get(OzoneConsts.BLOCK_COMMIT_SEQUENCE_ID);
  if (bcsId != null) {
    kvContainerData.updateBlockCommitSequenceId(bcsId);
  }
  Long bytesUsed=metadataTable.get(OzoneConsts.CONTAINER_BYTES_USED);
  if (bytesUsed != null) {
    isBlockMetadataSet=true;
    kvContainerData.setBytesUsed(bytesUsed);
  }
  Long blockCount=metadataTable.get(OzoneConsts.BLOCK_COUNT);
  if (blockCount != null) {
    isBlockMetadataSet=true;
    kvContainerData.setKeyCount(blockCount);
  }
  if (!isBlockMetadataSet) {
    initializeUsedBytesAndBlockCount(store,kvContainerData);
  }
}
  finally {
  if (cachedDB != null) {
    cachedDB.close();
  }
 else   if (store != null) {
    try {
      store.stop();
    }
 catch (    IOException e) {
      throw e;
    }
catch (    Exception e) {
      throw new RuntimeException(""Unexpected exception closing the "" + ""RocksDB when loading containers"",e);
    }
  }
}
",0,0,0,,
323,} finally {,"try {
  bsp.setup(bspPeer);
  bsp.bsp(bspPeer);
}
 catch (Exception e) {
  LOG.error(""Error running bsp setup and bsp function."",e);
  firstException=e;
}
 finally {
  try {
    bsp.cleanup(bspPeer);
  }
 catch (  Exception e) {
    LOG.error(""Error cleaning up after bsp executed."",e);
    if (firstException == null)     firstException=e;
  }
 finally {
    try {
      bspPeer.close();
    }
 catch (    Exception e) {
      LOG.error(""Error closing BSP Peer."",e);
      if (firstException == null)       firstException=e;
    }
    if (firstException != null)     throw firstException;
  }
}
",0,0,0,,
324,} finally {,"try {
  bsp.cleanup(bspPeer);
}
 catch (Exception e) {
  LOG.error(""Error cleaning up after bsp executed."",e);
  if (firstException == null)   firstException=e;
}
 finally {
  try {
    bspPeer.close();
  }
 catch (  Exception e) {
    LOG.error(""Error closing BSP Peer."",e);
    if (firstException == null)     firstException=e;
  }
  if (firstException != null)   throw firstException;
}
",0,0,0,,
325,} finally {,"try {
  bsp.setup(peer);
  bsp.bsp(peer);
}
 catch (Exception e) {
  LOG.error(""Exception during BSP execution!"",e);
  firstException=e;
}
 finally {
  try {
    bsp.cleanup(peer);
  }
 catch (  Exception e) {
    LOG.error(""Error cleaning up after bsp execution."",e);
    if (firstException == null)     firstException=e;
  }
 finally {
    try {
      peer.clear();
      peer.close();
    }
 catch (    Exception e) {
      LOG.error(""Exception closing BSP peer,"",e);
      if (firstException == null)       firstException=e;
    }
 finally {
      if (firstException != null)       throw firstException;
    }
  }
}
",0,0,0,,
326,} finally {,"try {
  bsp.cleanup(peer);
}
 catch (Exception e) {
  LOG.error(""Error cleaning up after bsp execution."",e);
  if (firstException == null)   firstException=e;
}
 finally {
  try {
    peer.clear();
    peer.close();
  }
 catch (  Exception e) {
    LOG.error(""Exception closing BSP peer,"",e);
    if (firstException == null)     firstException=e;
  }
 finally {
    if (firstException != null)     throw firstException;
  }
}
",0,0,0,,
327,} finally {,"try {
  peer.clear();
  peer.close();
}
 catch (Exception e) {
  LOG.error(""Exception closing BSP peer,"",e);
  if (firstException == null)   firstException=e;
}
 finally {
  if (firstException != null)   throw firstException;
}
",0,0,0,,
328,} finally {,"try {
  bspInstance.setup(peer);
  bspInstance.bsp(peer);
}
 catch (Exception e) {
  LOG.error(""Error occured while running bsp function."",e);
  firstException=e;
}
 finally {
  try {
    bspInstance.cleanup(peer);
  }
 catch (  Exception e) {
    LOG.error(""Cleaning up after bsp function."",e);
    if (firstException == null) {
      firstException=e;
    }
  }
 finally {
    try {
      peer.close();
    }
 catch (    Exception e) {
      LOG.error(""Error closing the bsp peer"",e);
      if (firstException == null)       firstException=e;
    }
 finally {
      if (firstException != null)       throw firstException;
    }
  }
}
",0,0,0,,
329,} finally {,"try {
  bspInstance.cleanup(peer);
}
 catch (Exception e) {
  LOG.error(""Cleaning up after bsp function."",e);
  if (firstException == null) {
    firstException=e;
  }
}
 finally {
  try {
    peer.close();
  }
 catch (  Exception e) {
    LOG.error(""Error closing the bsp peer"",e);
    if (firstException == null)     firstException=e;
  }
 finally {
    if (firstException != null)     throw firstException;
  }
}
",0,0,0,,
330,} finally {,"try {
  peer.close();
}
 catch (Exception e) {
  LOG.error(""Error closing the bsp peer"",e);
  if (firstException == null)   firstException=e;
}
 finally {
  if (firstException != null)   throw firstException;
}
",0,0,0,,
331,} finally {,"try {
  input=u.openStream();
  reader=new BufferedReader(new InputStreamReader(input,""utf-8""));
  String line;
  while ((line=reader.readLine()) != null) {
    int sharpIndex=line.indexOf('#');
    if (sharpIndex >= 0) {
      line=line.substring(0,sharpIndex);
    }
    line=line.trim();
    if (line.length() > 0) {
      char[] namechars=line.toCharArray();
      for (int i=0; i < namechars.length; i++) {
        if (!(Character.isJavaIdentifierPart(namechars[i]) || namechars[i] == '.')) {
          throw new ServiceConfigurationError(Messages.getString(""imageio.99"",line));
        }
      }
      names.add(line);
    }
  }
}
 catch (IOException e) {
  throw new ServiceConfigurationError(e.toString());
}
 finally {
  try {
    if (reader != null) {
      reader.close();
    }
    if (input != null) {
      input.close();
    }
  }
 catch (  IOException e) {
    throw new ServiceConfigurationError(e.toString());
  }
}
",0,0,0,,
332,} finally {,"try {
  currentConn=retrieveConnection();
  currentConn.setTypeMap(getTypeMap());
  acceptChanges(currentConn);
  currentConn.commit();
}
 catch (SQLException e) {
  try {
    if (currentConn != null) {
      currentConn.rollback();
    }
  }
 catch (  SQLException ex) {
  }
  SyncProviderException ex=new SyncProviderException();
  ex.initCause(e);
  throw ex;
}
 finally {
  conn=preConn;
  if (currentConn != null) {
    try {
      currentConn.close();
    }
 catch (    SQLException ex) {
      SyncProviderException spe=new SyncProviderException();
      spe.initCause(ex);
      throw spe;
    }
  }
}
",0,0,0,,
333,} finally {,"try {
  if (rowset.getMatchColumnIndexes() != null && rowset.getMatchColumnIndexes().length > 0) {
    matchCol=rowset.getMatchColumnIndexes()[0];
    if (matchCol <= 0 || matchCol > currentRs.getMetaData().getColumnCount()) {
      matchCol=-2;
    }
  }
}
 catch (SQLException e) {
  try {
    if (rowset.getMatchColumnNames() != null && rowset.getMatchColumnNames().length > 0) {
      try {
        matchCol=currentRs.findColumn(rowset.getMatchColumnNames()[0]);
      }
 catch (      SQLException e1) {
        matchCol=-3;
      }
    }
  }
 catch (  SQLException e2) {
  }
}
 finally {
  if (matchCol == -1) {
    throw new SQLException(Messages.getString(""rowset.34""));
  }
 else   if (matchCol == -2) {
    throw new SQLException(Messages.getString(""rowset.35""));
  }
 else   if (matchCol == -3) {
    throw new SQLException(Messages.getString(""rowset.1""));
  }
}
",0,0,0,,
334,} finally {,"try {
  size=Integer.parseInt(attrs.getValue(""size""));
}
  finally {
  if (size == 0) {
    throw new SAXException(""Invalid font size:"" + attrs.getValue(""size""));
  }
}
",0,0,0,,
335,} finally {,"try {
  currentConn=retrieveConnection();
  currentConn.setTypeMap(getTypeMap());
  acceptChanges(currentConn);
  currentConn.commit();
}
 catch (SQLException e) {
  try {
    if (currentConn != null) {
      currentConn.rollback();
    }
  }
 catch (  SQLException ex) {
  }
  SyncProviderException ex=new SyncProviderException();
  ex.initCause(e);
  throw ex;
}
 finally {
  conn=preConn;
  if (currentConn != null) {
    try {
      currentConn.close();
    }
 catch (    SQLException ex) {
      SyncProviderException spe=new SyncProviderException();
      spe.initCause(ex);
      throw spe;
    }
  }
}
",0,0,0,,
336,} finally {,"try {
  if (rowset.getMatchColumnIndexes() != null && rowset.getMatchColumnIndexes().length > 0) {
    matchCol=rowset.getMatchColumnIndexes()[0];
    if (matchCol <= 0 || matchCol > currentRs.getMetaData().getColumnCount()) {
      matchCol=-2;
    }
  }
}
 catch (SQLException e) {
  try {
    if (rowset.getMatchColumnNames() != null && rowset.getMatchColumnNames().length > 0) {
      try {
        matchCol=currentRs.findColumn(rowset.getMatchColumnNames()[0]);
      }
 catch (      SQLException e1) {
        matchCol=-3;
      }
    }
  }
 catch (  SQLException e2) {
  }
}
 finally {
  if (matchCol == -1) {
    throw new SQLException(Messages.getString(""rowset.34""));
  }
 else   if (matchCol == -2) {
    throw new SQLException(Messages.getString(""rowset.35""));
  }
 else   if (matchCol == -3) {
    throw new SQLException(Messages.getString(""rowset.1""));
  }
}
",0,0,0,,
337,} finally {,"try {
  size=Integer.parseInt(attrs.getValue(""size""));
}
  finally {
  if (size == 0) {
    throw new SAXException(""Invalid font size:"" + attrs.getValue(""size""));
  }
}
",0,0,0,,
338,} finally {,"try {
  doRead();
  return new String(outBytes.toByteArray());
}
  finally {
switch (outs) {
case OUT:
{
      System.setOut(oldPrintStream);
      break;
    }
case ERR:
{
    System.setErr(oldPrintStream);
    break;
  }
default :
throw new IllegalStateException(""OutputReader: unsupported PrintStream"");
}
}
",0,0,0,,
339,} finally {,"try {
  while (true) {
    if (!isRunning()) {
      throw new RuntimeException(""store no longer running"");
    }
 else     if (isSyncAborted()) {
      throw new RuntimeException(""sync aborted"",syncException.get());
    }
 else     if (inSync.get()) {
      syncCond.await();
    }
 else     if (slotIndex >= syncMaxSlot) {
      slotCond.signal();
      syncCond.await();
    }
 else {
      break;
    }
  }
  final long pushSyncId=syncId.get();
  updateStoreTracker(type,procId,subProcIds);
  slots[slotIndex++]=slot;
  logId=flushLogId;
  if (slotIndex == 1) {
    waitCond.signal();
  }
  if (slotIndex == syncMaxSlot) {
    waitCond.signal();
    slotCond.signal();
  }
  while (pushSyncId == syncId.get() && isRunning()) {
    syncCond.await();
  }
}
 catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sendAbortProcessSignal();
  throw new RuntimeException(e);
}
 finally {
  lock.unlock();
  if (isSyncAborted()) {
    throw new RuntimeException(""sync aborted"",syncException.get());
  }
}
",0,0,0,,
340,} finally {,"try {
  List<FileStatus> regionDirs=FSUtils.listStatusWithStatusFilter(fs,tableDir,new RegionDirFilter(fs));
  if (regionDirs == null) {
    return finalResultMap;
  }
  final List<Future<?>> futures=new ArrayList<>(regionDirs.size());
  for (  FileStatus regionDir : regionDirs) {
    if (null != progressReporter) {
      progressReporter.progress(regionDir);
    }
    final Path dd=regionDir.getPath();
    if (!exceptions.isEmpty()) {
      break;
    }
    Runnable getRegionStoreFileMapCall=new Runnable(){
      @Override public void run(){
        try {
          HashMap<String,Path> regionStoreFileMap=new HashMap<>();
          List<FileStatus> familyDirs=FSUtils.listStatusWithStatusFilter(fs,dd,familyFilter);
          if (familyDirs == null) {
            if (!fs.exists(dd)) {
              LOG.warn(""Skipping region because it no longer exists: "" + dd);
            }
 else {
              LOG.warn(""Skipping region because it has no family dirs: "" + dd);
            }
            return;
          }
          for (          FileStatus familyDir : familyDirs) {
            if (null != progressReporter) {
              progressReporter.progress(familyDir);
            }
            Path family=familyDir.getPath();
            if (family.getName().equals(HConstants.RECOVERED_EDITS_DIR)) {
              continue;
            }
            FileStatus[] familyStatus=fs.listStatus(family);
            for (            FileStatus sfStatus : familyStatus) {
              if (null != progressReporter) {
                progressReporter.progress(sfStatus);
              }
              Path sf=sfStatus.getPath();
              if (sfFilter == null || sfFilter.accept(sf)) {
                regionStoreFileMap.put(sf.getName(),sf);
              }
            }
          }
          finalResultMap.putAll(regionStoreFileMap);
        }
 catch (        Exception e) {
          LOG.error(""Could not get region store file map for region: "" + dd,e);
          exceptions.add(e);
        }
      }
    }
;
    if (executor != null) {
      Future<?> future=executor.submit(getRegionStoreFileMapCall);
      futures.add(future);
    }
 else {
      FutureTask<?> future=new FutureTask<>(getRegionStoreFileMapCall,null);
      future.run();
      futures.add(future);
    }
  }
  for (  Future<?> f : futures) {
    if (!exceptions.isEmpty()) {
      break;
    }
    try {
      f.get();
    }
 catch (    ExecutionException e) {
      LOG.error(""Unexpected exec exception!  Should've been caught already.  (Bug?)"",e);
    }
  }
}
 catch (IOException e) {
  LOG.error(""Cannot execute getTableStoreFilePathMap for "" + tableName,e);
  exceptions.add(e);
}
 finally {
  if (!exceptions.isEmpty()) {
    Throwables.propagateIfPossible(exceptions.firstElement(),IOException.class);
    throw new IOException(exceptions.firstElement());
  }
}
",0,0,0,,
341,} finally {,"try {
  for (  FileStatus regionStatus : statusList) {
    if (null == regionStatus || !regionStatus.isDirectory()) {
      continue;
    }
    final Path regionPath=regionStatus.getPath();
    if (null != regionPath) {
      tpe.execute(new FSRegionScanner(fs,regionPath,null,regionDegreeLocalityMapping));
    }
  }
}
  finally {
  tpe.shutdown();
  final long threadWakeFrequency=(long)conf.getInt(HConstants.THREAD_WAKE_FREQUENCY,HConstants.DEFAULT_THREAD_WAKE_FREQUENCY);
  try {
    while (!tpe.awaitTermination(threadWakeFrequency,TimeUnit.MILLISECONDS)) {
      LOG.info(""Locality checking is underway: { Scanned Regions : "" + ((ThreadPoolExecutor)tpe).getCompletedTaskCount() + ""/""+ ((ThreadPoolExecutor)tpe).getTaskCount()+ "" }"");
    }
  }
 catch (  InterruptedException e) {
    Thread.currentThread().interrupt();
    throw (InterruptedIOException)new InterruptedIOException().initCause(e);
  }
}
",0,0,0,,
342,} finally {,"try {
  final FileStatus[] regionDirs=fs.listStatus(tableDir.getPath());
  final List<Future<?>> futures=new ArrayList<>(regionDirs.length);
  for (  final FileStatus regionDir : regionDirs) {
    errors.progress();
    final String encodedName=regionDir.getPath().getName();
    if (!encodedName.toLowerCase(Locale.ROOT).matches(""[0-9a-f]+"")) {
      continue;
    }
    if (!exceptions.isEmpty()) {
      break;
    }
    futures.add(executor.submit(new Runnable(){
      @Override public void run(){
        try {
          LOG.debug(""Loading region info from hdfs:"" + regionDir.getPath());
          Path regioninfoFile=new Path(regionDir.getPath(),HRegionFileSystem.REGION_INFO_FILE);
          boolean regioninfoFileExists=fs.exists(regioninfoFile);
          if (!regioninfoFileExists) {
            if (!fs.exists(regionDir.getPath())) {
              LOG.warn(""By the time we tried to process this region dir it was already gone: "" + regionDir.getPath());
              return;
            }
          }
          HbckRegionInfo hbi=HBaseFsck.this.getOrCreateInfo(encodedName);
          HbckRegionInfo.HdfsEntry he=new HbckRegionInfo.HdfsEntry();
synchronized (hbi) {
            if (hbi.getHdfsRegionDir() != null) {
              errors.print(""Directory "" + encodedName + "" duplicate??""+ hbi.getHdfsRegionDir());
            }
            he.regionDir=regionDir.getPath();
            he.regionDirModTime=regionDir.getModificationTime();
            he.hdfsRegioninfoFilePresent=regioninfoFileExists;
            he.hdfsOnlyEdits=true;
            FileStatus[] subDirs=fs.listStatus(regionDir.getPath());
            Path ePath=WALSplitUtil.getRegionDirRecoveredEditsDir(regionDir.getPath());
            for (            FileStatus subDir : subDirs) {
              errors.progress();
              String sdName=subDir.getPath().getName();
              if (!sdName.startsWith(""."") && !sdName.equals(ePath.getName())) {
                he.hdfsOnlyEdits=false;
                break;
              }
            }
            hbi.setHdfsEntry(he);
          }
        }
 catch (        Exception e) {
          LOG.error(""Could not load region dir"",e);
          exceptions.add(e);
        }
      }
    }
));
  }
  for (  Future<?> f : futures) {
    if (!exceptions.isEmpty()) {
      break;
    }
    try {
      f.get();
    }
 catch (    ExecutionException e) {
      LOG.error(""Unexpected exec exception!  Should've been caught already.  (Bug?)"",e);
    }
  }
}
 catch (IOException e) {
  LOG.error(""Cannot execute WorkItemHdfsDir for "" + tableDir,e);
  exceptions.add(e);
}
 finally {
  if (!exceptions.isEmpty()) {
    errors.reportError(ERROR_CODE.RS_CONNECT_FAILURE,""Table Directory: "" + tableDir.getPath().getName() + "" Unable to fetch all HDFS region information. "");
    throw new ExecutionException(""First exception in WorkItemHdfsDir"",exceptions.firstElement());
  }
}
",0,0,0,,
343,} finally {,"try {
  TableDescriptors tds=new FSTableDescriptors(TEST_UTIL.getConfiguration());
  FSTableDescriptors.tryUpdateMetaTableDescriptor(TEST_UTIL.getConfiguration());
  TableDescriptor htd=tds.get(TableName.META_TABLE_NAME);
  for (int i=0; i < this.count; i++) {
    long now=EnvironmentEdgeManager.currentTime();
    if (i % 10 == 0) {
      this.wal.rollWriter();
    }
    WALEdit edit=new WALEdit();
    byte[] bytes=Bytes.toBytes(i);
    edit.add(new KeyValue(bytes,bytes,bytes,now,EMPTY_1K_ARRAY));
    RegionInfo hri=RegionInfoBuilder.FIRST_META_REGIONINFO;
    NavigableMap<byte[],Integer> scopes=new TreeMap<>(Bytes.BYTES_COMPARATOR);
    for (    byte[] fam : this.metaTableDescriptor.getColumnFamilyNames()) {
      scopes.put(fam,0);
    }
    final long txid=wal.appendData(hri,new WALKeyImpl(hri.getEncodedNameAsBytes(),TableName.META_TABLE_NAME,now,mvcc,scopes),edit);
    Threads.sleep(ThreadLocalRandom.current().nextInt(5));
    wal.sync(txid);
  }
  String msg=getName() + "" finished"";
  if (isException())   this.log.info(msg,getException());
 else   this.log.info(msg);
}
 catch (Exception e) {
  this.e=e;
  log.info(""Caught exception from Appender:"" + getName(),e);
}
 finally {
  try {
    this.wal.sync();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
344,} finally {,"try {
  checkHttpMethods(url);
  talkToThriftServer(url,customHeaderSize);
  break;
}
 catch (Exception ex) {
  clientSideException=ex;
  LOG.info(""Client-side Exception"",ex);
}
 finally {
  tsr.close();
  tsr.join();
  if (tsr.getRunException() != null) {
    LOG.error(""Invocation of HBase Thrift server threw exception"",tsr.getRunException());
    throw tsr.getRunException();
  }
}
",0,0,0,,
345,} finally {,"try {
  talkToThriftServer(thriftServerRunner.getThriftServer().listenPort);
  break;
}
 catch (Exception ex) {
  clientSideException=ex;
  LOG.info(""Exception"",ex);
}
 finally {
  LOG.debug(""Stopping "" + this.implType.simpleClassName() + "" Thrift server"");
  thriftServerRunner.close();
  thriftServerRunner.join();
  if (thriftServerRunner.getRunException() != null) {
    LOG.error(""Command-line invocation of HBase Thrift server threw exception"",thriftServerRunner.getRunException());
    throw thriftServerRunner.getRunException();
  }
}
",0,0,0,,
346,} finally {,"try {
  for (int i=1; i <= 8; i++) {
    Path dir=new Path(renameSource,""dir"" + i);
    hboss.mkdirs(dir);
    for (int j=1; j <= 8; j++) {
      Path file=new Path(dir,""file"" + j);
      FSDataOutputStream out=hboss.create(file);
      for (int k=0; k < 256; k++) {
        out.write(""0123456789ABCDEF"".getBytes());
      }
      out.close();
    }
  }
  Thread renameThread=new Thread(new Runnable(){
    public void run(){
      try {
        boolean success=hboss.rename(renameSource,renameTarget);
        Assert.assertTrue(""Rename returned false, indicating some error."",success);
      }
 catch (      IOException e) {
        Assert.fail(""Unexpected exception during rename: "" + e);
      }
    }
  }
);
  renameThread.start();
  while (!hboss.exists(renameTarget)) {
    Thread.sleep(1);
  }
  Assert.assertFalse(""Rename source is still visible after rename finished or target showed up."",hboss.exists(renameSource));
  renameThread.join();
}
  finally {
  try {
    hboss.delete(renameSource);
    hboss.delete(renameTarget);
  }
 catch (  Exception e) {
    e.printStackTrace();
    throw e;
  }
}
",0,0,0,,
347,} finally {,"try {
  List<FileStatus> regionDirs=FSUtils.listStatusWithStatusFilter(fs,tableDir,new FSUtils.RegionDirFilter(fs));
  if (regionDirs == null) {
    return finalResultMap;
  }
  final List<Future<?>> futures=new ArrayList<>(regionDirs.size());
  for (  FileStatus regionDir : regionDirs) {
    final Path dd=regionDir.getPath();
    if (!exceptions.isEmpty()) {
      break;
    }
    Runnable getRegionStoreFileMapCall=new Runnable(){
      @Override public void run(){
        try {
          HashMap<String,Path> regionStoreFileMap=new HashMap<>();
          List<FileStatus> familyDirs=FSUtils.listStatusWithStatusFilter(fs,dd,familyFilter);
          if (familyDirs == null) {
            if (!fs.exists(dd)) {
              LOG.warn(""Skipping region because it no longer exists: "" + dd);
            }
 else {
              LOG.warn(""Skipping region because it has no family dirs: "" + dd);
            }
            return;
          }
          for (          FileStatus familyDir : familyDirs) {
            Path family=familyDir.getPath();
            if (family.getName().equals(HConstants.RECOVERED_EDITS_DIR)) {
              continue;
            }
            FileStatus[] familyStatus=fs.listStatus(family);
            for (            FileStatus sfStatus : familyStatus) {
              Path sf=sfStatus.getPath();
              if (sfFilter == null || sfFilter.accept(sf)) {
                regionStoreFileMap.put(sf.getName(),sf);
              }
            }
          }
          finalResultMap.putAll(regionStoreFileMap);
        }
 catch (        Exception e) {
          LOG.error(""Could not get region store file map for region: "" + dd,e);
          exceptions.add(e);
        }
      }
    }
;
    if (executor != null) {
      Future<?> future=executor.submit(getRegionStoreFileMapCall);
      futures.add(future);
    }
 else {
      FutureTask<?> future=new FutureTask<>(getRegionStoreFileMapCall,null);
      future.run();
      futures.add(future);
    }
  }
  for (  Future<?> f : futures) {
    if (!exceptions.isEmpty()) {
      break;
    }
    try {
      f.get();
    }
 catch (    ExecutionException e) {
      LOG.error(""Unexpected exec exception!  Should've been caught already.  (Bug?)"",e);
    }
  }
}
 catch (IOException e) {
  LOG.error(""Cannot execute getTableStoreFilePathMap for "" + tableName,e);
  exceptions.add(e);
}
 finally {
  if (!exceptions.isEmpty()) {
    Throwables.propagateIfInstanceOf(exceptions.firstElement(),IOException.class);
    throw Throwables.propagate(exceptions.firstElement());
  }
}
",0,0,0,,
348,} finally {,"try {
  final FileStatus[] regionDirs=fs.listStatus(tableDir.getPath());
  final List<Future<?>> futures=new ArrayList<>(regionDirs.length);
  for (  final FileStatus regionDir : regionDirs) {
    errors.progress();
    final String encodedName=regionDir.getPath().getName();
    if (!encodedName.toLowerCase(Locale.ROOT).matches(""[0-9a-f]+"")) {
      continue;
    }
    if (!exceptions.isEmpty()) {
      break;
    }
    futures.add(executor.submit(new Runnable(){
      @Override public void run(){
        try {
          LOG.debug(""Loading region info from hdfs:"" + regionDir.getPath());
          Path regioninfoFile=new Path(regionDir.getPath(),HRegionFileSystem.REGION_INFO_FILE);
          boolean regioninfoFileExists=fs.exists(regioninfoFile);
          if (!regioninfoFileExists) {
            if (!fs.exists(regionDir.getPath())) {
              LOG.warn(""By the time we tried to process this region dir it was already "" + ""gone: "" + regionDir.getPath());
              return;
            }
          }
          HbckInfo hbi=HBaseFsck.this.getOrCreateInfo(encodedName);
          HdfsEntry he=new HdfsEntry();
synchronized (hbi) {
            if (hbi.getHdfsRegionDir() != null) {
              errors.print(""Directory "" + encodedName + "" duplicate?? ""+ hbi.getHdfsRegionDir());
            }
            he.hdfsRegionDir=regionDir.getPath();
            he.hdfsRegionDirModTime=regionDir.getModificationTime();
            he.hdfsRegioninfoFilePresent=regioninfoFileExists;
            he.hdfsOnlyEdits=true;
            FileStatus[] subDirs=fs.listStatus(regionDir.getPath());
            Path ePath=new Path(regionDir.getPath(),HConstants.RECOVERED_EDITS_DIR);
            for (            FileStatus subDir : subDirs) {
              errors.progress();
              String sdName=subDir.getPath().getName();
              if (!sdName.startsWith(""."") && !sdName.equals(ePath.getName())) {
                he.hdfsOnlyEdits=false;
                break;
              }
            }
            hbi.hdfsEntry=he;
          }
        }
 catch (        Exception e) {
          LOG.error(""Could not load region dir"",e);
          exceptions.add(e);
        }
      }
    }
));
  }
  for (  Future<?> f : futures) {
    if (!exceptions.isEmpty()) {
      break;
    }
    try {
      f.get();
    }
 catch (    ExecutionException e) {
      LOG.error(""Unexpected exec exception!  Should've been caught already.  (Bug?)"",e);
    }
  }
}
 catch (IOException e) {
  LOG.error(""Cannot execute WorkItemHdfsDir for "" + tableDir,e);
  exceptions.add(e);
}
 finally {
  if (!exceptions.isEmpty()) {
    errors.reportError(ErrorReporter.ERROR_CODE.RS_CONNECT_FAILURE,""Table Directory: "" + tableDir.getPath().getName() + "" Unable to fetch all HDFS region information. "");
    throw new ExecutionException(""First exception in WorkItemHdfsDir"",exceptions.firstElement());
  }
}
",0,0,0,,
349,} finally {,"try {
  cluster.stop();
  cluster=null;
}
  finally {
  System.out.println(""Trying to cleanup: "" + testDir);
  try {
    FileSystem fs=FileSystem.get(jobConf);
    fs.delete(new Path(testDir),true);
  }
 catch (  IOException e) {
    throw new IllegalStateException(""Failed to cleanup test dir"",e);
  }
}
",0,0,0,,
350,} finally {,"try {
  return execute(size);
}
 catch (Exception ex) {
  LOG.warn(String.format(""Exception thrown while processing using a batch size %d"",size),ex);
}
 finally {
  attempt++;
  if (attempt == maxRetries) {
    throw new RetryException(String.format(""Maximum number of retry attempts %d exhausted"",maxRetries));
  }
}
",0,0,0,,
351,} finally {,"try {
  ugi=UserGroupInformation.getCurrentUser();
  shim=ShimLoader.getHadoopShims().getWebHCatShim(appConf,ugi);
  Path shimCommonJar=new Path(TempletonUtils.findContainingJar(ShimLoader.class,HIVE_SHIMS_FILENAME_PATTERN));
  Path shimCommonSecureJar=new Path(TempletonUtils.findContainingJar(HadoopShimsSecure.class,HIVE_SHIMS_FILENAME_PATTERN));
  Path shimJar=new Path(TempletonUtils.findContainingJar(shim.getClass(),HIVE_SHIMS_FILENAME_PATTERN));
  return String.format(""%s,%s,%s"",shimCommonJar.toString(),shimCommonSecureJar.toString(),shimJar.toString());
}
 catch (IOException e) {
  throw new RuntimeException(""Failed to get shimLibJars"",e);
}
 finally {
  try {
    if (ugi != null) {
      FileSystem.closeAllForUGI(ugi);
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(""Failed to closeAllForUGI"",e);
  }
}
",0,0,0,,
352,} finally {,"try {
  cluster.stop();
  cluster=null;
}
  finally {
  System.out.println(""Trying to cleanup: "" + testDir);
  try {
    FileSystem fs=FileSystem.get(jobConf);
    fs.delete(new Path(testDir),true);
  }
 catch (  IOException e) {
    throw new IllegalStateException(""Failed to cleanup test dir"",e);
  }
}
",0,0,0,,
353,} finally {,"try {
  conn.rollback();
}
 catch (SQLException ex) {
  LOG.warn(""Failed to perform rollback on connection"",ex);
}
 finally {
  try {
    conn.close();
  }
 catch (  SQLException ex) {
    throw new IOException(ex.getMessage());
  }
}
",0,0,0,,
354,} finally {,"try {
  arrowStreamWriter.close();
}
  finally {
  rootVector.close();
  long bytesLeaked=allocator.getAllocatedMemory();
  if (bytesLeaked != 0) {
    LOG.error(""Arrow memory leaked bytes: {}"",bytesLeaked);
    throw new IllegalStateException(""Arrow memory leaked bytes:"" + bytesLeaked);
  }
  allocator.close();
}
",0,0,0,,
355,} finally {,"try {
  OrcFileValueWrapper v;
  OrcFileKeyWrapper k;
  if (key instanceof CombineHiveKey) {
    k=(OrcFileKeyWrapper)((CombineHiveKey)key).getKey();
  }
 else {
    k=(OrcFileKeyWrapper)key;
  }
  if (k.isIncompatFile()) {
    LOG.warn(""Incompatible ORC file merge! Stripe statistics is missing. "" + k.getInputPath());
    addIncompatibleFile(k.getInputPath());
    return;
  }
  filePath=k.getInputPath().toUri().getPath();
  Utilities.FILE_OP_LOGGER.info(""OrcFileMergeOperator processing "" + filePath);
  fixTmpPath(k.getInputPath().getParent());
  v=(OrcFileValueWrapper)value;
  if (prevPath == null) {
    prevPath=k.getInputPath();
    reader=OrcFile.createReader(fs,k.getInputPath());
    LOG.info(""ORC merge file input path: "" + k.getInputPath());
  }
  int bucketId=0;
  if (conf.getIsCompactionTable()) {
    bucketId=AcidUtils.parseBucketId(new Path(filePath));
  }
  if (outWriters.get(bucketId) == null) {
    compression=k.getCompression();
    compressBuffSize=k.getCompressBufferSize();
    fileVersion=k.getFileVersion();
    writerVersion=k.getWriterVersion();
    fileSchema=k.getFileSchema();
    rowIndexStride=k.getRowIndexStride();
    OrcFile.WriterOptions options=OrcFile.writerOptions(jc).compress(compression).version(fileVersion).rowIndexStride(rowIndexStride).inspector(reader.getObjectInspector());
    if (compression != CompressionKind.NONE) {
      options.bufferSize(compressBuffSize).enforceBufferSize();
    }
    Path outPath=getOutPath();
    if (conf.getIsCompactionTable()) {
      outPath=getOutPath(bucketId);
    }
    outWriters.put(bucketId,OrcFile.createWriter(outPath,options));
    LOG.info(""ORC merge file output path: {}"",outPath);
  }
  if (!checkCompatibility(k)) {
    addIncompatibleFile(k.getInputPath());
    return;
  }
  if (!k.getInputPath().equals(prevPath)) {
    reader=OrcFile.createReader(fs,k.getInputPath());
  }
  byte[] buffer=new byte[(int)v.getStripeInformation().getLength()];
  fdis=fs.open(k.getInputPath());
  fdis.readFully(v.getStripeInformation().getOffset(),buffer,0,(int)v.getStripeInformation().getLength());
  outWriters.get(bucketId).appendStripe(buffer,0,buffer.length,v.getStripeInformation(),v.getStripeStatistics());
  if (LOG.isInfoEnabled()) {
    LOG.info(""Merged stripe from file "" + k.getInputPath() + "" [ offset : ""+ v.getStripeInformation().getOffset()+ "" length: ""+ v.getStripeInformation().getLength()+ "" row: ""+ v.getStripeStatistics().getColStats(0).getNumberOfValues()+ "" ]"");
  }
  if (v.isLastStripeInFile()) {
    for (    Map.Entry<String,ByteBuffer> entry : v.getUserMetadata().entrySet()) {
      outWriters.get(bucketId).addUserMetadata(entry.getKey(),entry.getValue());
    }
  }
}
 catch (Throwable e) {
  exception=true;
  LOG.error(""Closing operator..Exception: "" + ExceptionUtils.getStackTrace(e));
  throw new HiveException(e);
}
 finally {
  if (exception) {
    closeOp(true);
  }
  if (fdis != null) {
    try {
      fdis.close();
    }
 catch (    IOException e) {
      throw new HiveException(String.format(""Unable to close file %s"",filePath),e);
    }
 finally {
      fdis=null;
    }
  }
}
",0,0,0,,
356,} finally {,"try {
  ReplExternalTables externalTablesWriter=new ReplExternalTables(conf);
  boolean isSingleTaskForExternalDb=conf.getBoolVar(REPL_EXTERNAL_WAREHOUSE_SINGLE_COPY_TASK) && work.replScope.includeAllTables();
  HashMap<String,Boolean> singleCopyPaths=getNonTableLevelCopyPaths(db,isSingleTaskForExternalDb);
  boolean isExternalTablePresent=false;
  String snapshotPrefix=dbName.toLowerCase();
  ArrayList<String> prevSnaps=new ArrayList<>();
  if (isSnapshotEnabled) {
    FileUtils.deleteIfExists(getDFS(SnapshotUtils.getSnapshotFileListPath(dumpRoot),conf),new Path(SnapshotUtils.getSnapshotFileListPath(dumpRoot),EximUtil.FILE_LIST_EXTERNAL_SNAPSHOT_CURRENT));
    FileUtils.deleteIfExists(getDFS(SnapshotUtils.getSnapshotFileListPath(dumpRoot),conf),new Path(SnapshotUtils.getSnapshotFileListPath(dumpRoot),EximUtil.FILE_LIST_EXTERNAL_SNAPSHOT_OLD));
    replSnapshotCount=new SnapshotUtils.ReplSnapshotCount();
  }
  for (  String tblName : Utils.matchesTbl(hiveDb,dbName,work.replScope)) {
    Table table=null;
    try {
      HiveWrapper.Tuple<Table> tableTuple=new HiveWrapper(hiveDb,dbName).table(tblName,conf);
      table=tableTuple != null ? tableTuple.object : null;
      if (tableTuple != null && !isMaterializedViewsReplEnabled() && TableType.MATERIALIZED_VIEW.equals(tableTuple.object.getTableType())) {
        LOG.info(""Attempt to dump materialized view : "" + tblName);
        continue;
      }
      LOG.debug(""Dumping table: "" + tblName + "" to db root ""+ dbRoot.toUri());
      if (shouldDumpExternalTableLocation(conf) && TableType.EXTERNAL_TABLE.equals(tableTuple.object.getTableType())) {
        LOG.debug(""Adding table {} to external tables list"",tblName);
        externalTablesWriter.dataLocationDump(tableTuple.object,extTableFileList,singleCopyPaths,!isSingleTaskForExternalDb,conf);
        isExternalTablePresent=true;
      }
      dumpTable(dbName,tblName,validTxnList,dbRoot,dbDataRoot,bootDumpBeginReplId,hiveDb,tableTuple,managedTblList,dataCopyAtLoad);
    }
 catch (    InvalidTableException te) {
      LOG.debug(te.getMessage());
    }
    dumpConstraintMetadata(dbName,tblName,dbRoot,hiveDb,table != null ? table.getTTable().getId() : -1);
    if (tableList != null && isTableSatifiesConfig(table)) {
      tableList.add(tblName);
    }
  }
  if (isExternalTablePresent && shouldDumpExternalTableLocation(conf) && isSingleTaskForExternalDb) {
    externalTablesWriter.dumpNonTableLevelCopyPaths(singleCopyPaths,extTableFileList,conf,isSnapshotEnabled,snapshotPrefix,replSnapshotCount,snapPathFileList,prevSnaps,true);
  }
  dumpTableListToDumpLocation(tableList,dumpRoot,dbName,conf);
}
 catch (Exception e) {
  caught=e;
}
 finally {
  try {
    Utils.resetDbBootstrapDumpState(hiveDb,dbName,uniqueKey);
  }
 catch (  Exception e) {
    if (caught == null) {
      throw e;
    }
 else {
      LOG.error(""failed to reset the db state for "" + uniqueKey + "" on failure of repl dump"",e);
      throw caught;
    }
  }
  if (caught != null) {
    throw caught;
  }
}
",0,0,0,,
357,} finally {,"try {
  if (!StringUtils.isEmpty(jsonString)) {
    FileSystem fileSystem=stagingDirPath.getFileSystem(conf);
    if (fileSystem != null) {
      if (!fileSystem.exists(stagingDirPath)) {
        fileSystem.mkdirs(stagingDirPath);
      }
      newPath=stagingDirPath.suffix(File.separator + fileName);
      outStream=fileSystem.create(newPath,true);
      writer=new OutputStreamWriter(outStream,""UTF-8"");
      writer.write(jsonString);
    }
  }
}
 catch (IOException ex) {
  if (newPath != null) {
    filePath=newPath.toString();
  }
  throw new IOException(""Failed to write json string to file:"" + filePath,ex);
}
catch (Exception ex) {
  if (newPath != null) {
    filePath=newPath.toString();
  }
  throw new IOException(""Failed to write json string to file:"" + filePath,ex);
}
 finally {
  try {
    if (writer != null) {
      writer.close();
    }
    if (outStream != null) {
      outStream.close();
    }
  }
 catch (  Exception ex) {
    throw new IOException(""Unable to close writer/outStream."",ex);
  }
}
",0,0,0,,
358,} finally {,"try {
  Path baseDir=work.getTmpPathForPartitionPruning();
  FileSystem fs=FileSystem.get(baseDir.toUri(),jobConf);
  for (  String name : sourceInfoMap.keySet()) {
    Path sourceDir=new Path(baseDir,name);
    for (    FileStatus fstatus : fs.listStatus(sourceDir)) {
      LOG.info(""Start processing pruning file: "" + fstatus.getPath());
      in=new ObjectInputStream(fs.open(fstatus.getPath()));
      final int numName=in.readInt();
      Set<String> columnNames=new HashSet<>();
      for (int i=0; i < numName; i++) {
        columnNames.add(in.readUTF());
      }
      for (      SourceInfo si : sourceInfoMap.get(name)) {
        Preconditions.checkArgument(columnNames.contains(si.columnName),""AssertionError: no output for column "" + si.columnName);
      }
      while (in.available() > 0) {
        writable.readFields(in);
        for (        SourceInfo info : sourceInfoMap.get(name)) {
          Object row=info.deserializer.deserialize(writable);
          Object value=info.soi.getStructFieldData(row,info.field);
          value=ObjectInspectorUtils.copyToStandardObject(value,info.fieldInspector);
          info.values.add(value);
        }
      }
    }
  }
}
 catch (Exception e) {
  throw new HiveException(e);
}
 finally {
  try {
    if (in != null) {
      in.close();
    }
  }
 catch (  IOException e) {
    throw new HiveException(""error while trying to close input stream"",e);
  }
}
",0,0,0,,
359,} finally {,"try {
  MRTaskReporter mrReporter=new MRTaskReporter(getContext());
  rproc.init(mrReporter,inputs,outputs);
  rproc.run();
  perfLogger.perfLogEnd(CLASS_NAME,PerfLogger.TEZ_RUN_PROCESSOR);
}
 catch (Throwable t) {
  originalThrowable=t;
}
 finally {
  if (originalThrowable != null && (originalThrowable instanceof Error || Throwables.getRootCause(originalThrowable) instanceof Error)) {
    LOG.error(""Cannot recover from this FATAL error"",originalThrowable);
    getContext().reportFailure(TaskFailureType.FATAL,originalThrowable,""Cannot recover from this error"");
    throw new RuntimeException(originalThrowable);
  }
  try {
    if (rproc != null) {
      rproc.close();
    }
  }
 catch (  Throwable t) {
    if (originalThrowable == null) {
      originalThrowable=t;
    }
  }
  try {
    for (    LogicalOutput output : outputs.values()) {
      if (output instanceof MROutput) {
        MROutput mrOutput=(MROutput)output;
        if (mrOutput.isCommitRequired()) {
          mrOutput.commit();
        }
      }
    }
  }
 catch (  Throwable t) {
    if (originalThrowable == null) {
      originalThrowable=t;
    }
  }
  if (originalThrowable != null) {
    LOG.error(""Failed initializeAndRunProcessor"",originalThrowable);
    for (    LogicalOutput output : outputs.values()) {
      if (output instanceof MROutput) {
        MROutput mrOutput=(MROutput)output;
        if (mrOutput.isCommitRequired()) {
          mrOutput.abort();
        }
      }
    }
    if (originalThrowable instanceof InterruptedException) {
      throw (InterruptedException)originalThrowable;
    }
 else {
      throw new RuntimeException(originalThrowable);
    }
  }
}
",0,0,0,,
360,} finally {,"try {
  ss.setTezSession(session);
  LOG.info(""Subscribed to counters: {} for queryId: {}"",wmContext.getSubscribedCounters(),wmContext.getQueryId());
  ensureSessionHasResources(session,allNonConfFiles);
  List<LocalResource> allNonAppResources=session.getLocalizedResources();
  logResources(allNonAppResources);
  Map<String,LocalResource> allResources=DagUtils.createTezLrMap(session.getAppJarLr(),allNonAppResources);
  DAG dag=build(jobConf,work,scratchDir,ctx,allResources);
  dag.setCallerContext(callerContext);
  if (this.isShutdown) {
    throw new HiveException(""Operation cancelled"");
  }
  DAGClient dagClient=submit(dag,sessionRef);
  session=sessionRef.value;
  boolean wasShutdown=false;
synchronized (dagClientLock) {
    assert this.dagClient == null;
    wasShutdown=this.isShutdown;
    if (!wasShutdown) {
      this.dagClient=dagClient;
    }
  }
  if (wasShutdown) {
    closeDagClientOnCancellation(dagClient);
    throw new HiveException(""Operation cancelled"");
  }
  LOG.info(""HS2 Host: [{}], Query ID: [{}], Dag ID: [{}], DAG Session ID: [{}]"",ServerUtils.hostname(),queryId,this.dagClient.getDagIdentifierString(),this.dagClient.getSessionIdentifierString());
  TezJobMonitor monitor=new TezJobMonitor(work.getAllWork(),dagClient,conf,dag,ctx,counters);
  rc=monitor.monitorExecution();
  if (rc != 0) {
    this.setException(new HiveException(monitor.getDiagnostics()));
  }
  try {
    Set<StatusGetOpts> statusGetOpts=EnumSet.of(StatusGetOpts.GET_COUNTERS);
    TezCounters dagCounters=dagClient.getDAGStatus(statusGetOpts).getDAGCounters();
    if (HiveConf.getBoolVar(conf,HiveConf.ConfVars.HIVE_SERVER2_METRICS_ENABLED)) {
      DeltaFilesMetricReporter.getInstance().submit(dagCounters);
    }
    TezCounters mergedCounters=counters == null ? dagCounters : Utils.mergeTezCounters(dagCounters,counters);
    counters=mergedCounters;
  }
 catch (  Exception err) {
    LOG.warn(""Failed to get counters. Ignoring, summary info will be incomplete."",err);
    counters=null;
  }
  if (rc == 0) {
    collectCommitInformation(work);
  }
}
  finally {
  wmContext=ctx.getWmContext();
  try {
    if (sessionRef.value != null) {
      sessionRef.value.returnToSessionManager();
    }
  }
 catch (  Exception e) {
    LOG.error(""Failed to return session: {} to pool"",session,e);
    throw e;
  }
  if (!conf.getVar(HiveConf.ConfVars.TEZ_SESSION_EVENTS_SUMMARY).equalsIgnoreCase(""none"") && wmContext != null) {
    if (conf.getVar(HiveConf.ConfVars.TEZ_SESSION_EVENTS_SUMMARY).equalsIgnoreCase(""json"")) {
      wmContext.printJson(console);
    }
 else     if (conf.getVar(HiveConf.ConfVars.TEZ_SESSION_EVENTS_SUMMARY).equalsIgnoreCase(""text"")) {
      wmContext.print(console);
    }
  }
}
",0,0,0,,
361,} finally {,"try {
  if (!wroteData) {
    ArrowWrapperWritable writable=converter.emptyBatch();
    if (recordWriter == null) {
      recordWriter=LlapOutputFormatService.get().getWriter(this.attemptId);
    }
    recordWriter.write(null,writable);
  }
}
 catch (Exception e) {
  LOG.error(""Failed to write Arrow stream schema"");
  throw new RuntimeException(e);
}
 finally {
  try {
    recordWriter.close(null);
  }
 catch (  Exception e) {
    LOG.error(""Failed to close Arrow stream"");
    throw new RuntimeException(e);
  }
}
",0,0,0,,
362,} finally {,"try {
  int rgCount=rowIndexStride == 0 ? 1 : (int)Math.ceil((double)stripe.getNumberOfRows() / rowIndexStride);
  for (int rgIx=0; rgIx < rgCount; ++rgIx) {
    if (rgs != null && !rgs[rgIx]) {
      continue;
    }
    boolean isLastRg=rgIx == rgCount - 1;
    OrcEncodedColumnBatch ecb=POOLS.ecbPool.take();
    trace.logStartRg(rgIx);
    boolean hasErrorForEcb=true;
    try {
      ecb.init(fileKey,stripeIx,rgIx,physicalFileIncludes.length);
      for (int colIx=0; colIx < colCtxs.length; ++colIx) {
        ColumnReadContext ctx=colCtxs[colIx];
        if (ctx == null)         continue;
        OrcProto.RowIndexEntry index;
        OrcProto.RowIndexEntry nextIndex;
        if (ctx.rowIndex == null) {
          if (isTracingEnabled) {
            LOG.trace(""Row index is null. Likely reading a file with indexes disabled."");
          }
          index=null;
          nextIndex=null;
        }
 else {
          index=ctx.rowIndex.getEntry(rgIx);
          nextIndex=isLastRg ? null : ctx.rowIndex.getEntry(rgIx + 1);
        }
        if (isTracingEnabled) {
          LOG.trace(""ctx: {} rgIx: {} isLastRg: {} rgCount: {}"",ctx,rgIx,isLastRg,rgCount);
        }
        ecb.initOrcColumn(ctx.colIx);
        trace.logStartCol(ctx.colIx);
        for (int streamIx=0; streamIx < ctx.streamCount; ++streamIx) {
          StreamContext sctx=ctx.streams[streamIx];
          ColumnStreamData cb=null;
          try {
            if (RecordReaderUtils.isDictionary(sctx.kind,ctx.encoding) || index == null) {
              if (sctx.stripeLevelStream == null) {
                if (isTracingEnabled) {
                  LOG.trace(""Getting stripe-level stream ["" + sctx.kind + "", ""+ ctx.encoding+ ""] for""+ "" column ""+ ctx.colIx+ "" RG ""+ rgIx+ "" at ""+ sctx.offset+ "", ""+ sctx.length);
                }
                trace.logStartStripeStream(sctx.kind);
                sctx.stripeLevelStream=POOLS.csdPool.take();
                sctx.stripeLevelStream.incRef();
                long unlockUntilCOffset=sctx.offset + sctx.length;
                DiskRangeList lastCached=readEncodedStream(stripeOffset,iter,sctx.offset,sctx.offset + sctx.length,sctx.stripeLevelStream,unlockUntilCOffset,sctx.offset,toRelease);
                if (lastCached != null) {
                  iter=lastCached;
                }
              }
              sctx.stripeLevelStream.incRef();
              cb=sctx.stripeLevelStream;
            }
 else {
              long cOffset=sctx.offset + index.getPositions(sctx.streamIndexOffset);
              long nextCOffsetRel=isLastRg ? sctx.length : nextIndex.getPositions(sctx.streamIndexOffset);
              long endCOffset=sctx.offset + estimateRgEndOffset(isCompressed,isLastRg,nextCOffsetRel,sctx.length,bufferSize);
              long unlockUntilCOffset=sctx.offset + nextCOffsetRel;
              cb=createRgColumnStreamData(rgIx,isLastRg,ctx.colIx,sctx,cOffset,endCOffset,isCompressed,unlockUntilCOffset);
              boolean isStartOfStream=sctx.bufferIter == null;
              DiskRangeList lastCached=readEncodedStream(stripeOffset,(isStartOfStream ? iter : sctx.bufferIter),cOffset,endCOffset,cb,unlockUntilCOffset,sctx.offset,toRelease);
              if (lastCached != null) {
                sctx.bufferIter=iter=lastCached;
              }
            }
          }
 catch (          Exception ex) {
            DiskRangeList drl=toRead == null ? null : toRead.next;
            LOG.error(""Error getting stream ["" + sctx.kind + "", ""+ ctx.encoding+ ""] for""+ "" column ""+ ctx.colIx+ "" RG ""+ rgIx+ "" at ""+ sctx.offset+ "", ""+ sctx.length+ ""; toRead ""+ RecordReaderUtils.stringifyDiskRanges(drl),ex);
            throw (ex instanceof IOException) ? (IOException)ex : new IOException(ex);
          }
 finally {
            if (cb != null) {
              ecb.setStreamData(ctx.colIx,sctx.kind.getNumber(),cb);
            }
          }
        }
      }
      hasErrorForEcb=false;
    }
  finally {
      if (hasErrorForEcb) {
        releaseEcbRefCountsOnError(ecb);
      }
    }
    try {
      consumer.consumeData(ecb);
    }
 catch (    InterruptedException e) {
      LOG.error(""IO thread interrupted while queueing data"");
      releaseEcbRefCountsOnError(ecb);
      throw new IOException(e);
    }
  }
  if (isTracingEnabled) {
    LOG.trace(""Disk ranges after preparing all the data "" + RecordReaderUtils.stringifyDiskRanges(toRead.next));
  }
  trace.logRanges(fileKey,stripeOffset,toRead.next,RangesSrc.PREREAD);
  hasError=false;
}
  finally {
  try {
    for (int colIx=0; colIx < colCtxs.length; ++colIx) {
      ColumnReadContext ctx=colCtxs[colIx];
      if (ctx == null)       continue;
      for (int streamIx=0; streamIx < ctx.streamCount; ++streamIx) {
        StreamContext sctx=ctx.streams[streamIx];
        if (sctx == null || sctx.stripeLevelStream == null)         continue;
        if (0 != sctx.stripeLevelStream.decRef())         continue;
        for (        MemoryBuffer buf : sctx.stripeLevelStream.getCacheBuffers()) {
          LOG.trace(""Unlocking {} at the end of processing"",buf);
          cacheWrapper.releaseBuffer(buf);
        }
      }
    }
    releaseInitialRefcounts(toRead.next);
    releaseBuffers(toRelease.keySet(),true);
  }
 catch (  Throwable t) {
    if (!hasError)     throw new IOException(t);
    LOG.error(""Error during the cleanup after another error; ignoring"",t);
  }
}
",0,0,0,,
363,} finally {,"try {
  for (int colIx=0; colIx < colCtxs.length; ++colIx) {
    ReadContext ctx=colCtxs[colIx];
    if (ctx == null)     continue;
    for (int streamIx=0; streamIx < ctx.streamCount; ++streamIx) {
      StreamContext sctx=ctx.streams[streamIx];
      try {
        if (isTracingEnabled) {
          LOG.trace(""Getting index stream "" + sctx.kind + "" for column ""+ ctx.colIx+ "" at ""+ sctx.offset+ "", ""+ sctx.length);
        }
        ColumnStreamData csd=POOLS.csdPool.take();
        long endCOffset=sctx.offset + sctx.length;
        DiskRangeList lastCached=readEncodedStream(stripeOffset,iter,sctx.offset,endCOffset,csd,endCOffset,sctx.offset,toRelease);
        if (lastCached != null) {
          iter=lastCached;
        }
        if (isTracingEnabled) {
          traceLogBuffersUsedToParse(csd);
        }
        CodedInputStream cis=CodedInputStream.newInstance(new IndexStream(csd.getCacheBuffers(),sctx.length));
        cis.setSizeLimit(InStream.PROTOBUF_MESSAGE_MAX_LIMIT);
switch (sctx.kind) {
case ROW_INDEX:
          OrcProto.RowIndex tmp=index.getRowGroupIndex()[colIx]=OrcProto.RowIndex.parseFrom(cis);
        if (isTracingEnabled) {
          LOG.trace(""Index is "" + tmp.toString().replace('\n',' '));
        }
      break;
case BLOOM_FILTER:
case BLOOM_FILTER_UTF8:
    index.getBloomFilterIndex()[colIx]=OrcProto.BloomFilterIndex.parseFrom(cis);
  break;
default :
throw new AssertionError(""Unexpected index stream type "" + sctx.kind);
}
for (MemoryBuffer buf : csd.getCacheBuffers()) {
if (buf == null) continue;
cacheWrapper.releaseBuffer(buf);
}
}
 catch (Exception ex) {
DiskRangeList drl=toRead == null ? null : toRead.next;
LOG.error(""Error getting stream "" + sctx.kind + "" for column ""+ ctx.colIx+ "" at ""+ sctx.offset+ "", ""+ sctx.length+ ""; toRead ""+ RecordReaderUtils.stringifyDiskRanges(drl),ex);
throw (ex instanceof IOException) ? (IOException)ex : new IOException(ex);
}
}
}
if (isTracingEnabled) {
LOG.trace(""Disk ranges after preparing all the data "" + RecordReaderUtils.stringifyDiskRanges(toRead.next));
}
hasError=false;
}
  finally {
try {
if (toRead != null) {
releaseInitialRefcounts(toRead.next);
}
releaseBuffers(toRelease.keySet(),true);
}
 catch (Throwable t) {
if (!hasError) throw new IOException(t);
LOG.error(""Error during the cleanup after another error; ignoring"",t);
}
}
",0,0,0,,
364,} finally {,"try {
  FileSystem fs=dumpFile.getFileSystem(hiveConf);
  br=new BufferedReader(new InputStreamReader(fs.open(dumpFile)));
  String line;
  if ((line=br.readLine()) != null) {
    String[] lineContents=line.split(""\t"",7);
    setDump(lineContents[0].equals(Utilities.nullStringOutput) ? null : DumpType.valueOf(lineContents[0]),lineContents[1].equals(Utilities.nullStringOutput) ? null : Long.valueOf(lineContents[1]),lineContents[2].equals(Utilities.nullStringOutput) ? null : Long.valueOf(lineContents[2]),lineContents[3].equals(Utilities.nullStringOutput) ? null : new Path(lineContents[3]),lineContents[4].equals(Utilities.nullStringOutput) ? null : Long.valueOf(lineContents[4]),(lineContents.length < 7 || lineContents[6].equals(Utilities.nullStringOutput)) ? Boolean.valueOf(false) : Boolean.valueOf(lineContents[6]));
    setPayload(lineContents[5].equals(Utilities.nullStringOutput) ? null : lineContents[5]);
  }
 else {
    throw new IOException(""Unable to read valid values from dumpFile:"" + dumpFile.toUri().toString());
  }
  readReplScope(br.readLine());
}
 catch (IOException ioe) {
  throw new SemanticException(ioe);
}
 finally {
  if (br != null) {
    try {
      br.close();
    }
 catch (    IOException e) {
      throw new SemanticException(e);
    }
  }
}
",0,0,0,,
365,} finally {,"try {
  try {
    driver.compileAndRespond(query,false);
  }
 catch (  CommandProcessorException e) {
    throw new HiveException(""Failed to compile query"",e);
  }
  QueryPlan plan=driver.getPlan();
  limitQuery=plan.getQueryProperties().getOuterQueryLimit() != -1;
  List<Task<?>> roots=plan.getRootTasks();
  Schema schema=convertSchema(plan.getResultSchema());
  boolean fetchTask=plan.getFetchTask() != null;
  TezWork tezWork;
  if (roots == null || roots.size() != 1 || !(roots.get(0) instanceof TezTask)) {
    if (fetchTask) {
      tezWork=null;
    }
 else {
      throw new HiveException(""Was expecting a single TezTask or FetchTask."");
    }
  }
 else {
    tezWork=((TezTask)roots.get(0)).getWork();
  }
  if (tezWork == null || tezWork.getAllWork().size() != 1 || limitQuery) {
    String tableName=""table_"" + UUID.randomUUID().toString().replaceAll(""-"","""");
    String storageFormatString=getTempTableStorageFormatString(conf);
    String ctas=""create temporary table "" + tableName + "" ""+ storageFormatString+ "" as ""+ query;
    LOG.info(""Materializing the query for LLAPIF; CTAS: "" + ctas);
    driver.releaseLocksAndCommitOrRollback(false);
    driver.releaseResources();
    HiveConf.setVar(conf,ConfVars.HIVE_EXECUTION_MODE,originalMode);
    try {
      driver.run(ctas);
    }
 catch (    CommandProcessorException e) {
      throw new HiveException(""Failed to create temp table ["" + tableName + ""]"",e);
    }
    HiveConf.setVar(conf,ConfVars.HIVE_EXECUTION_MODE,""llap"");
    query=""select * from "" + tableName;
    try {
      driver.compileAndRespond(query,true);
    }
 catch (    CommandProcessorException e) {
      throw new HiveException(""Failed to select from table ["" + tableName + ""]"",e);
    }
    plan=driver.getPlan();
    roots=plan.getRootTasks();
    schema=convertSchema(plan.getResultSchema());
    if (roots == null || roots.size() != 1 || !(roots.get(0) instanceof TezTask)) {
      throw new HiveException(""Was expecting a single TezTask."");
    }
    tezWork=((TezTask)roots.get(0)).getWork();
  }
 else {
    try {
      driver.lockAndRespond();
    }
 catch (    CommandProcessorException cpr1) {
      throw new HiveException(""Failed to acquire locks"",cpr1);
    }
    SessionState.get().addCleanupItem(driverCleanup);
    needsCleanup=false;
  }
  HiveConf driverConf=driver.getConf();
  String validTxnString=driverConf.get(ValidTxnList.VALID_TXNS_KEY);
  if (validTxnString != null) {
    jc.set(ValidTxnList.VALID_TXNS_KEY,validTxnString);
  }
  String validWriteIdString=driverConf.get(ValidTxnWriteIdList.VALID_TABLES_WRITEIDS_KEY);
  if (validWriteIdString != null) {
    assert validTxnString != null;
    jc.set(ValidTxnWriteIdList.VALID_TABLES_WRITEIDS_KEY,validWriteIdString);
  }
  return new PlanFragment(tezWork,schema,jc);
}
  finally {
  if (needsCleanup) {
    if (driverCleanup != null) {
      try {
        driverCleanup.close();
      }
 catch (      IOException err) {
        throw new HiveException(err);
      }
    }
 else     if (driver != null) {
      driver.close();
      driver.destroy();
    }
  }
}
",0,0,0,,
366,} finally {,"try {
  acquire(true,false);
  cancelDelegationToken();
}
  finally {
  release(true,false);
  try {
    super.close();
  }
  finally {
    try {
      FileSystem.closeAllForUGI(sessionUgi);
    }
 catch (    IOException ioe) {
      throw new HiveSQLException(""Could not clean up file-system handles for UGI: "" + sessionUgi,ioe);
    }
  }
}
",0,0,0,,
367,} finally {,"try {
  super.close();
}
  finally {
  try {
    FileSystem.closeAllForUGI(sessionUgi);
  }
 catch (  IOException ioe) {
    throw new HiveSQLException(""Could not clean up file-system handles for UGI: "" + sessionUgi,ioe);
  }
}
",0,0,0,,
368,} finally {,"try {
  tbl=get_table_core(catName,dbName,tblName);
  mustPurge=isMustPurge(envContext,tbl);
  int minCount=0;
  RequestPartsSpec spec=request.getParts();
  List<String> partNames=null;
  if (spec.isSetExprs()) {
    parts=new ArrayList<>(spec.getExprs().size());
    for (    DropPartitionsExpr expr : spec.getExprs()) {
      ++minCount;
      List<Partition> result=new ArrayList<>();
      boolean hasUnknown=ms.getPartitionsByExpr(catName,dbName,tblName,expr.getExpr(),null,(short)-1,result);
      if (hasUnknown) {
        throw new MetaException(""Unexpected unknown partitions to drop"");
      }
      if (!ignoreProtection && expr.isSetPartArchiveLevel()) {
        for (        Partition part : parts) {
          if (MetaStoreUtils.isArchived(part) && MetaStoreUtils.getArchivingLevel(part) < expr.getPartArchiveLevel()) {
            throw new MetaException(""Cannot drop a subset of partitions "" + "" in an archive, partition "" + part);
          }
        }
      }
      parts.addAll(result);
    }
  }
 else   if (spec.isSetNames()) {
    partNames=spec.getNames();
    minCount=partNames.size();
    parts=ms.getPartitionsByNames(catName,dbName,tblName,partNames);
  }
 else {
    throw new MetaException(""Partition spec is not set"");
  }
  if ((parts.size() < minCount) && !ifExists) {
    throw new NoSuchObjectException(""Some partitions to drop are missing"");
  }
  List<String> colNames=null;
  if (partNames == null) {
    partNames=new ArrayList<>(parts.size());
    colNames=new ArrayList<>(tbl.getPartitionKeys().size());
    for (    FieldSchema col : tbl.getPartitionKeys()) {
      colNames.add(col.getName());
    }
  }
  for (  Partition part : parts) {
    firePreEvent(new PreDropPartitionEvent(tbl,part,deleteData,this));
    if (colNames != null) {
      partNames.add(FileUtils.makePartName(colNames,part.getValues()));
    }
    if (MetaStoreUtils.isArchived(part)) {
      Path archiveParentDir=MetaStoreUtils.getOriginalLocation(part);
      verifyIsWritablePath(archiveParentDir);
      archToDelete.add(archiveParentDir);
    }
    if ((part.getSd() != null) && (part.getSd().getLocation() != null)) {
      Path partPath=new Path(part.getSd().getLocation());
      verifyIsWritablePath(partPath);
      dirsToDelete.add(new PathAndPartValSize(partPath,part.getValues().size()));
    }
  }
  ms.dropPartitions(catName,dbName,tblName,partNames);
  if (parts != null && !parts.isEmpty() && !transactionalListeners.isEmpty()) {
    transactionalListenerResponses=MetaStoreListenerNotifier.notifyEvent(transactionalListeners,EventType.DROP_PARTITION,new DropPartitionEvent(tbl,parts,true,deleteData,this),envContext);
  }
  success=ms.commitTransaction();
  DropPartitionsResult result=new DropPartitionsResult();
  if (needResult) {
    result.setPartitions(parts);
  }
  return result;
}
  finally {
  if (!success) {
    ms.rollbackTransaction();
  }
 else   if (checkTableDataShouldBeDeleted(tbl,deleteData)) {
    LOG.info(mustPurge ? ""dropPartition() will purge partition-directories directly, skipping trash."" : ""dropPartition() will move partition-directories to trash-directory."");
    for (    Path path : archToDelete) {
      wh.deleteDir(path,true,mustPurge,needsCm);
    }
    for (    PathAndPartValSize p : dirsToDelete) {
      wh.deleteDir(p.path,true,mustPurge,needsCm);
      try {
        deleteParentRecursive(p.path.getParent(),p.partValSize - 1,mustPurge,needsCm);
      }
 catch (      IOException ex) {
        LOG.warn(""Error from deleteParentRecursive"",ex);
        throw new MetaException(""Failed to delete parent: "" + ex.getMessage());
      }
    }
  }
  if (parts != null) {
    if (parts != null && !parts.isEmpty() && !listeners.isEmpty()) {
      MetaStoreListenerNotifier.notifyEvent(listeners,EventType.DROP_PARTITION,new DropPartitionEvent(tbl,parts,success,deleteData,this),envContext,transactionalListenerResponses,ms);
    }
  }
}
",0,0,0,,
369,} finally {,"try {
  Table tbl=ms.getTable(DEFAULT_CATALOG_NAME,dbName,tblName);
  if (tbl == null) {
    throw new NoSuchObjectException(dbName + ""."" + tblName+ "" not found"");
  }
  boolean isPartitioned=tbl.isSetPartitionKeys() && tbl.getPartitionKeysSize() > 0;
  String tableInputFormat=tbl.isSetSd() ? tbl.getSd().getInputFormat() : null;
  if (!isPartitioned) {
    if (partName != null || isAllPart) {
      throw new MetaException(""Table is not partitioned"");
    }
    if (!tbl.isSetSd() || !tbl.getSd().isSetLocation()) {
      throw new MetaException(""Table does not have storage location; this operation is not supported on views"");
    }
    FileMetadataExprType type=expressionProxy.getMetadataType(tableInputFormat);
    if (type == null) {
      throw new MetaException(""The operation is not supported for "" + tableInputFormat);
    }
    fileMetadataManager.queueCacheMetadata(tbl.getSd().getLocation(),type);
    success=true;
  }
 else {
    List<String> partNames;
    if (partName != null) {
      partNames=Lists.newArrayList(partName);
    }
 else     if (isAllPart) {
      partNames=ms.listPartitionNames(DEFAULT_CATALOG_NAME,dbName,tblName,(short)-1);
    }
 else {
      throw new MetaException(""Table is partitioned"");
    }
    int batchSize=MetastoreConf.getIntVar(conf,ConfVars.BATCH_RETRIEVE_OBJECTS_MAX);
    int index=0;
    int successCount=0, failCount=0;
    HashSet<String> failFormats=null;
    while (index < partNames.size()) {
      int currentBatchSize=Math.min(batchSize,partNames.size() - index);
      List<String> nameBatch=partNames.subList(index,index + currentBatchSize);
      index+=currentBatchSize;
      List<Partition> parts=ms.getPartitionsByNames(DEFAULT_CATALOG_NAME,dbName,tblName,nameBatch);
      for (      Partition part : parts) {
        if (!part.isSetSd() || !part.getSd().isSetLocation()) {
          throw new MetaException(""Partition does not have storage location;"" + "" this operation is not supported on views"");
        }
        String inputFormat=part.getSd().isSetInputFormat() ? part.getSd().getInputFormat() : tableInputFormat;
        FileMetadataExprType type=expressionProxy.getMetadataType(inputFormat);
        if (type == null) {
          ++failCount;
          if (failFormats == null) {
            failFormats=new HashSet<>();
          }
          failFormats.add(inputFormat);
        }
 else {
          ++successCount;
          fileMetadataManager.queueCacheMetadata(part.getSd().getLocation(),type);
        }
      }
    }
    success=true;
    if (failCount > 0) {
      String errorMsg=""The operation failed for "" + failCount + "" partitions and ""+ ""succeeded for ""+ successCount+ "" partitions; unsupported formats: "";
      boolean isFirst=true;
      for (      String s : failFormats) {
        if (!isFirst) {
          errorMsg+="", "";
        }
        isFirst=false;
        errorMsg+=s;
      }
      throw new MetaException(errorMsg);
    }
  }
}
  finally {
  if (success) {
    if (!ms.commitTransaction()) {
      throw new MetaException(""Failed to commit"");
    }
  }
 else {
    ms.rollbackTransaction();
  }
}
",0,0,0,,
370,} finally {,"try {
  openTransaction();
  if (newPart.isSetWriteId()) {
    LOG.warn(""Alter partitions with write ID called without transaction information"");
  }
  Ref<MColumnDescriptor> oldCd=new Ref<>();
  result=alterPartitionNoTxn(catName,dbname,name,part_vals,newPart,validWriteIds,oldCd);
  removeUnusedColumnDescriptor(oldCd.t);
  success=commitTransaction();
}
 catch (Throwable exception) {
  LOG.error(""alterPartition failed"",exception);
  e=exception;
}
 finally {
  if (!success) {
    rollbackTransaction();
    MetaException metaException=new MetaException(""The transaction for alter partition did not commit successfully."");
    if (e != null) {
      metaException.initCause(e);
    }
    throw metaException;
  }
}
",0,0,0,,
371,} finally {,"try {
  openTransaction();
  Iterator<List<String>> part_val_itr=part_vals.iterator();
  Set<MColumnDescriptor> oldCds=new HashSet<>();
  Ref<MColumnDescriptor> oldCdRef=new Ref<>();
  MTable table=null;
  for (  Partition tmpPart : newParts) {
    List<String> tmpPartVals=part_val_itr.next();
    if (writeId > 0) {
      tmpPart.setWriteId(writeId);
    }
    oldCdRef.t=null;
    if (table == null) {
      table=this.getMTable(tmpPart.getCatName(),tmpPart.getDbName(),tmpPart.getTableName());
    }
    Partition result=alterPartitionNoTxn(catName,dbname,name,tmpPartVals,tmpPart,queryWriteIdList,oldCdRef,table);
    results.add(result);
    if (oldCdRef.t != null) {
      oldCds.add(oldCdRef.t);
    }
  }
  for (  MColumnDescriptor oldCd : oldCds) {
    removeUnusedColumnDescriptor(oldCd);
  }
  success=commitTransaction();
}
 catch (Exception exception) {
  e=exception;
  LOG.error(""Alter failed"",e);
}
 finally {
  if (!success) {
    rollbackTransaction();
    MetaException metaException=new MetaException(""The transaction for alter partition did not commit successfully."");
    if (e != null) {
      metaException.initCause(e);
    }
    throw metaException;
  }
}
",0,0,0,,
372,} finally {,"try {
  success&=validateSchemaVersions();
  success&=validateSequences(conn);
  success&=validateSchemaTables(conn);
  success&=validateLocations(conn,schemaTool.getValidationServers());
  success&=validateColumnNullValues(conn);
}
  finally {
  if (conn != null) {
    try {
      conn.close();
    }
 catch (    SQLException e) {
      throw new HiveMetaException(""Failed to close metastore connection"",e);
    }
  }
}
",0,0,0,,
373,} finally {,"try {
  String schema=null;
  try {
    schema=hmsConn.getSchema();
  }
 catch (  SQLFeatureNotSupportedException e) {
    LOG.debug(""schema is not supported"");
  }
  DatabaseMetaData metadata=conn.getMetaData();
  rs=metadata.getTables(null,schema,""%"",new String[]{""TABLE""});
  while (rs.next()) {
    String table=rs.getString(""TABLE_NAME"");
    dbTables.add(table.toLowerCase());
    LOG.debug(""Found table "" + table + "" in HMS dbstore"");
  }
}
 catch (SQLException e) {
  throw new HiveMetaException(""Failed to retrieve schema tables from Hive Metastore DB,"" + e.getMessage(),e);
}
 finally {
  if (rs != null) {
    try {
      rs.close();
    }
 catch (    SQLException e) {
      throw new HiveMetaException(""Failed to close resultset"",e);
    }
  }
}
",0,0,0,,
374,} finally {,"try {
  return execute(size);
}
 catch (Exception ex) {
  LOG.warn(String.format(""Exception thrown while processing using a batch size %d"",size),ex);
}
 finally {
  attempt++;
  if (attempt == maxRetries) {
    throw new RetryException(String.format(""Maximum number of retry attempts %d exhausted"",maxRetries));
  }
}
",0,0,0,,
375,} finally {,"try {
  GetItemResponse table=dynamo.getItem(GetItemRequest.builder().tableName(awsProperties.dynamoDbTableName()).consistentRead(true).key(tableKey).build());
  checkMetadataLocation(table,base);
  Map<String,String> properties=prepareProperties(table,newMetadataLocation);
  persistTable(tableKey,table,properties);
  commitStatus=CommitStatus.SUCCESS;
}
 catch (ConditionalCheckFailedException e) {
  throw new CommitFailedException(e,""Cannot commit %s: concurrent update detected"",tableName());
}
catch (RuntimeException persistFailure) {
  LOG.error(""Confirming if commit to {} indeed failed to persist, attempting to reconnect and check."",fullTableName,persistFailure);
  commitStatus=checkCommitStatus(newMetadataLocation,metadata);
switch (commitStatus) {
case SUCCESS:
    break;
case FAILURE:
  throw new CommitFailedException(persistFailure,""Cannot commit %s due to unexpected exception"",tableName());
case UNKNOWN:
throw new CommitStateUnknownException(persistFailure);
}
}
 finally {
try {
if (commitStatus == CommitStatus.FAILURE) {
io().deleteFile(newMetadataLocation);
}
}
 catch (RuntimeException e) {
LOG.error(""Fail to cleanup metadata file at {}"",newMetadataLocation,e);
throw e;
}
}
",0,0,0,,
376,} finally {,"try {
  for (  ManifestEntry<DataFile> entry : reader.entries()) {
    Preconditions.checkArgument(allowedEntryStatus == entry.status(),""Invalid manifest entry status: %s (allowed status: %s)"",entry.status(),allowedEntryStatus);
switch (entry.status()) {
case ADDED:
      summaryBuilder.addedFile(reader.spec(),entry.file());
    writer.add(entry);
  break;
case EXISTING:
writer.existing(entry);
break;
case DELETED:
summaryBuilder.deletedFile(reader.spec(),entry.file());
writer.delete(entry);
break;
}
}
threw=false;
}
  finally {
try {
writer.close();
}
 catch (IOException e) {
if (!threw) {
throw new RuntimeIOException(e,""Failed to close manifest: %s"",outputFile);
}
}
}
",0,0,0,,
377,} finally {,"try {
  return block.run();
}
 catch (Throwable t) {
  failure=t;
  if (catchBlock != null) {
    try {
      catchBlock.run(failure);
    }
 catch (    Exception e) {
      LOG.warn(""Suppressing failure in catch block"",e);
      failure.addSuppressed(e);
    }
  }
  tryThrowAs(failure,e1Class);
  tryThrowAs(failure,e2Class);
  tryThrowAs(failure,e3Class);
  tryThrowAs(failure,RuntimeException.class);
  throw new RuntimeException(""Unknown throwable"",failure);
}
 finally {
  if (finallyBlock != null) {
    try {
      finallyBlock.run();
    }
 catch (    Exception e) {
      LOG.warn(""Suppressing failure in finally block"",e);
      if (failure != null) {
        failure.addSuppressed(e);
      }
 else {
        tryThrowAs(e,e1Class);
        tryThrowAs(e,e2Class);
        tryThrowAs(e,e3Class);
        tryThrowAs(e,RuntimeException.class);
        throw new RuntimeException(""Unknown exception in finally block"",failure);
      }
    }
  }
}
",0,0,0,,
378,finally {,"try {
  repeat(cnt,i -> {
    Path path=FS.getPath(typeNames[i] + "".bin"");
    typeBackups[i]=path;
    assertEquals(EXIT_CODE_OK,execute(""--meta"",""remove"",""--typeName"",typeNames[i],""--out"",path.toString()));
  }
);
  assertEquals(EXIT_CODE_OK,execute(""--meta"",""list""));
  String out=testOut.toString();
  repeat(cnt,i -> assertNotContains(log,out,""typeName="" + typeNames[i]));
  repeat(cnt,i -> crd.binary().builder(typeNames[i]).setField(""fld1"",typeValues[i]).build());
  repeat(cnt,i -> assertEquals(EXIT_CODE_OK,execute(""--meta"",""update"",""--in"",typeBackups[i].toString())));
  repeat(cnt,i -> {
    assertEquals(EXIT_CODE_OK,execute(""--meta"",""details"",""--typeName"",typeNames[i]));
    checkTypeDetails(log,testOut.toString(),crd.context().cacheObjects().metadata(typeIds[i]));
  }
);
}
  finally {
  repeat(cnt,i -> {
    if (typeBackups[i] != null) {
      try {
        Files.deleteIfExists(typeBackups[i]);
      }
 catch (      IOException e) {
        throw new RuntimeException(e);
      }
    }
  }
);
}
",0,0,0,,
379,finally {,"try {
  repeat(cnt,i -> {
    Path path=FS.getPath(typeNames[i] + "".bin"");
    typeBackups[i]=path;
    assertEquals(EXIT_CODE_OK,execute(""--meta"",""remove"",""--typeName"",typeNames[i],""--out"",path.toString()));
  }
);
  assertEquals(EXIT_CODE_OK,execute(""--meta"",""list""));
  String out=testOut.toString();
  repeat(cnt,i -> assertNotContains(log,out,""typeName="" + typeNames[i]));
  repeat(cnt,i -> crd.binary().builder(typeNames[i]).setField(""fld0"",typeValues[cnt - i - 1]).build());
  repeat(cnt,i -> {
    assertEquals(EXIT_CODE_UNEXPECTED_ERROR,execute(""--meta"",""update"",""--in"",typeBackups[i].toString()));
    assertContains(log,testOut.toString(),""The type of an existing field can not be changed"");
  }
);
}
  finally {
  repeat(cnt,i -> {
    if (typeBackups[i] != null) {
      try {
        Files.deleteIfExists(typeBackups[i]);
      }
 catch (      IOException e) {
        throw new RuntimeException(e);
      }
    }
  }
);
}
",0,0,0,,
380,finally {,"try {
  for (  int p : parts) {
    GridDhtLocalPartition part=locParts.get(p);
    if (part != null && part.state().active()) {
      AffinityTopologyVersion topVer=ctx.exchange().readyAffinityVersion();
      GridLongList gaps=part.finalizeUpdateCounters();
      if (gaps != null) {
        for (int j=0; j < gaps.size() / 2; j++) {
          long gapStart=gaps.get(j * 2);
          long gapStop=gaps.get(j * 2 + 1);
          if (part.group().persistenceEnabled() && part.group().walEnabled() && !part.group().mvccEnabled()) {
            RollbackRecord rec=new RollbackRecord(part.group().groupId(),part.id(),gapStart - 1,gapStop - gapStart + 1);
            try {
              ptr=ctx.wal().log(rec);
            }
 catch (            IgniteCheckedException e) {
              throw new IgniteException(e);
            }
          }
        }
        for (        GridCacheContext ctx0 : grp.caches())         ctx0.continuousQueries().closeBackupUpdateCountersGaps(ctx0,part.id(),topVer,gaps);
      }
    }
  }
}
  finally {
  try {
    if (ptr != null)     ctx.wal().flush(ptr,false);
  }
 catch (  IgniteCheckedException e) {
    throw new IgniteException(e);
  }
 finally {
    lock.readLock().unlock();
  }
}
",0,0,0,,
381,finally {,"try {
  if (!restore && markDirty && !wasDirty&& changeTracker != null)   changeTracker.apply(page,fullId,this);
  boolean pageWalRec=markDirty && walPlc != FALSE && (walPlc == TRUE || !wasDirty);
  assert PageIO.getCrc(page + PAGE_OVERHEAD) == 0;
  if (markDirty)   setDirty(fullId,page,true,false);
  beforeReleaseWrite(fullId,page + PAGE_OVERHEAD,pageWalRec);
}
 catch (IgniteCheckedException e) {
  throw new IgniteException(e);
}
 finally {
  long pageId=PageIO.getPageId(page + PAGE_OVERHEAD);
  try {
    assert pageId != 0 : U.hexLong(PageHeader.readPageId(page));
    rwLock.writeUnlock(page + PAGE_LOCK_OFFSET,PageIdUtils.tag(pageId));
    assert PageIO.getVersion(page + PAGE_OVERHEAD) != 0 : dumpPage(pageId,fullId.groupId());
    assert PageIO.getType(page + PAGE_OVERHEAD) != 0 : U.hexLong(pageId);
    if (throttlingPlc != ThrottlingPolicy.DISABLED && !restore && markDirty && !wasDirty)     writeThrottle.onMarkDirty(isInCheckpoint(fullId));
  }
 catch (  AssertionError ex) {
    U.error(log,""Failed to unlock page [fullPageId="" + fullId + "", binPage=""+ U.toHexString(page,systemPageSize())+ ']');
    throw ex;
  }
}
",0,0,0,,
382,finally {,"try {
  for (  Entry<KeyCacheObject,CacheObject> e : entries) {
    cctx.shared().database().checkpointReadLock();
    try {
      e.getKey().finishUnmarshal(cctx.cacheObjectContext(),cctx.deploy().globalLoader());
      if (!cctx.isLocal()) {
        int p=cctx.affinity().partition(e.getKey());
        if (ignoredParts.contains(p))         continue;
        if (!reservedParts.contains(p)) {
          GridDhtLocalPartition part=cctx.topology().localPartition(p,topVer,true);
          if (!part.reserve()) {
            ignoredParts.add(p);
            continue;
          }
 else {
            if (part.state() == GridDhtPartitionState.RENTING) {
              part.release();
              ignoredParts.add(p);
              continue;
            }
            reservedParts.add(p);
          }
        }
      }
      GridCacheEntryEx entry=internalCache.entryEx(e.getKey(),topVer);
      if (plc != null) {
        ttl=CU.toTtl(plc.getExpiryForCreation());
        if (ttl == CU.TTL_ZERO)         continue;
 else         if (ttl == CU.TTL_NOT_CHANGED)         ttl=0;
        expiryTime=CU.toExpireTime(ttl);
      }
      if (topFut != null) {
        Throwable err=topFut.validateCache(cctx,false,false,entry.key(),null);
        if (err != null)         throw new IgniteCheckedException(err);
      }
      boolean primary=cctx.affinity().primaryByKey(cctx.localNode(),entry.key(),topVer);
      entry.initialValue(e.getValue(),ver,ttl,expiryTime,false,topVer,primary ? GridDrType.DR_LOAD : GridDrType.DR_PRELOAD,false,primary);
      entry.touch();
      CU.unwindEvicts(cctx);
      entry.onUnlock();
    }
 catch (    GridDhtInvalidPartitionException ignored) {
      ignoredParts.add(cctx.affinity().partition(e.getKey()));
    }
catch (    GridCacheEntryRemovedException ignored) {
    }
catch (    IgniteCheckedException ex) {
      IgniteLogger log=cache.unwrap(Ignite.class).log();
      U.error(log,""Failed to set initial value for cache entry: "" + e,ex);
      throw new IgniteException(""Failed to set initial value for cache entry."",ex);
    }
 finally {
      cctx.shared().database().checkpointReadUnlock();
    }
  }
}
  finally {
  for (  Integer part : reservedParts) {
    GridDhtLocalPartition locPart=cctx.topology().localPartition(part,topVer,false);
    assert locPart != null : ""Evicted reserved partition: "" + locPart;
    locPart.release();
  }
  try {
    if (!cctx.isNear() && cctx.shared().wal() != null)     cctx.shared().wal().flush(null,false);
  }
 catch (  IgniteCheckedException e) {
    U.error(log,""Failed to write preloaded entries into write-ahead log."",e);
    throw new IgniteException(""Failed to write preloaded entries into write-ahead log."",e);
  }
}
",0,0,0,,
383,finally {,"try {
  if (cctx.isReplicated()) {
    GridDhtLocalPartition part=cctx.topology().localPartition(partId,topVer,false);
    if (part == null || part.state() != OWNING) {
      checkPartMapping=true;
      return reserved;
    }
  }
  GridDhtLocalPartition part=cctx.topology().localPartition(partId,topVer,false);
  if (part == null || part.state() != OWNING || !part.reserve()) {
    checkPartMapping=true;
    return reserved;
  }
  partititons[i]=part;
  if (part.state() != OWNING) {
    checkPartMapping=true;
    return reserved;
  }
}
  finally {
  if (checkPartMapping && !cctx.affinity().primaryByPartition(partId,topVer).id().equals(ctx.localNodeId()))   throw new IgniteException(""Failed partition reservation. "" + ""Partition is not primary on the node. [partition="" + partId + "", cacheName=""+ cctx.name()+ "", nodeId=""+ ctx.localNodeId()+ "", topology=""+ topVer+ ']');
}
",0,0,0,,
384,finally {,"try {
  while (pos < stop) {
    int b1=utfBuf[pos++] & 0xFF;
    int b2, b3;
switch (b1 >> 4) {
case 0:
case 1:
case 2:
case 3:
case 4:
case 5:
case 6:
case 7:
      urfCBuf[cpos++]=(char)b1;
    break;
case 12:
case 13:
  b2=utfBuf[pos++];
if ((b2 & 0xC0) != 0x80) throw new UTFDataFormatException();
urfCBuf[cpos++]=(char)(((b1 & 0x1F) << 6) | (b2 & 0x3F));
break;
case 14:
b3=utfBuf[pos + 1];
b2=utfBuf[pos];
pos+=2;
if ((b2 & 0xC0) != 0x80 || (b3 & 0xC0) != 0x80) throw new UTFDataFormatException();
urfCBuf[cpos++]=(char)(((b1 & 0x0F) << 12) | ((b2 & 0x3F) << 6) | (b3 & 0x3F));
break;
default :
throw new UTFDataFormatException();
}
}
}
 catch (ArrayIndexOutOfBoundsException ignored) {
outOfBounds=true;
}
 finally {
if (outOfBounds || (pos - start) > utfLen) {
pos=start + (int)utfLen;
throw new UTFDataFormatException();
}
}
",0,0,0,,
385,finally {,"try {
  client.doHandshake(new SHMemHandshakeClosure(log,rmtNodeId,clusterStateProvider,locNodeSupplier));
}
  finally {
  if (!obj.cancel())   throw handshakeTimeoutException();
}
",0,0,0,,
386,finally {,"try {
  return tcpHandshakeExecutor.tcpHandshake(ch,rmtNodeId,sslMeta,msg);
}
 catch (IOException e) {
  if (log.isDebugEnabled())   log.debug(""Failed to read from channel: "" + e);
  throw new IgniteCheckedException(""Failed to read from channel."",e);
}
 finally {
  if (!timeoutObject.cancel())   throw handshakeTimeoutException();
}
",0,0,0,,
387,finally {,"try {
  OutputStream out=sock.getOutputStream();
  out.write(data);
  out.flush();
}
 catch (IOException e) {
  err=e;
}
 finally {
  boolean cancelled=obj.cancel();
  if (cancelled)   removeTimeoutObject(obj);
  if (err != null)   throw err;
  if (!cancelled)   throw new SocketTimeoutException(""Write timed out (socket was concurrently closed)."");
}
",0,0,0,,
388,finally {,"try {
  U.marshal(marshaller(),msg,out);
}
 catch (IgniteCheckedException e) {
  err=e;
}
 finally {
  boolean cancelled=obj.cancel();
  if (cancelled)   removeTimeoutObject(obj);
  if (err != null)   throw err;
  if (!cancelled)   throw new SocketTimeoutException(""Write timed out (socket was concurrently closed)."");
}
",0,0,0,,
389,finally {,"try {
  out.write(res);
  out.flush();
}
 catch (IOException e) {
  err=e;
}
 finally {
  boolean cancelled=obj.cancel();
  if (cancelled)   removeTimeoutObject(obj);
  if (err != null)   throw err;
  if (!cancelled)   throw new SocketTimeoutException(""Write timed out (socket was concurrently closed)."");
}
",0,0,0,,
390,finally {,"try {
  beforeFirstTest();
  stmt.evaluate();
}
 catch (Throwable t) {
  suppressed=t;
  throw t;
}
 finally {
  try {
    afterLastTest();
  }
 catch (  Throwable t) {
    if (suppressed != null)     t.addSuppressed(suppressed);
    throw t;
  }
}
",0,0,0,,
391,} finally {,"try {
  try {
    doClose();
  }
 catch (  Exception e) {
  }
  transactionManager.setRollbackOnly();
  if (t instanceof Exception) {
    Exception e=(Exception)t;
    for (    ChunkListener chunkProxy : chunkListeners) {
      try {
        chunkProxy.onError(e);
      }
 catch (      final Exception e1) {
        logger.log(Level.SEVERE,e1.getMessage(),e1);
      }
    }
  }
  stepContext.getMetric(MetricImpl.MetricType.ROLLBACK_COUNT).incValue();
}
  finally {
  int txStatus=transactionManager.getStatus();
  if (txStatus == Status.STATUS_ACTIVE || txStatus == Status.STATUS_MARKED_ROLLBACK) {
    transactionManager.rollback();
  }
  throw new BatchContainerRuntimeException(""Failure in Read-Process-Write Loop"",t);
}
",0,0,0,,
392,} finally {,"try {
  Bundle bundle=getInstalledBundle(framework,localUrl);
  if (bundle != null) {
    return bundle;
  }
  LOG.debug(""Installing bundle into {} from url: {}"",framework,url);
  InputStream stream=getUrlStream(localUrl);
  Bundle installedBundle=framework.getBundleContext().installBundle(url,stream);
  return installedBundle;
}
  finally {
  if (!isLocal) {
    try {
      new File(new URI(localUrl)).delete();
    }
 catch (    URISyntaxException e) {
      throw Exceptions.propagate(e);
    }
  }
}
",0,0,0,,
393,} finally {,"try {
  if (this.runningMap.replace(this.jobContext.getJobName(),false,true)) {
    LOGGER.info(""Job {} will be executed, add into running map."",this.jobContext.getJobId());
    isLaunched=true;
    super.launchJob(jobListener);
  }
 else {
    LOGGER.warn(""Job {} will not be executed because other jobs are still running."",this.jobContext.getJobId());
  }
}
 catch (Throwable t) {
  errorInJobLaunching=t;
}
 finally {
  if (isLaunched) {
    if (this.runningMap.replace(this.jobContext.getJobName(),true,false)) {
      LOGGER.info(""Job {} is done, remove from running map."",this.jobContext.getJobId());
    }
 else {
      throw errorInJobLaunching == null ? new IllegalStateException(""A launched job should have running state equal to true in the running map."") : new RuntimeException(""Failure in launching job:"",errorInJobLaunching);
    }
  }
}
",0,0,0,,
394,} finally {,"try {
  launcher.cancelJob(this.jobLauncherListener);
}
 catch (JobException e) {
  throw new RuntimeException(""Unable to cancel planning job "" + this.planningJobId + "": "",e);
}
 finally {
  try {
    this.jobsMapping.deleteMapping(jobUri);
  }
 catch (  Exception e) {
    throw new RuntimeException(""Cannot delete jobs mapping for job : "" + jobUri);
  }
}
",0,0,0,,
395,} finally {,"try {
  HelixManager planningJobManager=this.taskDriverHelixManager.isPresent() ? this.taskDriverHelixManager.get() : this.jobHelixManager;
  String builderStr=jobProps.getProperty(GobblinClusterConfigurationKeys.DISTRIBUTED_JOB_LAUNCHER_BUILDER,GobblinHelixDistributeJobExecutionLauncher.Builder.class.getName());
  Optional<String> planningJobIdFromStore=jobsMapping.getPlanningJobId(this.jobUri);
  boolean nonblocking=false;
  Lock jobLock=locks.get(this.jobUri);
  jobLock.lock();
  try {
    if (planningJobIdFromStore.isPresent() && !canRun(planningJobIdFromStore.get(),planningJobManager)) {
      return;
    }
    log.info(""Planning job for {} does not exist. First time run."",this.jobUri);
    GobblinHelixDistributeJobExecutionLauncher.Builder builder=GobblinConstructorUtils.<GobblinHelixDistributeJobExecutionLauncher.Builder>invokeLongestConstructor(new ClassAliasResolver(GobblinHelixDistributeJobExecutionLauncher.Builder.class).resolveClass(builderStr));
    Properties jobPlanningProps=new Properties();
    jobPlanningProps.putAll(this.jobProps);
    newPlanningId=HelixJobsMapping.createPlanningJobId(jobPlanningProps);
    jobPlanningProps.setProperty(GobblinClusterConfigurationKeys.PLANNING_ID_KEY,newPlanningId);
    jobPlanningProps.setProperty(GobblinClusterConfigurationKeys.PLANNING_JOB_CREATE_TIME,String.valueOf(System.currentTimeMillis()));
    builder.setSysProps(this.sysProps);
    builder.setJobPlanningProps(jobPlanningProps);
    builder.setJobHelixManager(this.jobHelixManager);
    builder.setTaskDriverHelixManager(this.taskDriverHelixManager);
    builder.setAppWorkDir(this.appWorkDir);
    builder.setJobsMapping(this.jobsMapping);
    builder.setPlanningJobLauncherMetrics(this.planningJobLauncherMetrics);
    builder.setHelixMetrics(this.helixMetrics);
    Config combined=ConfigUtils.propertiesToConfig(jobPlanningProps).withFallback(ConfigUtils.propertiesToConfig(sysProps));
    nonblocking=ConfigUtils.getBoolean(combined,GobblinClusterConfigurationKeys.NON_BLOCKING_PLANNING_JOB_ENABLED,GobblinClusterConfigurationKeys.DEFAULT_NON_BLOCKING_PLANNING_JOB_ENABLED);
    log.info(""Planning job {} started."",newPlanningId);
    GobblinHelixDistributeJobExecutionLauncher launcher=builder.build();
    closer.register(launcher);
    this.jobsMapping.setPlanningJobId(this.jobUri,newPlanningId);
    startTime=System.currentTimeMillis();
    this.currentJobMonitor=launcher.launchJob(null);
    HelixUtils.waitJobInitialization(planningJobManager,newPlanningId,newPlanningId);
  }
  finally {
    jobLock.unlock();
  }
  this.deleteJobSpec();
  this.currentJobMonitor.get();
  this.currentJobMonitor=null;
  if (nonblocking) {
    log.info(""Planning job {} submitted successfully."",newPlanningId);
  }
 else {
    log.info(""Planning job {} finished."",newPlanningId);
    this.planningJobLauncherMetrics.updateTimeForCompletedPlanningJobs(startTime);
  }
}
 catch (Exception e) {
  if (startTime != 0) {
    this.planningJobLauncherMetrics.updateTimeForFailedPlanningJobs(startTime);
  }
  log.error(""Failed to run planning job for {}"",this.jobUri,e);
  throw new JobException(""Failed to run planning job for "" + this.jobUri,e);
}
 finally {
  try {
    closer.close();
  }
 catch (  IOException e) {
    throw new JobException(""Cannot properly close planning job for "" + this.jobUri,e);
  }
}
",0,0,0,,
396,} finally {,"try {
  httpEntity=getAuthentication();
  if (httpEntity != null) {
    JsonElement json=GSON.fromJson(EntityUtils.toString(httpEntity),JsonObject.class);
    if (json == null) {
      log.error(""Http entity: "" + httpEntity);
      log.error(""entity class: "" + httpEntity.getClass().getName());
      log.error(""entity string size: "" + EntityUtils.toString(httpEntity).length());
      log.error(""content length: "" + httpEntity.getContentLength());
      log.error(""content: "" + IOUtils.toString(httpEntity.getContent(),Charsets.UTF_8));
      throw new RestApiConnectionException(""JSON is NULL ! Failed on authentication with the following HTTP response received:\n"" + EntityUtils.toString(httpEntity));
    }
    JsonObject jsonRet=json.getAsJsonObject();
    log.info(""jsonRet: "" + jsonRet.toString());
    parseAuthenticationResponse(jsonRet);
  }
}
 catch (IOException e) {
  throw new RestApiConnectionException(""Failed to get rest api connection; error - "" + e.getMessage(),e);
}
 finally {
  if (httpEntity != null) {
    try {
      EntityUtils.consume(httpEntity);
    }
 catch (    IOException e) {
      throw new RestApiConnectionException(""Failed to consume httpEntity; error - "" + e.getMessage(),e);
    }
  }
}
",0,0,0,,
397,} finally {,"try {
  httpResponse=this.httpClient.execute(httpRequest);
  StatusLine status=httpResponse.getStatusLine();
  httpEntity=httpResponse.getEntity();
  if (httpEntity != null) {
    jsonStr=EntityUtils.toString(httpEntity);
  }
  if (status.getStatusCode() >= 400) {
    log.info(""Unable to get response using: {} got status code {}"",url,status.getStatusCode());
    JsonElement jsonRet=GSON.fromJson(jsonStr,JsonArray.class);
    throw new RestApiProcessingException(getFirstErrorMessage(""Failed to retrieve response from "",jsonRet));
  }
}
 catch (Exception e) {
  throw new RestApiProcessingException(""Failed to process rest api request; error - "" + e.getMessage(),e);
}
 finally {
  try {
    if (httpEntity != null) {
      EntityUtils.consume(httpEntity);
    }
  }
 catch (  Exception e) {
    throw new RestApiProcessingException(""Failed to consume httpEntity; error - "" + e.getMessage(),e);
  }
}
",0,0,0,,
398,} finally {,"try {
  List<File[]> branchPaths=Arrays.stream(publishPaths).map(branchPath -> new File[]{new File(branchPath,""1-2-3-4""),new File(branchPath,""5-6-7-8"")}).collect(Collectors.toList());
  branchPaths.forEach(partitionPaths -> Arrays.stream(partitionPaths).forEach(File::mkdir));
  State s=buildDefaultState(2);
  String md=new GlobalMetadata().toJson();
  s.removeProp(ConfigurationKeys.DATA_PUBLISHER_METADATA_OUTPUT_DIR);
  s.setProp(ConfigurationKeys.DATA_PUBLISH_WRITER_METADATA_KEY + "".0"",""true"");
  s.setProp(ConfigurationKeys.DATA_PUBLISH_WRITER_METADATA_KEY + "".1"",""true"");
  s.setProp(ConfigurationKeys.WRITER_METADATA_KEY + "".0"",md);
  s.setProp(ConfigurationKeys.WRITER_METADATA_KEY + "".1"",md);
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_FINAL_DIR + "".0"",publishPaths[0].getAbsolutePath());
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_FINAL_DIR + "".1"",publishPaths[1].getAbsolutePath());
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_APPEND_EXTRACT_TO_FINAL_DIR,""false"");
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_APPEND_EXTRACT_TO_FINAL_DIR + "".0"",""false"");
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_APPEND_EXTRACT_TO_FINAL_DIR + "".1"",""false"");
  s.setProp(ConfigurationKeys.DATA_PUBLISHER_METADATA_OUTPUT_FILE,""metadata.json"");
  WorkUnitState wuState1=new WorkUnitState();
  FsWriterMetrics metrics1=buildWriterMetrics(""foo1.json"",""1-2-3-4"",0,10);
  FsWriterMetrics metrics2=buildWriterMetrics(""foo1.json"",""5-6-7-8"",10,20);
  wuState1.setProp(ConfigurationKeys.WRITER_PARTITION_PATH_KEY + "".0"",""1-2-3-4"");
  wuState1.setProp(FsDataWriter.FS_WRITER_METRICS_KEY + "".0"",metrics1.toJson());
  wuState1.setProp(ConfigurationKeys.WRITER_PARTITION_PATH_KEY + "".0_0"",""1-2-3-4"");
  wuState1.setProp(FsDataWriter.FS_WRITER_METRICS_KEY + "".0_0"",metrics2.toJson());
  wuState1.setProp(ConfigurationKeys.WRITER_PARTITION_PATH_KEY + "".0"" + ""_1"",""5-6-7-8"");
  wuState1.setProp(FsDataWriter.FS_WRITER_METRICS_KEY + "".0_1"",metrics2.toJson());
  wuState1.setProp(ConfigurationKeys.WRITER_METADATA_KEY + "".0"",md);
  addStateToWorkunit(s,wuState1);
  WorkUnitState wuState2=new WorkUnitState();
  FsWriterMetrics metrics3=buildWriterMetrics(""foo3.json"",""1-2-3-4"",1,1,30);
  wuState2.setProp(ConfigurationKeys.WRITER_PARTITION_PATH_KEY + "".1"",""1-2-3-4"");
  wuState2.setProp(ConfigurationKeys.WRITER_METADATA_KEY + "".1"",md);
  wuState2.setProp(FsDataWriter.FS_WRITER_METRICS_KEY + "".1"",metrics3.toJson());
  addStateToWorkunit(s,wuState2);
  WorkUnitState wuState3=new WorkUnitState();
  FsWriterMetrics metrics4=buildWriterMetrics(""foo4.json"",""5-6-7-8"",2,55);
  wuState3.setProp(ConfigurationKeys.WRITER_PARTITION_PATH_KEY + "".0"",""5-6-7-8"");
  wuState3.setProp(ConfigurationKeys.WRITER_METADATA_KEY + "".0"",md);
  wuState3.setProp(FsDataWriter.FS_WRITER_METRICS_KEY + "".0"",metrics4.toJson());
  addStateToWorkunit(s,wuState3);
  BaseDataPublisher publisher=new BaseDataPublisher(s);
  publisher.publishMetadata(ImmutableList.of(wuState1,wuState2,wuState3));
  checkMetadata(new File(branchPaths.get(0)[0],""metadata.json.0""),1,10,new FsWriterMetrics.FileInfo(""foo1.json"",10));
  checkMetadata(new File(branchPaths.get(0)[1],""metadata.json.0""),2,75,new FsWriterMetrics.FileInfo(""foo1.json"",20),new FsWriterMetrics.FileInfo(""foo4.json"",55));
  checkMetadata(new File(branchPaths.get(1)[0],""metadata.json.1""),1,30,new FsWriterMetrics.FileInfo(""foo3.json"",30));
}
  finally {
  Arrays.stream(publishPaths).forEach(dir -> {
    try {
      FileUtils.deleteDirectory(dir);
    }
 catch (    IOException e) {
      throw new RuntimeException(""IOError"");
    }
  }
);
}
",0,0,0,,
399,} finally {,"try {
  fs=HiveSource.getSourceFs(workUnitState);
  if (publishEntity.getCleanupQueries() != null) {
    cleanUpQueries.addAll(publishEntity.getCleanupQueries());
  }
  if (publishEntity.getCleanupDirectories() != null) {
    directoriesToDelete.addAll(publishEntity.getCleanupDirectories());
  }
  if (publishEntity.getPublishDirectories() != null) {
    Map<String,String> publishDirectories=publishEntity.getPublishDirectories();
    try {
      for (      Map.Entry<String,String> publishDir : publishDirectories.entrySet()) {
        HadoopUtils.renamePath(fs,new Path(publishDir.getKey()),new Path(publishDir.getValue()),true);
      }
    }
 catch (    Throwable t) {
      throw Throwables.propagate(t);
    }
  }
  if (publishEntity.getPublishQueries() != null) {
    publishQueries.addAll(publishEntity.getPublishQueries());
  }
  WorkUnitState wus=this.workUnitState;
  this.hiveJdbcConnector.executeStatements(publishQueries.toArray(new String[publishQueries.size()]));
  wus.setWorkingState(WorkUnitState.WorkingState.COMMITTED);
  if (wus.getPropAsBoolean(USE_WATERMARKER_KEY,true)) {
    HiveSourceWatermarker watermarker=GobblinConstructorUtils.invokeConstructor(HiveSourceWatermarkerFactory.class,wus.getProp(HiveSource.HIVE_SOURCE_WATERMARKER_FACTORY_CLASS_KEY,HiveSource.DEFAULT_HIVE_SOURCE_WATERMARKER_FACTORY_CLASS)).createFromState(wus);
    watermarker.setActualHighWatermark(wus);
  }
}
 catch (RuntimeException re) {
  throw re;
}
catch (Exception e) {
  log.error(""Error in HiveMaterializer generate publish queries"",e);
}
 finally {
  try {
    this.hiveJdbcConnector.executeStatements(cleanUpQueries.toArray(new String[cleanUpQueries.size()]));
    HadoopUtils.deleteDirectories(fs,directoriesToDelete,true,true);
  }
 catch (  RuntimeException re) {
    throw re;
  }
catch (  Exception e) {
    log.error(""Failed to cleanup staging entities."",e);
  }
}
",0,0,0,,
400,} finally {,"try {
  future.get(this.ownAzkabanSla,TimeUnit.SECONDS);
}
 catch (final TimeoutException e) {
  LOG.info(""Cancelling job since SLA is reached: "" + this.ownAzkabanSla);
  future.cancel(true);
  isCancelled=true;
  this.cancelJob(jobListener);
}
 finally {
  service.shutdown();
  if (isCancelled) {
    this.cancel();
    throw new RuntimeException(""Job failed because it reaches SLA limit: "" + this.ownAzkabanSla);
  }
}
",0,0,0,,
401,} finally {,"try {
  conn.setAutoCommit(false);
  for (int i=0; i < branches; i++) {
    final String destinationTable=this.state.getProp(ForkOperatorUtils.getPropertyNameForBranch(JDBC_PUBLISHER_FINAL_TABLE_NAME,branches,i));
    final String databaseName=this.state.getProp(ForkOperatorUtils.getPropertyNameForBranch(JDBC_PUBLISHER_DATABASE_NAME,branches,i));
    Preconditions.checkNotNull(destinationTable);
    if (this.state.getPropAsBoolean(ForkOperatorUtils.getPropertyNameForBranch(JDBC_PUBLISHER_REPLACE_FINAL_TABLE,branches,i),false) && !emptiedDestTables.contains(destinationTable)) {
      LOG.info(""Deleting table "" + destinationTable);
      commands.deleteAll(databaseName,destinationTable);
      emptiedDestTables.add(destinationTable);
    }
    Map<String,List<WorkUnitState>> stagingTables=getStagingTables(states,branches,i);
    for (    Map.Entry<String,List<WorkUnitState>> entry : stagingTables.entrySet()) {
      String stagingTable=entry.getKey();
      LOG.info(""Copying data from staging table "" + stagingTable + "" into destination table ""+ destinationTable);
      commands.copyTable(databaseName,stagingTable,destinationTable);
      for (      WorkUnitState workUnitState : entry.getValue()) {
        workUnitState.setWorkingState(WorkUnitState.WorkingState.COMMITTED);
      }
    }
  }
  LOG.info(""Commit publish data"");
  conn.commit();
}
 catch (Exception e) {
  try {
    LOG.error(""Failed publishing. Rolling back."");
    conn.rollback();
  }
 catch (  SQLException se) {
    LOG.error(""Failed rolling back."",se);
  }
  throw new RuntimeException(""Failed publishing"",e);
}
 finally {
  try {
    conn.close();
  }
 catch (  SQLException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
402,} finally {,"try {
  return new GoogleCredential.Builder().setTransport(transport).setJsonFactory(JSON_FACTORY).setServiceAccountId(id.get()).setServiceAccountPrivateKeyFromP12File(localCopied).setServiceAccountScopes(serviceAccountScopes).build();
}
  finally {
  boolean isDeleted=localCopied.delete();
  if (!isDeleted) {
    throw new RuntimeException(localCopied.getAbsolutePath() + "" has not been deleted."");
  }
}
",0,0,0,,
403,} finally {,"try (Closer closer=Closer.create()){
  closer.register(this.jobContext);
  notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_PREPARE,new JobListenerAction(){
    @Override public void apply(    JobListener jobListener,    JobContext jobContext) throws Exception {
      jobListener.onJobPrepare(jobContext);
    }
  }
);
  if (this.jobContext.getSemantics() == DeliverySemantics.EXACTLY_ONCE) {
    executeUnfinishedCommitSequences(jobState.getJobName());
  }
  TimingEvent workUnitsCreationTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.WORK_UNITS_CREATION);
  Source<?,?> source=this.jobContext.getSource();
  WorkUnitStream workUnitStream;
  if (source instanceof WorkUnitStreamSource) {
    workUnitStream=((WorkUnitStreamSource)source).getWorkunitStream(jobState);
  }
 else {
    workUnitStream=new BasicWorkUnitStream.Builder(source.getWorkunits(jobState)).build();
  }
  workUnitsCreationTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.WORK_UNITS_CREATION));
  if (this.runtimeMetricContext.isPresent()) {
    String workunitCreationGaugeName=MetricRegistry.name(ServiceMetricNames.GOBBLIN_JOB_METRICS_PREFIX,TimingEvent.LauncherTimings.WORK_UNITS_CREATION,jobState.getJobName());
    long workUnitsCreationTime=workUnitsCreationTimer.getDuration() / TimeUnit.SECONDS.toMillis(1);
    ContextAwareGauge<Integer> workunitCreationGauge=this.runtimeMetricContext.get().newContextAwareGauge(workunitCreationGaugeName,() -> (int)workUnitsCreationTime);
    this.runtimeMetricContext.get().register(workunitCreationGaugeName,workunitCreationGauge);
  }
  if (workUnitStream == null || workUnitStream.getWorkUnits() == null) {
    this.eventSubmitter.submit(JobEvent.WORK_UNITS_MISSING);
    jobState.setState(JobState.RunningState.FAILED);
    String errMsg=""Failed to get work units for job "" + jobId;
    this.jobContext.getJobState().setJobFailureMessage(errMsg);
    this.jobContext.getJobState().setProp(NUM_WORKUNITS,0);
    throw new JobException(errMsg);
  }
  if (!workUnitStream.getWorkUnits().hasNext()) {
    this.eventSubmitter.submit(JobEvent.WORK_UNITS_EMPTY);
    LOG.warn(""No work units have been created for job "" + jobId);
    jobState.setState(JobState.RunningState.COMMITTED);
    isWorkUnitsEmpty=true;
    this.jobContext.getJobState().setProp(NUM_WORKUNITS,0);
    return;
  }
  Boolean canCleanUp=this.canCleanStagingData(this.jobContext.getJobState());
  closer.register(new DestinationDatasetHandlerService(jobState,canCleanUp,this.eventSubmitter)).executeHandlers(workUnitStream);
  closer.register(WriterInitializerFactory.newInstace(jobState,workUnitStream)).initialize();
  closer.register(ConverterInitializerFactory.newInstance(jobState,workUnitStream)).initialize();
  TimingEvent stagingDataCleanTimer=this.eventSubmitter.getTimingEvent(TimingEvent.RunJobTimings.MR_STAGING_DATA_CLEAN);
  cleanLeftoverStagingData(workUnitStream,jobState);
  stagingDataCleanTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.MR_STAGING_DATA_CLEAN));
  long startTime=System.currentTimeMillis();
  jobState.setStartTime(startTime);
  jobState.setState(JobState.RunningState.RUNNING);
  try {
    LOG.info(""Starting job "" + jobId);
    notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_START,new JobListenerAction(){
      @Override public void apply(      JobListener jobListener,      JobContext jobContext) throws Exception {
        jobListener.onJobStart(jobContext);
      }
    }
);
    TimingEvent workUnitsPreparationTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.WORK_UNITS_PREPARATION);
    workUnitStream=prepareWorkUnits(workUnitStream,jobState);
    workUnitStream=workUnitStream.filter(new SkippedWorkUnitsFilter(jobState));
    workUnitStream=workUnitStream.transform(new MultiWorkUnitForEach(){
      @Override public void forWorkUnit(      WorkUnit workUnit){
        jobState.incrementTaskCount();
        jobState.addTaskState(new TaskState(new WorkUnitState(workUnit,jobState)));
      }
    }
);
    this.jobContext.getJobState().setProp(NUM_WORKUNITS,workUnitStream.isSafeToMaterialize() ? workUnitStream.getMaterializedWorkUnitCollection().size() : 0);
    if (jobState.getPropAsBoolean(ConfigurationKeys.WORK_UNIT_ENABLE_TRACKING_LOGS)) {
      workUnitStream=workUnitStream.transform(new Function<WorkUnit,WorkUnit>(){
        @Nullable @Override public WorkUnit apply(        @Nullable WorkUnit input){
          LOG.info(""Work unit tracking log: {}"",input);
          return input;
        }
      }
);
    }
    workUnitsPreparationTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.WORK_UNITS_PREPARATION));
    this.jobContext.storeJobExecutionInfo();
    TimingEvent jobRunTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.JOB_RUN);
    runWorkUnitStream(workUnitStream);
    jobRunTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.JOB_RUN));
    this.eventSubmitter.submit(CaseFormat.UPPER_UNDERSCORE.to(CaseFormat.UPPER_CAMEL,""JOB_"" + jobState.getState()));
    if (jobState.getState() == JobState.RunningState.CANCELLED) {
      LOG.info(String.format(""Job %s has been cancelled, aborting now"",jobId));
      return;
    }
    TimingEvent jobCommitTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.JOB_COMMIT);
    this.jobContext.finalizeJobStateBeforeCommit();
    this.jobContext.commit();
    postProcessJobState(jobState);
    jobCommitTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.JOB_COMMIT));
  }
  finally {
    long endTime=System.currentTimeMillis();
    jobState.setEndTime(endTime);
    jobState.setDuration(endTime - jobState.getStartTime());
  }
}
 catch (Throwable t) {
  jobState.setState(JobState.RunningState.FAILED);
  String errMsg=""Failed to launch and run job "" + jobId + "" due to""+ t.getMessage();
  LOG.error(errMsg + "": "" + t,t);
  this.jobContext.getJobState().setJobFailureException(t);
}
 finally {
  try {
    troubleshooter.refineIssues();
    troubleshooter.logIssueSummary();
    troubleshooter.reportJobIssuesAsEvents(eventSubmitter);
  }
 catch (  Exception e) {
    LOG.error(""Failed to report issues"",e);
  }
  try {
    TimingEvent jobCleanupTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.JOB_CLEANUP);
    cleanupStagingData(jobState);
    jobCleanupTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.JOB_CLEANUP));
    this.jobContext.storeJobExecutionInfo();
  }
  finally {
    launchJobTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.FULL_JOB_EXECUTION));
    if (isWorkUnitsEmpty) {
      notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_COMPLETE,new JobListenerAction(){
        @Override public void apply(        JobListener jobListener,        JobContext jobContext) throws Exception {
          jobListener.onJobCompletion(jobContext);
        }
      }
);
      notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_SUCCEEDED,new JobListenerAction(){
        @Override public void apply(        JobListener jobListener,        JobContext jobContext) throws Exception {
          jobListener.onJobFailure(jobContext);
        }
      }
);
    }
 else {
      for (      JobState.DatasetState datasetState : this.jobContext.getDatasetStatesByUrns().values()) {
        if (datasetState.getState() == JobState.RunningState.FAILED) {
          jobState.setState(JobState.RunningState.FAILED);
          LOG.warn(""At least one dataset state is FAILED. Setting job state to FAILED."");
          break;
        }
      }
      notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_COMPLETE,new JobListenerAction(){
        @Override public void apply(        JobListener jobListener,        JobContext jobContext) throws Exception {
          jobListener.onJobCompletion(jobContext);
        }
      }
);
      if (jobState.getState() == JobState.RunningState.FAILED || jobState.getState() == JobState.RunningState.CANCELLED) {
        notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_FAILED,new JobListenerAction(){
          @Override public void apply(          JobListener jobListener,          JobContext jobContext) throws Exception {
            jobListener.onJobFailure(jobContext);
          }
        }
);
        throw new JobException(String.format(""Job %s failed"",jobId));
      }
 else {
        notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_SUCCEEDED,new JobListenerAction(){
          @Override public void apply(          JobListener jobListener,          JobContext jobContext) throws Exception {
            jobListener.onJobFailure(jobContext);
          }
        }
);
      }
    }
  }
}
",0,0,0,,
404,} finally {,"try {
  TimingEvent jobCleanupTimer=this.eventSubmitter.getTimingEvent(TimingEvent.LauncherTimings.JOB_CLEANUP);
  cleanupStagingData(jobState);
  jobCleanupTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.JOB_CLEANUP));
  this.jobContext.storeJobExecutionInfo();
}
  finally {
  launchJobTimer.stop(this.multiEventMetadataGenerator.getMetadata(this.jobContext,EventName.FULL_JOB_EXECUTION));
  if (isWorkUnitsEmpty) {
    notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_COMPLETE,new JobListenerAction(){
      @Override public void apply(      JobListener jobListener,      JobContext jobContext) throws Exception {
        jobListener.onJobCompletion(jobContext);
      }
    }
);
    notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_SUCCEEDED,new JobListenerAction(){
      @Override public void apply(      JobListener jobListener,      JobContext jobContext) throws Exception {
        jobListener.onJobFailure(jobContext);
      }
    }
);
  }
 else {
    for (    JobState.DatasetState datasetState : this.jobContext.getDatasetStatesByUrns().values()) {
      if (datasetState.getState() == JobState.RunningState.FAILED) {
        jobState.setState(JobState.RunningState.FAILED);
        LOG.warn(""At least one dataset state is FAILED. Setting job state to FAILED."");
        break;
      }
    }
    notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_COMPLETE,new JobListenerAction(){
      @Override public void apply(      JobListener jobListener,      JobContext jobContext) throws Exception {
        jobListener.onJobCompletion(jobContext);
      }
    }
);
    if (jobState.getState() == JobState.RunningState.FAILED || jobState.getState() == JobState.RunningState.CANCELLED) {
      notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_FAILED,new JobListenerAction(){
        @Override public void apply(        JobListener jobListener,        JobContext jobContext) throws Exception {
          jobListener.onJobFailure(jobContext);
        }
      }
);
      throw new JobException(String.format(""Job %s failed"",jobId));
    }
 else {
      notifyListeners(this.jobContext,jobListener,TimingEvent.LauncherTimings.JOB_SUCCEEDED,new JobListenerAction(){
        @Override public void apply(        JobListener jobListener,        JobContext jobContext) throws Exception {
          jobListener.onJobFailure(jobContext);
        }
      }
);
    }
  }
}
",0,0,0,,
405,} finally {,"try (Closer closer=Closer.create()){
  if (this.shouldCommitDataInJob) {
    log.info(String.format(""Committing dataset %s of job %s with commit policy %s and state %s"",this.datasetUrn,this.jobContext.getJobId(),this.jobContext.getJobCommitPolicy(),this.datasetState.getState()));
    ListMultimap<TaskFactoryWrapper,TaskState> taskStatesByFactory=groupByTaskFactory(this.datasetState);
    for (    Map.Entry<TaskFactoryWrapper,Collection<TaskState>> entry : taskStatesByFactory.asMap().entrySet()) {
      TaskFactory taskFactory=entry.getKey().getTaskFactory();
      if (this.deliverySemantics == DeliverySemantics.EXACTLY_ONCE) {
        if (taskFactory != null) {
          throw new RuntimeException(""Custom task factories do not support exactly once delivery semantics."");
        }
        generateCommitSequenceBuilder(this.datasetState,entry.getValue());
      }
 else {
        DataPublisher publisher;
        if (taskFactory == null) {
          publisher=DataPublisherFactory.get(dataPublisherClass.getName(),this.jobContext.getJobState(),this.jobContext.getJobBroker());
          if (!DataPublisherFactory.isPublisherCacheable(publisher)) {
            closer.register(publisher);
          }
        }
 else {
          publisher=taskFactory.createDataPublisher(this.datasetState);
        }
        if (this.isJobCancelled) {
          if (publisher.canBeSkipped()) {
            log.warn(publisher.getClass() + "" will be skipped."");
          }
 else {
            canPersistStates=false;
            throw new RuntimeException(""Cannot persist state upon cancellation because publisher has unfinished work and cannot be skipped."");
          }
        }
 else         if (this.isMultithreaded && !publisher.isThreadSafe()) {
          log.warn(String.format(""Gobblin is set up to parallelize publishing, however the publisher %s is not thread-safe. "" + ""Falling back to serial publishing."",publisher.getClass().getName()));
          safeCommitDataset(entry.getValue(),publisher);
        }
 else {
          commitDataset(entry.getValue(),publisher);
        }
      }
    }
    this.datasetState.setState(JobState.RunningState.COMMITTED);
  }
 else {
    if (this.datasetState.getState() == JobState.RunningState.SUCCESSFUL) {
      this.datasetState.setState(JobState.RunningState.COMMITTED);
    }
  }
}
 catch (Throwable throwable) {
  log.error(String.format(""Failed to commit dataset state for dataset %s of job %s"",this.datasetUrn,this.jobContext.getJobId()),throwable);
  throw new RuntimeException(throwable);
}
 finally {
  try {
    finalizeDatasetState(datasetState,datasetUrn);
    maySubmitFailureEvent(datasetState);
    maySubmitLineageEvent(datasetState);
    if (commitSequenceBuilder.isPresent()) {
      buildAndExecuteCommitSequence(commitSequenceBuilder.get(),datasetState,datasetUrn);
      datasetState.setState(JobState.RunningState.COMMITTED);
    }
 else     if (canPersistStates) {
      persistDatasetState(datasetUrn,datasetState);
    }
  }
 catch (  IOException|RuntimeException ioe) {
    log.error(String.format(""Failed to persist dataset state for dataset %s of job %s"",datasetUrn,this.jobContext.getJobId()),ioe);
    throw new RuntimeException(ioe);
  }
}
",0,0,0,,
406,} finally {,"try {
  closeChannels();
}
  finally {
  throw e;
}
",0,0,0,,
407,} finally {,"try {
  this.server.close();
  LOG.info(""Closed tunnel."");
}
 catch (IOException ioe) {
  LOG.warn(""Exception during shutdown of tunnel"",ioe);
}
 finally {
  try {
    this.thread.interrupt();
    this.thread.join();
  }
 catch (  InterruptedException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
408,} finally {,"try {
  if (dst.getPosition() == 0L) {
    if (buf.position() == 0) {
      return;
    }
    buf.flip();
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (buf.remaining() > 0) {
        int recordBytes=buf.getInt();
        assert (recordBytes > 0) : recordBytes;
        int featureVectorLength=buf.getInt();
        final FeatureValue[] featureVector=new FeatureValue[featureVectorLength];
        for (int j=0; j < featureVectorLength; j++) {
          featureVector[j]=readFeatureValue(buf,featureType);
        }
        float target=buf.getFloat();
        train(featureVector,target);
      }
      buf.rewind();
      if (is_mini_batch) {
        batchUpdate();
      }
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
    }
    logger.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(numTrainingExamples * cvState.getCurrentIteration())+ "" training updates in total) "");
  }
 else {
    if (buf.remaining() > 0) {
      writeBuffer(buf,dst);
    }
    try {
      dst.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + dst.getFile().getAbsolutePath(),e);
    }
    if (logger.isInfoEnabled()) {
      File tmpFile=dst.getFile();
      logger.info(""Wrote "" + numTrainingExamples + "" records to a temporary file for iterative training: ""+ tmpFile.getAbsolutePath()+ "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      setCounterValue(iterCounter,iter);
      buf.clear();
      dst.resetPosition();
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=dst.read(buf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + dst.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        buf.flip();
        int remain=buf.remaining();
        if (remain < SizeOf.INT) {
          throw new HiveException(""Illegal file format was detected"");
        }
        while (remain >= SizeOf.INT) {
          int pos=buf.position();
          int recordBytes=buf.getInt();
          remain-=SizeOf.INT;
          if (remain < recordBytes) {
            buf.position(pos);
            break;
          }
          int featureVectorLength=buf.getInt();
          final FeatureValue[] featureVector=new FeatureValue[featureVectorLength];
          for (int j=0; j < featureVectorLength; j++) {
            featureVector[j]=readFeatureValue(buf,featureType);
          }
          float target=buf.getFloat();
          train(featureVector,target);
          remain-=recordBytes;
        }
        buf.compact();
      }
      if (is_mini_batch) {
        batchUpdate();
      }
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
    }
    logger.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on a secondary storage (thus ""+ NumberUtils.formatNumber(numTrainingExamples * cvState.getCurrentIteration())+ "" training updates in total)"");
  }
}
 catch (Throwable e) {
  throw new HiveException(""Exception caused in the iterative training"",e);
}
 finally {
  try {
    dst.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + dst.getFile().getAbsolutePath(),e);
  }
  this.inputBuf=null;
  this.fileIO=null;
}
",0,0,0,,
409,} finally {,"try {
  if (fileIO.getPosition() == 0L) {
    if (inputBuf.position() == 0) {
      return;
    }
    inputBuf.flip();
    for (int iter=2; iter <= iterations; iter++) {
      _validationState.next();
      _cvState.next();
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (inputBuf.remaining() > 0) {
        int bytes=inputBuf.getInt();
        assert (bytes > 0) : bytes;
        int xLength=inputBuf.getInt();
        final Feature[] x=new Feature[xLength];
        for (int j=0; j < xLength; j++) {
          x[j]=instantiateFeature(inputBuf);
        }
        double y=inputBuf.getDouble();
        boolean validation=(inputBuf.get() == TRUE_BYTE);
        train(x,y,validation);
      }
      final boolean lossIncreased=_validationState.isLossIncreased();
      if ((lossIncreasedLastIter && lossIncreased) || _cvState.isConverged(numTrainingExamples)) {
        break;
      }
      lossIncreasedLastIter=lossIncreased;
      inputBuf.rewind();
    }
    LOG.info(""Performed "" + _cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(_t)+ "" training updates in total), used ""+ _numValidations+ "" validation examples"");
  }
 else {
    if (inputBuf.remaining() > 0) {
      writeBuffer(inputBuf,fileIO);
    }
    try {
      fileIO.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + fileIO.getFile().getAbsolutePath(),e);
    }
    if (LOG.isInfoEnabled()) {
      File tmpFile=fileIO.getFile();
      LOG.info(""Wrote "" + numTrainingExamples + "" records to a temporary file for iterative training: ""+ tmpFile.getAbsolutePath()+ "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    for (int iter=2; iter <= iterations; iter++) {
      _validationState.next();
      _cvState.next();
      setCounterValue(iterCounter,iter);
      inputBuf.clear();
      fileIO.resetPosition();
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=fileIO.read(inputBuf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + fileIO.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        inputBuf.flip();
        int remain=inputBuf.remaining();
        if (remain < SizeOf.INT) {
          throw new HiveException(""Illegal file format was detected"");
        }
        while (remain >= SizeOf.INT) {
          int pos=inputBuf.position();
          int recordBytes=inputBuf.getInt();
          remain-=SizeOf.INT;
          if (remain < recordBytes) {
            inputBuf.position(pos);
            break;
          }
          final int xLength=inputBuf.getInt();
          final Feature[] x=new Feature[xLength];
          for (int j=0; j < xLength; j++) {
            x[j]=instantiateFeature(inputBuf);
          }
          double y=inputBuf.getDouble();
          boolean validation=(inputBuf.get() == TRUE_BYTE);
          train(x,y,validation);
          remain-=recordBytes;
        }
        inputBuf.compact();
      }
      final boolean lossIncreased=_validationState.isLossIncreased();
      if ((lossIncreasedLastIter && lossIncreased) || _cvState.isConverged(numTrainingExamples)) {
        break;
      }
      lossIncreasedLastIter=lossIncreased;
    }
    LOG.info(""Performed "" + _cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on a secondary storage (thus ""+ NumberUtils.formatNumber(_t)+ "" training updates in total), used ""+ _numValidations+ "" validation examples"");
  }
}
  finally {
  try {
    fileIO.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + fileIO.getFile().getAbsolutePath(),e);
  }
  this._inputBuf=null;
  this._fileIO=null;
}
",0,0,0,,
410,} finally {,"try {
  if (lastWritePos == 0) {
    if (inputBuf.position() == 0) {
      return;
    }
    inputBuf.flip();
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (inputBuf.remaining() > 0) {
        int u=inputBuf.getInt();
        int i=inputBuf.getInt();
        int j=inputBuf.getInt();
        count++;
        train(u,i,j);
      }
      cvState.multiplyLoss(0.5d);
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
      if (cvState.isLossIncreased()) {
        etaEstimator.update(1.1f);
      }
 else {
        etaEstimator.update(0.5f);
      }
      inputBuf.rewind();
    }
    LOG.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(count)+ "" training updates in total) "");
  }
 else {
    if (inputBuf.position() > 0) {
      writeBuffer(inputBuf,fileIO,lastWritePos);
    }
    try {
      fileIO.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + fileIO.getFile().getAbsolutePath(),e);
    }
    if (LOG.isInfoEnabled()) {
      File tmpFile=fileIO.getFile();
      LOG.info(""Wrote "" + numTrainingExamples + "" records to a temporary file for iterative training: ""+ tmpFile.getAbsolutePath()+ "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      setCounterValue(iterCounter,iter);
      inputBuf.clear();
      long seekPos=0L;
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=fileIO.read(seekPos,inputBuf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + fileIO.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        seekPos+=bytesRead;
        inputBuf.flip();
        int remain=inputBuf.remaining();
        assert (remain > 0) : remain;
        for (; remain >= RECORD_BYTES; remain-=RECORD_BYTES) {
          int u=inputBuf.getInt();
          int i=inputBuf.getInt();
          int j=inputBuf.getInt();
          count++;
          train(u,i,j);
        }
        inputBuf.compact();
      }
      cvState.multiplyLoss(0.5d);
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
      if (cvState.isLossIncreased()) {
        etaEstimator.update(1.1f);
      }
 else {
        etaEstimator.update(0.5f);
      }
    }
    LOG.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples using a secondary storage (thus ""+ NumberUtils.formatNumber(count)+ "" training updates in total)"");
  }
}
  finally {
  try {
    fileIO.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + fileIO.getFile().getAbsolutePath(),e);
  }
  this.inputBuf=null;
  this.fileIO=null;
}
",0,0,0,,
411,} finally {,"try {
  if (lastWritePos == 0) {
    if (inputBuf.position() == 0) {
      return;
    }
    inputBuf.flip();
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (inputBuf.remaining() > 0) {
        int user=inputBuf.getInt();
        int item=inputBuf.getInt();
        double rating=inputBuf.getDouble();
        count++;
        train(user,item,rating);
      }
      cvState.multiplyLoss(0.5d);
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
      inputBuf.rewind();
    }
    logger.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(count)+ "" training updates in total) "");
  }
 else {
    if (inputBuf.position() > 0) {
      writeBuffer(inputBuf,fileIO,lastWritePos);
    }
    try {
      fileIO.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + fileIO.getFile().getAbsolutePath(),e);
    }
    if (logger.isInfoEnabled()) {
      File tmpFile=fileIO.getFile();
      logger.info(""Wrote "" + numTrainingExamples + "" records to a temporary file for iterative training: ""+ tmpFile.getAbsolutePath()+ "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    for (int iter=2; iter <= iterations; iter++) {
      cvState.next();
      setCounterValue(iterCounter,iter);
      inputBuf.clear();
      long seekPos=0L;
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=fileIO.read(seekPos,inputBuf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + fileIO.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        seekPos+=bytesRead;
        inputBuf.flip();
        int remain=inputBuf.remaining();
        assert (remain > 0) : remain;
        for (; remain >= RECORD_BYTES; remain-=RECORD_BYTES) {
          int user=inputBuf.getInt();
          int item=inputBuf.getInt();
          double rating=inputBuf.getDouble();
          count++;
          train(user,item,rating);
        }
        inputBuf.compact();
      }
      cvState.multiplyLoss(0.5d);
      if (cvState.isConverged(numTrainingExamples)) {
        break;
      }
    }
    logger.info(""Performed "" + cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples using a secondary storage (thus ""+ NumberUtils.formatNumber(count)+ "" training updates in total)"");
  }
}
  finally {
  try {
    fileIO.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + fileIO.getFile().getAbsolutePath(),e);
  }
  this.inputBuf=null;
  this.fileIO=null;
}
",0,0,0,,
412,} finally {,"try {
  if (dst.getPosition() == 0L) {
    if (buf.position() == 0) {
      return;
    }
    buf.flip();
    for (int iter=2; iter < numIterations; iter++) {
      _cvState.next();
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (buf.remaining() > 0) {
        int recordBytes=buf.getInt();
        assert (recordBytes > 0) : recordBytes;
        replayTrain(buf);
      }
      buf.rewind();
      if (_cvState.isConverged(_observedTrainingExamples)) {
        break;
      }
    }
    logger.info(""Performed "" + _cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(_observedTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(_observedTrainingExamples * _cvState.getCurrentIteration())+ "" training updates in total) "");
  }
 else {
    if (buf.remaining() > 0) {
      writeBuffer(buf,dst);
    }
    try {
      dst.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + dst.getFile().getAbsolutePath(),e);
    }
    if (logger.isInfoEnabled()) {
      File tmpFile=dst.getFile();
      logger.info(""Wrote KNN entries of axis items to a temporary file for iterative training: "" + tmpFile.getAbsolutePath() + "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    for (int iter=2; iter < numIterations; iter++) {
      _cvState.next();
      setCounterValue(iterCounter,iter);
      buf.clear();
      dst.resetPosition();
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=dst.read(buf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + dst.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        buf.flip();
        int remain=buf.remaining();
        if (remain < SizeOf.INT) {
          throw new HiveException(""Illegal file format was detected"");
        }
        while (remain >= SizeOf.INT) {
          int pos=buf.position();
          int recordBytes=buf.getInt();
          remain-=SizeOf.INT;
          if (remain < recordBytes) {
            buf.position(pos);
            break;
          }
          replayTrain(buf);
          remain-=recordBytes;
        }
        buf.compact();
      }
      if (_cvState.isConverged(_observedTrainingExamples)) {
        break;
      }
    }
    logger.info(""Performed "" + _cvState.getCurrentIteration() + "" iterations of ""+ NumberUtils.formatNumber(_observedTrainingExamples)+ "" training examples on memory and KNNi data on secondary storage (thus ""+ NumberUtils.formatNumber(_observedTrainingExamples * _cvState.getCurrentIteration())+ "" training updates in total) "");
  }
}
 catch (Throwable e) {
  throw new HiveException(""Exception caused in the iterative training"",e);
}
 finally {
  try {
    dst.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + dst.getFile().getAbsolutePath(),e);
  }
  this._inputBuf=null;
  this._fileIO=null;
}
",0,0,0,,
413,} finally {,"try {
  if (dst.getPosition() == 0L) {
    if (buf.position() == 0) {
      return;
    }
    buf.flip();
    int iter=2;
    float perplexity=cumPerplexity / numTrain;
    float perplexityPrev;
    for (; iter <= iterations; iter++) {
      perplexityPrev=perplexity;
      cumPerplexity=0.f;
      reportProgress(reporter);
      setCounterValue(iterCounter,iter);
      while (buf.remaining() > 0) {
        int recordBytes=buf.getInt();
        assert (recordBytes > 0) : recordBytes;
        int wcLength=buf.getInt();
        final String[] wordCounts=new String[wcLength];
        for (int j=0; j < wcLength; j++) {
          wordCounts[j]=NIOUtils.getString(buf);
        }
        update(wordCounts);
      }
      buf.rewind();
      perplexity=cumPerplexity / numTrain;
      logger.info(""Mean perplexity over mini-batches: "" + perplexity);
      if (Math.abs(perplexityPrev - perplexity) < eps) {
        break;
      }
    }
    logger.info(""Performed "" + Math.min(iter,iterations) + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on memory (thus ""+ NumberUtils.formatNumber(numTrainingExamples * Math.min(iter,iterations))+ "" training updates in total) "");
  }
 else {
    if (buf.remaining() > 0) {
      writeBuffer(buf,dst);
    }
    try {
      dst.flush();
    }
 catch (    IOException e) {
      throw new HiveException(""Failed to flush a file: "" + dst.getFile().getAbsolutePath(),e);
    }
    if (logger.isInfoEnabled()) {
      File tmpFile=dst.getFile();
      logger.info(""Wrote "" + numTrainingExamples + "" records to a temporary file for iterative training: ""+ tmpFile.getAbsolutePath()+ "" (""+ FileUtils.prettyFileSize(tmpFile)+ "")"");
    }
    int iter=2;
    float perplexity=cumPerplexity / numTrain;
    float perplexityPrev;
    for (; iter <= iterations; iter++) {
      perplexityPrev=perplexity;
      cumPerplexity=0.f;
      setCounterValue(iterCounter,iter);
      buf.clear();
      dst.resetPosition();
      while (true) {
        reportProgress(reporter);
        final int bytesRead;
        try {
          bytesRead=dst.read(buf);
        }
 catch (        IOException e) {
          throw new HiveException(""Failed to read a file: "" + dst.getFile().getAbsolutePath(),e);
        }
        if (bytesRead == 0) {
          break;
        }
        assert (bytesRead > 0) : bytesRead;
        buf.flip();
        int remain=buf.remaining();
        if (remain < SizeOf.INT) {
          throw new HiveException(""Illegal file format was detected"");
        }
        while (remain >= SizeOf.INT) {
          int pos=buf.position();
          int recordBytes=buf.getInt();
          remain-=SizeOf.INT;
          if (remain < recordBytes) {
            buf.position(pos);
            break;
          }
          int wcLength=buf.getInt();
          final String[] wordCounts=new String[wcLength];
          for (int j=0; j < wcLength; j++) {
            wordCounts[j]=NIOUtils.getString(buf);
          }
          update(wordCounts);
          remain-=recordBytes;
        }
        buf.compact();
      }
      perplexity=cumPerplexity / numTrain;
      logger.info(""Mean perplexity over mini-batches: "" + perplexity);
      if (Math.abs(perplexityPrev - perplexity) < eps) {
        break;
      }
    }
    logger.info(""Performed "" + Math.min(iter,iterations) + "" iterations of ""+ NumberUtils.formatNumber(numTrainingExamples)+ "" training examples on a secondary storage (thus ""+ NumberUtils.formatNumber(numTrainingExamples * Math.min(iter,iterations))+ "" training updates in total)"");
  }
}
 catch (Throwable e) {
  throw new HiveException(""Exception caused in the iterative training"",e);
}
 finally {
  try {
    dst.close(true);
  }
 catch (  IOException e) {
    throw new HiveException(""Failed to close a file: "" + dst.getFile().getAbsolutePath(),e);
  }
  this.inputBuf=null;
  this.fileIO=null;
}
",0,0,0,,
414,} finally {,"try {
  int counter=0;
  Random random=new Random();
  while (counter < 500000) {
    Document docToIndex=new Document();
    if (counter >= skillCount) {
      int index=random.nextInt(skillCount);
      docToIndex.add(new TextField(""skill"",skills[index],Field.Store.NO));
    }
 else {
      docToIndex.add(new TextField(""skill"",skills[counter],Field.Store.NO));
    }
    counter++;
    indexWriter.addDocument(docToIndex);
  }
}
 catch (Exception e) {
  throw new RuntimeException(""Caught exception while adding a document to index"");
}
 finally {
  try {
    indexWriter.commit();
    indexWriter.close();
  }
 catch (  Exception e) {
    throw new RuntimeException(""Failed to commit/close the index writer"");
  }
}
",0,0,0,,
415,} finally {,"try {
  post=new HttpPost(this.url_.getFile());
  post.setHeader(""Content-Type"",""application/x-thrift"");
  post.setHeader(""Accept"",""application/x-thrift"");
  post.setHeader(""User-Agent"",""Java/THttpClient/HC"");
  if (null != customHeaders_) {
    for (    Map.Entry<String,String> header : customHeaders_.entrySet()) {
      post.setHeader(header.getKey(),header.getValue());
    }
  }
  post.setEntity(new ByteArrayEntity(data));
  HttpResponse response=this.client.execute(this.host,post);
  int responseCode=response.getStatusLine().getStatusCode();
  is=response.getEntity().getContent();
  if (responseCode != HttpStatus.SC_OK) {
    throw new TTransportException(""HTTP Response code: "" + responseCode);
  }
  byte[] buf=new byte[1024];
  ByteArrayOutputStream baos=new ByteArrayOutputStream();
  int len=0;
  do {
    len=is.read(buf);
    if (len > 0) {
      baos.write(buf,0,len);
    }
  }
 while (-1 != len);
  try {
    EntityUtils.consume(response.getEntity());
  }
 catch (  IOException ioe) {
  }
  inputStream_=new ByteArrayInputStream(baos.toByteArray());
}
 catch (IOException ioe) {
  if (null != post) {
    post.abort();
  }
  throw new TTransportException(ioe);
}
 finally {
  if (null != is) {
    try {
      is.close();
    }
 catch (    IOException ioe) {
      throw new TTransportException(ioe);
    }
  }
}
",0,0,0,,
416,} finally {,"try {
  EditorStaticDeps.logger.error().log(""Repairing: "" + e);
  ContentElement el=Element.is(rawEvent.getEventTarget()) ? nodeManager.findElementWrapper(Element.as(rawEvent.getEventTarget())) : null;
  if (el == null) {
    repairListener.onFullDocumentRevert(mutable());
    ContentDocument savedDoc=removeContent();
    savedDoc.setShelved();
    setContent(savedDoc);
    repairer.flashShowRepair(full().getDocumentElement());
  }
 else {
    repairer.revert(Point.inElement(el,el.getFirstChild()),Point.inElement(el,(ContentNode)null));
  }
  rawEvent.preventDefault();
}
  finally {
  if (true) {
    throw e;
  }
}
",0,0,0,,
417,} finally {,"try {
  try {
    if (!update.hasFullImage()) {
      update.setSeqNum(updateCounter.increment().postValue());
    }
 else {
      if (updateCounter.get().preValue() < update.getSeqNum()) {
        updateCounter.add(update.getSeqNum() - updateCounter.get().preValue());
      }
    }
  }
 catch (  Exception e1) {
    failed=true;
    throw new SentryPluginException(""Error setting ZK counter for update cache syncup"" + e1,e1);
  }
  String updateSeq=String.valueOf(update.getSeqNum());
  String newPath=ZKPaths.makePath(zkPath + ""/cache"",updateSeq);
  try {
    haContext.getCuratorFramework().create().creatingParentsIfNeeded().forPath(newPath,update.serialize());
  }
 catch (  Exception e) {
    failed=true;
    throw new SentryPluginException(""error posting update to ZK "",e);
  }
}
  finally {
  try {
    updatorLock.release();
  }
 catch (  Exception e) {
    timerContext.stop();
    SentryHdfsMetricsUtil.getFailedCacheSyncToZK.inc();
    throw new SentryPluginException(""Error releasing ZK lock for update cache syncup"" + e,e);
  }
  timerContext.stop();
  if (failed) {
    SentryHdfsMetricsUtil.getFailedCacheSyncToZK.inc();
  }
}
",0,0,0,,
418,} finally {,"try {
  json=factory.createJsonGenerator(stringWriter);
  json.writeStartObject();
  json.writeStringField(Constants.LOG_FIELD_SERVICE_NAME,serviceName);
  json.writeStringField(Constants.LOG_FIELD_USER_NAME,userName);
  json.writeStringField(Constants.LOG_FIELD_IMPERSONATOR,impersonator);
  json.writeStringField(Constants.LOG_FIELD_IP_ADDRESS,ipAddress);
  json.writeStringField(Constants.LOG_FIELD_OPERATION,operation);
  json.writeStringField(Constants.LOG_FIELD_EVENT_TIME,eventTime);
  json.writeStringField(Constants.LOG_FIELD_OPERATION_TEXT,operationText);
  json.writeStringField(Constants.LOG_FIELD_ALLOWED,allowed);
  json.writeStringField(Constants.LOG_FIELD_DATABASE_NAME,databaseName);
  json.writeStringField(Constants.LOG_FIELD_TABLE_NAME,tableName);
  json.writeStringField(Constants.LOG_FIELD_COLUMN_NAME,columnName);
  json.writeStringField(Constants.LOG_FIELD_RESOURCE_PATH,resourcePath);
  json.writeStringField(Constants.LOG_FIELD_OBJECT_TYPE,objectType);
  json.writeEndObject();
  json.flush();
}
 catch (IOException e) {
  String msg=""Error creating audit log in json format: "" + e.getMessage();
  LOGGER.error(msg,e);
  throw e;
}
 finally {
  try {
    if (json != null) {
      json.close();
    }
  }
 catch (  IOException e) {
    throw e;
  }
}
",0,0,0,,
419,} finally {,"try {
  json=factory.createJsonGenerator(stringWriter);
  json.writeStartObject();
  json.writeStringField(Constants.LOG_FIELD_SERVICE_NAME,serviceName);
  json.writeStringField(Constants.LOG_FIELD_USER_NAME,userName);
  json.writeStringField(Constants.LOG_FIELD_IMPERSONATOR,impersonator);
  json.writeStringField(Constants.LOG_FIELD_IP_ADDRESS,ipAddress);
  json.writeStringField(Constants.LOG_FIELD_OPERATION,operation);
  json.writeStringField(Constants.LOG_FIELD_EVENT_TIME,eventTime);
  json.writeStringField(Constants.LOG_FIELD_OPERATION_TEXT,operationText);
  json.writeStringField(Constants.LOG_FIELD_ALLOWED,allowed);
  for (  Map.Entry<String,String> entry : privilegesMap.entrySet()) {
    json.writeStringField(entry.getKey(),entry.getValue());
  }
  json.writeStringField(Constants.LOG_FIELD_OBJECT_TYPE,objectType);
  json.writeStringField(Constants.LOG_FIELD_COMPONENT,component);
  json.writeEndObject();
  json.flush();
}
 catch (IOException e) {
  String msg=""Error creating audit log in json format: "" + e.getMessage();
  LOGGER.error(msg,e);
  throw e;
}
 finally {
  try {
    if (json != null) {
      json.close();
    }
  }
 catch (  IOException e) {
    throw e;
  }
}
",0,0,0,,
420,} finally{,"try {
  result=method.invoke(client,args);
}
 catch (InvocationTargetException e) {
  Throwable targetException=e.getCause();
  if (targetException != null && targetException instanceof SentryUserException) {
    Throwable sentryTargetException=targetException.getCause();
    if (sentryTargetException != null && sentryTargetException instanceof TTransportException) {
      pool.invalidateObject(client);
      throw new TTransportException(sentryTargetException);
    }
    throw (SentryUserException)targetException;
  }
  throw e;
}
 finally {
  try {
    pool.returnObject(client);
  }
 catch (  Exception e) {
    LOGGER.error(POOL_EXCEPTION_MESSAGE,e);
    throw e;
  }
}
",0,0,0,,
421,} finally {,"try {
  TransientFileFactory fileFactory=TransientFileFactory.getInstance();
  file=fileFactory.createTransientFile(""bin"",null,null);
  out=new FileOutputStream(file);
  length=IOUtils.copyLarge(in,out);
}
 catch (IOException e) {
  throw new RepositoryException(""Error creating temporary file"",e);
}
 finally {
  IOUtils.closeQuietly(in);
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException e) {
      throw new RepositoryException(""Error creating temporary file"",e);
    }
  }
}
",0,0,0,,
422,} finally {,"try {
  long tempModified;
  while (true) {
    try {
      tempModified=System.currentTimeMillis();
      String id=UUID.randomUUID().toString();
      tempId=TEMP_PREFIX + id;
      temporaryInUse.add(tempId);
      rs=conHelper.query(selectMetaSQL,tempId);
      boolean hasNext=rs.next();
      DbUtility.close(rs);
      rs=null;
      if (hasNext) {
        continue;
      }
      conHelper.exec(insertTempSQL,tempId,tempModified);
      break;
    }
 catch (    Exception e) {
      throw convert(""Can not insert new record"",e);
    }
 finally {
      DbUtility.close(rs);
      rs=null;
    }
  }
  MessageDigest digest=getDigest();
  DigestInputStream dIn=new DigestInputStream(stream,digest);
  CountingInputStream in=new CountingInputStream(dIn);
  StreamWrapper wrapper;
  if (STORE_SIZE_MINUS_ONE.equals(storeStream)) {
    wrapper=new StreamWrapper(in,-1);
  }
 else   if (STORE_SIZE_MAX.equals(storeStream)) {
    wrapper=new StreamWrapper(in,Integer.MAX_VALUE);
  }
 else   if (STORE_TEMP_FILE.equals(storeStream)) {
    File temp=moveToTempFile(in);
    long length=temp.length();
    wrapper=new StreamWrapper(new ResettableTempFileInputStream(temp),length);
  }
 else {
    throw new DataStoreException(""Unsupported stream store algorithm: "" + storeStream);
  }
  conHelper.exec(updateDataSQL,wrapper,tempId);
  long length=in.getByteCount();
  DataIdentifier identifier=new DataIdentifier(encodeHexString(digest.digest()));
  usesIdentifier(identifier);
  String id=identifier.toString();
  long newModified;
  while (true) {
    newModified=System.currentTimeMillis();
    if (checkExisting(tempId,length,identifier)) {
      touch(identifier,newModified);
      conHelper.exec(deleteSQL,tempId);
      break;
    }
    try {
      int count=conHelper.update(updateSQL,id,length,newModified,tempId,tempModified);
      if (count != 0) {
        break;
      }
    }
 catch (    SQLException e) {
    }
    rs=conHelper.query(selectMetaSQL,tempId);
    if (!rs.next()) {
      String msg=DIGEST + "" temporary entry deleted: "" + "" id=""+ tempId+ "" length=""+ length;
      log.error(msg);
      throw new DataStoreException(msg);
    }
    tempModified=rs.getLong(2);
    DbUtility.close(rs);
    rs=null;
  }
  usesIdentifier(identifier);
  DbDataRecord record=new DbDataRecord(this,identifier,length,newModified);
  return record;
}
 catch (Exception e) {
  throw convert(""Can not insert new record"",e);
}
 finally {
  if (tempId != null) {
    temporaryInUse.remove(tempId);
  }
  DbUtility.close(rs);
  if (fileInput != null) {
    try {
      fileInput.close();
    }
 catch (    IOException e) {
      throw convert(""Can not close temporary file"",e);
    }
  }
}
",0,0,0,,
423,} finally {,"try {
  Node contentNode=getContentNode(context,isCollection);
  success=importData(context,isCollection,contentNode);
  if (success) {
    success=importProperties(context,isCollection,contentNode);
  }
}
 catch (RepositoryException e) {
  success=false;
  throw new IOException(e.getMessage());
}
 finally {
  if (!success) {
    try {
      context.getImportRoot().refresh(false);
    }
 catch (    RepositoryException e) {
      throw new IOException(e.getMessage());
    }
  }
}
",0,0,0,,
424,} finally {,"try {
  s.importXML(parent.getPath(),in,ImportUUIDBehavior.IMPORT_UUID_COLLISION_THROW);
}
 catch (IOException e) {
  throw new RepositoryException(e.getMessage(),e);
}
 finally {
  try {
    in.close();
  }
 catch (  IOException e) {
    throw new RepositoryException(e.getMessage(),e);
  }
}
",0,0,0,,
425,} finally {,"try {
  String checkpoint=getAsync().getString(laneName);
  checkNotNull(checkpoint,""No current checkpoint found for lane [%s]"",laneName);
  NodeState after=nodeStore.retrieve(checkpoint);
  checkNotNull(after,""No state found for checkpoint [%s] for lane [%s]"",checkpoint,laneName);
  log.info(""Proceeding to update imported indexes {} to checkpoint [{}] for lane [{}]"",indexInfos,checkpoint,laneName);
  NodeState before=indexedState;
  NodeBuilder builder=nodeStore.getRoot().builder();
  IndexUpdate indexUpdate=new IndexUpdate(indexEditorProvider,AsyncLaneSwitcher.getTempLaneName(laneName),nodeStore.getRoot(),builder,IndexUpdateCallback.NOOP);
  CommitFailedException exception=EditorDiff.process(VisibleEditor.wrap(indexUpdate),before,after);
  if (exception != null) {
    throw exception;
  }
  revertLaneChange(builder,indexInfos);
  mergeWithConcurrentCheck(nodeStore,builder);
  success=true;
  log.info(""Imported index is updated to repository state at checkpoint [{}] for "" + ""indexing lane [{}]"",checkpoint,laneName);
}
  finally {
  try {
    resumeCurrentIndexing(lockToken);
  }
 catch (  CommitFailedException|RuntimeException e) {
    log.warn(""Error occurred while releasing indexer lock"",e);
    if (success) {
      throw e;
    }
  }
}
",0,0,0,,
426,} finally {,"try {
  cs=Subject.doAsPrivileged(SystemSubject.INSTANCE,new PrivilegedExceptionAction<ContentSession>(){
    @Override public ContentSession run() throws Exception {
      return repo.login(null,null);
    }
  }
,null);
  Root root=cs.getLatestRoot();
  AuthorizationConfiguration config=securityProvider.getConfiguration(AuthorizationConfiguration.class);
  AccessControlManager acMgr=config.getAccessControlManager(root,NamePathMapper.DEFAULT);
  setupPolicy(""/"" + IndexConstants.INDEX_DEFINITIONS_NAME,acMgr);
  setupPolicy(""/"" + JcrConstants.JCR_SYSTEM,acMgr);
  if (root.hasPendingChanges()) {
    root.commit();
  }
}
 catch (PrivilegedActionException|CommitFailedException e) {
  throw new RepositoryException(e);
}
 finally {
  if (cs != null) {
    try {
      cs.close();
    }
 catch (    IOException e) {
      throw new RepositoryException(e);
    }
  }
}
",0,0,0,,
427,} finally {,"try {
  while (store.getStats().get(1).getElementCount() > 0) {
    Thread.sleep(100);
  }
}
 catch (InterruptedException e) {
  throw new IOException(e);
}
 finally {
  try {
    store.close();
  }
 catch (  DataStoreException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
428,} finally {,"try {
  while (store.getStats().get(1).getElementCount() > 0) {
    Thread.sleep(100);
  }
}
 catch (InterruptedException e) {
  throw new IOException(e);
}
 finally {
  try {
    store.close();
  }
 catch (  DataStoreException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
429,} finally {,"try {
  read(model,new InputStreamReader(((new URL(url))).openStream()),url);
}
 catch (Exception e) {
  throw new JenaException(e);
}
 finally {
  if (errCount != 0) {
    throw new SyntaxError(""unknown"");
  }
}
",0,0,0,,
430,} finally {,"try {
  afterUnbound(s,o);
}
  finally {
  throw new IllegalStateException(e);
}
",0,0,0,,
431,} finally {,"try {
  System.out.println(""Installing "" + features);
  featureService.installFeatures(features,NO_AUTO_REFRESH);
  for (  String curFeature : feature) {
    assertFeatureInstalled(curFeature);
  }
  success=true;
}
  finally {
  System.out.println(""Uninstalling "" + features);
  try {
    featureService.uninstallFeatures(features,NO_AUTO_REFRESH);
  }
 catch (  Exception e) {
    if (success) {
      throw e;
    }
  }
}
",0,0,0,,
432,finally {,"try {
  final Console console=System.console();
  client=SshClient.setUpDefaultClient();
  setupAgent(user,keyFile,client);
  client.setUserInteraction(new UserInteraction(){
    @Override public void welcome(    ClientSession s,    String banner,    String lang){
      console.printf(banner);
    }
    @Override public String[] interactive(    ClientSession s,    String name,    String instruction,    String lang,    String[] prompt,    boolean[] echo){
      String[] answers=new String[prompt.length];
      try {
        for (int i=0; i < prompt.length; i++) {
          if (console != null) {
            if (echo[i]) {
              answers[i]=console.readLine(prompt[i] + "" "");
            }
 else {
              answers[i]=new String(console.readPassword(prompt[i] + "" ""));
            }
          }
        }
      }
 catch (      IOError e) {
      }
      return answers;
    }
    @Override public boolean isInteractionAllowed(    ClientSession session){
      return true;
    }
    @Override public void serverVersionInfo(    ClientSession session,    List<String> lines){
    }
    @Override public String getUpdatedPassword(    ClientSession session,    String prompt,    String lang){
      return null;
    }
  }
);
  client.start();
  if (console != null) {
    console.printf(""Logging in as %s\n"",user);
  }
  ClientSession session=connect(client);
  if (password != null) {
    session.addPasswordIdentity(password);
  }
  session.auth().verify();
  final ClientChannel channel=session.createChannel(""exec"",cmd.concat(NEW_LINE));
  channel.setIn(new ByteArrayInputStream(new byte[0]));
  final ByteArrayOutputStream sout=new ByteArrayOutputStream();
  final ByteArrayOutputStream serr=new ByteArrayOutputStream();
  channel.setOut(AnsiConsole.wrapOutputStream(sout));
  channel.setErr(AnsiConsole.wrapOutputStream(serr));
  channel.open();
  channel.waitFor(EnumSet.of(ClientChannelEvent.CLOSED),0);
  sout.writeTo(System.out);
  serr.writeTo(System.err);
  final boolean isError=(channel.getExitStatus() != null && channel.getExitStatus().intValue() != 0);
  if (isError) {
    final String errorMarker=Ansi.ansi().fg(Color.RED).toString();
    final int fromIndex=sout.toString().indexOf(errorMarker) + errorMarker.length();
    final int toIndex=sout.toString().lastIndexOf(Ansi.ansi().fg(Color.DEFAULT).toString());
    throw new MojoExecutionException(NEW_LINE + sout.toString().substring(fromIndex,toIndex));
  }
}
 catch (MojoExecutionException e) {
  throw e;
}
catch (Throwable t) {
  throw new MojoExecutionException(t,t.getMessage(),t.toString());
}
 finally {
  try {
    client.stop();
  }
 catch (  Throwable t) {
    throw new MojoExecutionException(t,t.getMessage(),t.toString());
  }
}
",0,0,0,,
433,finally {,"try {
  final Console console=System.console();
  client=SshClient.setUpDefaultClient();
  setupAgent(user,keyFile,client);
  client.setUserInteraction(new UserInteraction(){
    @Override public void welcome(    ClientSession s,    String banner,    String lang){
      console.printf(banner);
    }
    @Override public String[] interactive(    ClientSession s,    String name,    String instruction,    String lang,    String[] prompt,    boolean[] echo){
      String[] answers=new String[prompt.length];
      try {
        for (int i=0; i < prompt.length; i++) {
          if (console != null) {
            if (echo[i]) {
              answers[i]=console.readLine(prompt[i] + "" "");
            }
 else {
              answers[i]=new String(console.readPassword(prompt[i] + "" ""));
            }
          }
        }
      }
 catch (      IOError e) {
      }
      return answers;
    }
    @Override public boolean isInteractionAllowed(    ClientSession session){
      return true;
    }
    @Override public void serverVersionInfo(    ClientSession session,    List<String> lines){
    }
    @Override public String getUpdatedPassword(    ClientSession session,    String prompt,    String lang){
      return null;
    }
  }
);
  client.start();
  if (console != null) {
    console.printf(""Logging in as %s\n"",user);
  }
  ClientSession session=connect(client);
  if (password != null) {
    session.addPasswordIdentity(password);
  }
  session.auth().verify();
  StringWriter writer=new StringWriter();
  PrintWriter print=new PrintWriter(writer,true);
  for (  String location : locations) {
    print.println(""bundle:install -s "" + location);
  }
  final ClientChannel channel=session.createChannel(""exec"",writer.toString().concat(NEW_LINE));
  channel.setIn(new ByteArrayInputStream(new byte[0]));
  final ByteArrayOutputStream sout=new ByteArrayOutputStream();
  final ByteArrayOutputStream serr=new ByteArrayOutputStream();
  channel.setOut(AnsiConsole.wrapOutputStream(sout));
  channel.setErr(AnsiConsole.wrapOutputStream(serr));
  channel.open();
  channel.waitFor(EnumSet.of(ClientChannelEvent.CLOSED),0);
  sout.writeTo(System.out);
  serr.writeTo(System.err);
  final boolean isError=(channel.getExitStatus() != null && channel.getExitStatus().intValue() != 0);
  if (isError) {
    final String errorMarker=Ansi.ansi().fg(Color.RED).toString();
    final int fromIndex=sout.toString().indexOf(errorMarker) + errorMarker.length();
    final int toIndex=sout.toString().lastIndexOf(Ansi.ansi().fg(Color.DEFAULT).toString());
    throw new MojoExecutionException(NEW_LINE + sout.toString().substring(fromIndex,toIndex));
  }
}
 catch (MojoExecutionException e) {
  throw e;
}
catch (Throwable t) {
  t.printStackTrace();
  throw new MojoExecutionException(t,t.getMessage(),t.toString());
}
 finally {
  try {
    client.stop();
  }
 catch (  Throwable t) {
    throw new MojoExecutionException(t,t.getMessage(),t.toString());
  }
}
",0,0,0,,
434,} finally {,"try {
  source=getSourceResolver().resolveURI(getRealSourceUri());
  if (source.exists() && !(source instanceof TraversableSource && ((TraversableSource)source).isCollection())) {
    byte[] buf=new byte[4096];
    out=new ByteArrayOutputStream();
    in=source.getInputStream();
    int read=in.read(buf);
    while (read > 0) {
      out.write(buf,0,read);
      read=in.read(buf);
    }
    this.data=out.toByteArray();
    this.mimeType=source.getMimeType();
  }
}
 catch (Exception e) {
  throw new RepositoryException(e);
}
 finally {
  try {
    if (in != null)     in.close();
    if (out != null)     out.close();
  }
 catch (  Exception e) {
    throw new RepositoryException(e);
  }
  if (source != null) {
    getSourceResolver().release(source);
  }
}
",0,0,0,,
435,} finally {,"try {
  source=(ModifiableSource)getSourceResolver().resolveURI(realSourceUri);
  out=source.getOutputStream();
  byte[] buf=new byte[4096];
  in=new ByteArrayInputStream(this.data);
  int read=in.read(buf);
  while (read > 0) {
    out.write(buf,0,read);
    read=in.read(buf);
  }
}
 catch (Exception e) {
  throw new RepositoryException(e);
}
 finally {
  try {
    if (in != null) {
      in.close();
    }
    if (out != null) {
      out.flush();
      out.close();
    }
  }
 catch (  Throwable t) {
    throw new RuntimeException(""Could not close streams: "",t);
  }
  if (source != null) {
    getSourceResolver().release(source);
  }
}
",0,0,0,,
436,finally {,"try {
  resolver=(UsecaseResolver)this.manager.lookup(UsecaseResolver.ROLE);
  usecase=resolver.resolve(webappUrl,usecaseName);
  if (usecase.getView() != null) {
    Tab tab=usecase.getView().getTab();
    if (tab != null) {
      value=tab.getGroup();
    }
  }
}
 catch (ServiceException e) {
  throw new ConfigurationException(""Error: "",e);
}
 finally {
  if (resolver != null) {
    if (usecase != null) {
      try {
        resolver.release(usecase);
      }
 catch (      ServiceException e) {
        throw new RuntimeException(e);
      }
    }
    this.manager.release(resolver);
  }
}
",0,0,0,,
437,} finally {,"try {
  usecaseResolver=(UsecaseResolver)this.manager.lookup(UsecaseResolver.ROLE);
  usecase=usecaseResolver.resolve(webappUri,usecaseName);
  if (usecase.getView() != null) {
    Tab tab=usecase.getView().getTab();
    if (tab != null) {
      tabGroup=tab.getGroup();
    }
  }
}
 catch (ServiceException e) {
  throw new ProcessingException(e);
}
 finally {
  if (usecaseResolver != null) {
    if (usecase != null) {
      try {
        usecaseResolver.release(usecase);
      }
 catch (      ServiceException e) {
        throw new RuntimeException(e);
      }
    }
    this.manager.release(usecaseResolver);
  }
}
",0,0,0,,
438,} finally {,"try {
  for (int t=0; t < numThreads; t++) {
    final int iStart=t * subSize;
    final int iEnd=Math.min((t + 1) * subSize,shuffler.size());
    executor.execute(new Runnable(){
      @Override public void run(){
        for (int i=iStart; i < iEnd; i++) {
          update(shuffler.get(i),mu);
        }
      }
    }
);
  }
}
  finally {
  executor.shutdown();
  shuffler.shuffle();
  try {
    boolean terminated=executor.awaitTermination(numEpochs * shuffler.size(),TimeUnit.MICROSECONDS);
    if (!terminated) {
      logger.error(""subtasks takes forever, return anyway"");
    }
  }
 catch (  InterruptedException e) {
    throw new TasteException(""waiting fof termination interrupted"",e);
  }
}
",0,0,0,,
439,} finally {,"try {
  writer.open();
  DataModel dataModel=getRecommender().getDataModel();
  BlockingQueue<long[]> itemsIDsInBatches=queueItemIDsInBatches(dataModel,batchSize,degreeOfParallelism);
  BlockingQueue<List<SimilarItems>> results=new LinkedBlockingQueue<>();
  AtomicInteger numActiveWorkers=new AtomicInteger(degreeOfParallelism);
  for (int n=0; n < degreeOfParallelism; n++) {
    executorService.execute(new SimilarItemsWorker(n,itemsIDsInBatches,results,numActiveWorkers));
  }
  output=new Output(results,writer,numActiveWorkers);
  executorService.execute(output);
}
 catch (Exception e) {
  throw new IOException(e);
}
 finally {
  executorService.shutdown();
  try {
    boolean succeeded=executorService.awaitTermination(maxDurationInHours,TimeUnit.HOURS);
    if (!succeeded) {
      throw new RuntimeException(""Unable to complete the computation in "" + maxDurationInHours + "" hours!"");
    }
  }
 catch (  InterruptedException e) {
    throw new RuntimeException(e);
  }
  Closeables.close(writer,false);
}
",0,0,0,,
440,} finally {,"try {
  RepositoryDocument rd=new RepositoryDocument();
  List<NamedValue> contentProperties=PropertiesUtils.getContentProperties(properties);
  PropertiesUtils.ingestProperties(rd,properties,contentProperties);
  for (  NamedValue contentProperty : contentProperties) {
    Content binary=ContentReader.read(endpoint,username,password,socketTimeout,session,predicate,contentProperty.getName());
    fileLength=binary.getLength();
    is=ContentReader.getBinary(endpoint,binary,username,password,socketTimeout,session);
    rd.setBinary(is,fileLength);
    String id=PropertiesUtils.getNodeReference(properties);
    if (contentProperties.size() > 1) {
      id=id + INGESTION_SEPARATOR_FOR_MULTI_BINARY + contentProperty.getName();
    }
    String documentURI=binary.getUrl();
    activities.ingestDocumentWithException(documentIdentifier,id,versionString,documentURI,rd);
    fileLengthLong=new Long(fileLength);
  }
  AuthenticationUtils.endSession();
}
 catch (ParseException e) {
  errorCode=""PARSEEXCEPTION"";
  errorDesc=e.getMessage();
  Logging.connectors.warn(""Alfresco: Error during the reading process of dates: "" + e.getMessage(),e);
  handleParseException(e);
}
catch (IOException e) {
  errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
  errorDesc=e.getMessage();
  Logging.connectors.warn(""Alfresco: IOException: "" + e.getMessage(),e);
  handleIOException(e);
}
 finally {
  session=null;
  try {
    if (is != null) {
      is.close();
    }
  }
 catch (  InterruptedIOException e) {
    errorCode=null;
    throw new ManifoldCFException(e.getMessage(),e,ManifoldCFException.INTERRUPTED);
  }
catch (  IOException e) {
    errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
    errorDesc=e.getMessage();
    Logging.connectors.warn(""Alfresco: IOException closing file input stream: "" + e.getMessage(),e);
    handleIOException(e);
  }
}
",0,0,0,,
441,finally,"try {
  if (records.length == 0)   break;
  JSONArrayReader arrayReader=new JSONArrayReader();
  for (  DocumentRecord dr : records) {
    arrayReader.addArrayElement(new JSONValueReader(new InputStreamReader(dr.getDataStream(),Consts.UTF_8)));
  }
  String responsbody=postData(new ReaderInputStream(arrayReader,Consts.UTF_8));
  String status=getStatusFromJsonResponse(responsbody);
  if (""success"".equals(status)) {
    for (    DocumentRecord dr : records) {
      activities.recordActivity(null,dr.getActivity(),dr.getDataSize(),dr.getUri(),""OK"",null);
    }
    Logging.ingest.info(""AmazonCloudSearch: Successfully sent document chunk "" + chunkNumber);
    documentChunkManager.deleteChunk(records);
  }
 else {
    for (    DocumentRecord dr : records) {
      activities.recordActivity(null,dr.getActivity(),dr.getDataSize(),dr.getUri(),""FAILED"",responsbody);
    }
    Logging.ingest.error(""AmazonCloudSearch: Error sending document chunk "" + chunkNumber + "": '""+ responsbody+ ""'"");
    throw new ManifoldCFException(""Received error status from service after feeding document.  Response body: '"" + responsbody + ""'"");
  }
}
 catch (ManifoldCFException e) {
  if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)   throw e;
  for (  DocumentRecord dr : records) {
    activities.recordActivity(null,dr.getActivity(),dr.getDataSize(),dr.getUri(),e.getClass().getSimpleName().toUpperCase(Locale.ROOT),e.getMessage());
  }
  throw e;
}
catch (ServiceInterruption e) {
  for (  DocumentRecord dr : records) {
    activities.recordActivity(null,dr.getActivity(),dr.getDataSize(),dr.getUri(),e.getClass().getSimpleName().toUpperCase(Locale.ROOT),e.getMessage());
  }
  throw e;
}
 finally {
  Throwable exception=null;
  for (  DocumentRecord dr : records) {
    try {
      dr.close();
    }
 catch (    Throwable e) {
      exception=e;
    }
  }
  if (exception != null) {
    if (exception instanceof ManifoldCFException)     throw (ManifoldCFException)exception;
 else     if (exception instanceof Error)     throw (Error)exception;
 else     if (exception instanceof RuntimeException)     throw (RuntimeException)exception;
 else     throw new RuntimeException(""Unknown exception class thrown: "" + exception.getClass().getName() + "": ""+ exception.getMessage(),exception);
  }
}
",0,0,0,,
442,finally,"try {
  for (  String documentIdentifier : documentIdentifiers) {
    final Integer attachmentIndex=extractAttachmentNumberFromDocumentIdentifier(documentIdentifier);
    if (attachmentIndex == null) {
      String versionString=""_"" + urlTemplate;
      if (!activities.checkDocumentNeedsReindexing(documentIdentifier,versionString))       continue;
      String compositeID=documentIdentifier;
      String version=versionString;
      String folderName=extractFolderNameFromDocumentIdentifier(compositeID);
      String id=extractEmailIDFromDocumentIdentifier(compositeID);
      String errorCode=null;
      String errorDesc=null;
      Long fileLengthLong=null;
      long startTime=System.currentTimeMillis();
      try {
        try {
          Folder folder=openFolders.get(folderName);
          if (folder == null) {
            getSession();
            OpenFolderThread oft=new OpenFolderThread(session,folderName);
            oft.start();
            folder=oft.finishUp();
            openFolders.put(folderName,folder);
          }
          if (Logging.connectors.isDebugEnabled())           Logging.connectors.debug(""Email: Processing document identifier '"" + compositeID + ""'"");
          SearchTerm messageIDTerm=new MessageIDTerm(id);
          getSession();
          SearchMessagesThread smt=new SearchMessagesThread(session,folder,messageIDTerm);
          smt.start();
          Message[] message=smt.finishUp();
          String msgURL=makeDocumentURI(urlTemplate,folderName,id);
          Message msg=null;
          for (          Message msg2 : message) {
            msg=msg2;
          }
          if (msg == null) {
            activities.deleteDocument(documentIdentifier);
            continue;
          }
          if (!activities.checkURLIndexable(msgURL)) {
            errorCode=activities.EXCLUDED_URL;
            errorDesc=""Excluded because of URL ('"" + msgURL + ""')"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          long fileLength=msg.getSize();
          if (!activities.checkLengthIndexable(fileLength)) {
            errorCode=activities.EXCLUDED_LENGTH;
            errorDesc=""Excluded because of length ("" + fileLength + "")"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          Date sentDate=msg.getSentDate();
          if (!activities.checkDateIndexable(sentDate)) {
            errorCode=activities.EXCLUDED_DATE;
            errorDesc=""Excluded because of date ("" + sentDate + "")"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          String mimeType=""text/plain"";
          if (!activities.checkMimeTypeIndexable(mimeType)) {
            errorCode=activities.EXCLUDED_MIMETYPE;
            errorDesc=""Excluded because of mime type ('"" + mimeType + ""')"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          RepositoryDocument rd=new RepositoryDocument();
          rd.setFileName(msg.getFileName());
          rd.setMimeType(mimeType);
          rd.setCreatedDate(sentDate);
          rd.setModifiedDate(sentDate);
          for (          String metadata : requiredMetadata) {
            if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_TO)) {
              Address[] to=msg.getRecipients(Message.RecipientType.TO);
              if (to != null) {
                String[] toStr=new String[to.length];
                int j=0;
                for (                Address address : to) {
                  toStr[j]=useEmailExtractor ? extractEmailAddress(address.toString()) : address.toString();
                  j++;
                }
                rd.addField(EmailConfig.EMAIL_TO,toStr);
              }
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_FROM)) {
              Address[] from=msg.getFrom();
              String[] fromStr=new String[from.length];
              int j=0;
              for (              Address address : from) {
                fromStr[j]=useEmailExtractor ? extractEmailAddress(address.toString()) : address.toString();
                j++;
              }
              rd.addField(EmailConfig.EMAIL_FROM,fromStr);
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_SUBJECT)) {
              String subject=msg.getSubject();
              rd.addField(EmailConfig.EMAIL_SUBJECT,subject);
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_DATE)) {
              rd.addField(EmailConfig.EMAIL_DATE,sentDate.toString());
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_ATTACHMENT_ENCODING)) {
              Object o=msg.getContent();
              if (o != null) {
                if (o instanceof Multipart) {
                  Multipart mp=(Multipart)o;
                  String[] encoding=new String[mp.getCount()];
                  for (int k=0, n=mp.getCount(); k < n; k++) {
                    Part part=mp.getBodyPart(k);
                    if (isAttachment(part)) {
                      final String[] fileSplit=part.getFileName().split(""\\?"");
                      if (fileSplit.length > 1) {
                        encoding[k]=fileSplit[1];
                      }
 else {
                        encoding[k]="""";
                      }
                    }
                  }
                  rd.addField(EmailConfig.ENCODING_FIELD,encoding);
                }
 else                 if (o instanceof String) {
                  rd.addField(EmailConfig.ENCODING_FIELD,"""");
                }
              }
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_ATTACHMENT_MIMETYPE)) {
              Object o=msg.getContent();
              if (o != null) {
                if (o instanceof Multipart) {
                  Multipart mp=(Multipart)o;
                  String[] MIMEType=new String[mp.getCount()];
                  for (int k=0, n=mp.getCount(); k < n; k++) {
                    Part part=mp.getBodyPart(k);
                    if (isAttachment(part)) {
                      MIMEType[k]=part.getContentType();
                    }
                  }
                  rd.addField(EmailConfig.MIMETYPE_FIELD,MIMEType);
                }
 else                 if (o instanceof String) {
                  rd.addField(EmailConfig.MIMETYPE_FIELD,"""");
                }
              }
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_ATTACHMENTNAME)) {
              Object o=msg.getContent();
              if (o != null) {
                if (o instanceof Multipart) {
                  Multipart mp=(Multipart)o;
                  String[] attachmentNames=new String[mp.getCount()];
                  for (int k=0, n=mp.getCount(); k < n; k++) {
                    Part part=mp.getBodyPart(k);
                    if (isAttachment(part)) {
                      attachmentNames[k]=part.getFileName();
                    }
                  }
                  rd.addField(EmailConfig.ATTACHMENTNAME_FIELD,attachmentNames);
                }
 else                 if (o instanceof String) {
                  rd.addField(EmailConfig.ATTACHMENTNAME_FIELD,"""");
                }
              }
            }
          }
          final EmailContent bodyContent=extractBodyContent(msg);
          if (bodyContent != null) {
            rd.setMimeType(bodyContent.getMimeType());
            InputStream is=new ByteArrayInputStream(bodyContent.getContent().getBytes(StandardCharsets.UTF_8));
            try {
              rd.setBinary(is,fileLength);
              activities.ingestDocumentWithException(documentIdentifier,version,msgURL,rd);
              errorCode=""OK"";
              fileLengthLong=new Long(fileLength);
            }
  finally {
              is.close();
            }
          }
          if (attachmentUrlTemplate != null) {
            if (msg.getContent() != null && msg.getContent() instanceof Multipart) {
              final Multipart mp=(Multipart)msg.getContent();
              final int numAttachments=mp.getCount();
              for (int i=0; i < numAttachments; i++) {
                if (isAttachment(mp.getBodyPart(i))) {
                  activities.addDocumentReference(documentIdentifier + "":"" + i);
                }
              }
            }
          }
        }
 catch (        InterruptedException e) {
          throw new ManifoldCFException(e.getMessage(),ManifoldCFException.INTERRUPTED);
        }
catch (        MessagingException e) {
          errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
          errorDesc=e.getMessage();
          handleMessagingException(e,""processing email"");
        }
catch (        IOException e) {
          errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
          errorDesc=e.getMessage();
          handleIOException(e,""processing email"");
          throw new ManifoldCFException(e.getMessage(),e);
        }
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         errorCode=null;
        throw e;
      }
 finally {
        if (errorCode != null)         activities.recordActivity(new Long(startTime),EmailConfig.ACTIVITY_FETCH,fileLengthLong,documentIdentifier,errorCode,errorDesc,null);
      }
    }
 else {
      final int attachmentNumber=attachmentIndex;
      String versionString=""_"" + attachmentUrlTemplate;
      if (!activities.checkDocumentNeedsReindexing(documentIdentifier,versionString))       continue;
      String compositeID=documentIdentifier;
      String version=versionString;
      String folderName=extractFolderNameFromDocumentIdentifier(compositeID);
      String id=extractEmailIDFromDocumentIdentifier(compositeID);
      String errorCode=null;
      String errorDesc=null;
      Long fileLengthLong=null;
      long startTime=System.currentTimeMillis();
      try {
        try {
          Folder folder=openFolders.get(folderName);
          if (folder == null) {
            getSession();
            OpenFolderThread oft=new OpenFolderThread(session,folderName);
            oft.start();
            folder=oft.finishUp();
            openFolders.put(folderName,folder);
          }
          if (Logging.connectors.isDebugEnabled())           Logging.connectors.debug(""Email: Processing document identifier '"" + documentIdentifier + ""'"");
          SearchTerm messageIDTerm=new MessageIDTerm(id);
          getSession();
          SearchMessagesThread smt=new SearchMessagesThread(session,folder,messageIDTerm);
          smt.start();
          Message[] message=smt.finishUp();
          String msgURL=makeDocumentURI(attachmentUrlTemplate,folderName,id,attachmentNumber);
          Message msg=null;
          for (          Message msg2 : message) {
            msg=msg2;
          }
          if (msg == null) {
            activities.deleteDocument(documentIdentifier);
            continue;
          }
          if (!activities.checkURLIndexable(msgURL)) {
            errorCode=activities.EXCLUDED_URL;
            errorDesc=""Excluded because of URL ('"" + msgURL + ""')"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          final Date sentDate=msg.getSentDate();
          if (!activities.checkDateIndexable(sentDate)) {
            errorCode=activities.EXCLUDED_DATE;
            errorDesc=""Excluded because of date ("" + sentDate + "")"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          final Multipart mp=(Multipart)msg.getContent();
          if (mp.getCount() <= attachmentNumber) {
            activities.deleteDocument(documentIdentifier);
            continue;
          }
          final Part part=mp.getBodyPart(attachmentNumber);
          final long fileLength=part.getSize();
          if (!activities.checkLengthIndexable(fileLength)) {
            errorCode=activities.EXCLUDED_LENGTH;
            errorDesc=""Excluded because of length ("" + fileLength + "")"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          final String origMimeType=part.getContentType();
          final String mimeType;
          if (origMimeType == null || origMimeType.indexOf("";"") == -1) {
            mimeType=origMimeType;
          }
 else {
            mimeType=origMimeType.substring(0,origMimeType.indexOf("";""));
          }
          if (!activities.checkMimeTypeIndexable(mimeType)) {
            errorCode=activities.EXCLUDED_MIMETYPE;
            errorDesc=""Excluded because of mime type ('"" + mimeType + ""')"";
            activities.noDocument(documentIdentifier,version);
            continue;
          }
          RepositoryDocument rd=new RepositoryDocument();
          rd.setFileName(part.getFileName());
          rd.setMimeType(mimeType);
          rd.setCreatedDate(sentDate);
          rd.setModifiedDate(sentDate);
          for (          String metadata : requiredMetadata) {
            if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_TO)) {
              Address[] to=msg.getRecipients(Message.RecipientType.TO);
              if (to != null) {
                String[] toStr=new String[to.length];
                int j=0;
                for (                Address address : to) {
                  toStr[j]=useEmailExtractor ? extractEmailAddress(address.toString()) : address.toString();
                  j++;
                }
                rd.addField(EmailConfig.EMAIL_TO,toStr);
              }
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_FROM)) {
              Address[] from=msg.getFrom();
              String[] fromStr=new String[from.length];
              int j=0;
              for (              Address address : from) {
                fromStr[j]=useEmailExtractor ? extractEmailAddress(address.toString()) : address.toString();
                j++;
              }
              rd.addField(EmailConfig.EMAIL_FROM,fromStr);
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_SUBJECT)) {
              String subject=msg.getSubject();
              rd.addField(EmailConfig.MAILSUBJECT_FIELD,subject);
            }
 else             if (metadata.toLowerCase(Locale.ROOT).equals(EmailConfig.EMAIL_DATE)) {
              rd.addField(EmailConfig.EMAIL_DATE,sentDate.toString());
            }
          }
          final InputStream is=part.getInputStream();
          try {
            rd.setBinary(is,fileLength);
            activities.ingestDocumentWithException(documentIdentifier,version,msgURL,rd);
            errorCode=""OK"";
            fileLengthLong=new Long(fileLength);
          }
  finally {
            is.close();
          }
        }
 catch (        InterruptedException e) {
          throw new ManifoldCFException(e.getMessage(),ManifoldCFException.INTERRUPTED);
        }
catch (        MessagingException e) {
          errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
          errorDesc=e.getMessage();
          handleMessagingException(e,""processing email attachment"");
        }
catch (        IOException e) {
          errorCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
          errorDesc=e.getMessage();
          handleIOException(e,""processing email attachment"");
          throw new ManifoldCFException(e.getMessage(),e);
        }
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         errorCode=null;
        throw e;
      }
 finally {
        if (errorCode != null)         activities.recordActivity(new Long(startTime),EmailConfig.ACTIVITY_FETCH,fileLengthLong,documentIdentifier,errorCode,errorDesc,null);
      }
    }
  }
}
  finally {
  for (  Folder f : openFolders.values()) {
    try {
      CloseFolderThread cft=new CloseFolderThread(session,f);
      cft.start();
      cft.finishUp();
    }
 catch (    InterruptedException e) {
      throw new ManifoldCFException(e.getMessage(),ManifoldCFException.INTERRUPTED);
    }
catch (    MessagingException e) {
      handleMessagingException(e,""closing folders"");
    }
  }
}
",0,0,0,,
443,finally,"try {
  InputStreamReader isr=new InputStreamReader(socket.getInputStream(),""ASCII"");
  try {
    BufferedReader in=new BufferedReader(isr);
    try {
      OutputStream out=socket.getOutputStream();
      try {
        String uri=url.getFile();
        if (uri.length() == 0)         uri=""/"";
        byte[] tmp=(""POST "" + uri + "" HTTP/1.0\r\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        tmp=(""Document-URI: "" + documentURI + ""\r\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        writeCredentials(out);
        if (aclXmlString.length() > 0) {
          String encodedACL=new Base64().encodeByteArray(aclXmlString.getBytes(StandardCharsets.UTF_8));
          int index=0;
          while (true) {
            if (index + HEADER_CHUNK >= encodedACL.length()) {
              tmp=(""Document-ACL: "" + encodedACL.substring(index) + ""\r\n"").getBytes(StandardCharsets.UTF_8);
              out.write(tmp,0,tmp.length);
              break;
            }
            tmp=(""Document-ACL: "" + encodedACL.substring(index,index + HEADER_CHUNK) + ""\r\n"").getBytes(StandardCharsets.UTF_8);
            out.write(tmp,0,tmp.length);
            index+=HEADER_CHUNK;
          }
        }
        if (collections != null) {
          for (          String collectionName : collections) {
            String encodedValue=metadataEncode(collectionName);
            tmp=(""Document-Metadata: collection_name="" + encodedValue + ""\r\n"").getBytes(StandardCharsets.UTF_8);
            out.write(tmp,0,tmp.length);
          }
        }
        if (documentTemplate != null && documentTemplate.length() > 0) {
          String encodedTemplate=new Base64().encodeByteArray(documentTemplate.getBytes(StandardCharsets.UTF_8));
          int index=0;
          while (true) {
            if (index + HEADER_CHUNK >= encodedTemplate.length()) {
              tmp=(""Document-Template: "" + encodedTemplate.substring(index) + ""\r\n"").getBytes(StandardCharsets.UTF_8);
              out.write(tmp,0,tmp.length);
              break;
            }
            tmp=(""Document-Template: "" + encodedTemplate.substring(index,index + HEADER_CHUNK) + ""\r\n"").getBytes(StandardCharsets.UTF_8);
            out.write(tmp,0,tmp.length);
            index+=HEADER_CHUNK;
          }
        }
        Iterator<String> iter=document.getFields();
        while (iter.hasNext()) {
          String fieldName=iter.next();
          String[] values=document.getFieldAsStrings(fieldName);
          int k=0;
          while (k < values.length) {
            String value=(String)values[k++];
            String encodedValue=metadataEncode(value);
            tmp=(""Document-Metadata: "" + fieldName + ""=""+ encodedValue+ ""\r\n"").getBytes(StandardCharsets.UTF_8);
            out.write(tmp,0,tmp.length);
          }
        }
        tmp=(""Content-length: "" + new Long(length).toString() + ""\r\n\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        long total=0;
        long now, later;
        now=System.currentTimeMillis();
        byte[] bytes=new byte[buffersize];
        while (true) {
          int count;
          try {
            count=is.read(bytes);
          }
 catch (          java.net.SocketTimeoutException ioe) {
            Logging.ingest.warn(""Error reading data for transmission to Ingestion API: "" + ioe.getMessage(),ioe);
            activityStart=new Long(fullStartTime);
            activityCode=""-1"";
            activityDetails=""Couldn't read document: "" + ioe.getMessage();
            long currentTime=System.currentTimeMillis();
            throw new ServiceInterruption(""IO error reading document for ingestion: "" + ioe.getMessage() + ""; read will be retried again later"",ioe,currentTime + interruptionRetryTime,currentTime + 2L * 60L * 60000L,-1,true);
          }
catch (          InterruptedIOException ioe) {
            if (!ioe.getClass().getName().equals(""java.io.InterruptedIOException"")) {
              Logging.ingest.warn(""Error reading data for transmission to Ingestion API: "" + ioe.getMessage(),ioe);
              activityStart=new Long(fullStartTime);
              activityCode=""-1"";
              activityDetails=""Couldn't read document: "" + ioe.getMessage();
              long currentTime=System.currentTimeMillis();
              throw new ServiceInterruption(""IO error reading document for ingestion: "" + ioe.getMessage() + ""; read will be retried again later"",ioe,currentTime + interruptionRetryTime,currentTime + 2L * 60L * 60000L,-1,true);
            }
 else             throw ioe;
          }
catch (          IOException ioe) {
            Logging.ingest.warn(""Error reading data for transmission to Ingestion API: "" + ioe.getMessage(),ioe);
            activityStart=new Long(fullStartTime);
            activityCode=""-1"";
            activityDetails=""Couldn't read document: "" + ioe.getMessage();
            long currentTime=System.currentTimeMillis();
            throw new ServiceInterruption(""IO error reading document for ingestion: "" + ioe.getMessage() + ""; read will be retried again later"",ioe,currentTime + interruptionRetryTime,currentTime + 2L * 60L * 60000L,-1,true);
          }
          if (count == -1)           break;
          readFromDocumentStreamYet=true;
          out.write(bytes,0,count);
          total+=(long)count;
        }
        later=System.currentTimeMillis();
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Total bytes posted: "" + new Long(total).toString() + "", total time: ""+ (later - now));
        out.flush();
        String res;
        try {
          res=getResponse(in);
        }
 catch (        ServiceInterruption si) {
          activityStart=new Long(now);
          activityCode=""-2"";
          activityDetails=si.getMessage();
          throw si;
        }
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Response code from ingest: '"" + res + ""'"");
        CodeDetails cd=new CodeDetails(res);
        activityStart=new Long(now);
        activityBytes=new Long(length);
        activityCode=cd.getCode();
        activityDetails=cd.getDetails();
        int codeValue=cd.getCodeValue();
        if (codeValue < 0)         throw new ManifoldCFException(""Http protocol error"");
        if (codeValue == 200) {
          rval=true;
          return;
        }
        if (codeValue == 401)         throw new ManifoldCFException(""Bad credentials for ingestion"",ManifoldCFException.SETUP_ERROR);
        if (codeValue >= 400 && codeValue < 500) {
          rval=false;
          return;
        }
        long currentTime=System.currentTimeMillis();
        throw new ServiceInterruption(""Error "" + Integer.toString(codeValue) + "" from ingestion request; ingestion will be retried again later"",new ManifoldCFException(""Ingestion HTTP error code "" + Integer.toString(codeValue)),currentTime + interruptionRetryTime,currentTime + 2L * 60L * 60000L,-1,true);
      }
  finally {
        out.close();
      }
    }
  finally {
      in.close();
    }
  }
  finally {
    isr.close();
  }
}
  finally {
  try {
    socket.close();
  }
 catch (  InterruptedIOException e) {
    throw e;
  }
catch (  IOException e) {
    Logging.ingest.debug(""Error closing socket: "" + e.getMessage(),e);
  }
}
",0,0,0,,
444,finally,"try {
  InputStreamReader isr=new InputStreamReader(socket.getInputStream(),""ASCII"");
  try {
    BufferedReader in=new BufferedReader(isr);
    try {
      OutputStream out=socket.getOutputStream();
      try {
        long startTime=System.currentTimeMillis();
        byte[] tmp=(""POST "" + deleteURL.getFile() + "" HTTP/1.0\r\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        tmp=(""Document-URI: "" + documentURI + ""\r\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        writeCredentials(out);
        tmp=(""Content-length: 0\r\n\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Delete posted"");
        out.flush();
        String res;
        try {
          res=getResponse(in);
        }
 catch (        ServiceInterruption si) {
          activityStart=new Long(startTime);
          activityCode=""-2"";
          activityDetails=si.getMessage();
          throw si;
        }
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Response code from delete: '"" + res + ""'"");
        CodeDetails cd=new CodeDetails(res);
        activityStart=new Long(startTime);
        activityCode=cd.getCode();
        activityDetails=cd.getDetails();
        int codeValue=cd.getCodeValue();
        if (codeValue < 0)         throw new ManifoldCFException(""Http protocol error"");
        if (codeValue == 200)         return;
        if (codeValue == 401)         throw new ManifoldCFException(""Bad credentials for ingestion"",ManifoldCFException.SETUP_ERROR);
        if (codeValue >= 400 && codeValue < 500)         return;
        throw new ManifoldCFException(""Error deleting document: '"" + res + ""'"");
      }
  finally {
        out.close();
      }
    }
  finally {
      in.close();
    }
  }
  finally {
    isr.close();
  }
}
  finally {
  try {
    socket.close();
  }
 catch (  InterruptedIOException e) {
    throw e;
  }
catch (  IOException e) {
    Logging.ingest.debug(""Error closing socket: "" + e.getMessage(),e);
  }
}
",0,0,0,,
445,finally,"try {
  InputStreamReader isr=new InputStreamReader(socket.getInputStream(),""ASCII"");
  try {
    BufferedReader in=new BufferedReader(isr);
    try {
      OutputStream out=socket.getOutputStream();
      try {
        byte[] tmp=(""GET "" + infoURL.getFile() + "" HTTP/1.0\r\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        writeCredentials(out);
        tmp=(""Content-length: 0\r\n\n"").getBytes(StandardCharsets.UTF_8);
        out.write(tmp,0,tmp.length);
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Status request posted"");
        out.flush();
        String res=getResponse(in);
        if (Logging.ingest.isDebugEnabled())         Logging.ingest.debug(""Response code from delete: '"" + res + ""'"");
        CodeDetails cd=new CodeDetails(res);
        int codeValue=cd.getCodeValue();
        if (codeValue < 0)         throw new ManifoldCFException(""Http protocol error"");
        if (codeValue == 200)         return;
        if (codeValue == 401)         throw new ManifoldCFException(""Bad credentials for ingestion"",ManifoldCFException.SETUP_ERROR);
        throw new ManifoldCFException(""Error connecting to MetaCarta ingestion API: '"" + res + ""'"");
      }
  finally {
        out.close();
      }
    }
  finally {
      in.close();
    }
  }
  finally {
    isr.close();
  }
}
  finally {
  try {
    socket.close();
  }
 catch (  InterruptedIOException e) {
    throw e;
  }
catch (  IOException e) {
    Logging.ingest.debug(""Error closing socket: "" + e.getMessage(),e);
  }
}
",0,0,0,,
446,finally,"try {
  int statusCode=methodThread.getResponseCode();
switch (statusCode) {
case 500:
case 502:
    Logging.connectors.warn(""Livelink: Service interruption during fetch "" + contextMsg + "" with Livelink HTTP Server, retrying..."");
  resultCode=""FETCHFAILED"";
resultDescription=""HTTP error code "" + statusCode + "" fetching document"";
throw new ServiceInterruption(""Service interruption during fetch"",new ManifoldCFException(Integer.toString(statusCode) + "" error while fetching""),System.currentTimeMillis() + 60000L,System.currentTimeMillis() + 600000L,-1,true);
case HttpStatus.SC_UNAUTHORIZED:
Logging.connectors.warn(""Livelink: Document fetch unauthorized for "" + ingestHttpAddress + "" (""+ contextMsg+ "")"");
resultCode=""UNAUTHORIZED"";
resultDescription=""Document fetch was unauthorized by IIS"";
activities.noDocument(documentIdentifier,version);
return;
case HttpStatus.SC_OK:
if (Logging.connectors.isDebugEnabled()) Logging.connectors.debug(""Livelink: Created http document connection to Livelink "" + contextMsg);
if (methodThread.getResponseContentLength() < 0) {
resultCode=""SESSIONLOGINFAILED"";
resultDescription=""Response content length was -1, which usually means session login did not succeed"";
activities.noDocument(documentIdentifier,version);
return;
}
try {
InputStream is=methodThread.getSafeInputStream();
try {
rd.setBinary(is,dataSize);
activities.ingestDocumentWithException(documentIdentifier,version,viewHttpAddress,rd);
resultCode=""OK"";
readSize=dataSize;
if (Logging.connectors.isDebugEnabled()) Logging.connectors.debug(""Livelink: Ingesting done "" + contextMsg);
}
  finally {
is.close();
}
}
 catch (InterruptedException e) {
wasInterrupted=true;
throw new ManifoldCFException(""Interrupted: "" + e.getMessage(),e,ManifoldCFException.INTERRUPTED);
}
catch (HttpException e) {
resultCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
resultDescription=e.getMessage();
handleHttpException(contextMsg,e);
}
catch (IOException e) {
resultCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
resultDescription=e.getMessage();
handleIOException(contextMsg,e);
}
break;
case HttpStatus.SC_BAD_REQUEST:
case HttpStatus.SC_USE_PROXY:
case HttpStatus.SC_GONE:
resultCode=""HTTPERROR"";
resultDescription=""Http request returned status "" + Integer.toString(statusCode);
throw new ManifoldCFException(""Unrecoverable request failure; error = "" + Integer.toString(statusCode));
default :
resultCode=""UNKNOWNHTTPCODE"";
resultDescription=""Http request returned status "" + Integer.toString(statusCode);
Logging.connectors.warn(""Livelink: Attempt to retrieve document from '"" + ingestHttpAddress + ""' received a response of ""+ Integer.toString(statusCode)+ ""; retrying in one minute"");
currentTime=System.currentTimeMillis();
throw new ServiceInterruption(""Fetch failed; retrying in 1 minute"",new ManifoldCFException(""Fetch failed with unknown code "" + Integer.toString(statusCode)),currentTime + 60000L,currentTime + 600000L,-1,true);
}
}
 catch (InterruptedException e) {
methodThread.interrupt();
methodThread=null;
throw new ManifoldCFException(""Interrupted: "" + e.getMessage(),e,ManifoldCFException.INTERRUPTED);
}
catch (HttpException e) {
resultCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
resultDescription=e.getMessage();
handleHttpException(contextMsg,e);
}
catch (IOException e) {
resultCode=e.getClass().getSimpleName().toUpperCase(Locale.ROOT);
resultDescription=e.getMessage();
handleIOException(contextMsg,e);
}
 finally {
if (methodThread != null) {
methodThread.abort();
try {
if (!wasInterrupted) methodThread.finishUp();
}
 catch (InterruptedException e) {
throw new ManifoldCFException(e.getMessage(),e,ManifoldCFException.INTERRUPTED);
}
}
}
",0,0,0,,
447,finally,"try {
  mgr.importCertificate(alias,is);
}
 catch (Throwable e) {
  certError=e.getMessage();
}
 finally {
  try {
    is.close();
  }
 catch (  IOException e) {
    throw new ManifoldCFException(e.getMessage(),e);
  }
}
",0,0,0,,
448,finally,"try {
  RepositoryDocument data=new RepositoryDocument();
  data.setBinary(is,documentLength);
  data.setFileName(mapToFileName(documentIdentifier));
  if (contentType != null)   data.setMimeType(contentType);
  setDataACLs(data,accessTokens,denyTokens);
  setPathAttribute(data,sDesc,documentIdentifier);
  if (modifiedDate != null)   data.setModifiedDate(modifiedDate);
  if (createdDate != null)   data.setCreatedDate(createdDate);
  if (metadataValues != null) {
    Iterator<String> iter=metadataValues.keySet().iterator();
    while (iter.hasNext()) {
      String fieldName=iter.next();
      String fieldData=metadataValues.get(fieldName);
      data.addField(fieldName,fieldData);
    }
  }
  data.addField(""GUID"",guid);
  try {
    activities.ingestDocumentWithException(documentIdentifier,version,fileUrl,data);
    errorCode=""OK"";
    fileLengthLong=new Long(documentLength);
  }
 catch (  IOException e) {
    handleIOException(e,""reading document"");
  }
  return;
}
  finally {
  try {
    is.close();
  }
 catch (  java.net.SocketTimeoutException e) {
    Logging.connectors.debug(""SharePoint: Timeout before read could finish for '"" + fileUrl + ""': ""+ e.getMessage(),e);
  }
catch (  org.apache.http.conn.ConnectTimeoutException e) {
    Logging.connectors.debug(""SharePoint: Connect timeout before read could finish for '"" + fileUrl + ""': ""+ e.getMessage(),e);
  }
catch (  InterruptedIOException e) {
    throw new ManifoldCFException(""Interrupted: "" + e.getMessage(),e,ManifoldCFException.INTERRUPTED);
  }
catch (  IOException e) {
    Logging.connectors.debug(""SharePoint: Server closed connection before read could finish for '"" + fileUrl + ""': ""+ e.getMessage(),e);
  }
}
",0,0,0,,
449,finally,"try {
  File tempFile=File.createTempFile(""_webcache_"",""tmp"");
  try {
    ManifoldCF.addFile(tempFile);
    long checkSum=0L;
    OutputStream os=new FileOutputStream(tempFile);
    try {
      byte[] byteArray=new byte[65536];
      while (true) {
        int amt;
        try {
          amt=dataStream.read(byteArray,0,byteArray.length);
        }
 catch (        java.net.SocketTimeoutException e) {
          Logging.connectors.warn(""Socket timeout exception reading socket stream: "" + e.getMessage(),e);
          long currentTime=System.currentTimeMillis();
          throw new ServiceInterruption(""Socket timeout: "" + e.getMessage(),e,currentTime + 300000L,currentTime + 12 * 60 * 60000L,-1,false);
        }
catch (        ConnectTimeoutException e) {
          Logging.connectors.warn(""Socket connect timeout exception reading socket stream: "" + e.getMessage(),e);
          long currentTime=System.currentTimeMillis();
          throw new ServiceInterruption(""Socket timeout: "" + e.getMessage(),e,currentTime + 300000L,currentTime + 12 * 60 * 60000L,-1,false);
        }
catch (        InterruptedIOException e) {
          throw new ManifoldCFException(""Interrupted: "" + e.getMessage(),ManifoldCFException.INTERRUPTED);
        }
catch (        IOException e) {
          Logging.connectors.warn(""IO exception reading socket stream: "" + e.getMessage(),e);
          long currentTime=System.currentTimeMillis();
          throw new ServiceInterruption(""Read timeout: "" + e.getMessage(),e,currentTime + 300000L,currentTime + 12 * 60 * 60000L,-1,false);
        }
        if (amt == -1)         break;
        int i=0;
        while (i < amt) {
          byte x=byteArray[i++];
          long bytevalue=(long)x;
          checkSum=(checkSum << 5) ^ (checkSum >> 3) ^ (bytevalue << 2)^ (bytevalue >> 3);
        }
        os.write(byteArray,0,amt);
        activities.checkJobStillActive();
      }
    }
  finally {
      os.close();
    }
synchronized (this) {
      deleteData(documentIdentifier);
      cacheData.put(documentIdentifier,new DocumentData(tempFile,responseCode,contentType,referralURI));
      return new Long(checkSum).toString();
    }
  }
 catch (  IOException e) {
    ManifoldCF.deleteFile(tempFile);
    throw e;
  }
catch (  ManifoldCFException e) {
    ManifoldCF.deleteFile(tempFile);
    throw e;
  }
catch (  ServiceInterruption e) {
    ManifoldCF.deleteFile(tempFile);
    throw e;
  }
catch (  Error e) {
    ManifoldCF.deleteFile(tempFile);
    throw e;
  }
}
  finally {
  try {
    dataStream.close();
  }
 catch (  java.net.SocketTimeoutException e) {
    Logging.connectors.warn(""WEB: Socket timeout exception closing data stream, ignoring: "" + e.getMessage(),e);
  }
catch (  ConnectTimeoutException e) {
    Logging.connectors.warn(""WEB: Socket connect timeout exception closing data stream, ignoring: "" + e.getMessage(),e);
  }
catch (  InterruptedIOException e) {
    throw e;
  }
catch (  IOException e) {
    Logging.connectors.warn(""WEB: IO exception closing data stream, ignoring: "" + e.getMessage(),e);
  }
}
",0,0,0,,
450,finally,"try {
  if (xThreadInputStream != null) {
    xThreadInputStream.close();
    xThreadInputStream=null;
  }
}
  finally {
  if (methodThread != null) {
    methodThread.abort();
    try {
      methodThread.finishUp();
    }
 catch (    InterruptedException e) {
      throw new InterruptedIOException(e.getMessage());
    }
    methodThread=null;
  }
}
",0,0,0,,
451,finally,"try {
  Set<OutputAndRepositoryConnection> connectionNames=new HashSet<OutputAndRepositoryConnection>();
  for (  JobNotifyRecord jsr : jobsNeedingNotification) {
    Long jobID=jsr.getJobID();
    IJobDescription job=jobManager.load(jobID,true);
    if (job != null) {
      String repositoryConnectionName=job.getConnectionName();
      IPipelineSpecificationBasic basicSpec=new PipelineSpecificationBasic(job);
      for (int i=0; i < basicSpec.getOutputCount(); i++) {
        String outputConnectionName=basicSpec.getStageConnectionName(basicSpec.getOutputStage(i));
        OutputAndRepositoryConnection c=new OutputAndRepositoryConnection(outputConnectionName,repositoryConnectionName);
        connectionNames.add(c);
      }
    }
  }
  Map<OutputAndRepositoryConnection,Disposition> notifiedConnections=new HashMap<OutputAndRepositoryConnection,Disposition>();
  for (  OutputAndRepositoryConnection connections : connectionNames) {
    String outputConnectionName=connections.getOutputConnectionName();
    String repositoryConnectionName=connections.getRepositoryConnectionName();
    OutputNotifyActivity activity=new OutputNotifyActivity(repositoryConnectionName,repositoryConnectionManager,outputConnectionName);
    IOutputConnection connection=connectionManager.load(outputConnectionName);
    if (connection != null) {
      IOutputConnector connector=outputConnectorPool.grab(connection);
      if (connector != null) {
        try {
          try {
            connector.noteJobComplete(activity);
            notifiedConnections.put(connections,new Disposition());
          }
 catch (          ServiceInterruption e) {
            notifiedConnections.put(connections,new Disposition(e));
          }
catch (          ManifoldCFException e) {
            if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)             throw e;
            if (e.getErrorCode() == ManifoldCFException.DATABASE_CONNECTION_ERROR)             throw e;
            if (e.getErrorCode() == ManifoldCFException.SETUP_ERROR)             throw e;
            Logging.threads.error(e.getMessage(),e);
          }
        }
  finally {
          outputConnectorPool.release(connection,connector);
        }
      }
    }
  }
  for (  JobNotifyRecord jsr : jobsNeedingNotification) {
    Long jobID=jsr.getJobID();
    IJobDescription job=jobManager.load(jobID,true);
    if (job != null) {
      String repositoryConnectionName=job.getConnectionName();
      IPipelineSpecificationBasic basicSpec=new PipelineSpecificationBasic(job);
      boolean allOK=true;
      for (int i=0; i < basicSpec.getOutputCount(); i++) {
        String outputConnectionName=basicSpec.getStageConnectionName(basicSpec.getOutputStage(i));
        OutputAndRepositoryConnection c=new OutputAndRepositoryConnection(outputConnectionName,repositoryConnectionName);
        Disposition d=notifiedConnections.get(c);
        if (d != null) {
          ServiceInterruption e=d.getServiceInterruption();
          if (e == null) {
            break;
          }
 else {
            if (!e.jobInactiveAbort()) {
              Logging.jobs.warn(""Notification service interruption reported for job "" + jobID + "" output connection '""+ outputConnectionName+ ""': ""+ e.getMessage(),e);
            }
            if (!e.jobInactiveAbort() && (jsr.getFailTime() != -1L && jsr.getFailTime() < e.getRetryTime() || jsr.getFailRetryCount() == 0)) {
              if (e.isAbortOnFail()) {
                String message=e.jobInactiveAbort() ? """" : ""Repeated service interruptions during notification"" + ((e.getCause() != null) ? "": "" + e.getCause().getMessage() : """");
                if (jobManager.errorAbort(jobID,message) && message.length() > 0)                 Logging.jobs.error(message,e.getCause());
                jsr.noteStarted();
              }
 else {
                jobManager.inactivateJob(jobID);
                jsr.noteStarted();
              }
            }
 else {
              jobManager.retryNotification(jsr,e.getFailTime(),e.getFailRetryCount());
              jsr.noteStarted();
            }
            allOK=false;
            break;
          }
        }
      }
      if (allOK) {
        jobManager.inactivateJob(jobID);
        jsr.noteStarted();
      }
    }
  }
}
  finally {
  ManifoldCFException exception=null;
  int i=0;
  while (i < jobsNeedingNotification.length) {
    JobNotifyRecord jsr=jobsNeedingNotification[i++];
    if (!jsr.wasStarted()) {
      try {
        jobManager.resetNotifyJob(jsr.getJobID());
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         throw e;
        exception=e;
      }
    }
  }
  if (exception != null)   throw exception;
}
",0,0,0,,
452,finally,"try {
  Set<OutputAndRepositoryConnection> connectionNames=new HashSet<OutputAndRepositoryConnection>();
  for (  JobNotifyRecord jsr : jobsNeedingDeleteNotification) {
    Long jobID=jsr.getJobID();
    IJobDescription job=jobManager.load(jobID,true);
    if (job != null) {
      String repositoryConnectionName=job.getConnectionName();
      IPipelineSpecificationBasic basicSpec=new PipelineSpecificationBasic(job);
      for (int i=0; i < basicSpec.getOutputCount(); i++) {
        String outputConnectionName=basicSpec.getStageConnectionName(basicSpec.getOutputStage(i));
        OutputAndRepositoryConnection c=new OutputAndRepositoryConnection(outputConnectionName,repositoryConnectionName);
        connectionNames.add(c);
      }
    }
  }
  Map<OutputAndRepositoryConnection,Disposition> notifiedConnections=new HashMap<OutputAndRepositoryConnection,Disposition>();
  for (  OutputAndRepositoryConnection connections : connectionNames) {
    String outputConnectionName=connections.getOutputConnectionName();
    String repositoryConnectionName=connections.getRepositoryConnectionName();
    OutputNotifyActivity activity=new OutputNotifyActivity(repositoryConnectionName,repositoryConnectionManager,outputConnectionName);
    IOutputConnection connection=connectionManager.load(outputConnectionName);
    if (connection != null) {
      IOutputConnector connector=outputConnectorPool.grab(connection);
      if (connector != null) {
        try {
          try {
            connector.noteJobComplete(activity);
            notifiedConnections.put(connections,new Disposition());
          }
 catch (          ServiceInterruption e) {
            notifiedConnections.put(connections,new Disposition(e));
          }
catch (          ManifoldCFException e) {
            if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)             throw e;
            if (e.getErrorCode() == ManifoldCFException.DATABASE_CONNECTION_ERROR)             throw e;
            if (e.getErrorCode() == ManifoldCFException.SETUP_ERROR)             throw e;
            Logging.threads.error(e.getMessage(),e);
          }
        }
  finally {
          outputConnectorPool.release(connection,connector);
        }
      }
    }
  }
  for (  JobNotifyRecord jsr : jobsNeedingDeleteNotification) {
    Long jobID=jsr.getJobID();
    IJobDescription job=jobManager.load(jobID,true);
    if (job != null) {
      String repositoryConnectionName=job.getConnectionName();
      IPipelineSpecificationBasic basicSpec=new PipelineSpecificationBasic(job);
      boolean allOK=true;
      for (int i=0; i < basicSpec.getOutputCount(); i++) {
        String outputConnectionName=basicSpec.getStageConnectionName(basicSpec.getOutputStage(i));
        OutputAndRepositoryConnection c=new OutputAndRepositoryConnection(outputConnectionName,repositoryConnectionName);
        Disposition d=notifiedConnections.get(c);
        if (d != null) {
          ServiceInterruption e=d.getServiceInterruption();
          if (e == null) {
            break;
          }
 else {
            if (!e.jobInactiveAbort()) {
              Logging.jobs.warn(""Delete notification service interruption reported for job "" + jobID + "" output connection '""+ outputConnectionName+ ""': ""+ e.getMessage(),e);
            }
            if (!e.jobInactiveAbort() && (jsr.getFailTime() != -1L && jsr.getFailTime() < e.getRetryTime() || jsr.getFailRetryCount() == 0)) {
              if (e.isAbortOnFail()) {
                String message=e.jobInactiveAbort() ? """" : ""Repeated service interruptions during delete notification"" + ((e.getCause() != null) ? "": "" + e.getCause().getMessage() : """");
                if (message.length() > 0)                 Logging.jobs.error(message,e.getCause());
                jobManager.removeJob(jobID);
                jsr.noteStarted();
              }
 else {
                jobManager.removeJob(jobID);
                jsr.noteStarted();
              }
            }
 else {
              jobManager.retryDeleteNotification(jsr,e.getFailTime(),e.getFailRetryCount());
              jsr.noteStarted();
            }
            allOK=false;
            break;
          }
        }
      }
      if (allOK) {
        jobManager.removeJob(jobID);
        jsr.noteStarted();
      }
    }
  }
}
  finally {
  ManifoldCFException exception=null;
  int i=0;
  while (i < jobsNeedingDeleteNotification.length) {
    JobNotifyRecord jsr=jobsNeedingDeleteNotification[i++];
    if (!jsr.wasStarted()) {
      try {
        jobManager.resetDeleteNotifyJob(jsr.getJobID());
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         throw e;
        exception=e;
      }
    }
  }
  if (exception != null)   throw exception;
}
",0,0,0,,
453,finally,"try {
  if (seedJobs.length == 0) {
    Logging.threads.debug(""Seeding thread found nothing to do"");
    ManifoldCF.sleep(waitTime);
    continue;
  }
  if (Logging.threads.isDebugEnabled())   Logging.threads.debug(""Seeding thread: Found "" + Integer.toString(seedJobs.length) + "" jobs to seed"");
  int i=0;
  while (i < seedJobs.length) {
    JobSeedingRecord jsr=seedJobs[i++];
    Long jobID=jsr.getJobID();
    try {
      String lastSeedingVersion=jsr.getSeedingVersionString();
      IJobDescription jobDescription=jobManager.load(jobID,true);
      int jobType=jobDescription.getType();
      int hopcountMethod=jobDescription.getHopcountMode();
      IRepositoryConnection connection=connectionMgr.load(jobDescription.getConnectionName());
      IRepositoryConnector connector=repositoryConnectorPool.grab(connection);
      if (connector == null)       continue;
      String newSeedingVersion=null;
      try {
        String[] legalLinkTypes=connector.getRelationshipTypes();
        int model=connector.getConnectorModel();
        try {
          SeedingActivity activity=new SeedingActivity(connection.getName(),connectionMgr,jobManager,rt,connection,connector,jobID,legalLinkTypes,false,hopcountMethod,processID);
          if (Logging.threads.isDebugEnabled())           Logging.threads.debug(""Seeding thread: Getting seeds for job "" + jobID.toString());
          newSeedingVersion=connector.addSeedDocuments(activity,jobDescription.getSpecification(),lastSeedingVersion,currentTime,jobType);
          activity.doneSeeding(model == connector.MODEL_PARTIAL);
          if (Logging.threads.isDebugEnabled())           Logging.threads.debug(""Seeding thread: Done processing seeds from job "" + jobID.toString());
        }
 catch (        ServiceInterruption e) {
          if (!e.jobInactiveAbort()) {
            Logging.jobs.warn(""Seeding service interruption reported for job "" + jobID + "" connection '""+ connection.getName()+ ""': ""+ e.getMessage(),e);
          }
          if (!e.jobInactiveAbort() && (jsr.getFailTime() != -1L && jsr.getFailTime() < e.getRetryTime() || jsr.getFailRetryCount() == 0)) {
            if (e.isAbortOnFail()) {
              String message=e.jobInactiveAbort() ? """" : ""Repeated service interruptions during seeding"" + ((e.getCause() != null) ? "": "" + e.getCause().getMessage() : """");
              if (jobManager.errorAbort(jobID,message) && message.length() > 0)               Logging.jobs.error(message,e.getCause());
              jsr.noteStarted();
            }
 else {
              jobManager.noteJobSeeded(jobID,newSeedingVersion);
              jsr.noteStarted();
            }
          }
 else {
            jobManager.retrySeeding(jsr,e.getFailTime(),e.getFailRetryCount());
            jsr.noteStarted();
          }
          continue;
        }
      }
  finally {
        repositoryConnectorPool.release(connection,connector);
      }
      if (Logging.threads.isDebugEnabled())       Logging.threads.debug(""Seeding thread: Successfully reseeded job "" + jobID.toString());
      jobManager.noteJobSeeded(jobID,newSeedingVersion);
      jsr.noteStarted();
    }
 catch (    ManifoldCFException e) {
      if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)       throw new InterruptedException();
      if (e.getErrorCode() == ManifoldCFException.DATABASE_CONNECTION_ERROR)       throw e;
      if (jobManager.errorAbort(jobID,e.getMessage()))       Logging.threads.error(""Exception tossed: "" + e.getMessage(),e);
      jsr.noteStarted();
    }
  }
}
  finally {
  ManifoldCFException exception=null;
  int i=0;
  while (i < seedJobs.length) {
    JobSeedingRecord jsr=seedJobs[i++];
    if (!jsr.wasStarted()) {
      if (Logging.threads.isDebugEnabled())       Logging.threads.debug(""Seeding thread: aborting reseed for "" + jsr.getJobID().toString());
      try {
        jobManager.resetSeedJob(jsr.getJobID());
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         throw e;
        exception=e;
      }
    }
  }
  if (exception != null)   throw exception;
}
",0,0,0,,
454,finally,"try {
  if (deleteJobs.length == 0) {
    ManifoldCF.sleep(waitTime);
    continue;
  }
  if (Logging.threads.isDebugEnabled())   Logging.threads.debug(""Found "" + Integer.toString(deleteJobs.length) + "" jobs ready to be deleted"");
  long currentTime=System.currentTimeMillis();
  int i=0;
  while (i < deleteJobs.length) {
    JobDeleteRecord jsr=deleteJobs[i++];
    Long jobID=jsr.getJobID();
    try {
      jobManager.prepareDeleteScan(jobID);
      jobManager.noteJobDeleteStarted(jobID,currentTime);
      jsr.noteStarted();
    }
 catch (    ManifoldCFException e) {
      if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)       throw new InterruptedException();
      if (e.getErrorCode() == ManifoldCFException.DATABASE_CONNECTION_ERROR)       throw e;
      Logging.threads.error(""Exception tossed: "" + e.getMessage(),e);
    }
  }
}
  finally {
  ManifoldCFException exception=null;
  int i=0;
  while (i < deleteJobs.length) {
    JobDeleteRecord jsr=deleteJobs[i++];
    if (!jsr.wasStarted()) {
      try {
        jobManager.resetStartDeleteJob(jsr.getJobID());
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         throw e;
        exception=e;
      }
    }
  }
  if (exception != null)   throw exception;
}
",0,0,0,,
455,finally,"try {
  if (startupJobs.length == 0) {
    ManifoldCF.sleep(waitTime);
    continue;
  }
  if (Logging.threads.isDebugEnabled())   Logging.threads.debug(""Found "" + Integer.toString(startupJobs.length) + "" jobs ready to be started"");
  long currentTime=System.currentTimeMillis();
  for (int i=0; i < startupJobs.length; i++) {
    JobStartRecord jsr=startupJobs[i];
    Long jobID=jsr.getJobID();
    try {
      String lastSeedingVersion=jsr.getSeedingVersionString();
      IJobDescription jobDescription=jobManager.load(jobID,true);
      int jobType=jobDescription.getType();
      int hopcountMethod=jobDescription.getHopcountMode();
      IRepositoryConnection connection=connectionMgr.load(jobDescription.getConnectionName());
      IRepositoryConnector connector=repositoryConnectorPool.grab(connection);
      if (connector == null)       continue;
      String newSeedingVersion=null;
      try {
        connectionMgr.recordHistory(jobDescription.getConnectionName(),null,connectionMgr.ACTIVITY_JOBSTART,null,jobID.toString() + ""("" + jobDescription.getDescription()+ "")"",null,null,null);
        int model=connector.getConnectorModel();
        String[] legalLinkTypes=connector.getRelationshipTypes();
        boolean requestMinimum=jsr.getRequestMinimum();
        if (Logging.threads.isDebugEnabled())         Logging.threads.debug(""Preparing job "" + jobID.toString() + "" for execution..."");
        jobManager.prepareJobScan(jobID,legalLinkTypes,hopcountMethod,model,jobType == IJobDescription.TYPE_CONTINUOUS,lastSeedingVersion == null,requestMinimum);
        if (Logging.threads.isDebugEnabled())         Logging.threads.debug(""Prepared job "" + jobID.toString() + "" for execution."");
        try {
          SeedingActivity activity=new SeedingActivity(connection.getName(),connectionMgr,jobManager,rt,connection,connector,jobID,legalLinkTypes,true,hopcountMethod,processID);
          if (Logging.threads.isDebugEnabled())           Logging.threads.debug(""Adding initial seed documents for job "" + jobID.toString() + ""..."");
          newSeedingVersion=connector.addSeedDocuments(activity,jobDescription.getSpecification(),lastSeedingVersion,currentTime,jobType);
          activity.doneSeeding(model == connector.MODEL_PARTIAL);
          if (Logging.threads.isDebugEnabled())           Logging.threads.debug(""Done adding initial seed documents for job "" + jobID.toString() + ""."");
        }
 catch (        ServiceInterruption e) {
          if (!e.jobInactiveAbort()) {
            Logging.jobs.warn(""Startup service interruption reported for job "" + jobID + "" connection '""+ connection.getName()+ ""': ""+ e.getMessage(),e);
          }
          if (!e.jobInactiveAbort() && (jsr.getFailTime() != -1L && jsr.getFailTime() < e.getRetryTime() || jsr.getFailRetryCount() == 0)) {
            if (e.isAbortOnFail()) {
              String message=e.jobInactiveAbort() ? """" : ""Repeated service interruptions during startup"" + ((e.getCause() != null) ? "": "" + e.getCause().getMessage() : """");
              if (jobManager.errorAbort(jobID,message) && message.length() > 0)               Logging.jobs.error(message,e.getCause());
              jsr.noteStarted();
            }
 else {
              jobManager.noteJobStarted(jobID,currentTime,newSeedingVersion);
              jsr.noteStarted();
            }
          }
 else {
            jobManager.retryStartup(jsr,e.getFailTime(),e.getFailRetryCount());
            jsr.noteStarted();
          }
          continue;
        }
      }
  finally {
        repositoryConnectorPool.release(connection,connector);
      }
      jobManager.noteJobStarted(jobID,currentTime,newSeedingVersion);
      jsr.noteStarted();
    }
 catch (    ManifoldCFException e) {
      if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)       throw new InterruptedException();
      if (e.getErrorCode() == ManifoldCFException.DATABASE_CONNECTION_ERROR)       throw e;
      if (jobManager.errorAbort(jobID,e.getMessage()))       Logging.threads.error(""Exception tossed: "" + e.getMessage(),e);
      jsr.noteStarted();
    }
  }
}
  finally {
  ManifoldCFException exception=null;
  int i=0;
  while (i < startupJobs.length) {
    JobStartRecord jsr=startupJobs[i++];
    if (!jsr.wasStarted()) {
      try {
        jobManager.resetStartupJob(jsr.getJobID());
      }
 catch (      ManifoldCFException e) {
        if (e.getErrorCode() == ManifoldCFException.INTERRUPTED)         throw e;
        exception=e;
      }
    }
  }
  if (exception != null)   throw exception;
}
",0,0,0,,
456,finally,"try {
  dispose();
}
  finally {
  throw e;
}
",0,0,0,,
457,finally,"try {
  doWrite(project,outputFile,w);
}
  finally {
  try {
    w.close();
  }
 catch (  IOException e) {
    throw new MojoExecutionException(""Error when closing the writer."",e);
  }
}
",0,0,0,,
458,finally,"try {
  doFinish(containerName,fileName,monitor);
}
 catch (CoreException e) {
  throw new InvocationTargetException(e);
}
 finally {
  try {
    IFile file=getFile(containerName,fileName);
    file.delete(true,new NullProgressMonitor());
  }
 catch (  CoreException e) {
    throw new InvocationTargetException(e);
  }
  monitor.done();
}
",0,0,0,,
459,finally,"try {
  doWrite(project,outputFile,w);
}
  finally {
  try {
    w.close();
  }
 catch (  IOException e) {
    throw new MojoExecutionException(""Error when closing the writer."",e);
  }
}
",0,0,0,,
460,finally,"try {
  baseDir=File.createTempFile(""scm"",""tmp"");
  baseDir.delete();
  baseDir.mkdirs();
  ScmFileSet scmFileSet=new ScmFileSet(baseDir,new File(""""));
  CommandParameters commandParameters=new CommandParameters();
  commandParameters.setString(CommandParameter.SCM_MKDIR_CREATE_IN_LOCAL,Boolean.FALSE.toString());
  commandParameters.setString(CommandParameter.MESSAGE,""Automatic svn path creation: "" + remoteUrl);
  svnScmProvider.mkdir(scmRepository.getProviderRepository(),scmFileSet,commandParameters);
  if (checkoutDirectory.exists()) {
    FileUtils.deleteDirectory(checkoutDirectory);
  }
}
 catch (IOException e) {
  throw new MojoExecutionException(e.getMessage(),e);
}
catch (ScmException e) {
  throw new MojoExecutionException(e.getMessage(),e);
}
 finally {
  if (baseDir != null) {
    try {
      FileUtils.forceDeleteOnExit(baseDir);
    }
 catch (    IOException e) {
      throw new MojoExecutionException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
461,finally,"try {
  dispose();
}
  finally {
  throw e;
}
",0,0,0,,
462,finally,"try {
  baseDir=Files.createTempDirectory(""scm"").toFile();
  ScmFileSet scmFileSet=new ScmFileSet(baseDir,new File(""""));
  CommandParameters commandParameters=new CommandParameters();
  commandParameters.setString(CommandParameter.SCM_MKDIR_CREATE_IN_LOCAL,Boolean.FALSE.toString());
  commandParameters.setString(CommandParameter.MESSAGE,""Automatic svn path creation: "" + remoteUrl);
  svnScmProvider.mkdir(scmRepository.getProviderRepository(),scmFileSet,commandParameters);
  if (checkoutDirectory.exists()) {
    FileUtils.deleteDirectory(checkoutDirectory);
  }
}
 catch (IOException e) {
  throw new MojoExecutionException(e.getMessage(),e);
}
catch (ScmException e) {
  throw new MojoExecutionException(e.getMessage(),e);
}
 finally {
  if (baseDir != null) {
    try {
      FileUtils.forceDeleteOnExit(baseDir);
    }
 catch (    IOException e) {
      throw new MojoExecutionException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
463,finally,"try {
  boolean signed=false;
  in=new ZipInputStream(new BufferedInputStream(new FileInputStream(jarFile)));
  for (ZipEntry ze=in.getNextEntry(); ze != null; ze=in.getNextEntry()) {
    if (isSignatureFile(ze.getName())) {
      signed=true;
      break;
    }
  }
  suppressExceptionOnClose=false;
  return signed;
}
  finally {
  try {
    if (in != null) {
      in.close();
    }
  }
 catch (  IOException e) {
    if (!suppressExceptionOnClose) {
      throw e;
    }
  }
}
",0,0,0,,
464,finally,"try (CommandlineExecutor exec=new CommandlineExecutor(cli,countdownCloseable)){
  forkChannel.tryConnectToClient();
  CommandlineStreams streams=exec.execute();
  closer.addCloseable(streams);
  err=bindErrorStream(forkNumber,countdownCloseable,streams);
  forkChannel.bindCommandReader(commandReader,streams.getStdInChannel());
  forkChannel.bindEventHandler(eventConsumer,countdownCloseable,streams.getStdOutChannel());
  log.debug(""Fork Channel ["" + forkNumber + ""] connected to the client."");
  result=exec.awaitExit();
  if (forkClient.hadTimeout()) {
    runResult=timeout(reporter.getGlobalRunStatistics().getRunResult());
  }
 else   if (result != SUCCESS) {
    booterForkException=new SurefireBooterForkException(""Error occurred in starting fork, check output in log"");
  }
}
 catch (InterruptedException e) {
  log.error(""Closing the streams after (InterruptedException) '"" + e.getLocalizedMessage() + ""'"");
  forkChannel.disable();
  err.disable();
}
catch (Exception e) {
  runResult=failure(reporter.getGlobalRunStatistics().getRunResult(),e);
  String cliErr=e.getLocalizedMessage();
  Throwable cause=e.getCause();
  booterForkException=new SurefireBooterForkException(""Error while executing forked tests."",cliErr,cause,runResult);
}
 finally {
  log.debug(""Closing the fork "" + forkNumber + "" after ""+ (forkClient.isSaidGoodBye() ? ""saying GoodBye."" : ""not saying Good Bye.""));
  currentForkClients.remove(forkClient);
  try {
    Closeable c=forkClient.isSaidGoodBye() ? closer : commandReader;
    c.close();
  }
 catch (  IOException e) {
    InPluginProcessDumpSingleton.getSingleton().dumpException(e,e.getLocalizedMessage(),dumpLogDir,forkNumber);
  }
  if (runResult == null) {
    runResult=reporter.getGlobalRunStatistics().getRunResult();
  }
  forkClient.close(runResult.isTimeout());
  if (!runResult.isTimeout()) {
    Throwable cause=booterForkException == null ? null : booterForkException.getCause();
    String detail=booterForkException == null ? """" : ""\n"" + booterForkException.getMessage();
    if (forkClient.isErrorInFork()) {
      StackTraceWriter errorInFork=forkClient.getErrorInFork();
      String errorInForkMessage=errorInFork == null ? null : errorInFork.getThrowable().getLocalizedMessage();
      boolean showStackTrace=providerConfiguration.getMainCliOptions().contains(SHOW_ERRORS);
      String stackTrace=errorInForkMessage;
      if (showStackTrace) {
        if (errorInFork != null) {
          if (stackTrace == null) {
            stackTrace="""";
          }
 else {
            stackTrace+=NL;
          }
          stackTrace+=errorInFork.writeTrimmedTraceToString();
        }
      }
      throw new SurefireBooterForkException(""There was an error in the forked process"" + detail + (stackTrace == null ? """" : ""\n"" + stackTrace),cause);
    }
    if (!forkClient.isSaidGoodBye()) {
      String errorCode=result == null ? """" : ""\nProcess Exit Code: "" + result;
      String testsInProgress=forkClient.hasTestsInProgress() ? ""\nCrashed tests:"" : """";
      for (      String test : forkClient.testsInProgress()) {
        testsInProgress+=""\n"" + test;
      }
      throw new SurefireBooterForkException(""The forked VM terminated without properly saying goodbye. VM crash or System.exit called?"" + ""\nCommand was "" + cli.toString() + detail+ errorCode+ testsInProgress,cause);
    }
  }
  if (booterForkException != null) {
    throw booterForkException;
  }
}
",0,0,0,,
465,} finally {,"try {
  Class.forName(""org.postgresql.Driver"");
  connection=DriverManager.getConnection(CONNECTION_STRING,USERNAME,PASSWORD);
  JdbcDataContext dc=new JdbcDataContext(connection);
  final Schema schema=dc.getDefaultSchema();
  dc.executeUpdate(new UpdateScript(){
    @Override public void run(    UpdateCallback cb){
      Table table=cb.createTable(schema,""my_table"").withColumn(""id"").ofType(ColumnType.INTEGER).ofNativeType(""SERIAL"").nullable(false).withColumn(""person name"").ofSize(255).withColumn(""age"").ofType(ColumnType.INTEGER).execute();
      for (int i=0; i < 1000000; i++) {
        cb.insertInto(table).value(""person name"",""John Doe"").value(""age"",i + 10).execute();
      }
    }
  }
);
  Table table=schema.getTableByName(""my_table"");
  Query query=dc.query().from(table).selectCount().toQuery();
  DataSet ds=dc.executeQuery(query);
  ds.close();
}
 catch (ClassNotFoundException e) {
  e.printStackTrace();
}
catch (SQLException e) {
  e.printStackTrace();
}
 finally {
  try {
    if (connection != null) {
      connection.createStatement().execute(""DROP TABLE my_table"");
    }
  }
 catch (  SQLException e) {
    throw new MetaModelException(""Failed to execute INSERT statement"",e);
  }
}
",0,0,0,,
466,finally {,"try {
  LOG.info(""Started "" + cmd);
  Endpoint ep=readEndpoint(cwd);
  URL endpointUrl=correctLocalUrl(hostname,ep.getUrl());
  ep.setUrl(endpointUrl.toString());
  LOG.info(""Read endpoint "" + ep);
  ModelEndpoint endpoint=new ModelEndpoint();
{
    endpoint.setName(name);
    endpoint.setContainerId(containerId);
    endpoint.setEndpoint(ep);
    endpoint.setVersion(version);
  }
  ;
  ServiceInstanceBuilder<ModelEndpoint> builder=ServiceInstance.<ModelEndpoint>builder().address(endpointUrl.getHost()).id(containerId).name(name).port(endpointUrl.getPort()).registrationTimeUTC(System.currentTimeMillis()).serviceType(ServiceType.STATIC).payload(endpoint);
  final ServiceInstance<ModelEndpoint> instance=builder.build();
  try {
    LOG.info(""Installing service instance: "" + instance + "" at ""+ serviceDiscovery);
    serviceDiscovery.registerService(instance);
    LOG.info(""Installed instance "" + name + "":""+ version+ ""@""+ endpointUrl);
  }
 catch (  Throwable t) {
    LOG.error(""Unable to install instance "" + name + "":""+ version+ ""@""+ endpointUrl,t);
  }
  Runtime.getRuntime().addShutdownHook(new Thread(){
    @Override public void run(){
      LOG.info(""KILLING CONTAINER PROCESS..."");
      if (p != null) {
        LOG.info(""Process destroyed forcibly"");
        p.destroyForcibly();
      }
    }
  }
);
}
  finally {
  if (p.waitFor() != 0) {
    String stderr=Joiner.on(""\n"").join(IOUtils.readLines(p.getErrorStream()));
    String stdout=Joiner.on(""\n"").join(IOUtils.readLines(p.getInputStream()));
    throw new IllegalStateException(""Unable to execute "" + script + "".  Stderr is: ""+ stderr+ ""\nStdout is: ""+ stdout);
  }
}
",0,0,0,,
467,} finally {,"try {
  return executeRemoteCommand(command,stderr,StandardCharsets.US_ASCII);
}
  finally {
  if (stderr.size() > 0) {
    String errorMessage=stderr.toString(StandardCharsets.US_ASCII.name());
    throw new RemoteException(""Error reported from remote command="" + command,new ServerException(errorMessage));
  }
}
",0,0,0,,
468,} finally {,"try {
  signalTearingDownExplicitTunnel(boundAddress,true,remote);
}
  finally {
  try {
    localAcceptor.unbind(bound);
  }
 catch (  RuntimeException e) {
    signalTornDownExplicitTunnel(boundAddress,true,remote,e);
    throw e;
  }
}
",0,0,0,,
469,} finally {,"try {
  signalTearingDownDynamicTunnel(local);
}
  finally {
  try {
    try {
      if (proxy != null) {
        if (debugEnabled) {
          log.debug(""stopDynamicPortForwarding({}) close proxy={}"",local,proxy);
        }
        proxy.close(true);
      }
    }
  finally {
      if ((bound != null) && (dynamicAcceptor != null)) {
        if (debugEnabled) {
          log.debug(""stopDynamicPortForwarding({}) unbind address={}"",local,bound);
        }
        dynamicAcceptor.unbind(bound);
      }
 else {
        if (debugEnabled) {
          log.debug(""stopDynamicPortForwarding({}) no acceptor({}) or no binding({})"",local,dynamicAcceptor,bound);
        }
      }
    }
  }
 catch (  RuntimeException e) {
    signalTornDownDynamicTunnel(local,e);
    throw e;
  }
}
",0,0,0,,
470,} finally {,"try {
  boolean debugEnabled=log.isDebugEnabled();
  for (  SocketAddress address : addresses) {
    if (debugEnabled) {
      log.debug(""bind({}) binding to address"",address);
    }
    try {
      AsynchronousServerSocketChannel asyncChannel=openAsynchronousServerSocketChannel(address,group);
      java.io.Closeable protector=protectInProgressBinding(address,asyncChannel);
      bound.add(protector);
      AsynchronousServerSocketChannel socket=setSocketOptions(asyncChannel);
      socket.bind(address,backlog);
      SocketAddress local=socket.getLocalAddress();
      if (debugEnabled) {
        log.debug(""bind({}) bound to {}"",address,local);
      }
      AsynchronousServerSocketChannel prev=channels.put(local,socket);
      if (prev != null) {
        if (debugEnabled) {
          log.debug(""bind({}) replaced previous channel ({}) for {}"",address,prev.getLocalAddress(),local);
        }
      }
      CompletionHandler<AsynchronousSocketChannel,? super SocketAddress> handler=ValidateUtils.checkNotNull(createSocketCompletionHandler(channels,socket),""No completion handler created for address=%s[%s]"",address,local);
      socket.accept(local,handler);
    }
 catch (    IOException|RuntimeException e) {
      error(""bind({}) - failed ({}) to bind: {}"",address,e.getClass().getSimpleName(),e.getMessage(),e);
      throw e;
    }
  }
  bound.clear();
}
  finally {
  IOException err=IoUtils.closeQuietly(bound);
  if (err != null) {
    throw err;
  }
}
",0,0,0,,
471,} finally {,"try {
  return doWritePacket(buffer);
}
  finally {
  resetIdleTimeout();
  try {
    checkRekey();
  }
 catch (  GeneralSecurityException e) {
    debug(""writePacket({}) failed ({}) to check re-key: {}"",this,e.getClass().getSimpleName(),e.getMessage(),e);
    throw ValidateUtils.initializeExceptionCause(new ProtocolException(""Failed ("" + e.getClass().getSimpleName() + "")""+ "" to check re-key necessity: ""+ e.getMessage()),e);
  }
catch (  Exception e) {
    ExceptionUtils.rethrowAsIoException(e);
  }
}
",0,0,0,,
472,} finally {,"try {
  Collection<String> idSet=new HashSet<>();
  Map<String,Object> empty=Collections.emptyMap();
  for (int index=0; index < 4; index++) {
    String credentials=getCurrentTestName() + ""-user-"" + index;
    SftpFileSystem expected=provider.newFileSystem(createFileSystemURI(credentials,empty),empty);
    fsList.add(expected);
    String id=expected.getId();
    assertTrue(""Non unique file system id: "" + id,idSet.add(id));
    SftpFileSystem actual=provider.getFileSystem(id);
    assertSame(""Mismatched cached instances for "" + id,expected,actual);
    outputDebugMessage(""Created file system id: %s"",id);
  }
  for (  SftpFileSystem fs : fsList) {
    String id=fs.getId();
    fs.close();
    assertNull(""File system not removed from cache: "" + id,provider.getFileSystem(id));
  }
}
  finally {
  IOException err=null;
  for (  FileSystem fs : fsList) {
    try {
      fs.close();
    }
 catch (    IOException e) {
      err=ExceptionUtils.accumulateException(err,e);
    }
  }
  if (err != null) {
    throw err;
  }
}
",0,0,0,,
473,} finally {,"try {
  reader=new BufferedReader(new FileReader(inputFile));
  writer=new BufferedWriter(new FileWriter(outputFile));
  if (runMode.equals(""A"")) {
    tfsorter=new RegularTestFileSort();
  }
 else {
    tfsorter=new DNCSTextFileSort();
  }
  sttime=System.nanoTime();
  tfsorter.load(reader);
  reportElapse(""Load Time"",sttime,System.nanoTime());
  sttime=System.nanoTime();
  tfsorter.doSort();
  reportElapse(""Sort Time"",sttime,System.nanoTime());
  sttime=System.nanoTime();
  tfsorter.store(writer);
  reportElapse(""Store Time"",sttime,System.nanoTime());
  reportSortInfo(tfsorter.getSortInfo());
  tfsorter.clear();
}
 catch (FileNotFoundException e) {
  System.err.println(e.getMessage());
  throw e;
}
catch (IOException e) {
  System.err.println(e.getMessage());
  throw e;
}
 finally {
  try {
    if (null != reader) {
      reader.close();
    }
    if (null != writer) {
      writer.close();
    }
  }
 catch (  IOException e) {
    System.err.println(e.getMessage());
    throw e;
  }
}
",0,0,0,,
474,finally,"try {
  serviceProviderClass=resolveImplementation(ServiceProvider.class,CUSTOM_SERVICE_PROVIDER_NAME);
  serviceProviderContextClass=resolveImplementation(ServiceProviderContext.class,CUSTOM_SERVICE_PROVIDER_CONTEXT_NAME);
}
 catch (Exception e) {
  if (LOGGER.isLoggable(Level.WARNING)) {
    LOGGER.log(Level.WARNING,""An exception occurred during the initialization of the service provider"",e);
  }
}
 finally {
  try {
    if (serviceProviderClass == null) {
      serviceProviderClass=ClassUtils.loadClassForName(DEFAULT_SERVICE_PROVIDER_NAME);
    }
    if (serviceProviderContextClass == null) {
      serviceProviderContextClass=ClassUtils.loadClassForName(DEFAULT_SERVICE_PROVIDER_CONTEXT_NAME);
    }
  }
 catch (  Exception exception) {
    throw new UnhandledException(exception);
  }
}
",0,0,0,,
475,finally,"try {
  String serviceClassName;
  inputStream=serviceFile.openStream();
  BufferedReader bufferedReader=new BufferedReader(new InputStreamReader(inputStream,FILE_ENCODING));
  while ((serviceClassName=bufferedReader.readLine()) != null) {
    serviceClassName=extractConfiguredServiceClassName(serviceClassName);
    if (!"""".equals(serviceClassName)) {
      loadService(serviceClassName);
    }
  }
}
 catch (Exception e) {
  throw new UnhandledException(""Failed to process service-config: "" + serviceFile,e);
}
 finally {
  if (inputStream != null) {
    try {
      inputStream.close();
    }
 catch (    Exception e) {
      throw new UnhandledException(""Failed to close "" + serviceFile,e);
    }
  }
}
",0,0,0,,
476,finally,"try {
  if (!transaction.isActive()) {
    transaction.begin();
  }
  return invocationContext.proceed();
}
 catch (Exception e) {
  firstException=e;
  if (isOutermostInterceptor()) {
    HashMap<String,EntityManager> emsEntries=ems.get();
    for (    Map.Entry<String,EntityManager> emsEntry : emsEntries.entrySet()) {
      EntityManager em=emsEntry.getValue();
      transaction=em.getTransaction();
      if (transaction != null && transaction.isActive()) {
        try {
          transaction.rollback();
        }
 catch (        Exception eRollback) {
          if (LOGGER.isLoggable(Level.SEVERE)) {
            LOGGER.log(Level.SEVERE,""Got additional Exception while subsequently "" + ""rolling back other SQL transactions"",eRollback);
          }
        }
      }
    }
    ems.remove();
  }
  e=prepareException(e);
  throw e;
}
 finally {
  boolean commitFailed=false;
  if (isOutermostInterceptor()) {
    if (firstException == null) {
      for (      EntityManager em : ems.get().values()) {
        transaction=em.getTransaction();
        if (transaction != null && transaction.isActive()) {
          try {
            if (!commitFailed) {
              em.flush();
            }
          }
 catch (          Exception e) {
            firstException=e;
            commitFailed=true;
            break;
          }
        }
      }
      for (      Map.Entry<String,EntityManager> emEntry : ems.get().entrySet()) {
        EntityManager em=emEntry.getValue();
        transaction=em.getTransaction();
        if (transaction != null && transaction.isActive()) {
          try {
            if (!commitFailed) {
              transaction.commit();
            }
 else {
              transaction.rollback();
            }
          }
 catch (          Exception e) {
            firstException=e;
            commitFailed=true;
          }
        }
      }
      ems.remove();
      ems.set(null);
      refCounterMaps.set(null);
      refCounterMaps.remove();
      TransactionBeanStorage oldStorage=TransactionBeanStorage.getStorage();
      TransactionBeanStorage.resetStorage();
      oldStorage.endAllTransactionScopes();
    }
  }
 else {
    TransactionBeanStorage.getStorage().activateTransactionScope(previousTransactionKey);
  }
  decrementRefCounter(qualifierKey);
  if (commitFailed) {
    throw firstException;
  }
}
",0,0,0,,
477,finally,"try {
  ByteArrayOutputStream arrayOutputStream=new ByteArrayOutputStream();
  outputStream=new ObjectOutputStream(arrayOutputStream);
  outputStream.writeObject(source);
  outputStream.flush();
  ByteArrayInputStream arrayInputStream=new ByteArrayInputStream(arrayOutputStream.toByteArray());
  inputStream=new ObjectInputStream(arrayInputStream);
  return (T)inputStream.readObject();
}
 catch (Exception e) {
  throw new IllegalArgumentException(""you provided an implementation which isn't serializable or"" + ""implemented as anonymous class"" + e);
}
 finally {
  try {
    if (inputStream != null) {
      inputStream.close();
    }
    if (outputStream != null) {
      outputStream.close();
    }
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
478,finally,"try {
  visitResult=visitContext.invokeVisitCallback(component,callback);
  if (visitResult == VisitResult.COMPLETE)   doneVisiting=true;
 else   if (visitResult == VisitResult.ACCEPT) {
    boolean skipChildren=(uixComponent instanceof NamingContainer) && visitContext.getSubtreeIdsToVisit(uixComponent).isEmpty();
    if (!skipChildren) {
      if (rc != null) {
        uixComponent.setupEncodingContext(context,rc);
      }
      try {
        doneVisiting=visitChildren(visitContext,uixComponent,callback);
      }
  finally {
        if (rc != null) {
          uixComponent.tearDownEncodingContext(context,rc);
        }
      }
    }
  }
 else {
    assert (visitResult == VisitResult.REJECT);
  }
}
 catch (RuntimeException ex) {
  re=ex;
}
 finally {
  try {
    if (rc == null) {
      uixComponent.tearDownVisitingContext(context);
    }
  }
 catch (  RuntimeException ex) {
    if (re == null) {
      throw ex;
    }
 else {
      _LOG.warning(ex);
    }
  }
}
",0,0,0,,
479,finally,"try {
  RenderingContext rc=(_isEncodingVisit(visitContext)) ? RenderingContext.getCurrentInstance() : null;
  if (rc == null) {
    uixComponent.setupVisitingContext(context);
  }
  VisitResult visitResult=VisitResult.REJECT;
  try {
    visitResult=visitContext.invokeVisitCallback(component,callback);
    if (visitResult == VisitResult.COMPLETE)     doneVisiting=true;
 else     if (visitResult == VisitResult.ACCEPT) {
      boolean skipChildren=(uixComponent instanceof NamingContainer) && visitContext.getSubtreeIdsToVisit(uixComponent).isEmpty();
      if (!skipChildren) {
        if (rc != null) {
          uixComponent.setupEncodingContext(context,rc);
        }
        try {
          doneVisiting=visitChildren(visitContext,uixComponent,callback);
        }
  finally {
          if (rc != null) {
            uixComponent.tearDownEncodingContext(context,rc);
          }
        }
      }
    }
 else {
      assert (visitResult == VisitResult.REJECT);
    }
  }
 catch (  RuntimeException ex) {
    re=ex;
  }
 finally {
    try {
      if (rc == null) {
        uixComponent.tearDownVisitingContext(context);
      }
    }
 catch (    RuntimeException ex) {
      if (re == null) {
        throw ex;
      }
 else {
        _LOG.warning(ex);
      }
    }
  }
}
  finally {
  if (re != null) {
    throw re;
  }
}
",0,0,0,,
480,finally,"try {
  doneVisiting=uixParentComponent.visitChildren(visitContext,callback);
}
 catch (RuntimeException ex) {
  re=ex;
}
 finally {
  try {
    if (rc != null) {
      uixParentComponent.tearDownChildrenEncodingContext(context,rc);
    }
 else {
      uixParentComponent.tearDownChildrenVisitingContext(context);
    }
  }
 catch (  RuntimeException ex) {
    if (re == null) {
      throw ex;
    }
 else {
      _LOG.warning(ex);
    }
  }
  if (re != null) {
    throw re;
  }
}
",0,0,0,,
481,finally,"try {
  if (getRendersChildren()) {
    beforeEncode(context,rc,component,bean);
    RequestContext rContext=null;
    if (!(component instanceof UIXComponent)) {
      rContext=RequestContext.getCurrentInstance();
      rContext.pushCurrentComponent(context,component);
    }
    try {
      encodeAll(context,rc,component,bean);
    }
  finally {
      if (!(component instanceof UIXComponent) && rContext != null) {
        rContext.popCurrentComponent(context,component);
      }
    }
  }
 else {
    encodeEnd(context,rc,component,bean);
  }
}
 catch (RuntimeException ex) {
  re=ex;
}
 finally {
  try {
    afterEncode(context,rc,component,bean);
  }
 catch (  RuntimeException ex) {
    if (re == null) {
      throw ex;
    }
    _LOG.warning(ex);
  }
  if (re != null) {
    throw re;
  }
}
",0,0,0,,
482,finally,"try {
  if (_length > 0) {
    _writeFile(out);
  }
  _buffers=null;
  while (_length < remainingDiskSpace) {
    byte[] buffer=new byte[_DISK_BUFFER_SIZE];
    int bytes=_fillBuffer(in,buffer,_DISK_BUFFER_SIZE);
    out.write(buffer,0,bytes);
    _length=_length + bytes;
    if (bytes < _DISK_BUFFER_SIZE)     break;
  }
}
  finally {
  out.close();
  if (_length > remainingDiskSpace) {
    _file.delete();
    _file=null;
    _length=0;
    throw new EOFException(""Per-request disk space limits exceeded."");
  }
}
",0,0,0,,
483,finally,"try {
  s=serialFactory.getObjectInputStream(input);
  Object object=null;
  if (System.getSecurityManager() != null) {
    final ObjectInputStream ois=s;
    object=AccessController.doPrivileged(new PrivilegedExceptionAction<Object>(){
      public Object run() throws PrivilegedActionException, IOException, ClassNotFoundException {
        return ois.readObject();
      }
    }
);
  }
 else {
    object=s.readObject();
  }
  return object;
}
 catch (Exception e) {
  pendingException=e;
  throw new FacesException(e);
}
 finally {
  if (s != null) {
    try {
      s.close();
    }
 catch (    IOException e) {
      if (pendingException == null) {
        throw new FacesException(e);
      }
    }
 finally {
      s=null;
    }
  }
}
",0,0,0,,
484,} finally {,"try {
  jar=new JarFile(jarFile);
  mf=jar.getManifest();
}
 catch (Exception exc) {
  throw new MojoExecutionException(""Opening "" + jarFile + "": ""+ exc,exc);
}
 finally {
  if (jar != null) {
    try {
      jar.close();
    }
 catch (    IOException io) {
      throw new MojoExecutionException(io.getMessage(),io);
    }
  }
}
",0,0,0,,
485,} finally {,"try {
  stream=new FileInputStream(manifestFile);
  mf=new Manifest(stream);
}
 catch (Exception exc) {
  throw new MojoExecutionException(""Opening "" + manifestFile + "": ""+ exc,exc);
}
 finally {
  if (stream != null) {
    try {
      stream.close();
    }
 catch (    IOException io) {
      throw new MojoExecutionException(io.getMessage(),io);
    }
  }
}
",0,0,0,,
486,} finally {,"try {
  breakAtomicLock();
  completed=true;
}
  finally {
  if (completed) {
    throw ex;
  }
 else {
    LOG.log(Level.INFO,""Runtime exception thrown in BaseDocument.runAtomicAsUser() leading to breakAtomicLock():"",ex);
  }
}
",0,0,0,,
487,} finally {,"try {
  breakAtomicLock();
  completed=true;
}
  finally {
  if (completed) {
    throw ex;
  }
 else {
    LOG.log(Level.INFO,""Runtime exception thrown in GuardedDocument.runAtomic() leading to breakAtomicLock():"",ex);
  }
}
",0,0,0,,
488,} finally {,"try {
  breakAtomicLock();
  completed=true;
}
  finally {
  if (completed) {
    throw ex;
  }
 else {
    LOG.log(Level.INFO,""Runtime exception thrown in GuardedDocument.runAtomicAsUser() leading to breakAtomicLock():"",ex);
  }
}
",0,0,0,,
489,} finally {,"try {
  final Runnable pre=descriptor.getPreExecution();
  if (pre != null) {
    pre.run();
  }
  if (Thread.currentThread().isInterrupted()) {
    return null;
  }
  process=processCreator.call();
synchronized (RUNNING_PROCESSES) {
    RUNNING_PROCESSES.add(process);
  }
  if (Thread.currentThread().isInterrupted()) {
    return null;
  }
  outStream=new ProcessInputStream(process,process.getInputStream());
  errStream=new ProcessInputStream(process,process.getErrorStream());
  executor=Executors.newFixedThreadPool(in != null ? 3 : 2);
  Charset charset=descriptor.getCharset();
  if (charset == null) {
    charset=Charset.defaultCharset();
  }
  tasks.add(InputReaderTask.newDrainingTask(InputReaders.forStream(new BufferedInputStream(outStream),charset),createOutProcessor()));
  tasks.add(InputReaderTask.newDrainingTask(InputReaders.forStream(new BufferedInputStream(errStream),charset),createErrProcessor()));
  if (in != null) {
    tasks.add(InputReaderTask.newTask(InputReaders.forReader(in),createInProcessor(process.getOutputStream(),charset)));
  }
  for (  InputReaderTask task : tasks) {
    executor.submit(task);
  }
  process.waitFor();
}
 catch (InterruptedException ex) {
  LOGGER.log(Level.FINE,null,ex);
  interrupted=true;
}
catch (Throwable t) {
  LOGGER.log(Level.INFO,null,t);
  throw new WrappedException(t);
}
 finally {
  try {
    interrupted|=Thread.interrupted();
    if (!interrupted) {
      if (outStream != null) {
        outStream.close(true);
      }
      if (errStream != null) {
        errStream.close(true);
      }
    }
    if (process != null) {
      process.destroy();
synchronized (RUNNING_PROCESSES) {
        RUNNING_PROCESSES.remove(process);
      }
      try {
        ret=process.exitValue();
      }
 catch (      IllegalThreadStateException ex) {
        LOGGER.log(Level.FINE,""Process not yet exited"",ex);
      }
    }
  }
 catch (  Throwable t) {
    LOGGER.log(Level.INFO,null,t);
    throw new WrappedException(t);
  }
 finally {
    try {
      cleanup(tasks,executor);
      final ParametrizedRunnable<Integer> post=descriptor.getPostExecution();
      if (post != null) {
        post.run(ret);
      }
    }
  finally {
      finishedLatch.countDown();
      if (interrupted) {
        Thread.currentThread().interrupt();
      }
    }
  }
}
",0,0,0,,
490,} finally {,"try {
  bw=new BufferedWriter(new OutputStreamWriter(new FileOutputStream(tmpFile),Constants.CHARSET));
  for (ListIterator<IgnoreRule> it=ignoreRules.listIterator(); it.hasNext(); ) {
    String s=it.next().getPattern(false);
    bw.write(s,0,s.length());
    bw.newLine();
  }
}
  finally {
  if (bw != null) {
    try {
      bw.close();
    }
 catch (    IOException ex) {
    }
  }
  if (!tmpFile.renameTo(gitIgnore)) {
    File tmpCopy=generateTempFile(Constants.DOT_GIT_IGNORE,gitIgnore.getParentFile());
    boolean success=false;
    if (gitIgnore.renameTo(tmpCopy)) {
      success=tmpFile.renameTo(gitIgnore);
      if (!success) {
        tmpCopy.renameTo(gitIgnore);
      }
      tmpCopy.delete();
    }
    if (!success) {
      tmpFile.delete();
      throw new IOException(""Cannot write to "" + gitIgnore.getAbsolutePath());
    }
  }
}
",0,0,0,,
491,} finally {,"try {
  for (  Pair<SourceIndexerFactory,Context> entry : ctxToFinish) {
    parkWhileSuspended();
    if (TEST_LOGGER.isLoggable(Level.FINEST)) {
      TEST_LOGGER.log(Level.FINEST,""scanFinishing:{0}:{1}"",new Object[]{entry.first().getIndexerName(),entry.second().getRootURI().toExternalForm()});
    }
    logStartIndexer(entry.first().getIndexerName());
    SPIAccessor.getInstance().putProperty(entry.second(),ClusteredIndexables.DELETE,null);
    SPIAccessor.getInstance().putProperty(entry.second(),ClusteredIndexables.INDEX,null);
    cancelRequest.setResult(finished);
    try {
      int estimate=estimateSourceEndTime(entry.first());
      SamplerInvoker.start(getLogContext(),entry.first().getIndexerName(),estimate,entry.second().getRootURI());
      entry.first().scanFinished(entry.second());
    }
 catch (    Throwable t) {
      if (t instanceof ThreadDeath) {
        throw (ThreadDeath)t;
      }
 else {
        Exceptions.printStackTrace(t);
        SamplerInvoker.stop();
      }
    }
 finally {
      cancelRequest.setResult(null);
    }
    logFinishIndexer(entry.first().getIndexerName());
    if (TEST_LOGGER.isLoggable(Level.FINEST)) {
      TEST_LOGGER.log(Level.FINEST,""scanFinished:{0}:{1}"",new Object[]{entry.first().getIndexerName(),entry.second().getRootURI().toExternalForm()});
    }
  }
}
  finally {
  try {
    boolean indexOk=true;
    Union2<IOException,RuntimeException> exception=null;
    for (    Pair<SourceIndexerFactory,Context> entry : ctxToFinish) {
      try {
        indexOk&=storeChanges(entry.first().getIndexerName(),entry.second(),isSteady(),usedIterables.get(),finished);
      }
 catch (      IOException e) {
        exception=Union2.createFirst(e);
      }
catch (      RuntimeException e) {
        exception=Union2.createSecond(e);
      }
    }
    if (exception != null) {
      if (exception.hasFirst()) {
        throw exception.first();
      }
 else {
        throw exception.second();
      }
    }
 else     if (!indexOk) {
      final Context ctx=ctxToFinish.iterator().next().second();
      RepositoryUpdater.getDefault().addIndexingJob(ctx.getRootURI(),null,false,false,false,true,true,LogContext.create(LogContext.EventType.UI,""Broken Index Found.""));
    }
  }
  finally {
    InjectedTasksSupport.clear();
  }
}
",0,0,0,,
492,} finally {,"try {
  for (  Pair<SourceIndexerFactory,Context> pair : contexts.values()) {
    parkWhileSuspended();
    SPIAccessor.getInstance().putProperty(pair.second(),ClusteredIndexables.DELETE,ci);
    pair.first().filesDeleted(ci.getIndexablesFor(null),pair.second());
  }
}
  finally {
  for (  Pair<SourceIndexerFactory,Context> pair : contexts.values()) {
    final Context ctx=pair.second();
    final FileObject indexFolder=ctx.getIndexFolder();
    if (indexFolder == null) {
      throw new IllegalStateException(String.format(""No index folder for context: %s"",ctx));
    }
    final DocumentIndex index=SPIAccessor.getInstance().getIndexFactory(ctx).getIndex(indexFolder);
    if (index != null) {
      usedIterables.offer(ci.getIndexablesFor(null));
    }
  }
}
",0,0,0,,
493,} finally {,"try {
  int index=0;
  for (  Map.Entry<BinaryIndexerFactory,Context> entry : contexts.entrySet()) {
    if (startedIndexers.get(index++)) {
      try {
        final long st=System.currentTimeMillis();
        try {
          parkWhileSuspended();
          logStartIndexer(entry.getKey().getIndexerName());
        }
  finally {
          try {
            entry.getKey().scanFinished(entry.getValue());
          }
  finally {
            long et=System.currentTimeMillis();
            logIndexerTime(entry.getKey().getIndexerName(),(int)(et - st));
          }
        }
      }
 catch (      Throwable t) {
        if (t instanceof ThreadDeath) {
          throw (ThreadDeath)t;
        }
 else {
          Exceptions.printStackTrace(t);
        }
      }
    }
  }
}
  finally {
  boolean indexOk=true;
  Union2<IOException,RuntimeException> exception=null;
  for (  Context ctx : contexts.values()) {
    try {
      indexOk&=storeChanges(null,ctx,isSteady(),null,finished);
    }
 catch (    IOException e) {
      exception=Union2.createFirst(e);
    }
catch (    RuntimeException e) {
      exception=Union2.createSecond(e);
    }
  }
  if (exception != null) {
    if (exception.hasFirst()) {
      throw exception.first();
    }
 else {
      throw exception.second();
    }
  }
 else   if (!indexOk) {
    RepositoryUpdater.getDefault().addBinaryJob(contexts.values().iterator().next().getRootURI(),LogContext.create(LogContext.EventType.UI,""Broken Index Found.""));
  }
}
",0,0,0,,
494,} finally {,"try {
{
    boolean modifiableAllThreads=false;
    int n=allThreads.size();
    for (int i=0; i < n; i++) {
      JPDAThread t=allThreads.get(i);
      int status=t.getState();
      if (status == JPDAThread.STATE_ZOMBIE || status == JPDAThread.STATE_UNKNOWN || t.getName().contains(ThreadsCache.THREAD_NAME_FILTER_PATTERN) && !t.isSuspended()) {
        if (!modifiableAllThreads) {
          allThreads=new ArrayList<JPDAThread>(allThreads);
          modifiableAllThreads=true;
        }
        allThreads.remove(i);
        n--;
        i--;
      }
    }
  }
  threadsToResume=new ArrayList<JPDAThreadImpl>();
  for (  JPDAThread t : allThreads) {
    if (t.isSuspended() || ((JPDAThreadImpl)t).getThreadReference().suspendCount() > 0) {
      threadsToResume.add((JPDAThreadImpl)t);
    }
  }
  for (int i=0; i < threadsToResume.size(); i++) {
    JPDAThreadImpl t=threadsToResume.get(i);
    boolean can=t.cleanBeforeResume();
    if (!can) {
      threadsToResume.remove(i);
      i--;
    }
  }
  if (vmSuspended || allThreads.size() == threadsToResume.size()) {
    for (    JPDAThreadImpl t : threadsToResume) {
      t.setAsResumed(false);
      t.reduceThreadSuspendCount();
    }
    reduceThreadSuspendCountOfAllBut(vm,threadsToResume);
    VirtualMachineWrapper.resume(vm);
    vmSuspended=false;
    logger.finer(""All VM threads resumed."");
  }
 else {
    logger.finer(""Resuming selected suspended threads."");
    for (    JPDAThreadImpl t : threadsToResume) {
      t.setAsResumed(false);
      t.resumeAfterClean();
    }
  }
}
 catch (VMDisconnectedExceptionWrapper e) {
}
catch (InternalExceptionWrapper e) {
}
 finally {
  accessLock.writeLock().unlock();
  logger.finer(""Debugger WRITE lock released."");
  if (stateChangeEvent != null) {
    firePropertyChange(stateChangeEvent);
  }
  if (threadsToResume != null) {
    for (    JPDAThreadImpl t : threadsToResume) {
      try {
        t.fireAfterResume();
      }
 catch (      ThreadDeath td) {
        throw td;
      }
catch (      Throwable th) {
        Exceptions.printStackTrace(th);
      }
    }
  }
}
",0,0,0,,
495,} finally {,"try {
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""STARTED : {0}.<init> ({1}) in thread {2}"",new Object[]{classType,argVals,evaluationContext.getFrame().thread()});
  }
  evaluationContext.methodToBeInvoked();
  Method constructorMethod=getConcreteMethodAndReportProblems(arg0,classType,""<init>"",firstParamSignature,paramTypes,argTypes);
  if (isVarArgs) {
    transformVarArgsValues(arg0,argVals,paramTypes,evaluationContext);
  }
  ObjectReference o=classType.newInstance(evaluationContext.getFrame().thread(),constructorMethod,argVals,ObjectReference.INVOKE_SINGLE_THREADED);
  return o;
}
 catch (InvalidTypeException itex) {
  throw new IllegalStateException(new InvalidExpressionException(itex));
}
catch (ClassNotLoadedException cnlex) {
  throw new IllegalStateException(cnlex);
}
catch (IncompatibleThreadStateException|UnsupportedOperationException itsex) {
  InvalidExpressionException ieex=new InvalidExpressionException(itsex);
  throw new IllegalStateException(ieex);
}
catch (InvocationException iex) {
  Throwable ex=new InvocationExceptionTranslated(iex,evaluationContext.getDebugger());
  InvalidExpressionException ieex=new InvalidExpressionException(ex,true);
  throw new IllegalStateException(ieex);
}
 finally {
  try {
    evaluationContext.methodInvokeDone();
  }
 catch (  IncompatibleThreadStateException itsex) {
    InvalidExpressionException ieex=new InvalidExpressionException(itsex);
    throw new IllegalStateException(ieex);
  }
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""FINISHED: {0}.<init> ({1}) in thread {2}"",new Object[]{classType,argVals,evaluationContext.getFrame().thread()});
  }
}
",0,0,0,,
496,} finally {,"try {
  evaluationThread=evaluationContext.getFrame().thread();
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""STARTED : {0}.{1} ({2}) in thread {3}"",new Object[]{objectReference,method,argVals,evaluationThread});
  }
  evaluationContext.methodToBeInvoked();
  Value value;
  try {
    autoboxArguments(method.argumentTypes(),argVals,evaluationThread,evaluationContext);
  }
 catch (  ClassNotLoadedException cnlex) {
  }
  if (Boolean.TRUE.equals(isStatic)) {
    value=type.invokeMethod(evaluationThread,method,argVals,ObjectReference.INVOKE_SINGLE_THREADED);
  }
 else {
    ObjectReference object=objectReference;
    if (type != null) {
      if (method.isPrivate()) {
        object=findEnclosingObject(arg0,objectReference,type,null,method.name());
      }
 else {
        if (!instanceOf(objectReference.referenceType(),type)) {
          object=findEnclosingObject(arg0,objectReference,type,null,method.name());
        }
      }
    }
    if (object == null) {
      Assert.error(arg0,""noSuchMethod"",method.name(),objectReference.referenceType().name());
    }
    value=object.invokeMethod(evaluationThread,method,argVals,ObjectReference.INVOKE_SINGLE_THREADED | ((nonVirtual) ? ObjectReference.INVOKE_NONVIRTUAL : 0));
  }
  if (value instanceof ObjectReference) {
  }
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""   return = {0}"",value);
  }
  return value;
}
 catch (InvalidTypeException itex) {
  throw new IllegalStateException(new InvalidExpressionException(itex));
}
catch (ClassNotLoadedException cnlex) {
  throw new IllegalStateException(cnlex);
}
catch (IncompatibleThreadStateException itsex) {
  String message=Bundle.MSG_IncompatibleThreadStateMessage();
  InvalidExpressionException ieex=new InvalidExpressionException(message,itsex);
  throw new IllegalStateException(ieex);
}
catch (InvalidStackFrameException isfex) {
  InvalidExpressionException ieex=new InvalidExpressionException(isfex);
  throw new IllegalStateException(ieex);
}
catch (InvocationException iex) {
  loggerMethod.info(""InvocationException ("" + iex.getLocalizedMessage() + "") has occured when there were following VMs:\n""+ ""evaluationThread VM: ""+ InvocationExceptionTranslated.printVM(evaluationThread.virtualMachine())+ ""\n""+ ((objectReference != null) ? (""objectReference VM: "" + InvocationExceptionTranslated.printVM(objectReference.virtualMachine())) : ""objectReference = null"")+ ""\n""+ ""method VM: ""+ InvocationExceptionTranslated.printVM(method.virtualMachine())+ ""\n""+ ((type != null) ? (""type VM: "" + InvocationExceptionTranslated.printVM(type.virtualMachine())) : ""type = null"")+ ""\n"");
  for (  Value v : argVals) {
    if (v != null) {
      loggerMethod.info("" arg value VM: "" + InvocationExceptionTranslated.printVM(v.virtualMachine()));
    }
  }
  Throwable ex=new InvocationExceptionTranslated(iex,evaluationContext.getDebugger());
  InvalidExpressionException ieex=new InvalidExpressionException(ex,true);
  throw new IllegalStateException(iex.getLocalizedMessage(),ieex);
}
catch (UnsupportedOperationException uoex) {
  InvalidExpressionException ieex=new InvalidExpressionException(uoex);
  throw new IllegalStateException(ieex);
}
catch (InternalException inex) {
  if (inex.errorCode() == 502) {
    inex=(com.sun.jdi.InternalException)org.openide.util.Exceptions.attachLocalizedMessage(inex,org.openide.util.NbBundle.getMessage(org.netbeans.modules.debugger.jpda.JPDADebuggerImpl.class,""JDWPError502""));
  }
  throw inex;
}
 finally {
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""FINISHED: {0}.{1} ({2}) in thread {3}"",new Object[]{objectReference,method,argVals,evaluationThread});
  }
  try {
    evaluationContext.methodInvokeDone();
  }
 catch (  IncompatibleThreadStateException itsex) {
    InvalidExpressionException ieex=new InvalidExpressionException(itsex);
    throw new IllegalStateException(ieex);
  }
}
",0,0,0,,
497,} finally {,"try {
  evaluationThread=evaluationContext.getFrame().thread();
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""STARTED : {0}.{1} ({2}) in thread {3}"",new Object[]{type,method,argVals,evaluationThread});
  }
  evaluationContext.methodToBeInvoked();
  Value value;
  try {
    autoboxArguments(method.argumentTypes(),argVals,evaluationThread,evaluationContext);
  }
 catch (  ClassNotLoadedException cnlex) {
  }
  value=InterfaceTypeWrapper.invokeMethod(type,evaluationThread,method,argVals,ObjectReference.INVOKE_SINGLE_THREADED);
  if (value instanceof ObjectReference) {
  }
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""   return = {0}"",value);
  }
  return value;
}
 catch (VMDisconnectedExceptionWrapper vmdw) {
  throw vmdw.getCause();
}
catch (InvalidTypeException itex) {
  throw new IllegalStateException(new InvalidExpressionException(itex));
}
catch (ClassNotLoadedException cnlex) {
  throw new IllegalStateException(cnlex);
}
catch (IncompatibleThreadStateException itsex) {
  String message=Bundle.MSG_IncompatibleThreadStateMessage();
  InvalidExpressionException ieex=new InvalidExpressionException(message,itsex);
  throw new IllegalStateException(ieex);
}
catch (InvalidStackFrameException isfex) {
  InvalidExpressionException ieex=new InvalidExpressionException(isfex);
  throw new IllegalStateException(ieex);
}
catch (InvocationException iex) {
  loggerMethod.info(""InvocationException has occured when there were following VMs:\n"" + ""evaluationThread VM: "" + InvocationExceptionTranslated.printVM(evaluationThread.virtualMachine()) + ""\n""+ (""objectReference = null"")+ ""\n""+ ""method VM: ""+ InvocationExceptionTranslated.printVM(method.virtualMachine())+ ""\n""+ (""type VM: "" + InvocationExceptionTranslated.printVM(type.virtualMachine()))+ ""\n"");
  for (  Value v : argVals) {
    if (v != null) {
      loggerMethod.info("" arg value VM: "" + InvocationExceptionTranslated.printVM(v.virtualMachine()));
    }
  }
  Throwable ex=new InvocationExceptionTranslated(iex,evaluationContext.getDebugger());
  InvalidExpressionException ieex=new InvalidExpressionException(ex,true);
  throw new IllegalStateException(iex.getLocalizedMessage(),ieex);
}
catch (UnsupportedOperationException uoex) {
  InvalidExpressionException ieex=new InvalidExpressionException(uoex);
  throw new IllegalStateException(ieex);
}
catch (InternalExceptionWrapper inexw) {
  InternalException inex=inexw.getCause();
  if (inex.errorCode() == 502) {
    inex=(com.sun.jdi.InternalException)org.openide.util.Exceptions.attachLocalizedMessage(inex,org.openide.util.NbBundle.getMessage(org.netbeans.modules.debugger.jpda.JPDADebuggerImpl.class,""JDWPError502""));
  }
  throw inex;
}
 finally {
  if (loggerMethod.isLoggable(Level.FINE)) {
    loggerMethod.log(Level.FINE,""FINISHED: {0}.{1} ({2}) in thread {3}"",new Object[]{type,method,argVals,evaluationThread});
  }
  try {
    evaluationContext.methodInvokeDone();
  }
 catch (  IncompatibleThreadStateException itsex) {
    InvalidExpressionException ieex=new InvalidExpressionException(itsex);
    throw new IllegalStateException(ieex);
  }
}
",0,0,0,,
498,} finally {,"try {
  if (type instanceof PrimitiveType) {
    for (int i=0; i < elements.size(); i++) {
      Value v=elements.get(i);
      if (v instanceof ObjectReference) {
        if (!methodCalled) {
          if (!evaluationContext.canInvokeMethods()) {
            Assert.error(arg0,""canNotInvokeMethods"");
          }
          evaluationThread=evaluationContext.getFrame().thread();
          if (loggerMethod.isLoggable(Level.FINE)) {
            loggerMethod.log(Level.FINE,""STARTED : Unbox {0} in thread {1}"",new Object[]{v,evaluationThread});
          }
          evaluationContext.methodToBeInvoked();
          methodCalled=true;
        }
        elements.set(i,unbox((ObjectReference)v,(PrimitiveType)type,evaluationThread,evaluationContext));
      }
    }
  }
 else   if (type instanceof ReferenceType) {
    for (int i=0; i < elements.size(); i++) {
      Value v=elements.get(i);
      if (v instanceof PrimitiveValue) {
        if (!methodCalled) {
          if (!evaluationContext.canInvokeMethods()) {
            Assert.error(arg0,""canNotInvokeMethods"");
          }
          evaluationThread=evaluationContext.getFrame().thread();
          if (loggerMethod.isLoggable(Level.FINE)) {
            loggerMethod.log(Level.FINE,""STARTED : Autobox {0} in thread {1}"",new Object[]{v,evaluationThread});
          }
          evaluationContext.methodToBeInvoked();
          methodCalled=true;
        }
        elements.set(i,box((PrimitiveValue)v,(ReferenceType)type,evaluationThread,evaluationContext));
      }
    }
  }
}
 catch (InvalidTypeException itex) {
  throw new IllegalStateException(new InvalidExpressionException(itex));
}
catch (ClassNotLoadedException cnlex) {
  throw new IllegalStateException(cnlex);
}
catch (IncompatibleThreadStateException itsex) {
  InvalidExpressionException ieex=new InvalidExpressionException(itsex);
  throw new IllegalStateException(ieex);
}
catch (InvocationException iex) {
  Throwable ex=new InvocationExceptionTranslated(iex,evaluationContext.getDebugger());
  InvalidExpressionException ieex=new InvalidExpressionException(ex,true);
  throw new IllegalStateException(ieex);
}
catch (UnsupportedOperationException uoex) {
  InvalidExpressionException ieex=new InvalidExpressionException(uoex);
  throw new IllegalStateException(ieex);
}
 finally {
  if (methodCalled) {
    if (loggerMethod.isLoggable(Level.FINE)) {
      loggerMethod.log(Level.FINE,""FINISHED: Autobox/unbox in thread {0}"",evaluationThread);
    }
    try {
      evaluationContext.methodInvokeDone();
    }
 catch (    IncompatibleThreadStateException itsex) {
      InvalidExpressionException ieex=new InvalidExpressionException(itsex);
      throw new IllegalStateException(ieex);
    }
  }
}
",0,0,0,,
499,} finally {,"try {
  if (name.equals(Boolean.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""booleanValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Byte.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""byteValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Character.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""charValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Short.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""shortValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Integer.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""intValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Long.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""longValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Float.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""floatValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  if (name.equals(Double.class.getName())) {
    unboxMethodToBeCalled(arg0,r,evaluationContext);
    methodCalled=true;
    return invokeUnboxingMethod(r,""doubleValue"",evaluationContext.getFrame().thread(),evaluationContext);
  }
  return r;
}
 catch (InvalidTypeException itex) {
  throw new IllegalStateException(new InvalidExpressionException(itex));
}
catch (ClassNotLoadedException cnlex) {
  throw new IllegalStateException(cnlex);
}
catch (IncompatibleThreadStateException itsex) {
  InvalidExpressionException ieex=new InvalidExpressionException(itsex);
  throw new IllegalStateException(ieex);
}
catch (InvocationException iex) {
  Throwable ex=new InvocationExceptionTranslated(iex,evaluationContext.getDebugger());
  InvalidExpressionException ieex=new InvalidExpressionException(ex,true);
  throw new IllegalStateException(ieex);
}
catch (UnsupportedOperationException uoex) {
  InvalidExpressionException ieex=new InvalidExpressionException(uoex);
  throw new IllegalStateException(ieex);
}
 finally {
  if (methodCalled) {
    if (loggerMethod.isLoggable(Level.FINE)) {
      loggerMethod.log(Level.FINE,""FINISHED: unbox in thread {0}"",evaluationContext.getFrame().thread());
    }
    try {
      evaluationContext.methodInvokeDone();
    }
 catch (    IncompatibleThreadStateException itsex) {
      InvalidExpressionException ieex=new InvalidExpressionException(itsex);
      throw new IllegalStateException(ieex);
    }
  }
}
",0,0,0,,
500,} finally {,"try {
  Method constructor=null;
  String classType=type.name();
  if (!PRIMITIVE_CLASS_NAMES.contains(classType)) {
    type=adjustBoxingType(type,(PrimitiveType)v.type(),evaluationContext);
  }
 else {
    VirtualMachine vm=type.virtualMachine();
    if (classType.equals(""java.lang.Boolean"") && (v instanceof ArtificialMirror || !(v instanceof BooleanValue))) {
      v=vm.mirrorOf(v.booleanValue());
    }
 else     if (classType.equals(""java.lang.Byte"") && (v instanceof ArtificialMirror || !(v instanceof ByteValue))) {
      v=vm.mirrorOf(v.byteValue());
    }
 else     if (classType.equals(""java.lang.Character"") && (v instanceof ArtificialMirror || !(v instanceof CharValue))) {
      v=vm.mirrorOf(v.charValue());
    }
 else     if (classType.equals(""java.lang.Short"") && (v instanceof ArtificialMirror || !(v instanceof ShortValue))) {
      v=vm.mirrorOf(v.shortValue());
    }
 else     if (classType.equals(""java.lang.Integer"") && (v instanceof ArtificialMirror || !(v instanceof IntegerValue))) {
      v=vm.mirrorOf(v.intValue());
    }
 else     if (classType.equals(""java.lang.Long"") && (v instanceof ArtificialMirror || !(v instanceof LongValue))) {
      v=vm.mirrorOf(v.longValue());
    }
 else     if (classType.equals(""java.lang.Float"") && (v instanceof ArtificialMirror || !(v instanceof FloatValue))) {
      v=vm.mirrorOf(v.floatValue());
    }
 else     if (classType.equals(""java.lang.Double"") && (v instanceof ArtificialMirror || !(v instanceof DoubleValue))) {
      v=vm.mirrorOf(v.doubleValue());
    }
  }
  List<Method> methods=type.methodsByName(""<init>"");
  String signature=""("" + v.type().signature() + "")"";
  for (  Method method : methods) {
    if (!method.isAbstract() && equalMethodSignatures(method.signature(),signature)) {
      constructor=method;
    }
  }
  if (constructor == null) {
    throw new RuntimeException(""No constructor "" + type + "" ""+ signature);
  }
  if (evaluationContext != null) {
    evaluationContext.methodToBeInvoked();
  }
  ObjectReference o=((ClassType)type).newInstance(thread,constructor,Arrays.asList(new Value[]{v}),ObjectReference.INVOKE_SINGLE_THREADED);
  return o;
}
 catch (InvalidTypeException itex) {
  throw itex;
}
catch (ClassNotLoadedException cnlex) {
  throw cnlex;
}
catch (IncompatibleThreadStateException itsex) {
  throw itsex;
}
catch (InvocationException iex) {
  throw iex;
}
catch (RuntimeException rex) {
  throw rex;
}
catch (Exception e) {
  throw new RuntimeException(""Unexpected exception while invoking boxing method"",e);
}
 finally {
  if (evaluationContext != null) {
    try {
      evaluationContext.methodInvokeDone();
    }
 catch (    IncompatibleThreadStateException itsex) {
      InvalidExpressionException ieex=new InvalidExpressionException(itsex);
      throw new IllegalStateException(ieex);
    }
  }
}
",0,0,0,,
501,} finally {,"try {
  return (PrimitiveValue)reference.invokeMethod(thread,toCall,new ArrayList<Value>(0),ObjectReference.INVOKE_SINGLE_THREADED);
}
 catch (InvalidTypeException itex) {
  throw itex;
}
catch (ClassNotLoadedException cnlex) {
  throw cnlex;
}
catch (IncompatibleThreadStateException itsex) {
  throw itsex;
}
catch (InvocationException iex) {
  throw iex;
}
catch (Exception e) {
  throw new RuntimeException(""Unexpected exception while invoking unboxing method"",e);
}
 finally {
  if (evaluationContext != null) {
    try {
      evaluationContext.methodInvokeDone();
    }
 catch (    IncompatibleThreadStateException itsex) {
      InvalidExpressionException ieex=new InvalidExpressionException(itsex);
      throw new IllegalStateException(ieex);
    }
  }
}
",0,0,0,,
502,} finally {,"try {
  com.sun.jdi.Method forName=clazz.concreteMethodByName(""forName"",""(Ljava/lang/String;ZLjava/lang/ClassLoader;)Ljava/lang/Class;"");
  StackFrame frame=evaluationContext.getFrame();
  ClassLoaderReference executingClassloader=frame.location().declaringType().classLoader();
  List args=new ArrayList();
  StringReference className=createStringMirrorWithDisabledCollection(name,vm,evaluationContext);
  args.add(className);
  args.add(vm.mirrorOf(true));
  args.add(executingClassloader);
  ClassObjectReference cor=(ClassObjectReference)clazz.invokeMethod(frame.thread(),forName,args,ObjectReference.INVOKE_SINGLE_THREADED);
  return cor.reflectedType();
}
 catch (IncompatibleThreadStateException itsex) {
  String message=Bundle.MSG_IncompatibleThreadStateMessage();
  InvalidExpressionException ieex=new InvalidExpressionException(message,itsex);
  throw new IllegalStateException(ieex);
}
catch (Exception ex) {
  return null;
}
 finally {
  try {
    evaluationContext.methodInvokeDone();
  }
 catch (  IncompatibleThreadStateException itsex) {
    InvalidExpressionException ieex=new InvalidExpressionException(itsex);
    ieex.initCause(itsex);
    throw new IllegalStateException(ieex);
  }
}
",0,0,0,,
503,} finally {,"try {
  int newFrameCount=ThreadReferenceWrapper.frameCount0(tr);
  if (!(newFrameCount > frameCount)) {
    return null;
  }
  sf=ThreadReferenceWrapper.frames(tr,0,1).get(0);
  arguments=getArgumentValues(sf);
}
 catch (IncompatibleThreadStateException itsex) {
  Exceptions.printStackTrace(itsex);
  return null;
}
 finally {
  EventRequestManagerWrapper.deleteEventRequest(VirtualMachineWrapper.eventRequestManager(vm),step);
  debugger.getOperator().unregister(step);
  try {
    if (sf != null) {
      ThreadReferenceWrapper.popFrames(tr,sf);
    }
  }
 catch (  IncompatibleThreadStateException itsex) {
    Exceptions.printStackTrace(itsex);
    return null;
  }
catch (  NativeMethodExceptionWrapper nmex) {
    return null;
  }
catch (  InternalExceptionWrapper iex) {
    if (iex.getCause().errorCode() == 32) {
      return null;
    }
 else {
      throw iex;
    }
  }
}
",0,0,0,,
504,} finally {,"try {
  Log.assertInstances(""Checking if all projects are really garbage collected"",""Project"");
}
 catch (AssertionFailedError t) {
  Logger.getLogger(WatchProjects.class.getName()).warning(t.getMessage());
  if (!Boolean.getBoolean(""ignore.random.failures"")) {
    throw t;
  }
}
 finally {
  dumpHeap(null);
  try {
    Thread.sleep(4000);
  }
 catch (  InterruptedException exc) {
    Exceptions.printStackTrace(exc);
  }
  try {
    printTreeView(Frame.getFrames());
  }
 catch (  Exception ex) {
    throw new IllegalStateException(ex);
  }
}
",0,0,0,,
505,} finally {,"try {
  if (wagonAuth != null) {
    if (wagonProxy != null) {
      wagon.connect(repository,wagonAuth,wagonProxy);
    }
 else {
      wagon.connect(repository,wagonAuth);
    }
  }
 else {
    if (wagonProxy != null) {
      wagon.connect(repository,wagonProxy);
    }
 else {
      wagon.connect(repository);
    }
  }
  File temp=File.createTempFile(""maven"",""catalog"");
  try {
    wagon.get(""archetype-catalog.xml"",temp);
    if (temp.exists() && temp.length() > 0) {
      FileUtils.copyFile(temp,catalog);
      temp.delete();
    }
  }
  finally {
    wagon.disconnect();
  }
}
 catch (AuthenticationException ex) {
  String msg=""Authentication exception connecting to "" + repository;
  throw new IOException(msg,ex);
}
catch (WagonException ex) {
  String msg=""Wagon exception connecting to "" + repository;
  throw new IOException(msg,ex);
}
 finally {
  try {
    wagon.disconnect();
  }
 catch (  ConnectionException ex) {
    String msg=""Wagon exception disconnecting from "" + repository;
    throw new IOException(msg,ex);
  }
}
",0,0,0,,
506,} finally {,"try {
  File f=new File(filename);
  long len=f.length();
  if (len > Integer.MAX_VALUE)   throw new IllegalArgumentException(""Report file "" + filename + "" too big to process (> 32K)!"");
  int intlen=new Long(len).intValue();
  byte[] b=new byte[intlen];
  fis=new FileInputStream(f);
  fis.read(b);
  String s=new String(b);
  return s;
}
  finally {
  if (fis != null) {
    try {
      fis.close();
    }
 catch (    IOException e) {
      throw e;
    }
  }
}
",0,0,0,,
507,} finally {,"try {
  br=new BufferedReader(new FileReader(measuredFile));
  String readLine, value;
  int begin, end;
  while ((readLine=br.readLine()) != null && !startup_data.isEmpty()) {
    try {
      for (      String str : startup_data.keySet()) {
        begin=readLine.indexOf(str);
        if (begin != -1) {
          end=readLine.indexOf(startup_data.get(str));
          if (end <= begin) {
            end=readLine.length();
          }
          value=readLine.substring(begin + str.length(),end);
          measuredValues.put(str,new Long(value));
          startup_data.remove(str);
          break;
        }
      }
    }
 catch (    NumberFormatException nfe) {
      throw new CantParseMeasuredValuesException(nfe);
    }
  }
  return measuredValues;
}
 catch (IOException ioe) {
  throw new CantParseMeasuredValuesException(ioe);
}
 finally {
  if (br != null) {
    try {
      br.close();
    }
 catch (    IOException ioe) {
      throw new CantParseMeasuredValuesException(ioe);
    }
  }
}
",0,0,0,,
508,} finally {,"try {
  fis=new FileInputStream(locationFile);
  return getLocation(fis);
}
 catch (IOException e) {
  throw new ProjectImporterException(""Error during reading "" + "".location file"",e);
}
 finally {
  if (fis != null) {
    try {
      fis.close();
    }
 catch (    IOException e) {
      throw new ProjectImporterException(e);
    }
  }
}
",0,0,0,,
509,} finally {,"try {
  raf=new RandomAccessFile(file,""rw"");
  try {
    lock=raf.getChannel().tryLock(position,size,shared);
    if (lock == null) {
      return true;
    }
  }
 catch (  RuntimeException ex) {
    throw new IOException(ex);
  }
  return false;
}
 catch (IOException ex) {
  return true;
}
 finally {
  try {
    if (lock != null) {
      lock.release();
    }
    if (raf != null) {
      raf.close();
    }
  }
 catch (  IOException ex) {
    throw new BuildException(""Cannot close "" + file,ex);
  }
}
",0,0,0,,
510,} finally {,"try {
  progress.setPercentage(Progress.START);
  fos=new FileOutputStream(outputFile,false);
  long bundledSize=getBundledFilesSize();
  long total=bundledSize;
  if (stubFile != null) {
    total+=FileUtils.getSize(stubFile);
  }
  addExeInitialStub(fos,progress,total);
  LogManager.log(""Adding i18n..."");
  addI18NStrings(fos);
  addData(fos,jvmArguments,true);
  LogManager.log(""JVM Arguments: "" + ((jvmArguments != null) ? StringUtils.asString(jvmArguments,"" "") : StringUtils.EMPTY_STRING));
  addData(fos,appArguments,true);
  LogManager.log(""App Arguments: "" + ((appArguments != null) ? StringUtils.asString(appArguments,"" "") : StringUtils.EMPTY_STRING));
  addData(fos,mainClass,true);
  LogManager.log(""Main Class : "" + mainClass);
  addData(fos,testJVMClass,true);
  LogManager.log(""TestJVM Class : "" + testJVMClass);
  addNumber(fos,new Long("""" + compatibleJava.size()).longValue());
  addJavaCompatibleProperties(fos);
  addNumber(fos,getBundledFilesNumber());
  addNumber(fos,bundledSize,true);
  addFileSection(fos,testJVMFile,progress,total);
  LogManager.log(""Adding JVM external locations and bundled files"");
  addData(fos,jvms,progress,total);
  LogManager.log(""Adding bundled and external jars"");
  addData(fos,jars,progress,total);
  LogManager.log(""Adding other resources"");
  addData(fos,otherResources,progress,total);
}
 catch (IOException ex) {
  LogManager.log(ex);
  try {
    if (fos != null) {
      fos.close();
    }
  }
 catch (  IOException e) {
    LogManager.log(e);
  }
  try {
    FileUtils.deleteFile(outputFile);
  }
 catch (  IOException e) {
    LogManager.log(e);
  }
  fos=null;
}
 finally {
  if (fos != null) {
    try {
      fos.close();
    }
 catch (    IOException ex) {
      LogManager.log(ex.toString());
      throw ex;
    }
  }
  progress.setPercentage(Progress.COMPLETE);
}
",0,0,0,,
511,} finally {,"try {
  progress.setPercentage(Progress.START);
  long total=getBundledFilesSize();
  fos=new FileOutputStream(outputFile,false);
  StringBuilder sb=new StringBuilder(getStubString());
  addShInitialComment(sb);
  addPossibleJavaLocations(sb);
  addI18NStrings(sb);
  addTestJVMFile(sb);
  addClasspathJars(sb);
  addJavaCompatible(sb);
  addOtherResources(sb);
  addNumberVariable(sb,""TOTAL_BUNDLED_FILES_SIZE"",getBundledFilesSize());
  addNumberVariable(sb,""TOTAL_BUNDLED_FILES_NUMBER"",getBundledFilesNumber());
  LogManager.log(""Main Class : "" + mainClass);
  addStringVariable(sb,""MAIN_CLASS"",mainClass);
  LogManager.log(""TestJVM Class : "" + testJVMClass);
  addStringVariable(sb,""TEST_JVM_CLASS"",testJVMClass);
  addNumberVariable(sb,""JVM_ARGUMENTS_NUMBER"",jvmArguments.size());
  int counter=0;
  for (  String arg : jvmArguments) {
    addStringVariable(sb,""JVM_ARGUMENT_"" + (counter),escapeVarSign(escapeSlashes(arg)));
    LogManager.log(""... jvm argument ["" + counter + ""] = ""+ arg);
    counter++;
  }
  addNumberVariable(sb,""APP_ARGUMENTS_NUMBER"",appArguments.size());
  counter=0;
  for (  String arg : appArguments) {
    addStringVariable(sb,""APP_ARGUMENT_"" + (counter),escapeVarSign(escapeSlashes(arg)));
    LogManager.log(""... app argument ["" + counter + ""] = ""+ arg);
    counter++;
  }
  String token=""_^_^_^_^_^_^_^_^"";
  sb.append(""LAUNCHER_STUB_SIZE="" + token + SH_LINE_SEPARATOR);
  sb.append(""entryPoint \""$@\"""" + SH_LINE_SEPARATOR);
  nextLine(sb);
  long size=sb.length();
  long fullBlocks=(size - (size % SH_BLOCK)) / SH_BLOCK + 1;
  String str=Long.toString(fullBlocks);
  int spaces=token.length() - str.length();
  for (int j=0; j < spaces; j++) {
    str+=StringUtils.SPACE;
  }
  sb.replace(sb.indexOf(token),sb.indexOf(token) + token.length(),str);
  long pads=fullBlocks * SH_BLOCK - size;
  for (long i=0; i < pads; i++) {
    sb.append(SH_COMMENT);
  }
  addStringBuilder(fos,sb,false);
  addBundledData(fos,progress,total);
}
 catch (IOException ex) {
  LogManager.log(ex);
  try {
    fos.close();
  }
 catch (  IOException e) {
    LogManager.log(e);
  }
  try {
    FileUtils.deleteFile(outputFile);
  }
 catch (  IOException e) {
    LogManager.log(e);
  }
  fos=null;
}
 finally {
  if (fos != null) {
    try {
      fos.close();
    }
 catch (    IOException ex) {
      LogManager.log(ex);
      throw ex;
    }
  }
  progress.setPercentage(Progress.COMPLETE);
}
",0,0,0,,
512,} finally {,"try {
  StringBuilder sb=new StringBuilder();
  listFile(root,root,sb);
  fos=new FileOutputStream(outFile);
  fos.write(sb.toString().getBytes());
}
 catch (IOException ex) {
  throw new BuildException(ex);
}
 finally {
  if (fos != null) {
    try {
      fos.close();
    }
 catch (    IOException ex) {
      throw new BuildException(ex);
    }
  }
}
",0,0,0,,
513,} finally {,"try {
  pw=new PrintWriter(new OutputStreamWriter(new BufferedOutputStream(info.outputStream(safeName)),""UTF8""));
  map.writeToXML(pw);
  pw.flush();
}
 catch (IOException iex) {
  ioexc=iex;
}
 finally {
  if (pw != null) {
    pw.close();
  }
  if (ioexc != null) {
    try {
      deleteFile(safeName);
    }
 catch (    IOException ioe) {
      if (ioe.getCause() == null) {
        ioe.initCause(ioexc);
      }
      throw ioe;
    }
    throw ioexc;
  }
 else {
    for (int counter=0; ; counter++) {
      try {
        deleteFile(fullName);
      }
 catch (      IOException iex2) {
        FileSystem.LOG.log(Level.INFO,""Cannot delete "" + fullName,iex2);
      }
      try {
        this.change.rename(safeName,fullName);
        break;
      }
 catch (      IOException ex) {
        FileSystem.LOG.log(Level.INFO,""Cannot rename "" + fullName + "" to ""+ safeName,ex);
        if (counter > 10) {
          throw ex;
        }
      }
    }
  }
}
",0,0,0,,
514,} finally {,"try {
  this.file=file;
  this.who=new Exception(""Assigned from here"");
  byte[] arr=new byte[4096];
  is=file.getInputStream();
  is.read(arr);
}
 catch (IOException ex) {
  throw new IllegalStateException(ex);
}
 finally {
  if (is != null) {
    try {
      is.close();
    }
 catch (    IOException ex) {
      throw new IllegalStateException(ex);
    }
  }
}
",0,0,0,,
515,} finally {,"try {
  this.file=file;
  this.who=new Exception(""Assigned from here"");
  byte[] arr=new byte[4096];
  is=file.getInputStream();
  is.read(arr);
}
 catch (IOException ex) {
  throw new IllegalStateException(ex);
}
 finally {
  if (is != null) {
    try {
      is.close();
    }
 catch (    IOException ex) {
      throw new IllegalStateException(ex);
    }
  }
}
",0,0,0,,
516,} finally {,"try {
  this.file=file;
  this.who=new Exception(""Assigned from here"");
  byte[] arr=new byte[4096];
  is=file.getInputStream();
  is.read(arr);
}
 catch (IOException ex) {
  throw new IllegalStateException(ex);
}
 finally {
  if (is != null) {
    try {
      is.close();
    }
 catch (    IOException ex) {
      throw new IllegalStateException(ex);
    }
  }
}
",0,0,0,,
517,} finally {,"try {
  children.callAddNotify();
}
  finally {
synchronized (LOCK) {
class Notify implements Runnable {
      public Notify(      EntrySupportLazyState old){
        EntrySupportLazyState s=internal.get();
        setState(s,s.changeInited(true));
      }
      @Override public void run(){
synchronized (LOCK) {
          EntrySupportLazyState s=internal.get();
          if (s.isInited()) {
            setState(s,s.changeThread(null));
          }
 else {
            throw new IllegalStateException();
          }
          LOCK.notifyAll();
        }
      }
    }
    Notify notify=new Notify(state);
    if (Children.MUTEX.isReadAccess()) {
      Children.MUTEX.postWriteRequest(notify);
    }
 else {
      notify.run();
    }
  }
}
",0,0,0,,
518,} finally {,"try {
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  if (r instanceof InterruptedException) {
    if (count++ < 1000) {
      notify=false;
      try {
        Thread.sleep(30);
      }
 catch (      InterruptedException ignore) {
      }
      JS.execute(this);
      return;
    }
  }
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  if (notify) {
    notifyAll();
  }
  try {
    a.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
}
",0,0,0,,
519,} finally {,"try {
  is=u.openStream();
  byte[] arr=new byte[is.available()];
  int len=0;
  while (len < arr.length) {
    int read=is.read(arr,len,arr.length - len);
    if (read == -1) {
      throw new IOException(""Can't read "" + u);
    }
    len+=read;
  }
  is.close();
  is=null;
  if (JsPkgCache.process(this,name)) {
    arr=FnUtils.transform(arr,this);
  }
  return defineClass(name,arr,0,arr.length);
}
 catch (IOException ex) {
  throw new ClassNotFoundException(""Can't load "" + name,ex);
}
 finally {
  try {
    if (is != null)     is.close();
  }
 catch (  IOException ex) {
    throw new ClassNotFoundException(null,ex);
  }
}
",0,0,0,,
520,} finally {,"try {
  if (updateName != null) {
    updateName.invoke(null,getTestName(),cnt);
  }
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
  if (updateName != null) {
    updateName.invoke(null,getTestName(),""Done"");
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  try {
    c.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
  if (finished != null) {
    finished.countDown();
  }
}
",0,0,0,,
521,} finally {,"try {
  if (p instanceof Testing) {
    Testing tp=(Testing)p;
    tp.beforeTest(m.getDeclaringClass());
  }
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  try {
    c.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
  if (finished != null) {
    finished.countDown();
  }
}
",0,0,0,,
522,} finally {,"try {
  a=(Closeable)itClass.getMethod(""activateInOSGi"",Object.class).invoke(null,p);
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  if (r instanceof InterruptedException) {
    if (count++ < 10000) {
      notify=false;
      try {
        Thread.sleep(100);
      }
 catch (      Exception ex1) {
      }
      Platform.runLater(this);
      return;
    }
  }
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  if (notify) {
    notifyAll();
  }
  try {
    if (a != null)     a.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
}
",0,0,0,,
523,} finally {,"try {
  a=KnockoutEquinoxIT.activateInOSGi(p);
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  if (r instanceof InterruptedException) {
    if (count++ < 10000) {
      notify=false;
      try {
        Thread.sleep(100);
      }
 catch (      Exception ex1) {
      }
      Platform.runLater(this);
      return;
    }
  }
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  if (notify) {
    notifyAll();
  }
  try {
    if (a != null)     a.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
}
",0,0,0,,
524,} finally {,"try {
  if (inst == null) {
    inst=m.getDeclaringClass().newInstance();
  }
  result=m.invoke(inst);
  if (result == null) {
    result=this;
  }
}
 catch (InvocationTargetException ex) {
  Throwable r=ex.getTargetException();
  if (r instanceof InterruptedException) {
    if (count++ < 10000) {
      notify=false;
      try {
        Thread.sleep(100);
      }
 catch (      Exception ex1) {
      }
      Platform.runLater(this);
      return;
    }
  }
  result=r;
}
catch (Exception ex) {
  result=ex;
}
 finally {
  if (notify) {
    notifyAll();
  }
  try {
    a.close();
  }
 catch (  IOException ex) {
    throw new IllegalStateException(ex);
  }
}
",0,0,0,,
525,} finally {,"try {
  out=new JarOutputStream(new FileOutputStream(cache));
  pack(out,cacheTemp,null,""index"",new StringBuilder(categoryId));
  segments=cacheFolder.getFileObject(""segments"").getInputStream();
  Properties in=new Properties();
  in.load(segments);
  segments.close();
  String baseDirPath=baseDirFile.toURI().toString();
  Properties outSegments=new Properties();
  for (  String segment : in.stringPropertyNames()) {
    String url=in.getProperty(segment);
    String rel;
    if (url.startsWith(baseDirPath))     rel=""rel:/"" + url.substring(baseDirPath.length());
 else     if (url.startsWith(""jar:"" + baseDirPath))     rel=""jar:rel:/"" + url.substring(4 + baseDirPath.length());
 else     rel=url;
    outSegments.setProperty(segment,rel);
  }
  out.putNextEntry(new ZipEntry(categoryId + ""/segments""));
  outSegments.store(out,"""");
  out.putNextEntry(new ZipEntry(categoryId + ""/info""));
  out.write(""{\n"".getBytes(""UTF-8""));
  out.write((""\""displayName\"": \"""" + categoryName + ""\"""").getBytes(""UTF-8""));
  if (optionValues.containsKey(INFO)) {
    for (    String infoValue : optionValues.get(INFO)[0].split("";"")) {
      int eqSign=infoValue.indexOf('=');
      if (eqSign == (-1)) {
        LOG.log(Level.INFO,""No ''='' sign in: {0}"",infoValue);
        continue;
      }
      out.write(("",\n\"""" + infoValue.substring(0,eqSign) + ""\"": \""""+ infoValue.substring(eqSign + 1)+ ""\"""").getBytes(""UTF-8""));
    }
  }
  out.write("",\n \""statistics\"" : {\n"".getBytes(""UTF-8""));
  boolean wasEntry=false;
  for (  Entry<String,Long> e : statistics.entrySet()) {
    if (wasEntry)     out.write("", \n"".getBytes(""UTF-8""));
    out.write((""\"""" + e.getKey() + ""\"" : ""+ e.getValue()).getBytes(""UTF-8""));
    wasEntry=true;
  }
  out.write(""\n}\n"".getBytes(""UTF-8""));
  out.write(""\n}\n"".getBytes(""UTF-8""));
  if (STORE_CLASSPATH) {
    out.putNextEntry(new ZipEntry(categoryId + ""/classpath""));
    for (    Entry<String,String> e : classpath.entrySet()) {
      out.write((e.getKey() + ""="" + e.getValue()+ ""\n"").getBytes(""UTF-8""));
    }
    for (    Entry<FileObject,String> ej : extraJars.entrySet()) {
      out.putNextEntry(new ZipEntry(categoryId + ""/"" + ej.getValue()));
      InputStream jarIn=ej.getKey().getInputStream();
      try {
        FileUtil.copy(jarIn,out);
      }
  finally {
        jarIn.close();
      }
    }
  }
  for (  FileObject s : cacheFolder.getChildren()) {
    if (!s.isFolder() || !s.getNameExt().startsWith(""s"") || s.getChildren().length == 0)     continue;
    JarOutputStream local=null;
    try {
      out.putNextEntry(new ZipEntry(categoryId + ""/"" + s.getNameExt()));
      local=new JarOutputStream(out);
      pack(local,s,baseDir.toURI().toString(),"""",new StringBuilder(""""));
    }
  finally {
      if (local != null) {
        local.finish();
      }
    }
  }
}
 catch (IOException ex) {
  LOG.log(Level.FINE,null,ex);
  throw (CommandException)new CommandException(0).initCause(ex);
}
 finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException ex) {
      throw (CommandException)new CommandException(0).initCause(ex);
    }
  }
  if (segments != null) {
    try {
      segments.close();
    }
 catch (    IOException ex) {
      throw (CommandException)new CommandException(0).initCause(ex);
    }
  }
}
",0,0,0,,
526,finally,"try {
  jar=new JarFile(jarFile);
  mf=jar.getManifest();
}
 catch (Exception exc) {
  throw new MojoExecutionException(""Could not open "" + jarFile + "": ""+ exc.getMessage(),exc);
}
 finally {
  if (jar != null) {
    try {
      jar.close();
    }
 catch (    IOException io) {
      throw new MojoExecutionException(io.getMessage(),io);
    }
  }
}
",0,0,0,,
527,finally,"try {
  stream=new FileInputStream(manifestFile);
  mf=new Manifest(stream);
}
 catch (Exception exc) {
  throw new MojoExecutionException(exc.getMessage(),exc);
}
 finally {
  if (stream != null) {
    try {
      stream.close();
    }
 catch (    IOException io) {
      throw new MojoExecutionException(io.getMessage(),io);
    }
  }
}
",0,0,0,,
528,} finally {,"try {
  return next;
}
  finally {
  try {
    next=getNext();
  }
 catch (  IOException e) {
    throw new TemplatesIteratorException(e);
  }
}
",0,0,0,,
529,} finally {,"try {
  xmlStreamWriter.writeEndElement();
}
 catch (XMLStreamException e) {
  throw new IOException(e);
}
 finally {
  try {
    xmlStreamWriter.close();
  }
 catch (  XMLStreamException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
530,} finally {,"try {
  if (conflictResponse.equals(APPEND_RESOLUTION) && destinationExists) {
    fos=hdfs.append(copyFile,bufferSize);
  }
 else {
    final EnumSet<CreateFlag> cflags=EnumSet.of(CreateFlag.CREATE,CreateFlag.OVERWRITE);
    if (shouldIgnoreLocality(context,session)) {
      cflags.add(CreateFlag.IGNORE_CLIENT_LOCALITY);
    }
    fos=hdfs.create(tempCopyFile,FsCreateModes.applyUMask(FsPermission.getFileDefault(),FsPermission.getUMask(hdfs.getConf())),cflags,bufferSize,replication,blockSize,null,null);
  }
  if (codec != null) {
    fos=codec.createOutputStream(fos);
  }
  createdFile=tempCopyFile;
  BufferedInputStream bis=new BufferedInputStream(in);
  StreamUtils.copy(bis,fos);
  bis=null;
  fos.flush();
}
  finally {
  try {
    if (fos != null) {
      fos.close();
    }
  }
 catch (  Throwable t) {
    if (createdFile != null) {
      try {
        hdfs.delete(createdFile,false);
      }
 catch (      Throwable ignore) {
      }
    }
    throw t;
  }
  fos=null;
}
",0,0,0,,
531,} finally {,"try {
  incrementReadCount(source);
  reader.process(createTaskTerminationStream(ffais));
  if (rawIn == currentReadClaimStream && !allowSessionStreamManagement) {
    currentReadClaimStream.close();
    currentReadClaimStream=null;
  }
}
 catch (final ContentNotFoundException cnfe) {
  cnfeThrown=true;
  throw cnfe;
}
 finally {
  decrementReadCount(source);
  bytesRead+=countingStream.getBytesRead();
  if (!cnfeThrown && ffais.getContentNotFoundException() != null) {
    throw ffais.getContentNotFoundException();
  }
}
",0,0,0,,
532,} finally {,"try {
  writer.process(createTaskTerminationStream(ffais),createTaskTerminationStream(ffaos));
}
 catch (final ContentNotFoundException cnfe) {
  cnfeThrown=true;
  throw cnfe;
}
 finally {
  writtenToFlowFile=countingOut.getBytesWritten();
  this.bytesWritten+=writtenToFlowFile;
  this.bytesRead+=countingIn.getBytesRead();
  writeRecursionSet.remove(source);
  if (!cnfeThrown && ffais.getContentNotFoundException() != null) {
    throw ffais.getContentNotFoundException();
  }
}
",0,0,0,,
533,} finally {,"try {
  incrementReadCount(source);
  StreamUtils.copy(ffais,createTaskTerminationStream(destination),source.getSize());
}
 catch (final ContentNotFoundException cnfe) {
  cnfeThrown=true;
  throw cnfe;
}
 finally {
  decrementReadCount(source);
  if (!cnfeThrown && ffais.getContentNotFoundException() != null) {
    throw ffais.getContentNotFoundException();
  }
}
",0,0,0,,
534,} finally {,"try {
  if (replicateRequest) {
    final NiFiUser user=NiFiUserUtils.getNiFiUser();
    URI replicateUri=null;
    try {
      replicateUri=new URI(requestUri.getScheme(),requestUri.getUserInfo(),requestUri.getHost(),requestUri.getPort(),replicateUriPath,null,requestUri.getFragment());
    }
 catch (    URISyntaxException e) {
      throw new RuntimeException(e);
    }
    final Map<String,String> headers=new HashMap<>();
    headers.put(""content-type"",MediaType.APPLICATION_JSON);
    final Entity replicateEntity=createReplicateUpdateFlowEntity(revision,requestEntity,flowSnapshot);
    final NodeResponse clusterResponse;
    try {
      logger.debug(""Replicating PUT request to {} for user {}"",replicateUri,user);
      if (getReplicationTarget() == ReplicationTarget.CLUSTER_NODES) {
        clusterResponse=getRequestReplicator().replicate(user,HttpMethod.PUT,replicateUri,replicateEntity,headers).awaitMergedResponse();
      }
 else {
        clusterResponse=getRequestReplicator().forwardToCoordinator(getClusterCoordinatorNode(),user,HttpMethod.PUT,replicateUri,replicateEntity,headers).awaitMergedResponse();
      }
    }
 catch (    final InterruptedException ie) {
      logger.warn(""Interrupted while replicating PUT request to {} for user {}"",replicateUri,user);
      Thread.currentThread().interrupt();
      throw new LifecycleManagementException(""Interrupted while updating flows across cluster"",ie);
    }
    final int updateFlowStatus=clusterResponse.getStatus();
    if (updateFlowStatus != Status.OK.getStatusCode()) {
      final String explanation=getResponseEntity(clusterResponse,String.class);
      logger.error(""Failed to update flow across cluster when replicating PUT request to {} for user {}. Received {} response with explanation: {}"",replicateUri,user,updateFlowStatus,explanation);
      throw new LifecycleManagementException(""Failed to update Flow on all nodes in cluster due to "" + explanation);
    }
  }
 else {
    serviceFacade.verifyCanUpdate(groupId,flowSnapshot,true,!allowDirtyFlowUpdate);
    performUpdateFlow(groupId,revision,requestEntity,flowSnapshot,idGenerationSeed,!allowDirtyFlowUpdate,true);
  }
}
  finally {
  if (!asyncRequest.isCancelled()) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Re-Enabling {} Controller Services: {}"",enabledServices.size(),enabledServices);
    }
    asyncRequest.markStepComplete();
    final CancellableTimedPause enableServicesPause=new CancellableTimedPause(250,Long.MAX_VALUE,TimeUnit.MILLISECONDS);
    asyncRequest.setCancelCallback(enableServicesPause::cancel);
    final Set<AffectedComponentEntity> servicesToEnable=getUpdatedEntities(enabledServices);
    logger.info(""Successfully updated flow; re-enabling {} Controller Services"",servicesToEnable.size());
    try {
      componentLifecycle.activateControllerServices(requestUri,groupId,servicesToEnable,ControllerServiceState.ENABLED,enableServicesPause,InvalidComponentAction.SKIP);
    }
 catch (    final IllegalStateException ise) {
      throw new ResumeFlowException(""Successfully updated flow but could not re-enable all Controller Services because "" + ise.getMessage(),ise);
    }
  }
  if (!asyncRequest.isCancelled()) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Restart {} Processors: {}"",runningComponents.size(),runningComponents);
    }
    asyncRequest.markStepComplete();
    final Set<AffectedComponentEntity> componentsToStart=getUpdatedEntities(runningComponents);
    final Set<AffectedComponentEntity> avoidStarting=new HashSet<>();
    for (    final AffectedComponentEntity componentEntity : componentsToStart) {
      final AffectedComponentDTO componentDto=componentEntity.getComponent();
      final String referenceType=componentDto.getReferenceType();
      if (!AffectedComponentDTO.COMPONENT_TYPE_REMOTE_INPUT_PORT.equals(referenceType) && !AffectedComponentDTO.COMPONENT_TYPE_REMOTE_OUTPUT_PORT.equals(referenceType)) {
        continue;
      }
      boolean startComponent;
      try {
        startComponent=serviceFacade.isRemoteGroupPortConnected(componentDto.getProcessGroupId(),componentDto.getId());
      }
 catch (      final ResourceNotFoundException rnfe) {
        startComponent=false;
      }
      if (!startComponent) {
        avoidStarting.add(componentEntity);
      }
    }
    componentsToStart.removeAll(avoidStarting);
    final CancellableTimedPause startComponentsPause=new CancellableTimedPause(250,Long.MAX_VALUE,TimeUnit.MILLISECONDS);
    asyncRequest.setCancelCallback(startComponentsPause::cancel);
    logger.info(""Restarting {} Processors"",componentsToStart.size());
    try {
      componentLifecycle.scheduleComponents(requestUri,groupId,componentsToStart,ScheduledState.RUNNING,startComponentsPause,InvalidComponentAction.SKIP);
    }
 catch (    final IllegalStateException ise) {
      throw new ResumeFlowException(""Successfully updated flow but could not restart all Processors because "" + ise.getMessage(),ise);
    }
  }
}
",0,0,0,,
535,} finally {,"try {
  boolean completed=false;
  for (int i=0; i < 30; i++) {
    final ParameterContextUpdateRequestEntity retrievedUpdateRequest=client.getParamContextUpdateRequest(contextId,updateRequestId);
    if (retrievedUpdateRequest != null && retrievedUpdateRequest.getRequest().isComplete()) {
      completed=true;
      break;
    }
 else {
      try {
        if (getContext().isInteractive()) {
          println(""Waiting for update request to complete..."");
        }
        Thread.sleep(2000);
      }
 catch (      InterruptedException e) {
        e.printStackTrace();
      }
    }
  }
  if (!completed) {
    cancelled.set(true);
  }
}
  finally {
  final ParameterContextUpdateRequestEntity deleteUpdateRequest=client.deleteParamContextUpdateRequest(contextId,updateRequestId);
  final String failureReason=deleteUpdateRequest.getRequest().getFailureReason();
  if (!StringUtils.isBlank(failureReason)) {
    throw new NiFiClientException(failureReason);
  }
  if (cancelled.get()) {
    throw new NiFiClientException(""Unable to update parameter context, cancelling update request"");
  }
  return deleteUpdateRequest;
}
",0,0,0,,
536,} finally {,"try {
  return next;
}
  finally {
  try {
    next=getNext();
  }
 catch (  IOException e) {
    throw new TemplatesIteratorException(e);
  }
}
",0,0,0,,
537,} finally {,"try {
  beganTransaction=TransactionUtil.begin();
  int maxRows=startIndex + number;
  EntityListIterator eli=this.getEli(question,maxRows);
  if (startIndex > 0 && number > 0) {
    resp=eli.getPartialList(startIndex,number);
  }
 else {
    resp=eli.getCompleteList();
  }
  eli.close();
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),module);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
538,} finally {,"try {
  beganTransaction=TransactionUtil.begin();
  long[] result={0,0,0};
  EntityListIterator eli=this.getEli(question,-1);
  if (eli != null) {
    GenericValue value;
    while (((value=eli.next()) != null)) {
      if (""Y"".equalsIgnoreCase(value.getString(""booleanResponse""))) {
        result[1]++;
      }
 else {
        result[2]++;
      }
      result[0]++;
    }
    eli.close();
  }
  return result;
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Boolean result"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),module);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
539,} finally {,"try {
  beganTransaction=TransactionUtil.begin();
  EntityListIterator eli=this.getEli(question,-1);
  if (eli != null) {
    GenericValue value;
    while (((value=eli.next()) != null)) {
switch (type) {
case 1:
        Long n=value.getLong(""numericResponse"");
      if (UtilValidate.isNotEmpty(n)) {
        result[1]+=n.longValue();
      }
    break;
case 2:
  Double c=value.getDouble(""currencyResponse"");
if (UtilValidate.isNotEmpty(c)) {
  result[1]+=(((double)Math.round((c.doubleValue() - c.doubleValue()) * 100)) / 100);
}
break;
case 3:
Double f=value.getDouble(""floatResponse"");
if (UtilValidate.isNotEmpty(f)) {
result[1]+=f.doubleValue();
}
break;
}
result[0]++;
}
eli.close();
}
}
 catch (GenericEntityException e) {
try {
TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Number result"",e);
}
 catch (GenericEntityException e2) {
Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),module);
}
throw new SurveyWrapperException(e);
}
 finally {
try {
TransactionUtil.commit(beganTransaction);
}
 catch (GenericEntityException e) {
throw new SurveyWrapperException(e);
}
}
",0,0,0,,
540,} finally {,"try {
  beganTransaction=TransactionUtil.begin();
  EntityListIterator eli=this.getEli(question,-1);
  if (eli != null) {
    GenericValue value;
    while (((value=eli.next()) != null)) {
      String optionId=value.getString(""surveyOptionSeqId"");
      if (UtilValidate.isNotEmpty(optionId)) {
        Long optCount=(Long)result.remove(optionId);
        if (optCount == null) {
          optCount=Long.valueOf(1);
        }
 else {
          optCount=Long.valueOf(1 + optCount.longValue());
        }
        result.put(optionId,optCount);
        total++;
      }
    }
    eli.close();
  }
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Option result"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),module);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
541,} finally {,"try {
  writeDataFile(fos);
}
  finally {
  try {
    if (fos != null)     fos.close();
  }
 catch (  IOException e) {
    throw new DataFileException(""Could not close file "" + filename + "", may not have written correctly;"",e);
  }
}
",0,0,0,,
542,} finally {,"try {
  in=new ObjectInputStream(binaryInput);
  return in.readObject();
}
 catch (IOException ex) {
  if (Debug.verboseOn())   Debug.logVerbose(""Unable to read BLOB data from input stream while getting value : "" + curField.getName() + "" [""+ curField.getColName()+ ""] (""+ ind+ ""): ""+ ex.toString(),module);
  return null;
}
catch (ClassNotFoundException ex) {
  if (Debug.verboseOn())   Debug.logVerbose(""Class not found: Unable to cast BLOB data to an Java object while getting value: "" + curField.getName() + "" [""+ curField.getColName()+ ""] (""+ ind+ ""); most likely because it is a straight byte[], so just using the raw bytes""+ ex.toString(),module);
  return null;
}
 finally {
  if (in != null) {
    try {
      in.close();
    }
 catch (    IOException e) {
      throw new GenericDataSourceException(""Unable to close binary input stream while getting value : "" + curField.getName() + "" [""+ curField.getColName()+ ""] (""+ ind+ ""): ""+ e.toString(),e);
    }
  }
}
",0,0,0,,
543,} finally {,"try {
  this.createKey(keyName,handlers[0],encryptMethod);
}
 catch (EntityCryptoException e) {
  caught=e;
}
 finally {
  try {
    key=this.findKey(keyName,handlers[0]);
  }
 catch (  EntityCryptoException e) {
    throw caught != null ? caught : e;
  }
  if (key == null) {
    throw caught != null ? caught : new EntityCryptoException(""could not lookup key ("" + keyName + "") after creation"");
  }
}
",0,0,0,,
544,} finally {,"try {
  while ((theEntry=eli.next()) != null) {
    entryFma.put(methodContext.getEnvMap(),theEntry);
    try {
      for (      MethodOperation methodOperation : subOps) {
        if (!methodOperation.exec(methodContext)) {
          return false;
        }
      }
    }
 catch (    MiniLangException e) {
      if (e instanceof BreakElementException) {
        break;
      }
      if (e instanceof ContinueElementException) {
        continue;
      }
      throw e;
    }
  }
}
  finally {
  try {
    eli.close();
  }
 catch (  GenericEntityException e) {
    throw new MiniLangRuntimeException(""Error closing entityListIterator: "" + e.getMessage(),this);
  }
}
",0,0,0,,
545,} finally {,"try {
  int lockRetriesRemaining=LOCK_RETRIES;
  boolean needsLockRetry=false;
  do {
    needsLockRetry=false;
    lockRetriesRemaining--;
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-rollback"",ctx,context,result,isError,isFailure);
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-commit"",ctx,context,result,isError,isFailure);
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""auth"",ctx,context,result,isError,isFailure);
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    context=checkAuth(localName,context,modelService);
    GenericValue userLogin=(GenericValue)context.get(""userLogin"");
    if (modelService.auth && userLogin == null) {
      throw new ServiceAuthException(""User authorization is required for this service: "" + modelService.name + modelService.debugInfo());
    }
    if (userLogin != null && userLogin.getString(""userLoginId"") != null) {
      GenericDelegator.pushUserIdentifier(userLogin.getString(""userLoginId""));
    }
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""in-validate"",ctx,context,result,isError,isFailure);
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (modelService.validate && !isError && !isFailure) {
      try {
        modelService.validate(context,ModelService.IN_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        Debug.logError(e,""Incoming context (in runSync : "" + modelService.name + "") does not match expected requirements"",module);
        throw e;
      }
    }
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""invoke"",ctx,context,result,isError,isFailure);
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (!isError && !isFailure) {
      Map<String,Object> invokeResult=null;
      invokeResult=engine.runSync(localName,modelService,context);
      engine.sendCallbacks(modelService,context,invokeResult,GenericEngine.SYNC_MODE);
      if (invokeResult != null) {
        result.putAll(invokeResult);
      }
 else {
        Debug.logWarning(""Service (in runSync : "" + modelService.name + "") returns null result"",module);
      }
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (beganTrans) {
      String errMsg=ServiceUtil.getErrorMessage(result);
      if (errMsg != null && errMsg.toUpperCase().indexOf(""DEADLOCK"") >= 0) {
        String retryMsg=""RETRYING SERVICE ["" + modelService.name + ""]: Deadlock error found in message [""+ errMsg+ ""]; retry [""+ (LOCK_RETRIES - lockRetriesRemaining)+ ""] of [""+ LOCK_RETRIES+ ""]"";
        TransactionUtil.rollback(beganTrans,retryMsg,null);
        beganTrans=TransactionUtil.begin(modelService.transactionTimeout);
        if (beganTrans && TransactionUtil.debugResources()) {
          DebugXaResource dxa=new DebugXaResource(modelService.name);
          try {
            dxa.enlist();
          }
 catch (          Exception e) {
            Debug.logError(e,module);
          }
        }
        if (!beganTrans) {
          Debug.logError(""After rollback attempt for lock retry did not begin a new transaction!"",module);
        }
 else {
          needsLockRetry=true;
          result=new HashMap<String,Object>();
          isFailure=false;
          isError=false;
          Debug.logWarning(retryMsg,module);
        }
        if (errMsg != null && (errMsg.indexOf(""A lock could not be obtained within the time requested"") >= 0 || errMsg.indexOf(""Lock wait timeout exceeded"") >= 0)) {
        }
      }
    }
  }
 while (needsLockRetry && lockRetriesRemaining > 0);
  ecaContext=new HashMap<String,Object>();
  ecaContext.putAll(context);
  ecaContext.putAll(result);
  modelService.updateDefaultValues(context,ModelService.OUT_PARAM);
  if (modelService.validate && validateOut) {
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""out-validate"",ctx,ecaContext,result,isError,isFailure);
    try {
      modelService.validate(result,ModelService.OUT_PARAM,locale);
    }
 catch (    ServiceValidationException e) {
      throw new GenericServiceException(""Outgoing result (in runSync : "" + modelService.name + "") does not match expected requirements"",e);
    }
  }
  if (eventMap != null)   ServiceEcaUtil.evalRules(modelService.name,eventMap,""commit"",ctx,ecaContext,result,isError,isFailure);
  isFailure=ServiceUtil.isFailure(result);
  isError=ServiceUtil.isError(result);
  if (eventMap != null)   ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-commit-post-run"",ctx,ecaContext,result,isError,isFailure);
  if (isFailure) {
    Debug.logWarning(""Service Failure ["" + modelService.name + ""]: ""+ ServiceUtil.getErrorMessage(result),module);
  }
}
 catch (Throwable t) {
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + modelService.name,""Sync service failed..."",module);
  }
  String errMsg=""Service ["" + modelService.name + ""] threw an unexpected exception/error"";
  engine.sendCallbacks(modelService,context,t,GenericEngine.SYNC_MODE);
  try {
    TransactionUtil.rollback(beganTrans,errMsg,t);
  }
 catch (  GenericTransactionException te) {
    Debug.logError(te,""Cannot rollback transaction"",module);
  }
  rs.setEndStamp();
  if (t instanceof ServiceAuthException) {
    throw (ServiceAuthException)t;
  }
 else   if (t instanceof ServiceValidationException) {
    throw (ServiceValidationException)t;
  }
 else   if (t instanceof GenericServiceException) {
    throw (GenericServiceException)t;
  }
 else {
    throw new GenericServiceException(""Service ["" + modelService.name + ""] Failed""+ modelService.debugInfo(),t);
  }
}
 finally {
  if (isError) {
    String errMsg=""Error in Service ["" + modelService.name + ""]: ""+ ServiceUtil.getErrorMessage(result);
    Debug.logError(errMsg,module);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,null);
    }
 catch (    GenericTransactionException e) {
      Debug.logError(e,""Could not rollback transaction: "" + e.toString(),module);
    }
  }
 else {
    try {
      TransactionUtil.commit(beganTrans);
    }
 catch (    GenericTransactionException e) {
      GenericDelegator.popUserIdentifier();
      String errMsg=""Could not commit transaction for service ["" + modelService.name + ""] call"";
      Debug.logError(e,errMsg,module);
      if (e.getMessage() != null) {
        errMsg=errMsg + "": "" + e.getMessage();
      }
      throw new GenericServiceException(errMsg);
    }
  }
  modelService.evalNotifications(this.getLocalContext(localName),context,result);
  GenericDelegator.popUserIdentifier();
}
",0,0,0,,
546,} finally {,"try {
  if (""wait"".equals(modelService.semaphore) || ""fail"".equals(modelService.semaphore)) {
    lock=new ServiceSemaphore(delegator,modelService);
    lock.acquire();
  }
  if (Debug.verboseOn() || modelService.debug) {
    Debug.logVerbose(""[ServiceDispatcher.runSync] : invoking service "" + modelService.name + "" [""+ modelService.location+ ""/""+ modelService.invoke+ ""] (""+ modelService.engineName+ "")"",module);
  }
  Map<String,Object> context=new HashMap<String,Object>();
  if (params != null) {
    context.putAll(params);
  }
  Locale locale=this.checkLocale(context);
  rs=this.logService(localName,modelService,GenericEngine.SYNC_MODE);
  eventMap=ServiceEcaUtil.getServiceEventMap(modelService.name);
  engine=this.getGenericEngine(modelService.engineName);
  modelService.updateDefaultValues(context,ModelService.IN_PARAM);
  if (modelService.useTransaction) {
    if (TransactionUtil.isTransactionInPlace()) {
      if (modelService.requireNewTransaction) {
        parentTransaction=TransactionUtil.suspend();
        if (TransactionUtil.isTransactionInPlace()) {
          throw new GenericTransactionException(""In service "" + modelService.name + "" transaction is still in place after suspend, status is ""+ TransactionUtil.getStatusString());
        }
        beganTrans=TransactionUtil.begin(modelService.transactionTimeout);
      }
    }
 else {
      beganTrans=TransactionUtil.begin(modelService.transactionTimeout);
    }
    if (beganTrans && TransactionUtil.debugResources()) {
      DebugXaResource dxa=new DebugXaResource(modelService.name);
      try {
        dxa.enlist();
      }
 catch (      Exception e) {
        Debug.logError(e,module);
      }
    }
  }
  try {
    int lockRetriesRemaining=LOCK_RETRIES;
    boolean needsLockRetry=false;
    do {
      needsLockRetry=false;
      lockRetriesRemaining--;
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-rollback"",ctx,context,result,isError,isFailure);
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-commit"",ctx,context,result,isError,isFailure);
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""auth"",ctx,context,result,isError,isFailure);
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      context=checkAuth(localName,context,modelService);
      GenericValue userLogin=(GenericValue)context.get(""userLogin"");
      if (modelService.auth && userLogin == null) {
        throw new ServiceAuthException(""User authorization is required for this service: "" + modelService.name + modelService.debugInfo());
      }
      if (userLogin != null && userLogin.getString(""userLoginId"") != null) {
        GenericDelegator.pushUserIdentifier(userLogin.getString(""userLoginId""));
      }
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""in-validate"",ctx,context,result,isError,isFailure);
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (modelService.validate && !isError && !isFailure) {
        try {
          modelService.validate(context,ModelService.IN_PARAM,locale);
        }
 catch (        ServiceValidationException e) {
          Debug.logError(e,""Incoming context (in runSync : "" + modelService.name + "") does not match expected requirements"",module);
          throw e;
        }
      }
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""invoke"",ctx,context,result,isError,isFailure);
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (!isError && !isFailure) {
        Map<String,Object> invokeResult=null;
        invokeResult=engine.runSync(localName,modelService,context);
        engine.sendCallbacks(modelService,context,invokeResult,GenericEngine.SYNC_MODE);
        if (invokeResult != null) {
          result.putAll(invokeResult);
        }
 else {
          Debug.logWarning(""Service (in runSync : "" + modelService.name + "") returns null result"",module);
        }
      }
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (beganTrans) {
        String errMsg=ServiceUtil.getErrorMessage(result);
        if (errMsg != null && errMsg.toUpperCase().indexOf(""DEADLOCK"") >= 0) {
          String retryMsg=""RETRYING SERVICE ["" + modelService.name + ""]: Deadlock error found in message [""+ errMsg+ ""]; retry [""+ (LOCK_RETRIES - lockRetriesRemaining)+ ""] of [""+ LOCK_RETRIES+ ""]"";
          TransactionUtil.rollback(beganTrans,retryMsg,null);
          beganTrans=TransactionUtil.begin(modelService.transactionTimeout);
          if (beganTrans && TransactionUtil.debugResources()) {
            DebugXaResource dxa=new DebugXaResource(modelService.name);
            try {
              dxa.enlist();
            }
 catch (            Exception e) {
              Debug.logError(e,module);
            }
          }
          if (!beganTrans) {
            Debug.logError(""After rollback attempt for lock retry did not begin a new transaction!"",module);
          }
 else {
            needsLockRetry=true;
            result=new HashMap<String,Object>();
            isFailure=false;
            isError=false;
            Debug.logWarning(retryMsg,module);
          }
          if (errMsg != null && (errMsg.indexOf(""A lock could not be obtained within the time requested"") >= 0 || errMsg.indexOf(""Lock wait timeout exceeded"") >= 0)) {
          }
        }
      }
    }
 while (needsLockRetry && lockRetriesRemaining > 0);
    ecaContext=new HashMap<String,Object>();
    ecaContext.putAll(context);
    ecaContext.putAll(result);
    modelService.updateDefaultValues(context,ModelService.OUT_PARAM);
    if (modelService.validate && validateOut) {
      if (eventMap != null)       ServiceEcaUtil.evalRules(modelService.name,eventMap,""out-validate"",ctx,ecaContext,result,isError,isFailure);
      try {
        modelService.validate(result,ModelService.OUT_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        throw new GenericServiceException(""Outgoing result (in runSync : "" + modelService.name + "") does not match expected requirements"",e);
      }
    }
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""commit"",ctx,ecaContext,result,isError,isFailure);
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (eventMap != null)     ServiceEcaUtil.evalRules(modelService.name,eventMap,""global-commit-post-run"",ctx,ecaContext,result,isError,isFailure);
    if (isFailure) {
      Debug.logWarning(""Service Failure ["" + modelService.name + ""]: ""+ ServiceUtil.getErrorMessage(result),module);
    }
  }
 catch (  Throwable t) {
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + modelService.name,""Sync service failed..."",module);
    }
    String errMsg=""Service ["" + modelService.name + ""] threw an unexpected exception/error"";
    engine.sendCallbacks(modelService,context,t,GenericEngine.SYNC_MODE);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,t);
    }
 catch (    GenericTransactionException te) {
      Debug.logError(te,""Cannot rollback transaction"",module);
    }
    rs.setEndStamp();
    if (t instanceof ServiceAuthException) {
      throw (ServiceAuthException)t;
    }
 else     if (t instanceof ServiceValidationException) {
      throw (ServiceValidationException)t;
    }
 else     if (t instanceof GenericServiceException) {
      throw (GenericServiceException)t;
    }
 else {
      throw new GenericServiceException(""Service ["" + modelService.name + ""] Failed""+ modelService.debugInfo(),t);
    }
  }
 finally {
    if (isError) {
      String errMsg=""Error in Service ["" + modelService.name + ""]: ""+ ServiceUtil.getErrorMessage(result);
      Debug.logError(errMsg,module);
      try {
        TransactionUtil.rollback(beganTrans,errMsg,null);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not rollback transaction: "" + e.toString(),module);
      }
    }
 else {
      try {
        TransactionUtil.commit(beganTrans);
      }
 catch (      GenericTransactionException e) {
        GenericDelegator.popUserIdentifier();
        String errMsg=""Could not commit transaction for service ["" + modelService.name + ""] call"";
        Debug.logError(e,errMsg,module);
        if (e.getMessage() != null) {
          errMsg=errMsg + "": "" + e.getMessage();
        }
        throw new GenericServiceException(errMsg);
      }
    }
    modelService.evalNotifications(this.getLocalContext(localName),context,result);
    GenericDelegator.popUserIdentifier();
  }
}
 catch (GenericTransactionException te) {
  Debug.logError(te,""Problems with the transaction"",module);
  throw new GenericServiceException(""Problems with the transaction."",te.getNested());
}
 finally {
  if (lock != null) {
    try {
      lock.release();
    }
 catch (    GenericServiceException e) {
      Debug.logWarning(e,""Exception thrown while unlocking semaphore: "",module);
    }
  }
  if (parentTransaction != null) {
    try {
      TransactionUtil.resume(parentTransaction);
    }
 catch (    GenericTransactionException ite) {
      Debug.logWarning(ite,""Transaction error, not resumed"",module);
      throw new GenericServiceException(""Resume transaction exception, see logs"");
    }
  }
}
",0,0,0,,
547,} finally {,"try {
  Map<String,List<ServiceEcaRule>> eventMap=ServiceEcaUtil.getServiceEventMap(service.name);
  if (eventMap != null)   ServiceEcaUtil.evalRules(service.name,eventMap,""auth"",ctx,context,result,isError,isFailure);
  context=checkAuth(localName,context,service);
  Object userLogin=context.get(""userLogin"");
  if (service.auth && userLogin == null) {
    throw new ServiceAuthException(""User authorization is required for this service: "" + service.name + service.debugInfo());
  }
  if (eventMap != null)   ServiceEcaUtil.evalRules(service.name,eventMap,""in-validate"",ctx,context,result,isError,isFailure);
  isFailure=ModelService.RESPOND_FAIL.equals(result.get(ModelService.RESPONSE_MESSAGE));
  isError=ModelService.RESPOND_ERROR.equals(result.get(ModelService.RESPONSE_MESSAGE));
  if (service.validate && !isError && !isFailure) {
    try {
      service.validate(context,ModelService.IN_PARAM,locale);
    }
 catch (    ServiceValidationException e) {
      Debug.logError(e,""Incoming service context (in runAsync: "" + service.name + "") does not match expected requirements"",module);
      throw e;
    }
  }
  if (!isError && !isFailure) {
    if (requester != null) {
      engine.runAsync(localName,service,context,requester,persist);
    }
 else {
      engine.runAsync(localName,service,context,persist);
    }
    engine.sendCallbacks(service,context,GenericEngine.ASYNC_MODE);
  }
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + service.name,""ASync service finished..."",module);
  }
}
 catch (Throwable t) {
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + service.name,""ASync service failed..."",module);
  }
  String errMsg=""Service ["" + service.name + ""] threw an unexpected exception/error"";
  Debug.logError(t,errMsg,module);
  engine.sendCallbacks(service,context,t,GenericEngine.ASYNC_MODE);
  try {
    TransactionUtil.rollback(beganTrans,errMsg,t);
  }
 catch (  GenericTransactionException te) {
    Debug.logError(te,""Cannot rollback transaction"",module);
  }
  if (t instanceof ServiceAuthException) {
    throw (ServiceAuthException)t;
  }
 else   if (t instanceof ServiceValidationException) {
    throw (ServiceValidationException)t;
  }
 else   if (t instanceof GenericServiceException) {
    throw (GenericServiceException)t;
  }
 else {
    throw new GenericServiceException(""Service ["" + service.name + ""] Failed""+ service.debugInfo(),t);
  }
}
 finally {
  try {
    TransactionUtil.commit(beganTrans);
  }
 catch (  GenericTransactionException e) {
    Debug.logError(e,""Could not commit transaction"",module);
    throw new GenericServiceException(""Commit transaction failed"");
  }
}
",0,0,0,,
548,} finally {,"try {
  if (service.useTransaction) {
    if (TransactionUtil.isTransactionInPlace()) {
      if (service.requireNewTransaction) {
        parentTransaction=TransactionUtil.suspend();
        beganTrans=TransactionUtil.begin(service.transactionTimeout);
      }
    }
 else {
      beganTrans=TransactionUtil.begin(service.transactionTimeout);
    }
    if (beganTrans && TransactionUtil.debugResources()) {
      DebugXaResource dxa=new DebugXaResource(service.name);
      try {
        dxa.enlist();
      }
 catch (      Exception e) {
        Debug.logError(e,module);
      }
    }
  }
  try {
    Map<String,List<ServiceEcaRule>> eventMap=ServiceEcaUtil.getServiceEventMap(service.name);
    if (eventMap != null)     ServiceEcaUtil.evalRules(service.name,eventMap,""auth"",ctx,context,result,isError,isFailure);
    context=checkAuth(localName,context,service);
    Object userLogin=context.get(""userLogin"");
    if (service.auth && userLogin == null) {
      throw new ServiceAuthException(""User authorization is required for this service: "" + service.name + service.debugInfo());
    }
    if (eventMap != null)     ServiceEcaUtil.evalRules(service.name,eventMap,""in-validate"",ctx,context,result,isError,isFailure);
    isFailure=ModelService.RESPOND_FAIL.equals(result.get(ModelService.RESPONSE_MESSAGE));
    isError=ModelService.RESPOND_ERROR.equals(result.get(ModelService.RESPONSE_MESSAGE));
    if (service.validate && !isError && !isFailure) {
      try {
        service.validate(context,ModelService.IN_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        Debug.logError(e,""Incoming service context (in runAsync: "" + service.name + "") does not match expected requirements"",module);
        throw e;
      }
    }
    if (!isError && !isFailure) {
      if (requester != null) {
        engine.runAsync(localName,service,context,requester,persist);
      }
 else {
        engine.runAsync(localName,service,context,persist);
      }
      engine.sendCallbacks(service,context,GenericEngine.ASYNC_MODE);
    }
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + service.name,""ASync service finished..."",module);
    }
  }
 catch (  Throwable t) {
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + service.name,""ASync service failed..."",module);
    }
    String errMsg=""Service ["" + service.name + ""] threw an unexpected exception/error"";
    Debug.logError(t,errMsg,module);
    engine.sendCallbacks(service,context,t,GenericEngine.ASYNC_MODE);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,t);
    }
 catch (    GenericTransactionException te) {
      Debug.logError(te,""Cannot rollback transaction"",module);
    }
    if (t instanceof ServiceAuthException) {
      throw (ServiceAuthException)t;
    }
 else     if (t instanceof ServiceValidationException) {
      throw (ServiceValidationException)t;
    }
 else     if (t instanceof GenericServiceException) {
      throw (GenericServiceException)t;
    }
 else {
      throw new GenericServiceException(""Service ["" + service.name + ""] Failed""+ service.debugInfo(),t);
    }
  }
 finally {
    try {
      TransactionUtil.commit(beganTrans);
    }
 catch (    GenericTransactionException e) {
      Debug.logError(e,""Could not commit transaction"",module);
      throw new GenericServiceException(""Commit transaction failed"");
    }
  }
}
 catch (GenericTransactionException se) {
  Debug.logError(se,""Problems with the transaction"",module);
  throw new GenericServiceException(""Problems with the transaction: "" + se.getMessage() + ""; See logs for more detail"");
}
 finally {
  if (parentTransaction != null) {
    try {
      TransactionUtil.resume(parentTransaction);
    }
 catch (    GenericTransactionException ise) {
      Debug.logError(ise,""Trouble resuming parent transaction"",module);
      throw new GenericServiceException(""Resume transaction exception: "" + ise.getMessage() + ""; See logs for more detail"");
    }
  }
}
",0,0,0,,
549,} finally {,"try {
  if (eventGlobalTransaction) {
    try {
      beganTrans=TransactionUtil.begin(modelService.transactionTimeout * rowCount);
    }
 catch (    GenericTransactionException e) {
      throw new EventHandlerException(""Problem starting multi-service global transaction"",e);
    }
  }
  for (int i=0; i < rowCount; i++) {
    String curSuffix=UtilHttp.getMultiRowDelimiter() + i;
    boolean rowSelected=false;
    if (UtilValidate.isNotEmpty(request.getAttribute(UtilHttp.getRowSubmitPrefix() + i))) {
      rowSelected=request.getAttribute(UtilHttp.getRowSubmitPrefix() + i) == null ? false : ""Y"".equalsIgnoreCase((String)request.getAttribute(UtilHttp.getRowSubmitPrefix() + i));
    }
 else {
      rowSelected=request.getParameter(UtilHttp.getRowSubmitPrefix() + i) == null ? false : ""Y"".equalsIgnoreCase(request.getParameter(UtilHttp.getRowSubmitPrefix() + i));
    }
    if (useRowSubmit && !rowSelected) {
      continue;
    }
    Map<String,Object> serviceContext=new HashMap<String,Object>();
    for (    ModelParam modelParam : modelService.getInModelParamList()) {
      String paramName=modelParam.name;
      if (""userLogin"".equals(paramName))       continue;
      if (""locale"".equals(paramName))       continue;
      if (""timeZone"".equals(paramName))       continue;
      Object value=null;
      if (UtilValidate.isNotEmpty(modelParam.stringMapPrefix)) {
        Map<String,Object> paramMap=UtilHttp.makeParamMapWithPrefix(request,modelParam.stringMapPrefix,curSuffix);
        value=paramMap;
      }
 else       if (UtilValidate.isNotEmpty(modelParam.stringListSuffix)) {
        List<Object> paramList=UtilHttp.makeParamListWithSuffix(request,modelParam.stringListSuffix,null);
        value=paramList;
      }
 else {
        value=request.getAttribute(paramName + curSuffix);
        if (value == null) {
          String name=paramName + curSuffix;
          ServiceEventHandler.checkSecureParameter(requestMap,urlOnlyParameterNames,name,session,serviceName,dctx.getDelegator());
          String[] paramArr=request.getParameterValues(name);
          if (paramArr != null) {
            if (paramArr.length > 1) {
              value=Arrays.asList(paramArr);
            }
 else {
              value=paramArr[0];
            }
          }
        }
        if (value == null) {
          value=session.getAttribute(paramName + curSuffix);
        }
        if (value == null) {
          if (checkGlobalScope) {
            String[] gParamArr=request.getParameterValues(paramName);
            if (gParamArr != null) {
              if (gParamArr.length > 1) {
                value=Arrays.asList(gParamArr);
              }
 else {
                value=gParamArr[0];
              }
            }
            if (value == null) {
              value=request.getAttribute(paramName);
            }
            if (value == null) {
              value=session.getAttribute(paramName);
            }
          }
        }
        if (value == null) {
          value=UtilHttp.makeParamValueFromComposite(request,paramName + curSuffix,locale);
        }
        if (value == null) {
          continue;
        }
        if (value instanceof String && ((String)value).length() == 0) {
          value=null;
        }
      }
      serviceContext.put(paramName,value);
    }
    serviceContext=modelService.makeValid(serviceContext,ModelService.IN_PARAM,true,null,timeZone,locale);
    if (userLogin != null) {
      serviceContext.put(""userLogin"",userLogin);
    }
    if (locale != null) {
      serviceContext.put(""locale"",locale);
    }
    if (timeZone != null) {
      serviceContext.put(""timeZone"",timeZone);
    }
    Map<String,Object> result=null;
    try {
      result=dispatcher.runSync(serviceName,serviceContext);
    }
 catch (    ServiceAuthException e) {
      errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNonNestedMessage());
    }
catch (    ServiceValidationException e) {
      request.setAttribute(""serviceValidationException"",e);
      List<String> errors=e.getMessageList();
      if (errors != null) {
        for (        String message : errors) {
          errorMessages.add(""Service invocation error on row ("" + i + ""): ""+ message);
        }
      }
 else {
        errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNonNestedMessage());
      }
    }
catch (    GenericServiceException e) {
      Debug.logError(e,""Service invocation error"",module);
      errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNested()+ messageSuffixStr);
    }
    if (result == null) {
      returnString=ModelService.RESPOND_SUCCESS;
    }
 else {
      String errorMessage=ServiceUtil.makeErrorMessage(result,messagePrefixStr,messageSuffixStr,"""","""");
      if (UtilValidate.isNotEmpty(errorMessage)) {
        errorMessages.add(errorMessage);
      }
      if (UtilValidate.isNotEmpty(result.get(ModelService.SUCCESS_MESSAGE))) {
        String newSuccessMessage=(String)result.get(ModelService.SUCCESS_MESSAGE);
        if (!successMessages.contains(newSuccessMessage)) {
          successMessages.add(newSuccessMessage);
        }
      }
      if (UtilValidate.isNotEmpty(result.get(ModelService.SUCCESS_MESSAGE_LIST))) {
        List<String> newSuccessMessages=UtilGenerics.<String>checkList(result.get(ModelService.SUCCESS_MESSAGE_LIST));
        for (int j=0; j < newSuccessMessages.size(); j++) {
          String newSuccessMessage=newSuccessMessages.get(j);
          if (!successMessages.contains(newSuccessMessage)) {
            successMessages.add(newSuccessMessage);
          }
        }
      }
    }
    if ((result != null) && (result.entrySet() != null)) {
      for (      Map.Entry<String,Object> rme : result.entrySet()) {
        String resultKey=rme.getKey();
        Object resultValue=rme.getValue();
        if (resultKey != null && !ModelService.RESPONSE_MESSAGE.equals(resultKey) && !ModelService.ERROR_MESSAGE.equals(resultKey) && !ModelService.ERROR_MESSAGE_LIST.equals(resultKey) && !ModelService.ERROR_MESSAGE_MAP.equals(resultKey) && !ModelService.SUCCESS_MESSAGE.equals(resultKey) && !ModelService.SUCCESS_MESSAGE_LIST.equals(resultKey)) {
          request.setAttribute(resultKey + curSuffix,resultValue);
          request.setAttribute(resultKey,resultValue);
        }
      }
    }
  }
}
  finally {
  if (errorMessages.size() > 0) {
    if (eventGlobalTransaction) {
      try {
        TransactionUtil.rollback(beganTrans,""Error in multi-service event handling: "" + errorMessages.toString(),null);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not rollback multi-service global transaction"",module);
      }
    }
    errorMessages.add(0,errorPrefixStr);
    errorMessages.add(errorSuffixStr);
    StringBuilder errorBuf=new StringBuilder();
    for (    Object em : errorMessages) {
      errorBuf.append(em + ""\n"");
    }
    request.setAttribute(""_ERROR_MESSAGE_"",errorBuf.toString());
    returnString=""error"";
  }
 else {
    if (eventGlobalTransaction) {
      try {
        TransactionUtil.commit(beganTrans);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not commit multi-service global transaction"",module);
        throw new EventHandlerException(""Commit multi-service global transaction failed"");
      }
    }
    if (successMessages.size() > 0) {
      request.setAttribute(""_EVENT_MESSAGE_LIST_"",successMessages);
    }
    returnString=""success"";
  }
}
",0,0,0,,
550,} finally {,"try {
  String line;
  reader=new BufferedReader(new InputStreamReader(request.getInputStream()));
  while ((line=reader.readLine()) != null) {
    buf.append(line).append(""\n"");
  }
}
 catch (Exception e) {
  throw new EventHandlerException(e.getMessage(),e);
}
 finally {
  if (reader != null) {
    try {
      reader.close();
    }
 catch (    IOException e) {
      throw new EventHandlerException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
551,} finally {,"try (EntityListIterator eli=this.getEli(question,maxRows)){
  if (startIndex > 0 && number > 0) {
    resp=eli.getPartialList(startIndex,number);
  }
 else {
    resp=eli.getCompleteList();
  }
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),MODULE);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
552,} finally {,"try {
  beganTransaction=TransactionUtil.begin();
  long[] result={0,0,0};
  try (EntityListIterator eli=this.getEli(question,-1)){
    if (eli != null) {
      GenericValue value;
      while (((value=eli.next()) != null)) {
        if (""Y"".equalsIgnoreCase(value.getString(""booleanResponse""))) {
          result[1]++;
        }
 else {
          result[2]++;
        }
        result[0]++;
      }
    }
  }
   return result;
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Boolean result"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),MODULE);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
553,} finally {,"try (EntityListIterator eli=this.getEli(question,-1)){
  if (eli != null) {
    GenericValue value;
    while (((value=eli.next()) != null)) {
switch (type) {
case 1:
        Long n=value.getLong(""numericResponse"");
      if (UtilValidate.isNotEmpty(n)) {
        result[1]+=n;
      }
    break;
case 2:
  Double c=value.getDouble(""currencyResponse"");
if (UtilValidate.isNotEmpty(c)) {
  result[1]+=(((double)Math.round((c - c) * 100)) / 100);
}
break;
case 3:
Double f=value.getDouble(""floatResponse"");
if (UtilValidate.isNotEmpty(f)) {
result[1]+=f;
}
break;
}
result[0]++;
}
}
}
 catch (GenericEntityException e) {
try {
TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Number result"",e);
}
 catch (GenericEntityException e2) {
Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),MODULE);
}
throw new SurveyWrapperException(e);
}
 finally {
try {
TransactionUtil.commit(beganTransaction);
}
 catch (GenericEntityException e) {
throw new SurveyWrapperException(e);
}
}
",0,0,0,,
554,} finally {,"try (EntityListIterator eli=this.getEli(question,-1)){
  if (eli != null) {
    GenericValue value;
    while (((value=eli.next()) != null)) {
      String optionId=value.getString(""surveyOptionSeqId"");
      if (UtilValidate.isNotEmpty(optionId)) {
        Long optCount=(Long)result.remove(optionId);
        if (optCount == null) {
          optCount=1L;
        }
 else {
          optCount=1 + optCount;
        }
        result.put(optionId,optCount);
        total++;
      }
    }
  }
}
 catch (GenericEntityException e) {
  try {
    TransactionUtil.rollback(beganTransaction,""Error getting survey question responses Option result"",e);
  }
 catch (  GenericEntityException e2) {
    Debug.logError(e2,""Could not rollback transaction: "" + e2.toString(),MODULE);
  }
  throw new SurveyWrapperException(e);
}
 finally {
  try {
    TransactionUtil.commit(beganTransaction);
  }
 catch (  GenericEntityException e) {
    throw new SurveyWrapperException(e);
  }
}
",0,0,0,,
555,} finally {,"try {
  this.createKey(keyName,handlers[0],encryptMethod);
}
 catch (EntityCryptoException e) {
  caught=e;
}
 finally {
  try {
    key=this.findKey(keyName,handlers[0]);
  }
 catch (  EntityCryptoException e) {
    throw caught != null ? caught : e;
  }
  if (key == null) {
    throw caught != null ? caught : new EntityCryptoException(""could not lookup key ("" + keyName + "") after creation"");
  }
}
",0,0,0,,
556,} finally {,"try {
  int lockRetriesRemaining=LOCK_RETRIES;
  boolean needsLockRetry=false;
  do {
    needsLockRetry=false;
    lockRetriesRemaining--;
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-rollback"",ctx,context,result,isError,isFailure);
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-commit"",ctx,context,result,isError,isFailure);
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""auth"",ctx,context,result,isError,isFailure);
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    context=checkAuth(localName,context,modelService);
    GenericValue userLogin=(GenericValue)context.get(""userLogin"");
    if (modelService.isAuth() && userLogin == null) {
      rs.setEndStamp();
      throw new ServiceAuthException(""User authorization is required for this service: "" + modelService.getName() + modelService.debugInfo());
    }
    if (userLogin != null && userLogin.getString(""userLoginId"") != null) {
      GenericDelegator.pushUserIdentifier(userLogin.getString(""userLoginId""));
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""in-validate"",ctx,context,result,isError,isFailure);
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (modelService.isValidate() && !isError && !isFailure) {
      try {
        context=ctx.makeValidContext(modelService.getName(),ModelService.IN_PARAM,context);
        modelService.validate(context,ModelService.IN_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        Debug.logError(e,""Incoming context (in runSync : "" + modelService.getName() + "") does not match expected requirements"",MODULE);
        rs.setEndStamp();
        throw e;
      }
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""invoke"",ctx,context,result,isError,isFailure);
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (!isError && !isFailure) {
      Map<String,Object> invokeResult=null;
      invokeResult=engine.runSync(localName,modelService,context);
      engine.sendCallbacks(modelService,context,invokeResult,GenericEngine.SYNC_MODE);
      if (invokeResult != null) {
        result.putAll(invokeResult);
      }
 else {
        Debug.logWarning(""Service (in runSync : "" + modelService.getName() + "") returns null result"",MODULE);
      }
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (beganTrans) {
      String errMsg=ServiceUtil.getErrorMessage(result);
      if (errMsg != null && errMsg.toUpperCase(Locale.getDefault()).indexOf(""DEADLOCK"") >= 0) {
        String retryMsg=""RETRYING SERVICE ["" + modelService.getName() + ""]: Deadlock error found in message [""+ errMsg+ ""]; retry [""+ (LOCK_RETRIES - lockRetriesRemaining)+ ""] of [""+ LOCK_RETRIES+ ""]"";
        TransactionUtil.rollback(beganTrans,retryMsg,null);
        beganTrans=TransactionUtil.begin(modelService.getTransactionTimeout());
        if (beganTrans && TransactionUtil.debugResources()) {
          DebugXaResource dxa=new DebugXaResource(modelService.getName());
          try {
            dxa.enlist();
          }
 catch (          Exception e) {
            Debug.logError(e,MODULE);
          }
        }
        if (!beganTrans) {
          Debug.logError(""After rollback attempt for lock retry did not begin a new transaction!"",MODULE);
        }
 else {
          needsLockRetry=true;
          result=new HashMap<>();
          isFailure=false;
          isError=false;
          Debug.logWarning(retryMsg,MODULE);
        }
      }
    }
  }
 while (needsLockRetry && lockRetriesRemaining > 0);
  ecaContext=new HashMap<>();
  ecaContext.putAll(context);
  ecaContext.putAll(result);
  modelService.updateDefaultValues(context,ModelService.OUT_PARAM);
  if (modelService.isValidate() && validateOut) {
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""out-validate"",ctx,ecaContext,result,isError,isFailure);
    }
    try {
      result=ctx.makeValidContext(modelService.getName(),ModelService.OUT_PARAM,result);
      modelService.validate(result,ModelService.OUT_PARAM,locale);
    }
 catch (    ServiceValidationException e) {
      rs.setEndStamp();
      throw new GenericServiceException(""Outgoing result (in runSync : "" + modelService.getName() + "") does not match expected requirements"",e);
    }
  }
  if (eventMap != null) {
    ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""commit"",ctx,ecaContext,result,isError,isFailure);
  }
  isFailure=ServiceUtil.isFailure(result);
  isError=ServiceUtil.isError(result);
  if (eventMap != null) {
    ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-commit-post-run"",ctx,ecaContext,result,isError,isFailure);
  }
  if (isFailure) {
    Debug.logWarning(""Service Failure ["" + modelService.getName() + ""]: ""+ ServiceUtil.getErrorMessage(result),MODULE);
  }
}
 catch (Throwable t) {
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + modelService.getName(),""Sync service failed..."",MODULE);
  }
  String errMsg=""Service ["" + modelService.getName() + ""] threw an unexpected exception/error"";
  engine.sendCallbacks(modelService,context,t,GenericEngine.SYNC_MODE);
  try {
    TransactionUtil.rollback(beganTrans,errMsg,t);
  }
 catch (  GenericTransactionException te) {
    Debug.logError(te,""Cannot rollback transaction"",MODULE);
  }
  rs.setEndStamp();
  if (t instanceof ServiceAuthException) {
    throw (ServiceAuthException)t;
  }
 else   if (t instanceof ServiceValidationException) {
    throw (ServiceValidationException)t;
  }
 else   if (t instanceof GenericServiceException) {
    throw (GenericServiceException)t;
  }
 else {
    throw new GenericServiceException(""Service ["" + modelService.getName() + ""] Failed""+ modelService.debugInfo(),t);
  }
}
 finally {
  if (isError) {
    String errMsg=""Error in Service ["" + modelService.getName() + ""]: ""+ ServiceUtil.getErrorMessage(result);
    Debug.logError(errMsg,MODULE);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,null);
    }
 catch (    GenericTransactionException e) {
      Debug.logError(e,""Could not rollback transaction: "" + e.toString(),MODULE);
    }
  }
 else {
    try {
      TransactionUtil.commit(beganTrans);
    }
 catch (    GenericTransactionException e) {
      GenericDelegator.popUserIdentifier();
      String errMsg=""Could not commit transaction for service ["" + modelService.getName() + ""] call"";
      Debug.logError(e,errMsg,MODULE);
      if (e.getMessage() != null) {
        errMsg=errMsg + "": "" + e.getMessage();
      }
      rs.setEndStamp();
      throw new GenericServiceException(errMsg);
    }
  }
  modelService.evalNotifications(this.getLocalContext(localName),context,result);
  GenericDelegator.popUserIdentifier();
}
",0,0,0,,
557,} finally {,"try {
  if (""wait"".equals(modelService.getSemaphore()) || ""fail"".equals(modelService.getSemaphore())) {
    lock=new ServiceSemaphore(delegator,modelService);
    lock.acquire();
  }
  if (Debug.verboseOn() || modelService.isDebug()) {
    if (Debug.verboseOn()) {
      Debug.logVerbose(""[ServiceDispatcher.runSync] : invoking service "" + modelService.getName() + "" [""+ modelService.getLocation()+ ""/""+ modelService.getInvoke()+ ""] (""+ modelService.getEngineName()+ "")"",MODULE);
    }
  }
  Map<String,Object> context=new HashMap<>();
  if (params != null) {
    context.putAll(params);
  }
  Locale locale=checkLocale(context);
  rs=this.logService(localName,modelService,GenericEngine.SYNC_MODE);
  eventMap=ServiceEcaUtil.getServiceEventMap(modelService.getName());
  engine=this.getGenericEngine(modelService.getEngineName());
  modelService.informIfDeprecated();
  modelService.updateDefaultValues(context,ModelService.IN_PARAM);
  if (modelService.isUseTransaction()) {
    if (TransactionUtil.isTransactionInPlace()) {
      if (modelService.isRequireNewTransaction()) {
        parentTransaction=TransactionUtil.suspend();
        if (TransactionUtil.isTransactionInPlace()) {
          rs.setEndStamp();
          throw new GenericTransactionException(""In service "" + modelService.getName() + "" transaction is still in place after suspend, status is ""+ TransactionUtil.getStatusString());
        }
        beganTrans=TransactionUtil.begin(modelService.getTransactionTimeout());
      }
    }
 else {
      beganTrans=TransactionUtil.begin(modelService.getTransactionTimeout());
    }
    if (beganTrans && TransactionUtil.debugResources()) {
      DebugXaResource dxa=new DebugXaResource(modelService.getName());
      try {
        dxa.enlist();
      }
 catch (      Exception e) {
        Debug.logError(e,MODULE);
      }
    }
  }
  try {
    int lockRetriesRemaining=LOCK_RETRIES;
    boolean needsLockRetry=false;
    do {
      needsLockRetry=false;
      lockRetriesRemaining--;
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-rollback"",ctx,context,result,isError,isFailure);
      }
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-commit"",ctx,context,result,isError,isFailure);
      }
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""auth"",ctx,context,result,isError,isFailure);
      }
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      context=checkAuth(localName,context,modelService);
      GenericValue userLogin=(GenericValue)context.get(""userLogin"");
      if (modelService.isAuth() && userLogin == null) {
        rs.setEndStamp();
        throw new ServiceAuthException(""User authorization is required for this service: "" + modelService.getName() + modelService.debugInfo());
      }
      if (userLogin != null && userLogin.getString(""userLoginId"") != null) {
        GenericDelegator.pushUserIdentifier(userLogin.getString(""userLoginId""));
      }
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""in-validate"",ctx,context,result,isError,isFailure);
      }
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (modelService.isValidate() && !isError && !isFailure) {
        try {
          context=ctx.makeValidContext(modelService.getName(),ModelService.IN_PARAM,context);
          modelService.validate(context,ModelService.IN_PARAM,locale);
        }
 catch (        ServiceValidationException e) {
          Debug.logError(e,""Incoming context (in runSync : "" + modelService.getName() + "") does not match expected requirements"",MODULE);
          rs.setEndStamp();
          throw e;
        }
      }
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""invoke"",ctx,context,result,isError,isFailure);
      }
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (!isError && !isFailure) {
        Map<String,Object> invokeResult=null;
        invokeResult=engine.runSync(localName,modelService,context);
        engine.sendCallbacks(modelService,context,invokeResult,GenericEngine.SYNC_MODE);
        if (invokeResult != null) {
          result.putAll(invokeResult);
        }
 else {
          Debug.logWarning(""Service (in runSync : "" + modelService.getName() + "") returns null result"",MODULE);
        }
      }
      isFailure=ServiceUtil.isFailure(result);
      isError=ServiceUtil.isError(result);
      if (beganTrans) {
        String errMsg=ServiceUtil.getErrorMessage(result);
        if (errMsg != null && errMsg.toUpperCase(Locale.getDefault()).indexOf(""DEADLOCK"") >= 0) {
          String retryMsg=""RETRYING SERVICE ["" + modelService.getName() + ""]: Deadlock error found in message [""+ errMsg+ ""]; retry [""+ (LOCK_RETRIES - lockRetriesRemaining)+ ""] of [""+ LOCK_RETRIES+ ""]"";
          TransactionUtil.rollback(beganTrans,retryMsg,null);
          beganTrans=TransactionUtil.begin(modelService.getTransactionTimeout());
          if (beganTrans && TransactionUtil.debugResources()) {
            DebugXaResource dxa=new DebugXaResource(modelService.getName());
            try {
              dxa.enlist();
            }
 catch (            Exception e) {
              Debug.logError(e,MODULE);
            }
          }
          if (!beganTrans) {
            Debug.logError(""After rollback attempt for lock retry did not begin a new transaction!"",MODULE);
          }
 else {
            needsLockRetry=true;
            result=new HashMap<>();
            isFailure=false;
            isError=false;
            Debug.logWarning(retryMsg,MODULE);
          }
        }
      }
    }
 while (needsLockRetry && lockRetriesRemaining > 0);
    ecaContext=new HashMap<>();
    ecaContext.putAll(context);
    ecaContext.putAll(result);
    modelService.updateDefaultValues(context,ModelService.OUT_PARAM);
    if (modelService.isValidate() && validateOut) {
      if (eventMap != null) {
        ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""out-validate"",ctx,ecaContext,result,isError,isFailure);
      }
      try {
        result=ctx.makeValidContext(modelService.getName(),ModelService.OUT_PARAM,result);
        modelService.validate(result,ModelService.OUT_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        rs.setEndStamp();
        throw new GenericServiceException(""Outgoing result (in runSync : "" + modelService.getName() + "") does not match expected requirements"",e);
      }
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""commit"",ctx,ecaContext,result,isError,isFailure);
    }
    isFailure=ServiceUtil.isFailure(result);
    isError=ServiceUtil.isError(result);
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(modelService.getName(),eventMap,""global-commit-post-run"",ctx,ecaContext,result,isError,isFailure);
    }
    if (isFailure) {
      Debug.logWarning(""Service Failure ["" + modelService.getName() + ""]: ""+ ServiceUtil.getErrorMessage(result),MODULE);
    }
  }
 catch (  Throwable t) {
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + modelService.getName(),""Sync service failed..."",MODULE);
    }
    String errMsg=""Service ["" + modelService.getName() + ""] threw an unexpected exception/error"";
    engine.sendCallbacks(modelService,context,t,GenericEngine.SYNC_MODE);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,t);
    }
 catch (    GenericTransactionException te) {
      Debug.logError(te,""Cannot rollback transaction"",MODULE);
    }
    rs.setEndStamp();
    if (t instanceof ServiceAuthException) {
      throw (ServiceAuthException)t;
    }
 else     if (t instanceof ServiceValidationException) {
      throw (ServiceValidationException)t;
    }
 else     if (t instanceof GenericServiceException) {
      throw (GenericServiceException)t;
    }
 else {
      throw new GenericServiceException(""Service ["" + modelService.getName() + ""] Failed""+ modelService.debugInfo(),t);
    }
  }
 finally {
    if (isError) {
      String errMsg=""Error in Service ["" + modelService.getName() + ""]: ""+ ServiceUtil.getErrorMessage(result);
      Debug.logError(errMsg,MODULE);
      try {
        TransactionUtil.rollback(beganTrans,errMsg,null);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not rollback transaction: "" + e.toString(),MODULE);
      }
    }
 else {
      try {
        TransactionUtil.commit(beganTrans);
      }
 catch (      GenericTransactionException e) {
        GenericDelegator.popUserIdentifier();
        String errMsg=""Could not commit transaction for service ["" + modelService.getName() + ""] call"";
        Debug.logError(e,errMsg,MODULE);
        if (e.getMessage() != null) {
          errMsg=errMsg + "": "" + e.getMessage();
        }
        rs.setEndStamp();
        throw new GenericServiceException(errMsg);
      }
    }
    modelService.evalNotifications(this.getLocalContext(localName),context,result);
    GenericDelegator.popUserIdentifier();
  }
}
 catch (GenericTransactionException te) {
  Debug.logError(te,""Problems with the transaction"",MODULE);
  rs.setEndStamp();
  throw new GenericServiceException(""Problems with the transaction."",te.getNested());
}
 finally {
  if (lock != null) {
    lock.release();
  }
  if (parentTransaction != null) {
    try {
      TransactionUtil.resume(parentTransaction);
    }
 catch (    GenericTransactionException ite) {
      Debug.logWarning(ite,""Transaction error, not resumed"",MODULE);
      rs.setEndStamp();
      throw new GenericServiceException(""Resume transaction exception, see logs"");
    }
  }
}
",0,0,0,,
558,} finally {,"try {
  Map<String,List<ServiceEcaRule>> eventMap=ServiceEcaUtil.getServiceEventMap(service.getName());
  if (eventMap != null) {
    ServiceEcaUtil.evalRules(service.getName(),eventMap,""auth"",ctx,context,result,isError,isFailure);
  }
  context=checkAuth(localName,context,service);
  Object userLogin=context.get(""userLogin"");
  if (service.isAuth() && userLogin == null) {
    throw new ServiceAuthException(""User authorization is required for this service: "" + service.getName() + service.debugInfo());
  }
  if (eventMap != null) {
    ServiceEcaUtil.evalRules(service.getName(),eventMap,""in-validate"",ctx,context,result,isError,isFailure);
  }
  isFailure=ModelService.RESPOND_FAIL.equals(result.get(ModelService.RESPONSE_MESSAGE));
  isError=ModelService.RESPOND_ERROR.equals(result.get(ModelService.RESPONSE_MESSAGE));
  if (service.isValidate() && !isError && !isFailure) {
    try {
      service.validate(context,ModelService.IN_PARAM,locale);
    }
 catch (    ServiceValidationException e) {
      Debug.logError(e,""Incoming service context (in runAsync: "" + service.getName() + "") does not match expected requirements"",MODULE);
      throw e;
    }
  }
  if (!isError && !isFailure) {
    if (requester != null) {
      engine.runAsync(localName,service,context,requester,persist);
    }
 else {
      engine.runAsync(localName,service,context,persist);
    }
    engine.sendCallbacks(service,context,GenericEngine.ASYNC_MODE);
  }
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + service.getName(),""ASync service finished..."",MODULE);
  }
}
 catch (Throwable t) {
  if (Debug.timingOn()) {
    UtilTimer.closeTimer(localName + "" / "" + service.getName(),""ASync service failed..."",MODULE);
  }
  String errMsg=""Service ["" + service.getName() + ""] threw an unexpected exception/error"";
  Debug.logError(t,errMsg,MODULE);
  engine.sendCallbacks(service,context,t,GenericEngine.ASYNC_MODE);
  try {
    TransactionUtil.rollback(beganTrans,errMsg,t);
  }
 catch (  GenericTransactionException te) {
    Debug.logError(te,""Cannot rollback transaction"",MODULE);
  }
  if (t instanceof ServiceAuthException) {
    throw (ServiceAuthException)t;
  }
 else   if (t instanceof ServiceValidationException) {
    throw (ServiceValidationException)t;
  }
 else   if (t instanceof GenericServiceException) {
    throw (GenericServiceException)t;
  }
 else {
    throw new GenericServiceException(""Service ["" + service.getName() + ""] Failed""+ service.debugInfo(),t);
  }
}
 finally {
  try {
    TransactionUtil.commit(beganTrans);
  }
 catch (  GenericTransactionException e) {
    Debug.logError(e,""Could not commit transaction"",MODULE);
    throw new GenericServiceException(""Commit transaction failed"");
  }
}
",0,0,0,,
559,} finally {,"try {
  if (service.isUseTransaction()) {
    if (TransactionUtil.isTransactionInPlace()) {
      if (service.isRequireNewTransaction()) {
        parentTransaction=TransactionUtil.suspend();
        beganTrans=TransactionUtil.begin(service.getTransactionTimeout());
      }
    }
 else {
      beganTrans=TransactionUtil.begin(service.getTransactionTimeout());
    }
    if (beganTrans && TransactionUtil.debugResources()) {
      DebugXaResource dxa=new DebugXaResource(service.getName());
      try {
        dxa.enlist();
      }
 catch (      Exception e) {
        Debug.logError(e,MODULE);
      }
    }
  }
  try {
    Map<String,List<ServiceEcaRule>> eventMap=ServiceEcaUtil.getServiceEventMap(service.getName());
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(service.getName(),eventMap,""auth"",ctx,context,result,isError,isFailure);
    }
    context=checkAuth(localName,context,service);
    Object userLogin=context.get(""userLogin"");
    if (service.isAuth() && userLogin == null) {
      throw new ServiceAuthException(""User authorization is required for this service: "" + service.getName() + service.debugInfo());
    }
    if (eventMap != null) {
      ServiceEcaUtil.evalRules(service.getName(),eventMap,""in-validate"",ctx,context,result,isError,isFailure);
    }
    isFailure=ModelService.RESPOND_FAIL.equals(result.get(ModelService.RESPONSE_MESSAGE));
    isError=ModelService.RESPOND_ERROR.equals(result.get(ModelService.RESPONSE_MESSAGE));
    if (service.isValidate() && !isError && !isFailure) {
      try {
        service.validate(context,ModelService.IN_PARAM,locale);
      }
 catch (      ServiceValidationException e) {
        Debug.logError(e,""Incoming service context (in runAsync: "" + service.getName() + "") does not match expected requirements"",MODULE);
        throw e;
      }
    }
    if (!isError && !isFailure) {
      if (requester != null) {
        engine.runAsync(localName,service,context,requester,persist);
      }
 else {
        engine.runAsync(localName,service,context,persist);
      }
      engine.sendCallbacks(service,context,GenericEngine.ASYNC_MODE);
    }
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + service.getName(),""ASync service finished..."",MODULE);
    }
  }
 catch (  Throwable t) {
    if (Debug.timingOn()) {
      UtilTimer.closeTimer(localName + "" / "" + service.getName(),""ASync service failed..."",MODULE);
    }
    String errMsg=""Service ["" + service.getName() + ""] threw an unexpected exception/error"";
    Debug.logError(t,errMsg,MODULE);
    engine.sendCallbacks(service,context,t,GenericEngine.ASYNC_MODE);
    try {
      TransactionUtil.rollback(beganTrans,errMsg,t);
    }
 catch (    GenericTransactionException te) {
      Debug.logError(te,""Cannot rollback transaction"",MODULE);
    }
    if (t instanceof ServiceAuthException) {
      throw (ServiceAuthException)t;
    }
 else     if (t instanceof ServiceValidationException) {
      throw (ServiceValidationException)t;
    }
 else     if (t instanceof GenericServiceException) {
      throw (GenericServiceException)t;
    }
 else {
      throw new GenericServiceException(""Service ["" + service.getName() + ""] Failed""+ service.debugInfo(),t);
    }
  }
 finally {
    try {
      TransactionUtil.commit(beganTrans);
    }
 catch (    GenericTransactionException e) {
      Debug.logError(e,""Could not commit transaction"",MODULE);
      throw new GenericServiceException(""Commit transaction failed"");
    }
  }
}
 catch (GenericTransactionException se) {
  Debug.logError(se,""Problems with the transaction"",MODULE);
  throw new GenericServiceException(""Problems with the transaction: "" + se.getMessage() + ""; See logs for more detail"");
}
 finally {
  if (parentTransaction != null) {
    try {
      TransactionUtil.resume(parentTransaction);
    }
 catch (    GenericTransactionException ise) {
      Debug.logError(ise,""Trouble resuming parent transaction"",MODULE);
      throw new GenericServiceException(""Resume transaction exception: "" + ise.getMessage() + ""; See logs for more detail"");
    }
  }
}
",0,0,0,,
560,} finally {,"try {
  if (eventGlobalTransaction) {
    try {
      beganTrans=TransactionUtil.begin(modelService.getTransactionTimeout() * rowCount);
    }
 catch (    GenericTransactionException e) {
      throw new EventHandlerException(""Problem starting multi-service global transaction"",e);
    }
  }
  for (int i=0; i < rowCount; i++) {
    String curSuffix=UtilHttp.getMultiRowDelimiter() + i;
    boolean rowSelected=false;
    if (UtilValidate.isNotEmpty(request.getAttribute(UtilHttp.getRowSubmitPrefix() + i))) {
      rowSelected=request.getAttribute(UtilHttp.getRowSubmitPrefix() + i) == null ? false : ""Y"".equalsIgnoreCase((String)request.getAttribute(UtilHttp.getRowSubmitPrefix() + i));
    }
 else {
      rowSelected=request.getParameter(UtilHttp.getRowSubmitPrefix() + i) == null ? false : ""Y"".equalsIgnoreCase(request.getParameter(UtilHttp.getRowSubmitPrefix() + i));
    }
    if (useRowSubmit && !rowSelected) {
      continue;
    }
    Map<String,Object> serviceContext=new HashMap<>();
    for (    ModelParam modelParam : modelService.getInModelParamList()) {
      String paramName=modelParam.getName();
      if (""userLogin"".equals(paramName))       continue;
      if (""locale"".equals(paramName))       continue;
      if (""timeZone"".equals(paramName))       continue;
      Object value=null;
      if (UtilValidate.isNotEmpty(modelParam.getStringMapPrefix())) {
        Map<String,Object> paramMap=UtilHttp.makeParamMapWithPrefix(request,modelParam.getStringMapPrefix(),curSuffix);
        value=paramMap;
      }
 else       if (UtilValidate.isNotEmpty(modelParam.getStringListSuffix())) {
        List<Object> paramList=UtilHttp.makeParamListWithSuffix(request,modelParam.getStringListSuffix(),null);
        value=paramList;
      }
 else {
        value=request.getAttribute(paramName + curSuffix);
        if (value == null) {
          String name=paramName + curSuffix;
          String[] paramArr=request.getParameterValues(name);
          if (paramArr != null) {
            if (paramArr.length > 1) {
              value=Arrays.asList(paramArr);
            }
 else {
              value=paramArr[0];
            }
          }
        }
        if (value == null) {
          value=session.getAttribute(paramName + curSuffix);
        }
        if (value == null) {
          if (checkGlobalScope) {
            String[] gParamArr=request.getParameterValues(paramName);
            if (gParamArr != null) {
              if (gParamArr.length > 1) {
                value=Arrays.asList(gParamArr);
              }
 else {
                value=gParamArr[0];
              }
            }
            if (value == null) {
              value=request.getAttribute(paramName);
            }
            if (value == null) {
              value=session.getAttribute(paramName);
            }
          }
        }
        if (value == null) {
          value=UtilHttp.makeParamValueFromComposite(request,paramName + curSuffix);
        }
        if (value == null) {
          continue;
        }
        if (value instanceof String && ((String)value).isEmpty()) {
          value=null;
        }
      }
      serviceContext.put(paramName,value);
    }
    serviceContext=modelService.makeValid(serviceContext,ModelService.IN_PARAM,true,null,timeZone,locale);
    if (userLogin != null) {
      serviceContext.put(""userLogin"",userLogin);
    }
    if (locale != null) {
      serviceContext.put(""locale"",locale);
    }
    if (timeZone != null) {
      serviceContext.put(""timeZone"",timeZone);
    }
    Map<String,Object> result=null;
    try {
      result=dispatcher.runSync(serviceName,serviceContext);
    }
 catch (    ServiceAuthException e) {
      errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNonNestedMessage());
    }
catch (    ServiceValidationException e) {
      request.setAttribute(""serviceValidationException"",e);
      List<String> errors=e.getMessageList();
      if (errors != null) {
        for (        String message : errors) {
          errorMessages.add(""Service invocation error on row ("" + i + ""): ""+ message);
        }
      }
 else {
        errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNonNestedMessage());
      }
    }
catch (    GenericServiceException e) {
      Debug.logError(e,""Service invocation error"",MODULE);
      errorMessages.add(messagePrefixStr + ""Service invocation error on row ("" + i+ ""): ""+ e.getNested()+ messageSuffixStr);
    }
    if (result == null) {
      returnString=ModelService.RESPOND_SUCCESS;
    }
 else {
      String errorMessage=ServiceUtil.makeErrorMessage(result,messagePrefixStr,messageSuffixStr,"""","""");
      if (UtilValidate.isNotEmpty(errorMessage)) {
        errorMessages.add(errorMessage);
      }
      if (UtilValidate.isNotEmpty(result.get(ModelService.SUCCESS_MESSAGE))) {
        String newSuccessMessage=(String)result.get(ModelService.SUCCESS_MESSAGE);
        if (!successMessages.contains(newSuccessMessage)) {
          successMessages.add(newSuccessMessage);
        }
      }
      if (UtilValidate.isNotEmpty(result.get(ModelService.SUCCESS_MESSAGE_LIST))) {
        List<String> newSuccessMessages=UtilGenerics.cast(result.get(ModelService.SUCCESS_MESSAGE_LIST));
        for (int j=0; j < newSuccessMessages.size(); j++) {
          String newSuccessMessage=newSuccessMessages.get(j);
          if (!successMessages.contains(newSuccessMessage)) {
            successMessages.add(newSuccessMessage);
          }
        }
      }
    }
    if ((result != null) && (result.entrySet() != null)) {
      for (      Map.Entry<String,Object> rme : result.entrySet()) {
        String resultKey=rme.getKey();
        Object resultValue=rme.getValue();
        if (resultKey != null && !ModelService.RESPONSE_MESSAGE.equals(resultKey) && !ModelService.ERROR_MESSAGE.equals(resultKey) && !ModelService.ERROR_MESSAGE_LIST.equals(resultKey) && !ModelService.ERROR_MESSAGE_MAP.equals(resultKey) && !ModelService.SUCCESS_MESSAGE.equals(resultKey) && !ModelService.SUCCESS_MESSAGE_LIST.equals(resultKey)) {
          request.setAttribute(resultKey + curSuffix,resultValue);
          request.setAttribute(resultKey,resultValue);
        }
      }
    }
  }
}
  finally {
  if (!errorMessages.isEmpty()) {
    if (eventGlobalTransaction) {
      try {
        TransactionUtil.rollback(beganTrans,""Error in multi-service event handling: "" + errorMessages.toString(),null);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not rollback multi-service global transaction"",MODULE);
      }
    }
    errorMessages.add(0,errorPrefixStr);
    errorMessages.add(errorSuffixStr);
    StringBuilder errorBuf=new StringBuilder();
    for (    Object em : errorMessages) {
      errorBuf.append(em + ""\n"");
    }
    request.setAttribute(""_ERROR_MESSAGE_"",errorBuf.toString());
    returnString=""error"";
  }
 else {
    if (eventGlobalTransaction) {
      try {
        TransactionUtil.commit(beganTrans);
      }
 catch (      GenericTransactionException e) {
        Debug.logError(e,""Could not commit multi-service global transaction"",MODULE);
        throw new EventHandlerException(""Commit multi-service global transaction failed"");
      }
    }
    if (!successMessages.isEmpty()) {
      request.setAttribute(""_EVENT_MESSAGE_LIST_"",successMessages);
    }
    returnString=""success"";
  }
}
",0,0,0,,
561,} finally {,"try {
  String line;
  reader=new BufferedReader(new InputStreamReader(req.getInputStream()));
  while ((line=reader.readLine()) != null) {
    buf.append(line).append(""\n"");
  }
}
 catch (Exception e) {
  throw new EventHandlerException(e.getMessage(),e);
}
 finally {
  if (reader != null) {
    try {
      reader.close();
    }
 catch (    IOException e) {
      throw new EventHandlerException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
562,} finally {,"try {
  jarFile=new JarFile(jarFilePath);
  List<String> classFileNames=new ArrayList<String>();
  Enumeration<JarEntry> entries=jarFile.entries();
  while (entries.hasMoreElements()) {
    JarEntry je=entries.nextElement();
    String name=je.getName();
    if (!je.isDirectory() && name.matches("".*"" + packageToScan + "".*""+ CLASSFILE_ENDING)) {
      String className=name.substring(0,name.length() - CLASSFILE_ENDING.length());
      classFileNames.add(className.replace(RESOURCE_SEPARATOR,PACKAGE_SEPARATOR));
    }
  }
  return classFileNames;
}
 catch (IOException e) {
  throw new IllegalArgumentException(""Exception during class loading from path '"" + jarFilePath + ""' with message '""+ e.getMessage()+ ""'."");
}
 finally {
  if (jarFile != null) {
    try {
      jarFile.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Error during close of jar file: "" + jarFile.getName() + """",e);
    }
  }
}
",0,0,0,,
563,} finally {,"try {
  extractCharset(ContentType.parse(response.getHeader(""Content-Type"")));
  ByteArrayOutputStream output=new ByteArrayOutputStream();
  ByteBuffer inBuffer=ByteBuffer.allocate(BUFFER_SIZE);
  ic=Channels.newChannel((InputStream)entity);
  oc=Channels.newChannel(output);
  while (ic.read(inBuffer) > 0) {
    inBuffer.flip();
    oc.write(inBuffer);
    inBuffer.rewind();
  }
  return output.toByteArray();
}
 catch (IOException e) {
  throw new ODataRuntimeException(""Error on reading request content"");
}
 finally {
  try {
    if (ic != null) {
      ic.close();
    }
  }
 catch (  IOException e) {
    throw new ODataRuntimeException(""Error closing the Readable Byte Channel"",e);
  }
  try {
    if (oc != null) {
      oc.close();
    }
  }
 catch (  IOException e) {
    throw new ODataRuntimeException(""Error closing the Writable Byte Channel"",e);
  }
}
",0,0,0,,
564,} finally {,"try {
  return parseBatch(in,transformator);
}
 catch (IOException e) {
  throw new ODataRuntimeException(e);
}
 finally {
  try {
    in.close();
  }
 catch (  IOException e) {
    throw new ODataRuntimeException(e);
  }
}
",0,0,0,,
565,} finally {,"try (JsonGenerator json=new JsonFactory().createGenerator(outputStream)){
  if (obj instanceof AbstractEntityCollection) {
    doSerialize(entityType,(AbstractEntityCollection)obj,contextURLString,metadataETag,json);
  }
 else   if (obj instanceof Entity) {
    doSerialize(entityType,(Entity)obj,contextURLString,metadataETag,json);
  }
 else {
    throw new SerializerException(""Input type not supported."",MessageKeys.NOT_IMPLEMENTED);
  }
  json.flush();
  json.close();
  return SerializerResultImpl.with().content(buffer.getInputStream()).build();
}
 catch (final IOException e) {
  cachedException=new SerializerException(IO_EXCEPTION_TEXT,e,SerializerException.MessageKeys.IO_EXCEPTION);
  throw cachedException;
}
 finally {
  if (outputStream != null) {
    try {
      outputStream.close();
    }
 catch (    final IOException e) {
      throw cachedException == null ? new SerializerException(IO_EXCEPTION_TEXT,e,SerializerException.MessageKeys.IO_EXCEPTION) : cachedException;
    }
  }
}
",0,0,0,,
566,} finally {,"try {
  this.conf=new PGEConfigFileReader().read(new FileInputStream(file));
}
 catch (PGEConfigFileException e) {
  throw new InstantiationException(e.getMessage());
}
 finally {
  if (this.conf == null) {
    throw new InstantiationException(""Configuration is null!"");
  }
}
",0,0,0,,
567,finally {,"try {
  String externalStatus=action.getExternalStatus();
  WorkflowAction.Status status=externalStatus.equals(SUCCEEDED) ? WorkflowAction.Status.OK : WorkflowAction.Status.ERROR;
  context.setEndData(status,getActionSignal(status));
}
 catch (Exception ex) {
  throw convertException(ex);
}
 finally {
  try {
    FileSystem actionFs=context.getAppFileSystem();
    cleanUpActionDir(actionFs,context);
  }
 catch (  Exception ex) {
    throw convertException(ex);
  }
}
",0,0,0,,
568,} finally {,"try {
  Element actionXml=XmlUtils.parseXml(action.getConf());
  final Configuration jobConf=createBaseHadoopConf(context,actionXml);
  String launcherTag=getActionYarnTag(context,action);
  jobConf.set(LauncherMain.CHILD_MAPREDUCE_JOB_TAGS,LauncherHelper.getTag(launcherTag));
  yarnClient=createYarnClient(context,jobConf);
  String appExternalId=action.getExternalId();
  killExternalApp(action,yarnClient,appExternalId);
  killExternalChildApp(action,yarnClient,appExternalId);
  killExternalChildAppByTags(action,yarnClient,jobConf,appExternalId);
  context.setExternalStatus(KILLED);
  context.setExecutionData(KILLED,null);
}
 catch (Exception ex) {
  LOG.error(""Error when killing YARN application"",ex);
  throw convertException(ex);
}
 finally {
  try {
    FileSystem actionFs=context.getAppFileSystem();
    cleanUpActionDir(actionFs,context);
    IOUtils.closeQuietly(yarnClient);
  }
 catch (  Exception ex) {
    LOG.error(""Error when cleaning up action dir"",ex);
    throw convertException(ex);
  }
}
",0,0,0,,
569,finally {,"try {
  if (action.getStatus() == WorkflowAction.Status.OK) {
    Element actionXml=XmlUtils.parseXml(action.getConf());
    Configuration jobConf=createBaseHadoopConf(context,actionXml);
    jobClient=createJobClient(context,jobConf);
    RunningJob runningJob=jobClient.getJob(JobID.forName(action.getExternalChildIDs()));
    if (runningJob == null) {
      throw new ActionExecutorException(ActionExecutorException.ErrorType.FAILED,""MR002"",""Unknown hadoop job [{0}] associated with action [{1}].  Failing this action!"",action.getExternalChildIDs(),action.getId());
    }
    Counters counters=runningJob.getCounters();
    if (counters != null) {
      ActionStats stats=new MRStats(counters);
      String statsJsonString=stats.toJSON();
      context.setVar(HADOOP_COUNTERS,statsJsonString);
      if (Boolean.parseBoolean(evaluateConfigurationProperty(actionXml,OOZIE_ACTION_EXTERNAL_STATS_WRITE,""false"")) && (statsJsonString.getBytes(StandardCharsets.UTF_8).length <= getMaxExternalStatsSize())) {
        context.setExecutionStats(statsJsonString);
        log.debug(""Printing stats for Map-Reduce action as a JSON string : [{0}]"",statsJsonString);
      }
    }
 else {
      context.setVar(HADOOP_COUNTERS,"""");
      XLog.getLog(getClass()).warn(""Could not find Hadoop Counters for: [{0}]"",action.getExternalChildIDs());
    }
  }
}
 catch (Exception ex) {
  exception=true;
  throw convertException(ex);
}
 finally {
  if (jobClient != null) {
    try {
      jobClient.close();
    }
 catch (    Exception e) {
      if (exception) {
        log.error(""JobClient error: "",e);
      }
 else {
        throw convertException(e);
      }
    }
  }
}
",0,0,0,,
570,} finally {,"try {
  jobClient=createJobClient(context,new JobConf(jobConf));
  final JobID jobid=JobID.forName(newJobId);
  final RunningJob runningJob=jobClient.getJob(jobid);
  if (runningJob == null) {
    context.setExternalStatus(FAILED);
    throw new ActionExecutorException(ActionExecutorException.ErrorType.FAILED,""JA017"",""Unknown hadoop job [{0}] associated with action [{1}].  Failing this action!"",newJobId,action.getId());
  }
  jobCompleted=runningJob.isComplete();
}
 catch (Exception e) {
  LOG.warn(""Unable to check the state of a running MapReduce job -"" + "" please check the health of the Job History Server!"",e);
  exception=true;
  throw convertException(e);
}
 finally {
  if (jobClient != null) {
    try {
      jobClient.close();
    }
 catch (    Exception e) {
      if (exception) {
        LOG.error(""JobClient error (not re-throwing due to a previous error): "",e);
      }
 else {
        throw convertException(e);
      }
    }
  }
}
",0,0,0,,
571,finally {,"try {
  if (action.getStatus() == WorkflowAction.Status.OK) {
    Element actionXml=XmlUtils.parseXml(action.getConf());
    Configuration jobConf=createBaseHadoopConf(context,actionXml);
    jobClient=createJobClient(context,jobConf);
    Counters counters=null;
    String externalIds=action.getExternalChildIDs();
    if (externalIds != null && !externalIds.trim().isEmpty()) {
      String[] jobIds=externalIds.split("","");
      for (      String jobId : jobIds) {
        RunningJob runningJob=jobClient.getJob(JobID.forName(jobId));
        if (runningJob == null) {
          throw new ActionExecutorException(ActionExecutorException.ErrorType.FAILED,""SQOOP001"",""Unknown hadoop job [{0}] associated with action [{1}].  Failing this action!"",action.getExternalId(),action.getId());
        }
        Counters taskCounters=runningJob.getCounters();
        if (taskCounters != null) {
          if (counters == null) {
            counters=taskCounters;
          }
 else {
            counters.incrAllCounters(taskCounters);
          }
        }
 else {
          XLog.getLog(getClass()).warn(""Could not find Hadoop Counters for job: [{0}]"",jobId);
        }
      }
    }
    if (counters != null) {
      ActionStats stats=new MRStats(counters);
      String statsJsonString=stats.toJSON();
      context.setVar(MapReduceActionExecutor.HADOOP_COUNTERS,statsJsonString);
      if (Boolean.parseBoolean(evaluateConfigurationProperty(actionXml,OOZIE_ACTION_EXTERNAL_STATS_WRITE,""true"")) && (statsJsonString.getBytes(StandardCharsets.UTF_8).length <= getMaxExternalStatsSize())) {
        context.setExecutionStats(statsJsonString);
        LOG.debug(""Printing stats for sqoop action as a JSON string : [{0}]"",statsJsonString);
      }
    }
 else {
      context.setVar(MapReduceActionExecutor.HADOOP_COUNTERS,"""");
      XLog.getLog(getClass()).warn(""Can't find any associated Hadoop job counters"");
    }
  }
}
 catch (Exception ex) {
  exception=true;
  throw convertException(ex);
}
 finally {
  if (jobClient != null) {
    try {
      jobClient.close();
    }
 catch (    Exception e) {
      if (exception) {
        LOG.error(""JobClient error: "",e);
      }
 else {
        throw convertException(e);
      }
    }
  }
}
",0,0,0,,
572,finally {,"try {
  Configuration runConf=mergeConfig(coordAction);
  coordAction.setRunConf(XmlUtils.prettyPrint(runConf).toString());
  DagEngine dagEngine=Services.get().get(DagEngineService.class).getDagEngine(user);
  Configuration conf=new XConfiguration(new StringReader(coordAction.getRunConf()));
  SLAEventBean slaEvent=SLADbOperations.createStatusEvent(coordAction.getSlaXml(),coordAction.getId(),Status.STARTED,SlaAppType.COORDINATOR_ACTION,log);
  if (slaEvent != null) {
    insertList.add(slaEvent);
  }
  if (OozieJobInfo.isJobInfoEnabled()) {
    conf.set(OozieJobInfo.COORD_ID,actionId);
    conf.set(OozieJobInfo.COORD_NAME,appName);
    conf.set(OozieJobInfo.COORD_NOMINAL_TIME,coordAction.getNominalTimestamp().toString());
  }
  JobUtils.normalizeAppPath(conf.get(OozieClient.USER_NAME),conf.get(OozieClient.GROUP_NAME),conf);
  if (coordAction.getExternalId() != null) {
    conf.setBoolean(OozieClient.RERUN_FAIL_NODES,true);
    dagEngine.reRun(coordAction.getExternalId(),conf);
  }
 else {
    conf.set(OOZIE_COORD_ACTION_NOMINAL_TIME,String.valueOf(coordAction.getNominalTime().getTime()));
    String wfId=dagEngine.submitJobFromCoordinator(conf,actionId);
    coordAction.setExternalId(wfId);
  }
  coordAction.setStatus(CoordinatorAction.Status.RUNNING);
  coordAction.incrementAndGetPending();
  JPAService jpaService=Services.get().get(JPAService.class);
  if (jpaService != null) {
    log.debug(""Updating WF record for WFID :"" + coordAction.getExternalId() + "" with parent id: ""+ actionId);
    WorkflowJobBean wfJob=WorkflowJobQueryExecutor.getInstance().get(WorkflowJobQuery.GET_WORKFLOW_STARTTIME,coordAction.getExternalId());
    wfJob.setParentId(actionId);
    wfJob.setLastModifiedTime(new Date());
    BatchQueryExecutor executor=BatchQueryExecutor.getInstance();
    updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_PARENT_MODIFIED,wfJob));
    updateList.add(new UpdateEntry<CoordActionQuery>(CoordActionQuery.UPDATE_COORD_ACTION_FOR_START,coordAction));
    try {
      executor.executeBatchInsertUpdateDelete(insertList,updateList,null);
      queue(new CoordActionNotificationXCommand(coordAction),100);
      if (EventHandlerService.isEnabled()) {
        generateEvent(coordAction,user,appName,wfJob.getStartTime());
      }
    }
 catch (    JPAExecutorException je) {
      throw new CommandException(je);
    }
  }
 else {
    log.error(ErrorCode.E0610);
  }
  makeFail=false;
}
 catch (DagEngineException dee) {
  errMsg=dee.getMessage();
  errCode=dee.getErrorCode().toString();
  log.warn(""can not create DagEngine for submitting jobs"",dee);
}
catch (CommandException ce) {
  errMsg=ce.getMessage();
  errCode=ce.getErrorCode().toString();
  log.warn(""command exception occurred "",ce);
}
catch (java.io.IOException ioe) {
  errMsg=ioe.getMessage();
  errCode=""E1005"";
  log.warn(""Configuration parse error. read from DB :"" + coordAction.getRunConf(),ioe);
}
catch (Exception ex) {
  errMsg=ex.getMessage();
  errCode=""E1005"";
  log.warn(""can not create DagEngine for submitting jobs"",ex);
}
 finally {
  if (makeFail == true) {
    log.error(""Failing the action "" + coordAction.getId() + "". Because ""+ errCode+ "" : ""+ errMsg);
    coordAction.setStatus(CoordinatorAction.Status.FAILED);
    if (errMsg.length() > 254) {
      errMsg=errMsg.substring(0,255);
    }
    coordAction.setErrorMessage(errMsg);
    coordAction.setErrorCode(errCode);
    updateList=new ArrayList<UpdateEntry>();
    updateList.add(new UpdateEntry<CoordActionQuery>(CoordActionQuery.UPDATE_COORD_ACTION_FOR_START,coordAction));
    insertList=new ArrayList<JsonBean>();
    SLAEventBean slaEvent=SLADbOperations.createStatusEvent(coordAction.getSlaXml(),coordAction.getId(),Status.FAILED,SlaAppType.COORDINATOR_ACTION,log);
    if (slaEvent != null) {
      insertList.add(slaEvent);
    }
    try {
      BatchQueryExecutor.getInstance().executeBatchInsertUpdateDelete(insertList,updateList,null);
      if (EventHandlerService.isEnabled()) {
        generateEvent(coordAction,user,appName,null);
      }
    }
 catch (    JPAExecutorException je) {
      throw new CommandException(je);
    }
    queue(new CoordActionReadyXCommand(coordAction.getJobId()));
  }
}
",0,0,0,,
573,finally {,"try {
  boolean isRetry=false;
  if (wfAction.getRetries() > 0) {
    isRetry=true;
  }
  boolean isUserRetry=false;
  context=new ActionXCommand.ActionExecutorContext(wfJob,wfAction,isRetry,isUserRetry);
  incrActionCounter(wfAction.getType(),1);
  Instrumentation.Cron cron=new Instrumentation.Cron();
  cron.start();
  executor.check(context,wfAction);
  cron.stop();
  addActionCron(wfAction.getType(),cron);
  if (wfAction.isExecutionComplete()) {
    if (!context.isExecuted()) {
      LOG.warn(XLog.OPS,""Action Completed, ActionExecutor [{0}] must call setExecutionData()"",executor.getType());
      wfAction.setErrorInfo(EXEC_DATA_MISSING,""Execution Complete, but Execution Data Missing from Action"");
      failJob(context);
      generateEvent=true;
    }
 else {
      wfAction.setPending();
      execSynchronous=true;
    }
  }
  wfAction.setLastCheckTime(new Date());
  updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_CHECK,wfAction));
  wfJob.setLastModifiedTime(new Date());
  updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_STATUS_INSTANCE_MODIFIED,wfJob));
}
 catch (ActionExecutorException ex) {
  LOG.warn(""Exception while executing check(). Error Code [{0}], Message[{1}]"",ex.getErrorCode(),ex.getMessage(),ex);
  wfAction.setErrorInfo(ex.getErrorCode(),ex.getMessage());
switch (ex.getErrorType()) {
case ERROR:
    if (handleUserRetry(context,wfAction)) {
      break;
    }
case FAILED:
  failJob(context,wfAction);
generateEvent=true;
break;
case TRANSIENT:
if (!handleTransient(context,executor,WorkflowAction.Status.RUNNING)) {
handleNonTransient(context,executor,WorkflowAction.Status.START_MANUAL);
generateEvent=true;
wfAction.setPendingAge(new Date());
wfAction.setRetries(0);
wfAction.setStartTime(null);
}
break;
}
wfAction.setLastCheckTime(new Date());
updateList=new ArrayList<UpdateEntry>();
updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_CHECK,wfAction));
wfJob.setLastModifiedTime(new Date());
updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_STATUS_INSTANCE_MODIFIED,wfJob));
}
 finally {
try {
BatchQueryExecutor.getInstance().executeBatchInsertUpdateDelete(null,updateList,null);
if (generateEvent && EventHandlerService.isEnabled()) {
generateEvent(wfAction,wfJob.getUser());
}
if (execSynchronous) {
new ActionEndXCommand(wfAction.getId(),wfAction.getType()).call();
}
}
 catch (JPAExecutorException e) {
throw new CommandException(e);
}
}
",0,0,0,,
574,finally {,"try {
  LOG.debug(""End, name [{0}] type [{1}] status[{2}] external status [{3}] signal value [{4}]"",wfAction.getName(),wfAction.getType(),wfAction.getStatus(),wfAction.getExternalStatus(),wfAction.getSignalValue());
  Instrumentation.Cron cron=new Instrumentation.Cron();
  cron.start();
  executor.end(context,wfAction);
  cron.stop();
  addActionCron(wfAction.getType(),cron);
  incrActionCounter(wfAction.getType(),1);
  if (!context.isEnded()) {
    LOG.warn(XLog.OPS,""Action Ended, ActionExecutor [{0}] must call setEndData()"",executor.getType());
    wfAction.setErrorInfo(END_DATA_MISSING,""Execution Ended, but End Data Missing from Action"");
    failJob(context);
  }
 else {
    wfAction.setRetries(0);
    wfAction.setEndTime(new Date());
    boolean shouldHandleUserRetry=false;
    Status slaStatus=null;
switch (wfAction.getStatus()) {
case OK:
      slaStatus=Status.SUCCEEDED;
    break;
case KILLED:
  slaStatus=Status.KILLED;
break;
case FAILED:
slaStatus=Status.FAILED;
shouldHandleUserRetry=true;
break;
case ERROR:
LOG.info(""ERROR is considered as FAILED for SLA"");
slaStatus=Status.KILLED;
shouldHandleUserRetry=true;
break;
default :
slaStatus=Status.FAILED;
shouldHandleUserRetry=true;
break;
}
if (!shouldHandleUserRetry || !handleUserRetry(context,wfAction)) {
SLAEventBean slaEvent=SLADbXOperations.createStatusEvent(wfAction.getSlaXml(),wfAction.getId(),slaStatus,SlaAppType.WORKFLOW_ACTION);
if (slaEvent != null) {
insertList.add(slaEvent);
}
}
}
WorkflowInstance wfInstance=wfJob.getWorkflowInstance();
DagELFunctions.setActionInfo(wfInstance,wfAction);
wfJob.setWorkflowInstance(wfInstance);
updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_END,wfAction));
wfJob.setLastModifiedTime(new Date());
updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_STATUS_INSTANCE_MODIFIED,wfJob));
}
 catch (ActionExecutorException ex) {
LOG.warn(""Error ending action [{0}]. ErrorType [{1}], ErrorCode [{2}], Message [{3}]"",wfAction.getName(),ex.getErrorType(),ex.getErrorCode(),ex.getMessage());
wfAction.setErrorInfo(ex.getErrorCode(),ex.getMessage());
wfAction.setEndTime(null);
switch (ex.getErrorType()) {
case TRANSIENT:
if (!handleTransient(context,executor,WorkflowAction.Status.END_RETRY)) {
handleNonTransient(context,executor,WorkflowAction.Status.END_MANUAL);
wfAction.setPendingAge(new Date());
wfAction.setRetries(0);
}
wfAction.setEndTime(null);
break;
case NON_TRANSIENT:
handleNonTransient(context,executor,WorkflowAction.Status.END_MANUAL);
wfAction.setEndTime(null);
break;
case ERROR:
handleError(context,executor,COULD_NOT_END,false,WorkflowAction.Status.ERROR);
break;
case FAILED:
failJob(context);
break;
}
WorkflowInstance wfInstance=wfJob.getWorkflowInstance();
DagELFunctions.setActionInfo(wfInstance,wfAction);
wfJob.setWorkflowInstance(wfInstance);
updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_END,wfAction));
wfJob.setLastModifiedTime(new Date());
updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_STATUS_INSTANCE_MODIFIED,wfJob));
}
 finally {
try {
BatchQueryExecutor.getInstance().executeBatchInsertUpdateDelete(insertList,updateList,null);
}
 catch (JPAExecutorException e) {
throw new CommandException(e);
}
if (!(executor instanceof ControlNodeActionExecutor) && EventHandlerService.isEnabled()) {
generateEvent(wfAction,wfJob.getUser());
}
new SignalXCommand(jobId,actionId).call();
}
",0,0,0,,
575,finally {,"try {
  boolean isRetry=false;
  boolean isUserRetry=false;
  context=new ActionXCommand.ActionExecutorContext(wfJob,wfAction,isRetry,isUserRetry);
  incrActionCounter(wfAction.getType(),1);
  Instrumentation.Cron cron=new Instrumentation.Cron();
  cron.start();
  executor.kill(context,wfAction);
  cron.stop();
  addActionCron(wfAction.getType(),cron);
  wfAction.resetPending();
  wfAction.setStatus(WorkflowActionBean.Status.KILLED);
  wfAction.setEndTime(new Date());
  updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_END,wfAction));
  wfJob.setLastModifiedTime(new Date());
  updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_MODTIME,wfJob));
  SLAEventBean slaEvent=SLADbXOperations.createStatusEvent(wfAction.getSlaXml(),wfAction.getId(),Status.KILLED,SlaAppType.WORKFLOW_ACTION);
  if (slaEvent != null) {
    insertList.add(slaEvent);
  }
  queue(new WorkflowNotificationXCommand(wfJob,wfAction));
}
 catch (ActionExecutorException ex) {
  wfAction.resetPending();
  wfAction.setStatus(WorkflowActionBean.Status.FAILED);
  wfAction.setErrorInfo(ex.getErrorCode().toString(),""KILL COMMAND FAILED - exception while executing job kill"");
  wfAction.setEndTime(new Date());
  wfJob.setStatus(WorkflowJobBean.Status.KILLED);
  updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_END,wfAction));
  wfJob.setLastModifiedTime(new Date());
  updateList.add(new UpdateEntry<WorkflowJobQuery>(WorkflowJobQuery.UPDATE_WORKFLOW_STATUS_MODTIME,wfJob));
  SLAEventBean slaEvent=SLADbXOperations.createStatusEvent(wfAction.getSlaXml(),wfAction.getId(),Status.FAILED,SlaAppType.WORKFLOW_ACTION);
  if (slaEvent != null) {
    insertList.add(slaEvent);
  }
  LOG.warn(""Exception while executing kill(). Error Code [{0}], Message[{1}]"",ex.getErrorCode(),ex.getMessage(),ex);
}
 finally {
  try {
    cleanupActionDir(context);
    BatchQueryExecutor.getInstance().executeBatchInsertUpdateDelete(insertList,updateList,null);
    if (!(executor instanceof ControlNodeActionExecutor) && EventHandlerService.isEnabled()) {
      generateEvent(wfAction,wfJob.getUser());
    }
  }
 catch (  JPAExecutorException e) {
    throw new CommandException(e);
  }
}
",0,0,0,,
576,finally {,"try {
  boolean isRetry=false;
  if (wfAction.getStatus() == WorkflowActionBean.Status.START_RETRY || wfAction.getStatus() == WorkflowActionBean.Status.START_MANUAL) {
    isRetry=true;
    prepareForRetry(wfAction);
  }
  boolean isUserRetry=false;
  if (wfAction.getStatus() == WorkflowActionBean.Status.USER_RETRY) {
    isUserRetry=true;
    prepareForRetry(wfAction);
  }
  context=getContext(isRetry,isUserRetry);
  boolean caught=false;
  try {
    if (!(executor instanceof ControlNodeActionExecutor)) {
      String tmpActionConf=XmlUtils.removeComments(wfAction.getConf());
      String actionConf=context.getELEvaluator().evaluate(tmpActionConf,String.class);
      wfAction.setConf(actionConf);
      LOG.debug(""Start, name [{0}] type [{1}] configuration{E}{E}{2}{E}"",wfAction.getName(),wfAction.getType(),actionConf);
    }
  }
 catch (  ELEvaluationException ex) {
    caught=true;
    throw new ActionExecutorException(ActionExecutorException.ErrorType.TRANSIENT,EL_EVAL_ERROR,ex.getMessage(),ex);
  }
catch (  ELException ex) {
    caught=true;
    context.setErrorInfo(EL_ERROR,ex.getMessage());
    LOG.warn(""ELException in ActionStartXCommand "",ex.getMessage(),ex);
    handleError(context,wfJob,wfAction);
  }
catch (  org.jdom.JDOMException je) {
    caught=true;
    context.setErrorInfo(""ParsingError"",je.getMessage());
    LOG.warn(""JDOMException in ActionStartXCommand "",je.getMessage(),je);
    handleError(context,wfJob,wfAction);
  }
catch (  Exception ex) {
    caught=true;
    context.setErrorInfo(EL_ERROR,ex.getMessage());
    LOG.warn(""Exception in ActionStartXCommand "",ex.getMessage(),ex);
    handleError(context,wfJob,wfAction);
  }
  if (!caught) {
    wfAction.setErrorInfo(null,null);
    incrActionCounter(wfAction.getType(),1);
    LOG.info(""Start action [{0}] with user-retry state : userRetryCount [{1}], userRetryMax [{2}], userRetryInterval"" + "" [{3}]"",wfAction.getId(),wfAction.getUserRetryCount(),wfAction.getUserRetryMax(),wfAction.getUserRetryInterval());
    Instrumentation.Cron cron=new Instrumentation.Cron();
    cron.start();
    if (wfAction.getStartTime() == null) {
      context.setStartTime();
    }
    context.setVar(JobUtils.getRetryKey(wfAction,JsonTags.WORKFLOW_ACTION_START_TIME),String.valueOf(new Date().getTime()));
    executor.start(context,wfAction);
    cron.stop();
    FaultInjection.activate(""org.apache.oozie.command.SkipCommitFaultInjection"");
    addActionCron(wfAction.getType(),cron);
    wfAction.setRetries(0);
    if (wfAction.isExecutionComplete()) {
      if (!context.isExecuted()) {
        LOG.warn(XLog.OPS,""Action Completed, ActionExecutor [{0}] must call setExecutionData()"",executor.getType());
        wfAction.setErrorInfo(EXEC_DATA_MISSING,""Execution Complete, but Execution Data Missing from Action"");
        failJob(context);
      }
 else {
        wfAction.setPending();
        if (!(executor instanceof ControlNodeActionExecutor)) {
          queue(new ActionEndXCommand(wfAction.getId(),wfAction.getType()));
        }
 else {
          execSynchronous=true;
        }
      }
    }
 else {
      if (!context.isStarted()) {
        LOG.warn(XLog.OPS,""Action Started, ActionExecutor [{0}] must call setStartData()"",executor.getType());
        wfAction.setErrorInfo(START_DATA_MISSING,""Execution Started, but Start Data Missing from Action"");
        failJob(context);
      }
 else {
        queue(new WorkflowNotificationXCommand(wfJob,wfAction));
      }
    }
    LOG.info(XLog.STD,""[***"" + wfAction.getId() + ""***]""+ ""Action status=""+ wfAction.getStatusStr());
    updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_START,wfAction));
    updateJobLastModified();
    SLAEventBean slaEvent=SLADbXOperations.createStatusEvent(wfAction.getSlaXml(),wfAction.getId(),Status.STARTED,SlaAppType.WORKFLOW_ACTION);
    if (slaEvent != null) {
      insertList.add(slaEvent);
    }
    LOG.info(XLog.STD,""[***"" + wfAction.getId() + ""***]""+ ""Action updated in DB!"");
  }
}
 catch (ActionExecutorException ex) {
  LOG.warn(""Error starting action [{0}]. ErrorType [{1}], ErrorCode [{2}], Message [{3}]"",wfAction.getName(),ex.getErrorType(),ex.getErrorCode(),ex.getMessage(),ex);
  wfAction.setErrorInfo(ex.getErrorCode(),ex.getMessage());
switch (ex.getErrorType()) {
case TRANSIENT:
    if (!handleTransient(context,executor,WorkflowAction.Status.START_RETRY)) {
      handleNonTransient(context,executor,WorkflowAction.Status.START_MANUAL);
      wfAction.setPendingAge(new Date());
      wfAction.setRetries(0);
      wfAction.setStartTime(null);
    }
  break;
case NON_TRANSIENT:
handleNonTransient(context,executor,WorkflowAction.Status.START_MANUAL);
break;
case ERROR:
handleError(context,executor,WorkflowAction.Status.ERROR.toString(),true,WorkflowAction.Status.DONE);
break;
case FAILED:
try {
failJob(context);
endWF();
SLAEventBean slaEvent1=SLADbXOperations.createStatusEvent(wfAction.getSlaXml(),wfAction.getId(),Status.FAILED,SlaAppType.WORKFLOW_ACTION);
if (slaEvent1 != null) {
insertList.add(slaEvent1);
}
}
 catch (XException x) {
LOG.warn(""ActionStartXCommand - case:FAILED "",x.getMessage());
}
break;
}
updateList.add(new UpdateEntry<WorkflowActionQuery>(WorkflowActionQuery.UPDATE_ACTION_START,wfAction));
updateJobLastModified();
}
 finally {
try {
BatchQueryExecutor.getInstance().executeBatchInsertUpdateDelete(insertList,updateList,null);
if (!(executor instanceof ControlNodeActionExecutor) && EventHandlerService.isEnabled()) {
generateEvent(wfAction,wfJob.getUser());
}
if (execSynchronous) {
callActionEnd();
}
}
 catch (JPAExecutorException e) {
throw new CommandException(e);
}
}
",0,0,0,,
577,finally {,"try {
  value=atomicIdGenerator.increment();
}
 catch (Exception e) {
  throw new Exception(""Exception incrementing UID for session "",e);
}
 finally {
  if (value != null && value.succeeded()) {
    return value.preValue();
  }
 else {
    throw new Exception(""Exception incrementing UID for session "");
  }
}
",0,0,0,,
578,finally {,"try {
  jobClient=createJobClient(jobConf);
  runJob=jobClient.submitJob(jobConf);
}
 catch (Exception ex) {
  exception=true;
  throw ex;
}
 finally {
  try {
    if (jobClient != null) {
      jobClient.close();
    }
  }
 catch (  Exception ex) {
    if (exception) {
      System.out.println(""JobClient Error: "" + ex);
    }
 else {
      throw ex;
    }
  }
}
",0,0,0,,
579,}finally {,"try {
  if (needCaptured) {
    File file=new File(System.getProperty(OUTPUT_PROPERTIES));
    os=new BufferedWriter(new OutputStreamWriter(new FileOutputStream(file),StandardCharsets.UTF_8));
  }
  while ((line=reader.readLine()) != null) {
    if (isStdout) {
      System.out.println(""Stdoutput "" + line);
      if (os != null) {
        if (Shell.WINDOWS) {
          line=line.replace(""\\u"",""\\\\u"");
        }
        os.write(line);
        os.newLine();
      }
    }
 else {
      System.err.println(line);
    }
  }
}
 catch (IOException e) {
  e.printStackTrace();
  throw new RuntimeException(""Stdout/Stderr read/write error :"" + e);
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException ex) {
  }
  if (os != null) {
    try {
      os.close();
    }
 catch (    IOException e) {
      e.printStackTrace();
      throw new RuntimeException(""Unable to close the file stream :"" + e);
    }
  }
}
",0,0,0,,
580,finally {,"try {
  jobClient=createJobClient(jobConf);
  runJob=jobClient.submitJob(jobConf);
}
 catch (Exception ex) {
  exception=true;
  throw ex;
}
 finally {
  try {
    if (jobClient != null) {
      jobClient.close();
    }
  }
 catch (  Exception ex) {
    if (exception) {
      System.out.println(""JobClient Error: "" + ex);
    }
 else {
      throw ex;
    }
  }
}
",0,0,0,,
581,} finally {,"try {
  if (type == InterfaceType.SERVICE_ENDPOINT) {
    callContext.setCurrentOperation(Operation.BUSINESS_WS);
    returnValue=invokeWebService(args,beanContext,runMethod,instance,returnValue);
  }
 else {
    List<InterceptorData> interceptors=beanContext.getMethodInterceptors(runMethod);
    InterceptorStack interceptorStack=new InterceptorStack(instance.bean,runMethod,type == InterfaceType.TIMEOUT ? Operation.TIMEOUT : Operation.BUSINESS,interceptors,instance.interceptors);
    returnValue=interceptorStack.invoke(args);
  }
}
 catch (Throwable re) {
  ExceptionType exceptionType=beanContext.getExceptionType(re);
  if (exceptionType == ExceptionType.SYSTEM) {
    callContext.setDiscardInstance(true);
    handleSystemException(txPolicy,re,callContext);
  }
 else {
    handleApplicationException(txPolicy,re,exceptionType == ExceptionType.APPLICATION_ROLLBACK);
  }
}
 finally {
  try {
    afterInvoke(txPolicy,callContext);
  }
 catch (  SystemException e) {
    callContext.setDiscardInstance(true);
    throw e;
  }
catch (  ApplicationException e) {
    throw e;
  }
catch (  RuntimeException e) {
    callContext.setDiscardInstance(true);
    throw e;
  }
}
",0,0,0,,
582,} finally {,"try {
  JobDataMap jobDataMap=execution.getJobDetail().getJobDataMap();
  Data data=Data.class.cast(jobDataMap.get(Data.class.getName()));
  Job job=data.job;
  endpoint=(MessageEndpoint)job;
  if (null == method) {
    method=Job.class.getMethod(""execute"",JobExecutionContext.class);
  }
  endpoint.beforeDelivery(method);
  job.execute(execution);
}
 catch (NoSuchMethodException e) {
  throw new IllegalStateException(e);
}
catch (ResourceException e) {
  throw new JobExecutionException(e);
}
catch (Throwable t) {
  throw new JobExecutionException(new Exception(t));
}
 finally {
  if (null != endpoint) {
    try {
      endpoint.afterDelivery();
    }
 catch (    ResourceException e) {
      throw new JobExecutionException(e);
    }
  }
}
",0,0,0,,
583,} finally {,"try {
  RowImpl onerow=null;
  ps=prepareStatement(batchedSql);
  if (batchSize == 1) {
    onerow=batchedRows.get(0);
    flushSingleRow(onerow,ps);
  }
 else {
    int count=0;
    int batchedRowsBaseIndex=0;
    Iterator<RowImpl> itr=batchedRows.iterator();
    while (itr.hasNext()) {
      onerow=itr.next();
      if (_batchLimit == 1) {
        flushSingleRow(onerow,ps);
      }
 else {
        if (count < _batchLimit || _batchLimit == -1) {
          if (ps != null)           onerow.flush(ps,_dict,_store);
          addBatch(ps,onerow,count);
          count++;
        }
 else {
          int[] rtn=executeBatch(ps);
          checkUpdateCount(rtn,batchedRowsBaseIndex,ps);
          batchedRowsBaseIndex+=_batchLimit;
          if (ps != null)           onerow.flush(ps,_dict,_store);
          addBatch(ps,onerow,count);
          count=1;
        }
      }
    }
    int[] rtn=executeBatch(ps);
    checkUpdateCount(rtn,batchedRowsBaseIndex,ps);
  }
}
 catch (SQLException se) {
  SQLException sqex=se.getNextException();
  if (sqex == null) {
    sqex=se;
  }
  if (se instanceof ReportingSQLException) {
    int index=((ReportingSQLException)se).getIndexOfFirstFailedObject();
    if (batchSize == 1) {
      index=0;
    }
    if (index < 0) {
      throw SQLExceptions.getStore(se,ps,_dict);
    }
 else {
      if (_batchedRows.size() == 0) {
        if (_log.isTraceEnabled()) {
          _log.trace(""No batched rows found. The failed object may not be reliable"");
        }
        throw SQLExceptions.getStore(se,ps,_dict);
      }
      throw SQLExceptions.getStore(se,(_batchedRows.get(index)).getFailedObject(),_dict);
    }
  }
 else {
    throw SQLExceptions.getStore(sqex,ps,_dict);
  }
}
 finally {
  _batchedSql=null;
  batchedRows.clear();
  if (ps != null) {
    ps.clearParameters();
    try {
      ps.close();
    }
 catch (    SQLException sqex) {
      throw SQLExceptions.getStore(sqex,ps,_dict);
    }
  }
}
",0,0,0,,
584,finally,"try {
  xmlStream=beansXmlUrl.openStream();
  return readBeansXml(xmlStream,beansXmlUrl.toExternalForm());
}
 catch (Exception e) {
  throw new WebBeansDeploymentException(""Error while parsing the beans.xml file "" + beansXmlLocation,e);
}
 finally {
  try {
    if (xmlStream != null) {
      xmlStream.close();
    }
  }
 catch (  IOException ioe) {
    throw new WebBeansDeploymentException(""Error while closing the input stream!"",ioe);
  }
}
",0,0,0,,
585,} finally {,"try {
  final Path dstFile=Paths.get(base.getAbsolutePath() + ""/conf/"" + certificate);
  resourceAsStream=Thread.currentThread().getContextClassLoader().getResourceAsStream(certificate);
  if (resourceAsStream == null) {
    resourceAsStream=new FileInputStream(new File((this.getClass().getResource(""/"").toString().replaceAll(""file:"","""") + ""/"" + certificate)));
  }
  Files.copy(resourceAsStream,dstFile,StandardCopyOption.REPLACE_EXISTING);
}
 catch (IOException e) {
  throw new IllegalStateException(e);
}
 finally {
  if (resourceAsStream != null) {
    try {
      resourceAsStream.close();
    }
 catch (    IOException e) {
      throw new IllegalStateException(e);
    }
  }
}
",0,0,0,,
586,} finally {,"try {
  contexts.values().forEach(Runnable::run);
}
  finally {
  try {
    tomcat.stop();
    tomcat.destroy();
  }
 catch (  final LifecycleException e) {
    throw new IllegalStateException(e);
  }
 finally {
    Cxfs.resetDefaultBusIfEquals(clientBus);
    tomcat=null;
    contexts.clear();
    if (clearCatalinaSystemProperties) {
      Stream.of(""catalina.base"",""catalina.home"").forEach(System::clearProperty);
    }
    if (configuration.isUseLog4j2JulLogManager()) {
      System.clearProperty(""java.util.logging.manager"");
    }
    ofNullable(postTask).ifPresent(Runnable::run);
    postTask=null;
    try {
      if (deleteBase && base != null) {
        IO.delete(base);
      }
      if (ownedTempDir != null) {
        IO.delete(ownedTempDir);
      }
    }
 catch (    final IllegalArgumentException e) {
    }
 finally {
      base=null;
      ofNullable(configuration.getPidFile()).ifPresent(File::delete);
    }
  }
}
",0,0,0,,
587,} finally {,"try {
  if (state.old != state.current) {
    try {
      state.current.commit();
    }
 catch (    final HeuristicMixedException|HeuristicRollbackException|RollbackException|SystemException e) {
      throw new TransactionalException(e.getMessage(),e);
    }
  }
}
  finally {
  if (state.old != null) {
    try {
      transactionManager.resume(state.old);
    }
 catch (    final InvalidTransactionException|SystemException e) {
      throw new TransactionalException(e.getMessage(),e);
    }
  }
}
",0,0,0,,
588,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,false,numRows,true,conn,false);
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,0,true,numRows,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
589,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,false,numRows,true,conn,true);
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,0,true,numRows,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
590,} finally {,"try {
  conn=getConnFromTestDriver();
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    conn.setAutoCommit(true);
    for (int i=0; i < numRows; i++) {
      prepStmt.setString(1,KEY + i);
      prepStmt.setString(2,VALUE + i);
      prepStmt.executeUpdate();
    }
  }
 }
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,writeMutMetrics.get(UPSERT_COMMIT_TIME),true,numRows,0,0,numRows,0,writeMutMetrics,conn);
}
",0,0,0,,
591,} finally {,"try {
  conn=getConnFromTestDriver();
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    prepStmt.setString(1,KEY);
    prepStmt.setString(2,VALUE);
    try {
      prepStmt.executeUpdate();
      fail();
    }
 catch (    SQLException sqlE) {
      assertEquals(DATA_EXCEEDS_MAX_CAPACITY.getErrorCode(),sqlE.getErrorCode());
    }
  }
 }
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  conn.close();
  assertMutationTableMetrics(true,tableName,0,1,0,false,0,0,0,1,0,null,conn);
}
",0,0,0,,
592,} finally {,"try {
  conn=getConnFromTestDriver();
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    MyClock clock=new MyClock(10,delay);
    EnvironmentEdgeManager.injectEdge(clock);
    for (int i=0; i < numRows; i++) {
      prepStmt.setString(1,KEY + i);
      prepStmt.setString(2,VALUE + i);
      prepStmt.executeUpdate();
    }
  }
   conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,delay,true,numRows,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
593,} finally {,"try {
  conn=getConnFromTestDriver();
  conn.setAutoCommit(true);
  DelayedOrFailingRegionServer.injectFailureForRegionOfTable(tableName);
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    for (int i=0; i < numRows; i++) {
      prepStmt.setString(1,KEY + i);
      prepStmt.setString(2,VALUE + i);
      prepStmt.executeUpdate();
    }
  }
 }
 catch (CommitException e) {
  Throwable retriesExhaustedEx=null;
  for (Throwable t=e.getCause(); t != null; t=t.getCause()) {
    if (t instanceof RetriesExhaustedWithDetailsException) {
      retriesExhaustedEx=t;
      break;
    }
  }
  assertNotNull(retriesExhaustedEx);
  assertTrue(retriesExhaustedEx.getMessage().contains(INJECTED_EXCEPTION_STRING));
}
catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,0,1,0,true,1,0,1,0,1,writeMutMetrics,conn);
}
",0,0,0,,
594,} finally {,"try {
  conn=getConnFromTestDriver();
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    for (int i=0; i < numRows; i++) {
      prepStmt.setString(1,KEY + i);
      prepStmt.setString(2,VALUE + i);
      prepStmt.executeUpdate();
    }
  }
   DelayedOrFailingRegionServer.injectFailureForRegionOfTable(tableName);
  try {
    conn.commit();
    fail();
  }
 catch (  CommitException e) {
    Throwable retriesExhaustedEx=null;
    for (Throwable t=e.getCause(); t != null; t=t.getCause()) {
      if (t instanceof RetriesExhaustedWithDetailsException) {
        retriesExhaustedEx=t;
        break;
      }
    }
    assertNotNull(retriesExhaustedEx);
    assertTrue(retriesExhaustedEx.getMessage().contains(INJECTED_EXCEPTION_STRING));
  }
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,0,true,numRows,0,numRows,0,1,writeMutMetrics,conn);
}
",0,0,0,,
595,} finally {,"try {
  conn=getConnFromTestDriver();
  try (PreparedStatement prepStmt=conn.prepareStatement(dml)){
    for (int i=0; i < numRows; i++) {
      prepStmt.setString(1,KEY + i);
      prepStmt.setString(2,VALUE + i);
      prepStmt.executeUpdate();
    }
  }
   DelayedOrFailingRegionServer.setDelayEnabled(true);
  DelayedOrFailingRegionServer.setDelayMultiOp(delayRs);
  conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(true,tableName,numRows,0,0,true,numRows,delayRs,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
596,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,true,numRows,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  doPointDeleteFromTable(tableName,conn);
  conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,0,true,1,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
597,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,true,numRows,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  doDeleteAllFromTable(tableName,conn);
  conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,0,true,numRows,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
598,} finally {,"try {
  conn=getConnFromTestDriver();
  conn.setAutoCommit(true);
  doPointDeleteFromTable(tableName,conn);
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  assertNull(writeMutMetrics);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,0,false,0,0,0,0,0,writeMutMetrics,conn);
}
",0,0,0,,
599,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,true,numRows,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  failExecuteQueryAndClientSideDeletes=true;
  try {
    doPointDeleteFromTable(tableName,conn);
    fail();
  }
 catch (  SQLException sqlE) {
    assertEquals(GET_TABLE_REGIONS_FAIL.getErrorCode(),sqlE.getErrorCode());
  }
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  assertNull(writeMutMetrics);
  conn.close();
  assertMutationTableMetrics(false,tableName,0,1,0,false,0,0,0,0,1,null,conn);
}
",0,0,0,,
600,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,false,true,10,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  injectDelay=3000;
  doPointDeleteFromTable(tableName,conn);
  conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,injectDelay,true,1,0,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
601,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,true,numRows,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  doDeleteAllFromTable(tableName,conn);
  DelayedOrFailingRegionServer.injectFailureForRegionOfTable(tableName);
  try {
    conn.commit();
    fail();
  }
 catch (  CommitException e) {
    Throwable retriesExhaustedEx=null;
    for (Throwable t=e.getCause(); t != null; t=t.getCause()) {
      if (t instanceof RetriesExhaustedWithDetailsException) {
        retriesExhaustedEx=t;
        break;
      }
    }
    assertNotNull(retriesExhaustedEx);
    assertTrue(retriesExhaustedEx.getMessage().contains(INJECTED_EXCEPTION_STRING));
  }
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,0,true,numRows,0,numRows,0,1,writeMutMetrics,conn);
}
",0,0,0,,
602,} finally {,"try {
  conn=getConnFromTestDriver();
  createTableAndInsertValues(tableName,true,true,numRows,true,conn,false);
  PhoenixRuntime.resetMetrics(conn);
  clearTableLevelMetrics();
  doDeleteAllFromTable(tableName,conn);
  DelayedOrFailingRegionServer.setDelayEnabled(true);
  DelayedOrFailingRegionServer.setDelayMultiOp(delayRs);
  conn.commit();
}
 catch (Throwable t) {
  exception=t;
}
 finally {
  if (exception != null) {
    throw exception;
  }
  assertNotNull(""Failed to get a connection!"",conn);
  Map<MetricType,Long> writeMutMetrics=getWriteMetricInfoForMutationsSinceLastReset(conn).get(tableName);
  conn.close();
  assertMutationTableMetrics(false,tableName,1,0,0,true,numRows,delayRs,0,1,0,writeMutMetrics,conn);
}
",0,0,0,,
603,} finally {,"try {
  conn=QueryUtil.getConnectionOnServer(ctx.getEnvironment().getConfiguration()).unwrap(PhoenixConnection.class);
  PTable dataTable=IndexUtil.getPDataTable(conn,ctx.getEnvironment().getRegion().getTableDescriptor());
  List<PTable> indexes=dataTable.getIndexes();
  Map<ImmutableBytesWritable,IndexMaintainer> indexMaintainers=new HashMap<ImmutableBytesWritable,IndexMaintainer>();
  for (  PTable index : indexes) {
    if (index.getIndexType() == IndexType.LOCAL) {
      IndexMaintainer indexMaintainer=index.getIndexMaintainer(dataTable,conn);
      indexMaintainers.put(new ImmutableBytesWritable(index.getviewIndexIdType().toBytes(index.getViewIndexId())),indexMaintainer);
    }
  }
  if (indexMaintainers.isEmpty())   return reader;
  byte[][] viewConstants=getViewConstants(dataTable);
  return new IndexHalfStoreFileReader(fs,p,cacheConf,in,size,r,ctx.getEnvironment().getConfiguration(),indexMaintainers,viewConstants,childRegion,regionStartKeyInHFile,splitKey,childRegion.getReplicaId() == RegionInfo.DEFAULT_REPLICA_ID,new AtomicInteger(0),region.getRegionInfo());
}
 catch (SQLException e) {
  throw new IOException(e);
}
 finally {
  if (conn != null) {
    try {
      conn.close();
    }
 catch (    SQLException e) {
      throw new IOException(e);
    }
  }
}
",0,0,0,,
604,} finally {,"try {
  List<HRegionLocation> locations=services.getAllTableRegions(cacheUsingTable.getPhysicalName().getBytes());
  int nRegions=locations.size();
  futures=new ArrayList<Future<Boolean>>(nRegions);
  Set<HRegionLocation> servers=new HashSet<HRegionLocation>(nRegions);
  for (  HRegionLocation entry : locations) {
    byte[] regionStartKey=entry.getRegion().getStartKey();
    byte[] regionEndKey=entry.getRegion().getEndKey();
    if (!servers.contains(entry) && keyRanges.intersectRegion(regionStartKey,regionEndKey,cacheUsingTable.getIndexType() == IndexType.LOCAL)) {
      servers.add(entry);
      if (LOGGER.isDebugEnabled()) {
        LOGGER.debug(addCustomAnnotations(""Adding cache entry to be sent for "" + entry,connection));
      }
      final byte[] key=getKeyInRegion(entry.getRegionInfo().getStartKey());
      final Table htable=services.getTable(cacheUsingTable.getPhysicalName().getBytes());
      closeables.add(htable);
      futures.add(executor.submit(new JobCallable<Boolean>(){
        @Override public Boolean call() throws Exception {
          return addServerCache(htable,key,cacheUsingTable,cacheId,cachePtr,cacheFactory,txState,usePersistentCache);
        }
        /** 
 * Defines the grouping for round robin behavior.  All threads spawned to process this scan will be grouped together and time sliced with other simultaneously executing parallel scans.
 */
        @Override public Object getJobId(){
          return ServerCacheClient.this;
        }
        @Override public TaskExecutionMetricsHolder getTaskExecutionMetric(){
          return NO_OP_INSTANCE;
        }
      }
));
    }
 else {
      if (LOGGER.isDebugEnabled()) {
        LOGGER.debug(addCustomAnnotations(""NOT adding cache entry to be sent for "" + entry + "" since one already exists for that entry"",connection));
      }
    }
  }
  hashCacheSpec=new ServerCache(cacheId,servers,cachePtr,services,storeCacheOnClient);
  int timeoutMs=services.getProps().getInt(QueryServices.THREAD_TIMEOUT_MS_ATTRIB,QueryServicesOptions.DEFAULT_THREAD_TIMEOUT_MS);
  for (  Future<Boolean> future : futures) {
    future.get(timeoutMs,TimeUnit.MILLISECONDS);
  }
  cacheUsingTableMap.put(Bytes.mapKey(cacheId),cacheUsingTable);
  success=true;
}
 catch (SQLException e) {
  firstException=e;
}
catch (Exception e) {
  firstException=new SQLException(e);
}
 finally {
  try {
    if (!success) {
      if (hashCacheSpec != null) {
        SQLCloseables.closeAllQuietly(Collections.singletonList(hashCacheSpec));
      }
      SQLCloseables.closeAllQuietly(Collections.singletonList(hashCacheSpec));
      for (      Future<Boolean> future : futures) {
        future.cancel(true);
      }
    }
  }
  finally {
    try {
      Closeables.closeAll(closeables);
    }
 catch (    IOException e) {
      if (firstException == null) {
        firstException=new SQLException(e);
      }
    }
 finally {
      if (firstException != null) {
        throw firstException;
      }
    }
  }
}
",0,0,0,,
605,} finally {,"try {
  if (!success) {
    if (hashCacheSpec != null) {
      SQLCloseables.closeAllQuietly(Collections.singletonList(hashCacheSpec));
    }
    SQLCloseables.closeAllQuietly(Collections.singletonList(hashCacheSpec));
    for (    Future<Boolean> future : futures) {
      future.cancel(true);
    }
  }
}
  finally {
  try {
    Closeables.closeAll(closeables);
  }
 catch (  IOException e) {
    if (firstException == null) {
      firstException=new SQLException(e);
    }
  }
 finally {
    if (firstException != null) {
      throw firstException;
    }
  }
}
",0,0,0,,
606,} finally {,"try {
  Closeables.closeAll(closeables);
}
 catch (IOException e) {
  if (firstException == null) {
    firstException=new SQLException(e);
  }
}
 finally {
  if (firstException != null) {
    throw firstException;
  }
}
",0,0,0,,
607,} finally {,"try {
  Tuple row=iterator.next();
  ImmutableBytesWritable ptr=context.getTempPtr();
  totalMutationCount+=(Long)projector.getColumnProjector(0).getValue(row,PLong.INSTANCE,ptr);
}
 catch (SQLException e) {
  sqlE=e;
}
 finally {
  try {
    iterator.close();
  }
 catch (  SQLException e) {
    if (sqlE == null) {
      sqlE=e;
    }
 else {
      sqlE.setNextException(e);
    }
  }
 finally {
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
608,} finally {,"try {
  iterator.close();
}
 catch (SQLException e) {
  if (sqlE == null) {
    sqlE=e;
  }
 else {
    sqlE.setNextException(e);
  }
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
609,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  WritableUtils.writeVInt(output,arrayKVRefs.size());
  for (  Expression expression : arrayKVRefs) {
    expression.write(output);
  }
  WritableUtils.writeVInt(output,arrayKVFuncs.size());
  for (  Expression expression : arrayKVFuncs) {
    expression.write(output);
  }
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
610,} finally {,"try {
  if (groupByExpressions.isEmpty()) {
    stream.write(QueryConstants.TRUE);
  }
 else {
    DataOutputStream output=new DataOutputStream(stream);
    for (    Expression expression : groupByExpressions) {
      WritableUtils.writeVInt(output,ExpressionType.valueOf(expression).ordinal());
      expression.write(output);
    }
  }
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
611,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  WritableUtils.writeVInt(output,limit);
  WritableUtils.writeVInt(output,estimatedRowSize);
  WritableUtils.writeVInt(output,orderByExpressions.size());
  for (  OrderByExpression orderingCol : orderByExpressions) {
    orderingCol.write(output);
  }
  scan.setAttribute(BaseScannerRegionObserver.TOPN,stream.toByteArray());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
612,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  int size=WritableUtils.readVInt(input);
  List<Expression> selectExpressions=Lists.newArrayListWithExpectedSize(size);
  for (int i=0; i < size; i++) {
    ExpressionType type=ExpressionType.values()[WritableUtils.readVInt(input)];
    Expression selectExpression=type.newInstance();
    selectExpression.readFields(input);
    selectExpressions.add(selectExpression);
  }
  return selectExpressions;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
613,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  WritableUtils.writeVInt(output,selectExpressions.size());
  for (int i=0; i < selectExpressions.size(); i++) {
    Expression expression=selectExpressions.get(i);
    WritableUtils.writeVInt(output,ExpressionType.valueOf(expression).ordinal());
    expression.write(output);
  }
  return stream.toByteArray();
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
614,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  WritableUtils.writeVInt(output,viewConstants.length);
  for (  byte[] viewConstant : viewConstants) {
    Bytes.writeByteArray(output,viewConstant);
  }
  scan.setAttribute(BaseScannerRegionObserver.VIEW_CONSTANTS,stream.toByteArray());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
615,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  boolean storeColsInSingleCell=dataTable.getImmutableStorageScheme() == ImmutableStorageScheme.SINGLE_CELL_ARRAY_WITH_OFFSETS;
  if (storeColsInSingleCell) {
    scan.setAttribute(BaseScannerRegionObserver.COLUMNS_STORED_IN_SINGLE_CELL,QueryConstants.EMPTY_COLUMN_VALUE_BYTES);
  }
  WritableUtils.writeVInt(output,dataColumns.size());
  for (  PColumn column : dataColumns) {
    byte[] cf=column.getFamilyName().getBytes();
    byte[] cq=column.getColumnQualifierBytes();
    Bytes.writeByteArray(output,cf);
    Bytes.writeByteArray(output,cq);
  }
  scan.setAttribute(BaseScannerRegionObserver.DATA_TABLE_COLUMNS_TO_JOIN,stream.toByteArray());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
616,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  schema.write(output);
  scan.setAttribute(BaseScannerRegionObserver.LOCAL_INDEX_JOIN_SCHEMA,stream.toByteArray());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
617,} finally {,"try {
  if (table.isTransactional()) {
    if (tableInfo.isDataTable()) {
      uncommittedPhysicalNames.add(table.getPhysicalName().getString());
      phoenixTransactionContext.markDMLFence(table);
    }
    hTable=phoenixTransactionContext.getTransactionalTableWriter(connection,table,hTable,tableInfo.isDataTable() && table.getType() == PTableType.INDEX);
  }
  numMutations=mutationList.size();
  GLOBAL_MUTATION_BATCH_SIZE.update(numMutations);
  totalMutationBytesObject=calculateMutationSize(mutationList,true);
  child.addTimelineAnnotation(""Attempt "" + retryCount);
  Iterator<List<Mutation>> itrListMutation=mutationBatchList.iterator();
  while (itrListMutation.hasNext()) {
    final List<Mutation> mutationBatch=itrListMutation.next();
    currentMutationBatch=mutationBatch;
    if (shouldRetryIndexedMutation) {
      final Table finalHTable=hTable;
      final ImmutableBytesWritable finalindexMetaDataPtr=indexMetaDataPtr;
      final PTable finalPTable=table;
      PhoenixIndexFailurePolicy.doBatchWithRetries(new MutateCommand(){
        @Override public void doMutation() throws IOException {
          try {
            finalHTable.batch(mutationBatch,null);
          }
 catch (          InterruptedException e) {
            Thread.currentThread().interrupt();
            throw new IOException(e);
          }
catch (          IOException e) {
            e=updateTableRegionCacheIfNecessary(e);
            throw e;
          }
        }
        @Override public List<Mutation> getMutationList(){
          return mutationBatch;
        }
        private IOException updateTableRegionCacheIfNecessary(        IOException ioe){
          SQLException sqlE=ServerUtil.parseLocalOrRemoteServerException(ioe);
          if (sqlE != null && sqlE.getErrorCode() == SQLExceptionCode.INDEX_METADATA_NOT_FOUND.getErrorCode()) {
            try {
              connection.getQueryServices().clearTableRegionCache(finalHTable.getName());
              IndexMetaDataCacheClient.setMetaDataOnMutations(connection,finalPTable,mutationBatch,finalindexMetaDataPtr);
            }
 catch (            SQLException e) {
              return ServerUtil.createIOException(""Exception during updating index meta data cache"",ioe);
            }
          }
          return ioe;
        }
      }
,iwe,connection,connection.getQueryServices().getProps());
      shouldRetryIndexedMutation=false;
    }
 else {
      hTable.batch(mutationBatch,null);
    }
    itrListMutation.remove();
    batchCount++;
    if (LOGGER.isDebugEnabled())     LOGGER.debug(""Sent batch of "" + mutationBatch.size() + "" for ""+ Bytes.toString(htableName));
  }
  child.stop();
  child.stop();
  shouldRetry=false;
  mutationCommitTime=EnvironmentEdgeManager.currentTimeMillis() - startTime;
  GLOBAL_MUTATION_COMMIT_TIME.update(mutationCommitTime);
  numFailedMutations=0;
  removeMutations(this.mutationsMap,origTableRef);
  if (tableInfo.isDataTable()) {
    numRows-=numMutations;
    estimatedSize=PhoenixKeyValueUtil.getEstimatedRowMutationSizeWithBatch(this.mutationsMap);
  }
  areAllBatchesSuccessful=true;
}
 catch (Exception e) {
  long serverTimestamp=ServerUtil.parseServerTimestamp(e);
  SQLException inferredE=ServerUtil.parseServerExceptionOrNull(e);
  if (inferredE != null) {
    if (shouldRetry && retryCount == 0 && inferredE.getErrorCode() == SQLExceptionCode.INDEX_METADATA_NOT_FOUND.getErrorCode()) {
      String msg=""Swallowing exception and retrying after clearing meta cache on connection. "" + inferredE;
      LOGGER.warn(LogUtil.addCustomAnnotations(msg,connection));
      connection.getQueryServices().clearTableRegionCache(TableName.valueOf(htableName));
      child.addTimelineAnnotation(msg);
      child.stop();
      child=Tracing.child(span,""Failed batch, attempting retry"");
      continue;
    }
 else     if (inferredE.getErrorCode() == SQLExceptionCode.INDEX_WRITE_FAILURE.getErrorCode()) {
      iwe=PhoenixIndexFailurePolicy.getIndexWriteException(inferredE);
      if (iwe != null && !shouldRetryIndexedMutation) {
        for (        Mutation m : mutationBatchList.get(0)) {
          if (!PhoenixIndexMetaData.isIndexRebuild(m.getAttributesMap())) {
            m.setAttribute(BaseScannerRegionObserver.REPLAY_WRITES,BaseScannerRegionObserver.REPLAY_ONLY_INDEX_WRITES);
          }
          PhoenixKeyValueUtil.setTimestamp(m,serverTimestamp);
        }
        shouldRetry=true;
        shouldRetryIndexedMutation=true;
        continue;
      }
    }
    e=inferredE;
  }
  int[] uncommittedStatementIndexes=getUncommittedStatementIndexes();
  sqlE=new CommitException(e,uncommittedStatementIndexes,serverTimestamp);
  numFailedMutations=uncommittedStatementIndexes.length;
  GLOBAL_MUTATION_BATCH_FAILED_COUNT.update(numFailedMutations);
  if (isVerifiedPhase) {
    numFailedPhase3Mutations=numFailedMutations;
    GLOBAL_MUTATION_INDEX_COMMIT_FAILURE_COUNT.update(numFailedPhase3Mutations);
  }
}
 finally {
  mutationCommitTime=EnvironmentEdgeManager.currentTimeMillis() - startTime;
  GLOBAL_MUTATION_COMMIT_TIME.update(mutationCommitTime);
  MutationMetric failureMutationMetrics=MutationMetric.EMPTY_METRIC;
  if (!areAllBatchesSuccessful) {
    failureMutationMetrics=updateMutationBatchFailureMetrics(currentMutationBatch,htableNameStr,numFailedMutations,table.isTransactional());
  }
  MutationMetric committedMutationsMetric=getCommittedMutationsMetric(totalMutationBytesObject,mutationBatchList,numMutations,numFailedMutations,numFailedPhase3Mutations,mutationCommitTime);
  committedMutationsMetric.combineMetric(failureMutationMetrics);
  mutationMetricQueue.addMetricsForTable(htableNameStr,committedMutationsMetric);
  if (allUpsertsMutations ^ allDeletesMutations) {
    if (areAllBatchesSuccessful) {
      TableMetricsManager.updateMetricsMethod(htableNameStr,allUpsertsMutations ? UPSERT_AGGREGATE_SUCCESS_SQL_COUNTER : DELETE_AGGREGATE_SUCCESS_SQL_COUNTER,1);
    }
    if (!areAllBatchesSuccessful && !connection.getAutoCommit()) {
      TableMetricsManager.updateMetricsMethod(htableNameStr,allUpsertsMutations ? UPSERT_AGGREGATE_FAILURE_SQL_COUNTER : DELETE_AGGREGATE_FAILURE_SQL_COUNTER,1);
    }
  }
  resetAllMutationState();
  try {
    if (cache != null)     cache.close();
  }
  finally {
    try {
      hTable.close();
    }
 catch (    IOException e) {
      if (sqlE != null) {
        sqlE.setNextException(ServerUtil.parseServerException(e));
      }
 else {
        sqlE=ServerUtil.parseServerException(e);
      }
    }
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
618,} finally {,"try {
  if (cache != null)   cache.close();
}
  finally {
  try {
    hTable.close();
  }
 catch (  IOException e) {
    if (sqlE != null) {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
 else {
      sqlE=ServerUtil.parseServerException(e);
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
619,} finally {,"try {
  send();
  txMutations=this.txMutations;
  sendSuccessful=true;
}
 catch (SQLException e) {
  sqlE=e;
}
 finally {
  try {
    boolean finishSuccessful=false;
    try {
      if (sendSuccessful) {
        phoenixTransactionContext.commit();
        finishSuccessful=true;
      }
    }
 catch (    SQLException e) {
      if (LOGGER.isInfoEnabled())       LOGGER.info(e.getClass().getName() + "" at timestamp "" + getInitialWritePointer()+ "" with retry count of ""+ retryCount);
      retryCommit=(e.getErrorCode() == SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode() && retryCount < MAX_COMMIT_RETRIES);
      if (sqlE == null) {
        sqlE=e;
      }
 else {
        sqlE.setNextException(e);
      }
    }
 finally {
      if (!finishSuccessful) {
        try {
          phoenixTransactionContext.abort();
          if (LOGGER.isInfoEnabled())           LOGGER.info(""Abort successful"");
        }
 catch (        SQLException e) {
          if (LOGGER.isInfoEnabled())           LOGGER.info(""Abort failed with "" + e);
          if (sqlE == null) {
            sqlE=e;
          }
 else {
            sqlE.setNextException(e);
          }
        }
      }
    }
  }
  finally {
    TransactionFactory.Provider provider=phoenixTransactionContext.getProvider();
    try {
      resetState();
    }
  finally {
      if (retryCommit) {
        startTransaction(provider);
        Set<TableRef> txTableRefs=txMutations.keySet();
        for (        TableRef tableRef : txTableRefs) {
          PTable dataTable=tableRef.getTable();
          phoenixTransactionContext.markDMLFence(dataTable);
        }
        try {
          retryCommit=shouldResubmitTransaction(txTableRefs);
        }
 catch (        SQLException e) {
          retryCommit=false;
          if (sqlE == null) {
            sqlE=e;
          }
 else {
            sqlE.setNextException(e);
          }
        }
      }
      if (sqlE != null && !retryCommit) {
        throw sqlE;
      }
    }
  }
}
",0,0,0,,
620,} finally {,"try {
  boolean finishSuccessful=false;
  try {
    if (sendSuccessful) {
      phoenixTransactionContext.commit();
      finishSuccessful=true;
    }
  }
 catch (  SQLException e) {
    if (LOGGER.isInfoEnabled())     LOGGER.info(e.getClass().getName() + "" at timestamp "" + getInitialWritePointer()+ "" with retry count of ""+ retryCount);
    retryCommit=(e.getErrorCode() == SQLExceptionCode.TRANSACTION_CONFLICT_EXCEPTION.getErrorCode() && retryCount < MAX_COMMIT_RETRIES);
    if (sqlE == null) {
      sqlE=e;
    }
 else {
      sqlE.setNextException(e);
    }
  }
 finally {
    if (!finishSuccessful) {
      try {
        phoenixTransactionContext.abort();
        if (LOGGER.isInfoEnabled())         LOGGER.info(""Abort successful"");
      }
 catch (      SQLException e) {
        if (LOGGER.isInfoEnabled())         LOGGER.info(""Abort failed with "" + e);
        if (sqlE == null) {
          sqlE=e;
        }
 else {
          sqlE.setNextException(e);
        }
      }
    }
  }
}
  finally {
  TransactionFactory.Provider provider=phoenixTransactionContext.getProvider();
  try {
    resetState();
  }
  finally {
    if (retryCommit) {
      startTransaction(provider);
      Set<TableRef> txTableRefs=txMutations.keySet();
      for (      TableRef tableRef : txTableRefs) {
        PTable dataTable=tableRef.getTable();
        phoenixTransactionContext.markDMLFence(dataTable);
      }
      try {
        retryCommit=shouldResubmitTransaction(txTableRefs);
      }
 catch (      SQLException e) {
        retryCommit=false;
        if (sqlE == null) {
          sqlE=e;
        }
 else {
          sqlE.setNextException(e);
        }
      }
    }
    if (sqlE != null && !retryCommit) {
      throw sqlE;
    }
  }
}
",0,0,0,,
621,} finally {,"try {
  resetState();
}
  finally {
  if (retryCommit) {
    startTransaction(provider);
    Set<TableRef> txTableRefs=txMutations.keySet();
    for (    TableRef tableRef : txTableRefs) {
      PTable dataTable=tableRef.getTable();
      phoenixTransactionContext.markDMLFence(dataTable);
    }
    try {
      retryCommit=shouldResubmitTransaction(txTableRefs);
    }
 catch (    SQLException e) {
      retryCommit=false;
      if (sqlE == null) {
        sqlE=e;
      }
 else {
        sqlE.setNextException(e);
      }
    }
  }
  if (sqlE != null && !retryCommit) {
    throw sqlE;
  }
}
",0,0,0,,
622,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  projector.schema.write(output);
  int count=projector.expressions.length;
  WritableUtils.writeVInt(output,count);
  for (int i=0; i < count; i++) {
    WritableUtils.writeVInt(output,ExpressionType.valueOf(projector.expressions[i]).ordinal());
    projector.expressions[i].write(output);
  }
  return stream.toByteArray();
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
623,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  KeyValueSchema schema=new KeyValueSchema();
  schema.readFields(input);
  int count=WritableUtils.readVInt(input);
  Expression[] expressions=new Expression[count];
  for (int i=0; i < count; i++) {
    int ordinal=WritableUtils.readVInt(input);
    expressions[i]=ExpressionType.values()[ordinal].newInstance();
    expressions[i].readFields(input);
  }
  return new TupleProjector(schema,expressions);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
624,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  WritableUtils.writeVInt(output,minNullableIndex);
  WritableUtils.writeVInt(output,aggFuncs.size());
  for (int i=0; i < aggFuncs.size(); i++) {
    SingleAggregateFunction aggFunc=aggFuncs.get(i);
    WritableUtils.writeVInt(output,ExpressionType.valueOf(aggFunc).ordinal());
    aggFunc.write(output);
  }
  return stream.toByteArray();
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
625,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  int minNullableIndex=WritableUtils.readVInt(input);
  int len=WritableUtils.readVInt(input);
  Aggregator[] aggregators=new Aggregator[len];
  Expression[] expressions=new Expression[len];
  SingleAggregateFunction[] functions=new SingleAggregateFunction[len];
  for (int i=0; i < aggregators.length; i++) {
    SingleAggregateFunction aggFunc=(SingleAggregateFunction)ExpressionType.values()[WritableUtils.readVInt(input)].newInstance();
    aggFunc.readFields(input,conf);
    functions[i]=aggFunc;
    aggregators[i]=aggFunc.getAggregator();
    expressions[i]=aggFunc.getAggregatorExpression();
  }
  boolean trackSize=false;
  if (chunk != null) {
    for (    Aggregator aggregator : aggregators) {
      if (aggregator.trackSize()) {
        trackSize=true;
        break;
      }
    }
  }
  return trackSize ? new SizeTrackingServerAggregators(functions,aggregators,expressions,minNullableIndex,chunk,conf.getInt(QueryServices.AGGREGATE_CHUNK_SIZE_INCREASE_ATTRIB,QueryServicesOptions.DEFAULT_AGGREGATE_CHUNK_SIZE_INCREASE)) : new NonSizeTrackingServerAggregators(functions,aggregators,expressions,minNullableIndex);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
626,} finally {,"try {
  if (prependRegionStartKey) {
    if (regionStartKey.length == 0) {
      output.write(new byte[prefixKeyLength]);
    }
 else {
      output.write(regionStartKey);
    }
  }
  if (isIndexSalted) {
    output.write(0);
  }
  int dataPosOffset=isDataTableSalted ? 1 : 0;
  BitSet viewConstantColumnBitSet=this.rowKeyMetaData.getViewConstantColumnBitSet();
  int nIndexedColumns=getIndexPkColumnCount() - getNumViewConstants();
  int[][] dataRowKeyLocator=new int[2][nIndexedColumns];
  int maxRowKeyOffset=rowKeyPtr.getOffset() + rowKeyPtr.getLength();
  dataRowKeySchema.iterator(rowKeyPtr,ptr,dataPosOffset);
  if (viewIndexId != null) {
    output.write(viewIndexId);
  }
  if (isMultiTenant) {
    dataRowKeySchema.next(ptr,dataPosOffset,maxRowKeyOffset);
    output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
    if (!dataRowKeySchema.getField(dataPosOffset).getDataType().isFixedWidth()) {
      output.writeByte(SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable,ptr.getLength() == 0,dataRowKeySchema.getField(dataPosOffset)));
    }
    dataPosOffset++;
  }
  for (int i=dataPosOffset; i < indexDataColumnCount; i++) {
    Boolean hasValue=dataRowKeySchema.next(ptr,i,maxRowKeyOffset);
    if (!viewConstantColumnBitSet.get(i) || isIndexOnBaseTable()) {
      int pos=rowKeyMetaData.getIndexPkPosition(i - dataPosOffset);
      if (Boolean.TRUE.equals(hasValue)) {
        dataRowKeyLocator[0][pos]=ptr.getOffset();
        dataRowKeyLocator[1][pos]=ptr.getLength();
      }
 else {
        dataRowKeyLocator[0][pos]=0;
        dataRowKeyLocator[1][pos]=0;
      }
    }
  }
  BitSet descIndexColumnBitSet=rowKeyMetaData.getDescIndexColumnBitSet();
  Iterator<Expression> expressionIterator=indexedExpressions.iterator();
  int trailingVariableWidthColumnNum=0;
  for (int i=0; i < nIndexedColumns; i++) {
    PDataType dataColumnType;
    boolean isNullable;
    SortOrder dataSortOrder;
    if (dataPkPosition[i] == EXPRESSION_NOT_PRESENT) {
      Expression expression=expressionIterator.next();
      dataColumnType=expression.getDataType();
      dataSortOrder=expression.getSortOrder();
      isNullable=expression.isNullable();
      expression.evaluate(new ValueGetterTuple(valueGetter,ts),ptr);
    }
 else {
      Field field=dataRowKeySchema.getField(dataPkPosition[i]);
      dataColumnType=field.getDataType();
      ptr.set(rowKeyPtr.get(),dataRowKeyLocator[0][i],dataRowKeyLocator[1][i]);
      dataSortOrder=field.getSortOrder();
      isNullable=field.isNullable();
    }
    boolean isDataColumnInverted=dataSortOrder != SortOrder.ASC;
    PDataType indexColumnType=IndexUtil.getIndexColumnDataType(isNullable,dataColumnType);
    boolean isBytesComparable=dataColumnType.isBytesComparableWith(indexColumnType);
    boolean isIndexColumnDesc=descIndexColumnBitSet.get(i);
    if (isBytesComparable && isDataColumnInverted == isIndexColumnDesc) {
      output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
    }
 else {
      if (!isBytesComparable) {
        indexColumnType.coerceBytes(ptr,dataColumnType,dataSortOrder,SortOrder.getDefault());
      }
      if (isDataColumnInverted != isIndexColumnDesc) {
        writeInverted(ptr.get(),ptr.getOffset(),ptr.getLength(),output);
      }
 else {
        output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
      }
    }
    if (!indexColumnType.isFixedWidth()) {
      byte sepByte=SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable,ptr.getLength() == 0,isIndexColumnDesc ? SortOrder.DESC : SortOrder.ASC);
      output.writeByte(sepByte);
      trailingVariableWidthColumnNum++;
    }
 else {
      trailingVariableWidthColumnNum=0;
    }
  }
  byte[] indexRowKey=stream.getBuffer();
  int length=stream.size();
  int minLength=length - maxTrailingNulls;
  while (trailingVariableWidthColumnNum > 0 && length > minLength && indexRowKey[length - 1] == QueryConstants.SEPARATOR_BYTE) {
    length--;
    trailingVariableWidthColumnNum--;
  }
  if (isIndexSalted) {
    byte saltByte=SaltingUtil.getSaltingByte(indexRowKey,SaltingUtil.NUM_SALTING_BYTES,length - SaltingUtil.NUM_SALTING_BYTES,nIndexSaltBuckets);
    indexRowKey[0]=saltByte;
  }
  return indexRowKey.length == length ? indexRowKey : Arrays.copyOf(indexRowKey,length);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
627,} finally {,"try {
  int indexPosOffset=!isLocalIndex && nIndexSaltBuckets > 0 ? 1 : 0;
  int maxRowKeyOffset=indexRowKeyPtr.getOffset() + indexRowKeyPtr.getLength();
  indexRowKeySchema.iterator(indexRowKeyPtr,ptr,indexPosOffset);
  if (isDataTableSalted) {
    dataPosOffset++;
    output.write(0);
  }
  if (viewIndexId != null) {
    indexRowKeySchema.next(ptr,indexPosOffset++,maxRowKeyOffset);
  }
  if (isMultiTenant) {
    indexRowKeySchema.next(ptr,indexPosOffset,maxRowKeyOffset);
    output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
    if (!dataRowKeySchema.getField(dataPosOffset).getDataType().isFixedWidth()) {
      output.writeByte(SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable,ptr.getLength() == 0,dataRowKeySchema.getField(dataPosOffset)));
    }
    indexPosOffset++;
    dataPosOffset++;
  }
  indexPosOffset=(!isLocalIndex && nIndexSaltBuckets > 0 ? 1 : 0) + (isMultiTenant ? 1 : 0) + (viewIndexId == null ? 0 : 1);
  BitSet viewConstantColumnBitSet=this.rowKeyMetaData.getViewConstantColumnBitSet();
  BitSet descIndexColumnBitSet=rowKeyMetaData.getDescIndexColumnBitSet();
  for (int i=dataPosOffset; i < dataRowKeySchema.getFieldCount(); i++) {
    if (viewConstantColumnBitSet.get(i)) {
      output.write(viewConstants[viewConstantsIndex++]);
    }
 else {
      int pos=rowKeyMetaData.getIndexPkPosition(i - dataPosOffset);
      Boolean hasValue=indexRowKeySchema.iterator(indexRowKeyPtr,ptr,pos + indexPosOffset + 1);
      if (Boolean.TRUE.equals(hasValue)) {
        Field dataField=dataRowKeySchema.getField(i);
        Field indexField=indexRowKeySchema.getField(pos + indexPosOffset);
        PDataType indexColumnType=indexField.getDataType();
        PDataType dataColumnType=dataField.getDataType();
        SortOrder dataSortOrder=dataField.getSortOrder();
        SortOrder indexSortOrder=indexField.getSortOrder();
        boolean isDataColumnInverted=dataSortOrder != SortOrder.ASC;
        boolean isBytesComparable=dataColumnType.isBytesComparableWith(indexColumnType);
        if (isBytesComparable && isDataColumnInverted == descIndexColumnBitSet.get(pos)) {
          output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
        }
 else {
          if (!isBytesComparable) {
            dataColumnType.coerceBytes(ptr,indexColumnType,indexSortOrder,SortOrder.getDefault());
          }
          if (descIndexColumnBitSet.get(pos) != isDataColumnInverted) {
            writeInverted(ptr.get(),ptr.getOffset(),ptr.getLength(),output);
          }
 else {
            output.write(ptr.get(),ptr.getOffset(),ptr.getLength());
          }
        }
      }
    }
    byte sepByte=SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable,ptr.getLength() == 0,dataRowKeySchema.getField(i));
    if (!dataRowKeySchema.getField(i).getDataType().isFixedWidth() && (((i + 1) != dataRowKeySchema.getFieldCount()) || sepByte == QueryConstants.DESC_SEPARATOR_BYTE)) {
      output.writeByte(sepByte);
    }
  }
  int length=stream.size();
  int minLength=length - maxTrailingNulls;
  byte[] dataRowKey=stream.getBuffer();
  int index=dataRowKeySchema.getFieldCount() - 1;
  while (index >= 0 && !dataRowKeySchema.getField(index).getDataType().isFixedWidth() && length > minLength && dataRowKey[length - 1] == QueryConstants.SEPARATOR_BYTE) {
    length--;
    index--;
  }
  if (isDataTableSalted) {
    byte saltByte=SaltingUtil.getSaltingByte(dataRowKey,SaltingUtil.NUM_SALTING_BYTES,length - SaltingUtil.NUM_SALTING_BYTES,nIndexSaltBuckets);
    dataRowKey[0]=saltByte;
  }
  return dataRowKey.length == length ? dataRowKey : Arrays.copyOf(dataRowKey,length);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
628,} finally {,"try {
  timestamp=handleFailureWithExceptions(attempted,cause);
  throwing=false;
}
 catch (Throwable t) {
  LOGGER.warn(""handleFailure failed"",t);
  super.handleFailure(attempted,cause);
  throwing=false;
}
 finally {
  if (!throwing) {
    SQLException sqlException=new SQLExceptionInfo.Builder(SQLExceptionCode.INDEX_WRITE_FAILURE).setRootCause(cause).setMessage(cause.getLocalizedMessage()).build().buildException();
    IOException ioException=ServerUtil.wrapInDoNotRetryIOException(null,sqlException,timestamp);
    if (throwIndexWriteFailure) {
      throw ioException;
    }
 else {
      LOGGER.warn(""Swallowing index write failure"",ioException);
    }
  }
}
",0,0,0,,
629,} finally {,"try {
  conn=QueryUtil.getConnectionOnServer(this.env.getConfiguration()).unwrap(PhoenixConnection.class);
  PTable dataTable=PhoenixRuntime.getTableNoCache(conn,ref.getTableName());
  List<PTable> indexes=dataTable.getIndexes();
  PTable localIndex=null;
  Map<ImmutableBytesWritable,String> localIndexNames=new HashMap<ImmutableBytesWritable,String>();
  for (  PTable index : indexes) {
    if (localIndex == null)     localIndex=index;
    localIndexNames.put(new ImmutableBytesWritable(index.getviewIndexIdType().toBytes(index.getViewIndexId())),index.getName().getString());
  }
  if (localIndex == null) {
    return Collections.emptySet();
  }
  IndexMaintainer indexMaintainer=localIndex.getIndexMaintainer(dataTable,conn);
  RegionInfo regionInfo=this.env.getRegion().getRegionInfo();
  int offset=regionInfo.getStartKey().length == 0 ? regionInfo.getEndKey().length : regionInfo.getStartKey().length;
  byte[] viewId=null;
  for (  Mutation mutation : mutations) {
    viewId=indexMaintainer.getViewIndexIdFromIndexRowKey(new ImmutableBytesWritable(mutation.getRow(),offset,mutation.getRow().length - offset));
    String indexTableName=localIndexNames.get(new ImmutableBytesWritable(viewId));
    if (indexTableName == null) {
      LOGGER.error(""Unable to find local index on "" + ref.getTableName() + "" with viewID of ""+ Bytes.toStringBinary(viewId));
    }
 else {
      indexTableNames.add(indexTableName);
    }
  }
}
 catch (SQLException e) {
  throw new IOException(e);
}
 finally {
  if (conn != null) {
    try {
      conn.close();
    }
 catch (    SQLException e) {
      throw new IOException(e);
    }
  }
}
",0,0,0,,
630,} finally {,"try {
  submitWork(scan,futures,allIterators,splitSize,isReverse,scanGrouper);
  boolean clearedCache=false;
  for (  List<Pair<Scan,Future<PeekingResultIterator>>> future : reverseIfNecessary(futures,isReverse)) {
    List<PeekingResultIterator> concatIterators=Lists.newArrayListWithExpectedSize(future.size());
    Iterator<Pair<Scan,Future<PeekingResultIterator>>> scanPairItr=reverseIfNecessary(future,isReverse).iterator();
    while (scanPairItr.hasNext()) {
      Pair<Scan,Future<PeekingResultIterator>> scanPair=scanPairItr.next();
      try {
        long timeOutForScan=maxQueryEndTime - EnvironmentEdgeManager.currentTimeMillis();
        if (timeOutForScan < 0) {
          throw new SQLExceptionInfo.Builder(OPERATION_TIMED_OUT).setMessage("". Query couldn't be completed in the allotted time: "" + queryTimeOut + "" ms"").build().buildException();
        }
        if (isLocalIndex && previousScan != null && previousScan.getScan() != null && (((!isReverse && Bytes.compareTo(scanPair.getFirst().getAttribute(SCAN_ACTUAL_START_ROW),previousScan.getScan().getStopRow()) < 0) || (isReverse && previousScan.getScan().getStopRow().length > 0 && Bytes.compareTo(scanPair.getFirst().getAttribute(SCAN_ACTUAL_START_ROW),previousScan.getScan().getStopRow()) > 0) || (Bytes.compareTo(scanPair.getFirst().getStopRow(),previousScan.getScan().getStopRow()) == 0)) && Bytes.compareTo(scanPair.getFirst().getAttribute(SCAN_START_ROW_SUFFIX),previousScan.getScan().getAttribute(SCAN_START_ROW_SUFFIX)) == 0)) {
          continue;
        }
        PeekingResultIterator iterator=scanPair.getSecond().get(timeOutForScan,TimeUnit.MILLISECONDS);
        concatIterators.add(iterator);
        previousScan.setScan(scanPair.getFirst());
      }
 catch (      ExecutionException e) {
        try {
          throw ServerUtil.parseServerException(e);
        }
 catch (        StaleRegionBoundaryCacheException|HashJoinCacheNotFoundException e2) {
          if (!clearedCache) {
            services.clearTableRegionCache(TableName.valueOf(physicalTableName));
            context.getOverallQueryMetrics().cacheRefreshedDueToSplits();
          }
          Scan oldScan=scanPair.getFirst();
          byte[] startKey=oldScan.getAttribute(SCAN_ACTUAL_START_ROW);
          if (e2 instanceof HashJoinCacheNotFoundException) {
            LOGGER.debug(""Retrying when Hash Join cache is not found on the server ,by sending the cache again"");
            if (retryCount <= 0) {
              throw e2;
            }
            Long cacheId=((HashJoinCacheNotFoundException)e2).getCacheId();
            ServerCache cache=caches.get(new ImmutableBytesPtr(Bytes.toBytes(cacheId)));
            if (cache.getCachePtr() != null) {
              if (!hashCacheClient.addHashCacheToServer(startKey,cache,plan.getTableRef().getTable())) {
                throw e2;
              }
            }
          }
          concatIterators=recreateIterators(services,isLocalIndex,allIterators,iterators,isReverse,maxQueryEndTime,previousScan,clearedCache,concatIterators,scanPairItr,scanPair,retryCount - 1);
        }
catch (        ColumnFamilyNotFoundException cfnfe) {
          if (scanPair.getFirst().getAttribute(LOCAL_INDEX_BUILD) != null) {
            Thread.sleep(1000);
            concatIterators=recreateIterators(services,isLocalIndex,allIterators,iterators,isReverse,maxQueryEndTime,previousScan,clearedCache,concatIterators,scanPairItr,scanPair,retryCount);
          }
        }
      }
    }
    addIterator(iterators,concatIterators);
  }
  success=true;
  return iterators;
}
 catch (TimeoutException e) {
  OverAllQueryMetrics overAllQueryMetrics=context.getOverallQueryMetrics();
  overAllQueryMetrics.queryTimedOut();
  if (context.getScanRanges().isPointLookup()) {
    overAllQueryMetrics.queryPointLookupTimedOut();
  }
 else {
    overAllQueryMetrics.queryScanTimedOut();
  }
  GLOBAL_QUERY_TIMEOUT_COUNTER.increment();
  toThrow=new SQLExceptionInfo.Builder(OPERATION_TIMED_OUT).setMessage("". Query couldn't be completed in the allotted time: "" + queryTimeOut + "" ms"").setRootCause(e).build().buildException();
}
catch (SQLException e) {
  if (e.getErrorCode() == OPERATION_TIMED_OUT.getErrorCode()) {
    OverAllQueryMetrics overAllQueryMetrics=context.getOverallQueryMetrics();
    overAllQueryMetrics.queryTimedOut();
    if (context.getScanRanges().isPointLookup()) {
      overAllQueryMetrics.queryPointLookupTimedOut();
    }
 else {
      overAllQueryMetrics.queryScanTimedOut();
    }
    GLOBAL_QUERY_TIMEOUT_COUNTER.increment();
  }
  toThrow=e;
}
catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  try {
    if (!success) {
      try {
        close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
 finally {
        try {
          SQLCloseables.closeAll(allIterators);
        }
 catch (        Exception e) {
          if (toThrow == null) {
            toThrow=ServerUtil.parseServerException(e);
          }
 else {
            toThrow.setNextException(ServerUtil.parseServerException(e));
          }
        }
      }
    }
  }
  finally {
    if (toThrow != null) {
      GLOBAL_FAILED_QUERY_COUNTER.increment();
      OverAllQueryMetrics overAllQueryMetrics=context.getOverallQueryMetrics();
      overAllQueryMetrics.queryFailed();
      if (context.getScanRanges().isPointLookup()) {
        overAllQueryMetrics.queryPointLookupFailed();
      }
 else {
        overAllQueryMetrics.queryScanFailed();
      }
      throw toThrow;
    }
  }
}
",0,0,0,,
631,} finally {,"try {
  if (!success) {
    try {
      close();
    }
 catch (    Exception e) {
      if (toThrow == null) {
        toThrow=ServerUtil.parseServerException(e);
      }
 else {
        toThrow.setNextException(ServerUtil.parseServerException(e));
      }
    }
 finally {
      try {
        SQLCloseables.closeAll(allIterators);
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
}
  finally {
  if (toThrow != null) {
    GLOBAL_FAILED_QUERY_COUNTER.increment();
    OverAllQueryMetrics overAllQueryMetrics=context.getOverallQueryMetrics();
    overAllQueryMetrics.queryFailed();
    if (context.getScanRanges().isPointLookup()) {
      overAllQueryMetrics.queryPointLookupFailed();
    }
 else {
      overAllQueryMetrics.queryScanFailed();
    }
    throw toThrow;
  }
}
",0,0,0,,
632,} finally {,"try {
  if (resultIterators != null) {
    resultIterators.close();
  }
}
 catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  try {
    if (iterators != null) {
      for (; index < iterators.size(); index++) {
        PeekingResultIterator iterator=iterators.get(index);
        try {
          iterator.close();
        }
 catch (        Exception e) {
          if (toThrow == null) {
            toThrow=ServerUtil.parseServerException(e);
          }
 else {
            toThrow.setNextException(ServerUtil.parseServerException(e));
          }
        }
      }
    }
  }
  finally {
    if (toThrow != null) {
      throw toThrow;
    }
  }
}
",0,0,0,,
633,} finally {,"try {
  if (iterators != null) {
    for (; index < iterators.size(); index++) {
      PeekingResultIterator iterator=iterators.get(index);
      try {
        iterator.close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
}
  finally {
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
634,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  if (shouldDecodeSpoolThreshold) {
    WritableUtils.readVInt(input);
  }
  int limit=WritableUtils.readVInt(input);
  int estimatedRowSize=WritableUtils.readVInt(input);
  int size=WritableUtils.readVInt(input);
  List<OrderByExpression> orderByExpressions=Lists.newArrayListWithExpectedSize(size);
  for (int i=0; i < size; i++) {
    OrderByExpression orderByExpression=new OrderByExpression();
    orderByExpression.readFields(input);
    orderByExpressions.add(orderByExpression);
  }
  PTable.QualifierEncodingScheme encodingScheme=EncodedColumnsUtil.getQualifierEncodingScheme(scan);
  ResultIterator inner=new RegionScannerResultIterator(s,EncodedColumnsUtil.getMinMaxQualifiersFromScan(scan),encodingScheme);
  return new OrderedResultIterator(inner,orderByExpressions,spoolingEnabled,thresholdBytes,limit >= 0 ? limit : null,null,estimatedRowSize,getPageSizeMsForRegionScanner(scan));
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
635,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  int arrayKVRefSize=WritableUtils.readVInt(input);
  for (int i=0; i < arrayKVRefSize; i++) {
    PTable.ImmutableStorageScheme scheme=EncodedColumnsUtil.getImmutableStorageScheme(scan);
    KeyValueColumnExpression kvExp=scheme != PTable.ImmutableStorageScheme.ONE_CELL_PER_COLUMN ? new SingleCellColumnExpression(scheme) : new KeyValueColumnExpression();
    kvExp.readFields(input);
    arrayKVRefs.add(kvExp);
  }
  int arrayKVFuncSize=WritableUtils.readVInt(input);
  Expression[] arrayFuncRefs=new Expression[arrayKVFuncSize];
  for (int i=0; i < arrayKVFuncSize; i++) {
    ArrayIndexFunction arrayIdxFunc=new ArrayIndexFunction();
    arrayIdxFunc.readFields(input);
    arrayFuncRefs[i]=arrayIdxFunc;
  }
  return arrayFuncRefs;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
636,} finally {,"try {
  if (resultIterators != null) {
    resultIterators.close();
  }
}
 catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  try {
    if (openIterators.size() > 0) {
      for (      RoundRobinIterator itr : openIterators) {
        try {
          itr.close();
        }
 catch (        Exception e) {
          if (toThrow == null) {
            toThrow=ServerUtil.parseServerException(e);
          }
 else {
            toThrow.setNextException(ServerUtil.parseServerException(e));
          }
        }
      }
    }
  }
  finally {
    if (toThrow != null) {
      throw toThrow;
    }
  }
}
",0,0,0,,
637,} finally {,"try {
  if (openIterators.size() > 0) {
    for (    RoundRobinIterator itr : openIterators) {
      try {
        itr.close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
}
  finally {
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
638,} finally {,"try {
  StatementContext context=plan.getContext();
  final ConnectionQueryServices services=context.getConnection().getQueryServices();
  ExecutorService executor=services.getExecutor();
  numParallelFetches++;
  if (LOGGER.isDebugEnabled()) {
    LOGGER.debug(""Performing parallel fetch for "" + openIterators.size() + "" iterators. "");
  }
  for (  final RoundRobinIterator itr : openIterators) {
    Future<Tuple> future=executor.submit(new Callable<Tuple>(){
      @Override public Tuple call() throws Exception {
        return itr.next();
      }
    }
);
    futures.add(future);
  }
  int i=0;
  for (  Future<Tuple> future : futures) {
    Tuple tuple=future.get();
    if (tuple != null) {
      results.add(new RoundRobinIterator(openIterators.get(i).delegate,tuple));
    }
 else {
      openIterators.get(i).close();
    }
    i++;
  }
  success=true;
  return results;
}
 catch (SQLException e) {
  toThrow=e;
}
catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  try {
    if (!success) {
      try {
        close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
  finally {
    if (toThrow != null) {
      GLOBAL_FAILED_QUERY_COUNTER.increment();
      OverAllQueryMetrics overAllQueryMetrics=plan.getContext().getOverallQueryMetrics();
      overAllQueryMetrics.queryFailed();
      if (plan.getContext().getScanRanges().isPointLookup()) {
        overAllQueryMetrics.queryPointLookupFailed();
      }
 else {
        overAllQueryMetrics.queryScanFailed();
      }
      throw toThrow;
    }
  }
}
",0,0,0,,
639,} finally {,"try {
  if (!success) {
    try {
      close();
    }
 catch (    Exception e) {
      if (toThrow == null) {
        toThrow=ServerUtil.parseServerException(e);
      }
 else {
        toThrow.setNextException(ServerUtil.parseServerException(e));
      }
    }
  }
}
  finally {
  if (toThrow != null) {
    GLOBAL_FAILED_QUERY_COUNTER.increment();
    OverAllQueryMetrics overAllQueryMetrics=plan.getContext().getOverallQueryMetrics();
    overAllQueryMetrics.queryFailed();
    if (plan.getContext().getScanRanges().isPointLookup()) {
      overAllQueryMetrics.queryPointLookupFailed();
    }
 else {
      overAllQueryMetrics.queryScanFailed();
    }
    throw toThrow;
  }
}
",0,0,0,,
640,} finally {,"try {
  if (resultIterators != null) {
    resultIterators.close();
  }
}
 catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  try {
    if (iterators != null) {
      for (; index < iterators.size(); index++) {
        PeekingResultIterator iterator=iterators.get(index);
        try {
          iterator.close();
        }
 catch (        Exception e) {
          if (toThrow == null) {
            toThrow=ServerUtil.parseServerException(e);
          }
 else {
            toThrow.setNextException(ServerUtil.parseServerException(e));
          }
        }
      }
    }
  }
  finally {
    if (toThrow != null) {
      throw toThrow;
    }
  }
}
",0,0,0,,
641,} finally {,"try {
  if (iterators != null) {
    for (; index < iterators.size(); index++) {
      PeekingResultIterator iterator=iterators.get(index);
      try {
        iterator.close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
}
  finally {
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
642,} finally {,"try {
  scanIterator.close();
}
  finally {
  try {
    scanIterator=UNINITIALIZED_SCANNER;
    htable.close();
  }
 catch (  IOException e) {
    throw ServerUtil.parseServerException(e);
  }
}
",0,0,0,,
643,} finally {,"try {
  if (iterators != null) {
    for (int index=0; index < iterators.size(); index++) {
      PeekingResultIterator iterator=iterators.get(index);
      try {
        iterator.close();
      }
 catch (      Exception e) {
        if (toThrow == null) {
          toThrow=ServerUtil.parseServerException(e);
        }
 else {
          toThrow.setNextException(ServerUtil.parseServerException(e));
        }
      }
    }
  }
}
 catch (Exception e) {
  toThrow=ServerUtil.parseServerException(e);
}
 finally {
  setMetricsInParentContext();
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
644,finally {,"try {
  connectionQueryServices=connectionQueryServicesCache.get(normalizedConnInfo,new Callable<ConnectionQueryServices>(){
    @Override public ConnectionQueryServices call() throws Exception {
      ConnectionQueryServices connectionQueryServices;
      if (normalizedConnInfo.isConnectionless()) {
        connectionQueryServices=new ConnectionlessQueryServicesImpl(services,normalizedConnInfo,info);
      }
 else {
        connectionQueryServices=new ConnectionQueryServicesImpl(services,normalizedConnInfo,info);
      }
      return connectionQueryServices;
    }
  }
);
  connectionQueryServices.init(url,info);
  success=true;
}
 catch (ExecutionException ee) {
  if (ee.getCause() instanceof SQLException) {
    sqlE=(SQLException)ee.getCause();
  }
 else {
    throw new SQLException(ee);
  }
}
catch (SQLException e) {
  sqlE=e;
}
 finally {
  if (!success) {
    connectionQueryServicesCache.invalidate(normalizedConnInfo);
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
645,} finally {,"try {
  DataOutputStream output=new DataOutputStream(stream);
  joinInfo.joinedSchema.write(output);
  int count=joinInfo.joinIds.length;
  WritableUtils.writeVInt(output,count);
  for (int i=0; i < count; i++) {
    joinInfo.joinIds[i].write(output);
    WritableUtils.writeVInt(output,joinInfo.joinExpressions[i].size());
    for (    Expression expr : joinInfo.joinExpressions[i]) {
      WritableUtils.writeVInt(output,ExpressionType.valueOf(expr).ordinal());
      expr.write(output);
    }
    WritableUtils.writeVInt(output,joinInfo.joinTypes[i].ordinal());
    output.writeBoolean(joinInfo.earlyEvaluation[i]);
    joinInfo.schemas[i].write(output);
    WritableUtils.writeVInt(output,joinInfo.fieldPositions[i]);
  }
  if (joinInfo.postJoinFilterExpression != null) {
    WritableUtils.writeVInt(output,ExpressionType.valueOf(joinInfo.postJoinFilterExpression).ordinal());
    joinInfo.postJoinFilterExpression.write(output);
  }
 else {
    WritableUtils.writeVInt(output,-1);
  }
  WritableUtils.writeVInt(output,joinInfo.limit == null ? -1 : joinInfo.limit);
  output.writeBoolean(joinInfo.forceProjection);
  scan.setAttribute(HASH_JOIN,stream.toByteArray());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
646,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  KeyValueSchema joinedSchema=new KeyValueSchema();
  joinedSchema.readFields(input);
  int count=WritableUtils.readVInt(input);
  ImmutableBytesPtr[] joinIds=new ImmutableBytesPtr[count];
  List<Expression>[] joinExpressions=new List[count];
  JoinType[] joinTypes=new JoinType[count];
  boolean[] earlyEvaluation=new boolean[count];
  KeyValueSchema[] schemas=new KeyValueSchema[count];
  int[] fieldPositions=new int[count];
  for (int i=0; i < count; i++) {
    joinIds[i]=new ImmutableBytesPtr();
    joinIds[i].readFields(input);
    int nExprs=WritableUtils.readVInt(input);
    joinExpressions[i]=new ArrayList<Expression>(nExprs);
    for (int j=0; j < nExprs; j++) {
      int expressionOrdinal=WritableUtils.readVInt(input);
      Expression expression=ExpressionType.values()[expressionOrdinal].newInstance();
      expression.readFields(input);
      joinExpressions[i].add(expression);
    }
    int type=WritableUtils.readVInt(input);
    joinTypes[i]=JoinType.values()[type];
    earlyEvaluation[i]=input.readBoolean();
    schemas[i]=new KeyValueSchema();
    schemas[i].readFields(input);
    fieldPositions[i]=WritableUtils.readVInt(input);
  }
  Expression postJoinFilterExpression=null;
  int expressionOrdinal=WritableUtils.readVInt(input);
  if (expressionOrdinal != -1) {
    postJoinFilterExpression=ExpressionType.values()[expressionOrdinal].newInstance();
    postJoinFilterExpression.readFields(input);
  }
  int limit=-1;
  boolean forceProjection=false;
  try {
    limit=WritableUtils.readVInt(input);
    forceProjection=input.readBoolean();
  }
 catch (  EOFException ignore) {
  }
  return new HashJoinInfo(joinedSchema,joinIds,joinExpressions,joinTypes,earlyEvaluation,schemas,fieldPositions,postJoinFilterExpression,limit >= 0 ? limit : null,forceProjection);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
647,} finally {,"try {
  conn.commit();
}
 catch (SQLException e) {
  LOGGER.error(""SQLException while performing the commit for the task."");
  throw new RuntimeException(e);
}
 finally {
  try {
    statement.close();
    conn.close();
  }
 catch (  SQLException ex) {
    LOGGER.error(""SQLException while closing the connection for the task."");
    throw new RuntimeException(ex);
  }
}
",0,0,0,,
648,} finally {,"try {
  CommandLine cmdLine=null;
  try {
    cmdLine=parseOptions(args);
  }
 catch (  IllegalStateException e) {
    printHelpAndExit(e.getMessage(),getOptions());
  }
  final Configuration configuration=HBaseConfiguration.addHbaseResources(getConf());
  boolean useTenantId=cmdLine.hasOption(TENANT_ID_OPTION.getOpt());
  String tenantId=null;
  if (useTenantId) {
    tenantId=cmdLine.getOptionValue(TENANT_ID_OPTION.getOpt());
    configuration.set(PhoenixRuntime.TENANT_ID_ATTRIB,tenantId);
    LOGGER.info(String.format(""IndexScrutinyTool uses a tenantId %s"",tenantId));
  }
  connection=ConnectionUtil.getInputConnection(configuration);
  final String schemaName=cmdLine.getOptionValue(SCHEMA_NAME_OPTION.getOpt());
  final String dataTable=cmdLine.getOptionValue(DATA_TABLE_OPTION.getOpt());
  String indexTable=cmdLine.getOptionValue(INDEX_TABLE_OPTION.getOpt());
  final String qDataTable=SchemaUtil.getQualifiedTableName(schemaName,dataTable);
  String basePath=cmdLine.getOptionValue(OUTPUT_PATH_OPTION.getOpt());
  boolean isForeground=cmdLine.hasOption(RUN_FOREGROUND_OPTION.getOpt());
  boolean useSnapshot=cmdLine.hasOption(SNAPSHOT_OPTION.getOpt());
  boolean outputInvalidRows=cmdLine.hasOption(OUTPUT_INVALID_ROWS_OPTION.getOpt());
  SourceTable sourceTable=cmdLine.hasOption(SOURCE_TABLE_OPTION.getOpt()) ? SourceTable.valueOf(cmdLine.getOptionValue(SOURCE_TABLE_OPTION.getOpt())) : SourceTable.BOTH;
  long batchSize=cmdLine.hasOption(BATCH_SIZE_OPTION.getOpt()) ? Long.parseLong(cmdLine.getOptionValue(BATCH_SIZE_OPTION.getOpt())) : PhoenixConfigurationUtil.DEFAULT_SCRUTINY_BATCH_SIZE;
  long ts=cmdLine.hasOption(TIMESTAMP.getOpt()) ? Long.parseLong(cmdLine.getOptionValue(TIMESTAMP.getOpt())) : EnvironmentEdgeManager.currentTimeMillis() - 60000;
  validateTimestamp(configuration,ts);
  if (indexTable != null) {
    if (!IndexTool.isValidIndexTable(connection,qDataTable,indexTable,tenantId)) {
      throw new IllegalArgumentException(String.format("" %s is not an index table for %s "",indexTable,qDataTable));
    }
  }
  String outputFormatOption=cmdLine.getOptionValue(OUTPUT_FORMAT_OPTION.getOpt());
  OutputFormat outputFormat=outputFormatOption != null ? OutputFormat.valueOf(outputFormatOption.toUpperCase()) : OutputFormat.TABLE;
  long outputMaxRows=cmdLine.hasOption(OUTPUT_MAX.getOpt()) ? Long.parseLong(cmdLine.getOptionValue(OUTPUT_MAX.getOpt())) : 1000000L;
  if (outputInvalidRows && OutputFormat.TABLE.equals(outputFormat)) {
    Configuration outputConfiguration=HBaseConfiguration.create(configuration);
    outputConfiguration.unset(PhoenixRuntime.TENANT_ID_ATTRIB);
    try (Connection outputConn=ConnectionUtil.getOutputConnection(outputConfiguration)){
      outputConn.createStatement().execute(IndexScrutinyTableOutput.OUTPUT_TABLE_DDL);
      outputConn.createStatement().execute(IndexScrutinyTableOutput.OUTPUT_TABLE_BEYOND_LOOKBACK_DDL);
      outputConn.createStatement().execute(IndexScrutinyTableOutput.OUTPUT_METADATA_DDL);
      outputConn.createStatement().execute(IndexScrutinyTableOutput.OUTPUT_METADATA_BEYOND_LOOKBACK_COUNTER_DDL);
    }
   }
  LOGGER.info(String.format(""Running scrutiny [schemaName=%s, dataTable=%s, indexTable=%s, useSnapshot=%s, timestamp=%s, batchSize=%s, outputBasePath=%s, outputFormat=%s, outputMaxRows=%s]"",schemaName,dataTable,indexTable,useSnapshot,ts,batchSize,basePath,outputFormat,outputMaxRows));
  JobFactory jobFactory=new JobFactory(connection,configuration,batchSize,useSnapshot,ts,outputInvalidRows,outputFormat,basePath,outputMaxRows,tenantId,mapperClass);
  if (SourceTable.BOTH.equals(sourceTable)) {
    jobs.add(jobFactory.createSubmittableJob(schemaName,indexTable,dataTable,SourceTable.DATA_TABLE_SOURCE,mapperClass));
    jobs.add(jobFactory.createSubmittableJob(schemaName,indexTable,dataTable,SourceTable.INDEX_TABLE_SOURCE,mapperClass));
  }
 else {
    jobs.add(jobFactory.createSubmittableJob(schemaName,indexTable,dataTable,sourceTable,mapperClass));
  }
  if (!isForeground) {
    LOGGER.info(""Running Index Scrutiny in Background - Submit async and exit"");
    for (    Job job : jobs) {
      job.submit();
    }
    return 0;
  }
  LOGGER.info(""Running Index Scrutiny in Foreground. Waits for the build to complete. This may take a long time!."");
  boolean result=true;
  for (  Job job : jobs) {
    result=result && job.waitForCompletion(true);
  }
  if (outputInvalidRows && OutputFormat.TABLE.equals(outputFormat)) {
    LOGGER.info(""Writing results of jobs to output table "" + IndexScrutinyTableOutput.OUTPUT_METADATA_TABLE_NAME);
    IndexScrutinyTableOutput.writeJobResults(connection,args,jobs);
  }
  if (result) {
    return 0;
  }
 else {
    LOGGER.error(""IndexScrutinyTool job failed! Check logs for errors.."");
    return -1;
  }
}
 catch (Exception ex) {
  LOGGER.error(""An exception occurred while performing the indexing job: "" + ExceptionUtils.getMessage(ex) + "" at:\n""+ ExceptionUtils.getStackTrace(ex));
  return -1;
}
 finally {
  try {
    if (connection != null) {
      connection.close();
    }
  }
 catch (  SQLException sqle) {
    LOGGER.error(""Failed to close connection "",sqle.getMessage());
    throw new RuntimeException(""Failed to close connection"");
  }
}
",0,0,0,,
649,} finally {,"try {
  if (connection != null)   returnAllSequences(this.sequenceMap);
}
 catch (SQLException e) {
  sqlE=e;
}
 finally {
  try {
    childServices.clear();
synchronized (latestMetaDataLock) {
      latestMetaData=null;
      latestMetaDataLock.notifyAll();
    }
    try {
      closeConnection();
    }
  finally {
      if (renewLeaseExecutor != null) {
        renewLeaseExecutor.shutdownNow();
      }
      for (      PhoenixTransactionClient client : txClients) {
        if (client != null) {
          client.close();
        }
      }
    }
  }
 catch (  IOException e) {
    if (sqlE == null) {
      sqlE=ServerUtil.parseServerException(e);
    }
 else {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
  }
 finally {
    try {
      tableStatsCache.invalidateAll();
      super.close();
    }
 catch (    SQLException e) {
      if (sqlE == null) {
        sqlE=e;
      }
 else {
        sqlE.setNextException(e);
      }
    }
 finally {
      if (sqlE != null) {
        throw sqlE;
      }
    }
  }
}
",0,0,0,,
650,} finally {,"try {
  childServices.clear();
synchronized (latestMetaDataLock) {
    latestMetaData=null;
    latestMetaDataLock.notifyAll();
  }
  try {
    closeConnection();
  }
  finally {
    if (renewLeaseExecutor != null) {
      renewLeaseExecutor.shutdownNow();
    }
    for (    PhoenixTransactionClient client : txClients) {
      if (client != null) {
        client.close();
      }
    }
  }
}
 catch (IOException e) {
  if (sqlE == null) {
    sqlE=ServerUtil.parseServerException(e);
  }
 else {
    sqlE.setNextException(ServerUtil.parseServerException(e));
  }
}
 finally {
  try {
    tableStatsCache.invalidateAll();
    super.close();
  }
 catch (  SQLException e) {
    if (sqlE == null) {
      sqlE=e;
    }
 else {
      sqlE.setNextException(e);
    }
  }
 finally {
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
651,} finally {,"try {
  tableStatsCache.invalidateAll();
  super.close();
}
 catch (SQLException e) {
  if (sqlE == null) {
    sqlE=e;
  }
 else {
    sqlE.setNextException(e);
  }
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
652,} finally {,"try (Admin admin=getAdmin()){
  NamespaceDescriptor namespaceDescriptor=null;
  try {
    namespaceDescriptor=admin.getNamespaceDescriptor(schemaName);
  }
 catch (  NamespaceNotFoundException ignored) {
  }
  if (namespaceDescriptor == null) {
    namespaceDescriptor=NamespaceDescriptor.create(schemaName).build();
    admin.createNamespace(namespaceDescriptor);
    createdNamespace=true;
  }
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
653,} finally {,"try (Admin admin=getAdmin()){
  final String quorum=ZKConfig.getZKQuorumServersString(config);
  final String znode=this.getProps().get(HConstants.ZOOKEEPER_ZNODE_PARENT);
  boolean createdNamespace=false;
  LOGGER.debug(""Found quorum: "" + quorum + "":""+ znode);
  if (isMetaTable) {
    if (SchemaUtil.isNamespaceMappingEnabled(PTableType.SYSTEM,this.getProps())) {
      try {
        createdNamespace=ensureNamespaceCreated(QueryConstants.SYSTEM_SCHEMA_NAME);
      }
 catch (      PhoenixIOException e) {
      }
      if (admin.tableExists(SchemaUtil.getPhysicalTableName(SYSTEM_CATALOG_NAME_BYTES,false))) {
        try {
          checkClientServerCompatibility(SYSTEM_CATALOG_NAME_BYTES);
        }
 catch (        SQLException possibleCompatException) {
          if (createdNamespace && possibleCompatException.getErrorCode() == SQLExceptionCode.INCONSISTENT_NAMESPACE_MAPPING_PROPERTIES.getErrorCode()) {
            ensureNamespaceDropped(QueryConstants.SYSTEM_SCHEMA_NAME);
          }
          throw possibleCompatException;
        }
        throw new UpgradeRequiredException(MIN_SYSTEM_TABLE_TIMESTAMP);
      }
    }
 else     if (admin.tableExists(SchemaUtil.getPhysicalTableName(SYSTEM_CATALOG_NAME_BYTES,true))) {
      throw new SQLExceptionInfo.Builder(SQLExceptionCode.INCONSISTENT_NAMESPACE_MAPPING_PROPERTIES).setMessage(""Cannot initiate connection as "" + SchemaUtil.getPhysicalTableName(SYSTEM_CATALOG_NAME_BYTES,true) + "" is found but client does not have ""+ IS_NAMESPACE_MAPPING_ENABLED+ "" enabled"").build().buildException();
    }
    if (isDoNotUpgradePropSet) {
      try {
        checkClientServerCompatibility(SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,this.getProps()).getName());
      }
 catch (      SQLException possibleCompatException) {
        if (possibleCompatException.getCause() instanceof org.apache.hadoop.hbase.TableNotFoundException) {
          throw new UpgradeRequiredException(MIN_SYSTEM_TABLE_TIMESTAMP);
        }
        throw possibleCompatException;
      }
      return null;
    }
  }
  try {
    existingDesc=admin.getDescriptor(TableName.valueOf(physicalTableName));
  }
 catch (  org.apache.hadoop.hbase.TableNotFoundException e) {
    tableExist=false;
    if (tableType == PTableType.VIEW) {
      String fullTableName=Bytes.toString(physicalTableName);
      throw new ReadOnlyTableException(""An HBase table for a VIEW must already exist"",SchemaUtil.getSchemaNameFromFullName(fullTableName),SchemaUtil.getTableNameFromFullName(fullTableName));
    }
  }
  TableDescriptorBuilder newDesc=generateTableDescriptor(physicalTableName,parentPhysicalTableName,existingDesc,tableType,props,families,splits,isNamespaceMapped);
  if (!tableExist) {
    if (SchemaUtil.isSystemTable(physicalTableName) && !isUpgradeRequired() && (!isAutoUpgradeEnabled || isDoNotUpgradePropSet)) {
      throw new UpgradeRequiredException();
    }
    if (newDesc.build().getValue(MetaDataUtil.IS_LOCAL_INDEX_TABLE_PROP_BYTES) != null && Boolean.TRUE.equals(PBoolean.INSTANCE.toObject(newDesc.build().getValue(MetaDataUtil.IS_LOCAL_INDEX_TABLE_PROP_BYTES)))) {
      newDesc.setRegionSplitPolicyClassName(IndexRegionSplitPolicy.class.getName());
    }
    try {
      if (splits == null) {
        admin.createTable(newDesc.build());
      }
 else {
        admin.createTable(newDesc.build(),splits);
      }
    }
 catch (    TableExistsException e) {
      if (isMetaTable && !isUpgradeRequired()) {
        checkClientServerCompatibility(SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,this.getProps()).getName());
      }
      return null;
    }
    if (isMetaTable && !isUpgradeRequired()) {
      try {
        checkClientServerCompatibility(SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,this.getProps()).getName());
      }
 catch (      SQLException possibleCompatException) {
        if (possibleCompatException.getErrorCode() == SQLExceptionCode.INCONSISTENT_NAMESPACE_MAPPING_PROPERTIES.getErrorCode()) {
          try {
            admin.disableTable(TableName.valueOf(physicalTableName));
            admin.deleteTable(TableName.valueOf(physicalTableName));
          }
 catch (          org.apache.hadoop.hbase.TableNotFoundException ignored) {
          }
          if (createdNamespace && SchemaUtil.isNamespaceMappingEnabled(PTableType.SYSTEM,this.getProps())) {
            ensureNamespaceDropped(QueryConstants.SYSTEM_SCHEMA_NAME);
          }
        }
        throw possibleCompatException;
      }
    }
    return null;
  }
 else {
    if (isMetaTable && !isUpgradeRequired()) {
      checkClientServerCompatibility(SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,this.getProps()).getName());
    }
 else {
      for (      Pair<byte[],Map<String,Object>> family : families) {
        if ((Bytes.toString(family.getFirst()).startsWith(QueryConstants.LOCAL_INDEX_COLUMN_FAMILY_PREFIX))) {
          newDesc.setRegionSplitPolicyClassName(IndexRegionSplitPolicy.class.getName());
          break;
        }
      }
    }
    if (!modifyExistingMetaData) {
      return existingDesc;
    }
    TransactionFactory.Provider provider=getTransactionProvider(props);
    boolean willBeTx=provider != null;
    if (willBeTx) {
      if (!equalTxCoprocessor(provider,existingDesc,newDesc.build())) {
        if (hasTxCoprocessor(existingDesc)) {
          throw new SQLExceptionInfo.Builder(SQLExceptionCode.CANNOT_SWITCH_TXN_PROVIDERS).setSchemaName(SchemaUtil.getSchemaNameFromFullName(physicalTableName)).setTableName(SchemaUtil.getTableNameFromFullName(physicalTableName)).build().buildException();
        }
        if (provider.getTransactionProvider().isUnsupported(PhoenixTransactionProvider.Feature.ALTER_NONTX_TO_TX)) {
          throw new SQLExceptionInfo.Builder(SQLExceptionCode.CANNOT_ALTER_TABLE_FROM_NON_TXN_TO_TXNL).setMessage(provider.name()).setSchemaName(SchemaUtil.getSchemaNameFromFullName(physicalTableName)).setTableName(SchemaUtil.getTableNameFromFullName(physicalTableName)).build().buildException();
        }
        newDesc.setValue(PhoenixTransactionContext.READ_NON_TX_DATA,Boolean.TRUE.toString());
      }
    }
 else {
      if (hasTxCoprocessor(existingDesc)) {
        throw new SQLExceptionInfo.Builder(SQLExceptionCode.TX_MAY_NOT_SWITCH_TO_NON_TX).setSchemaName(SchemaUtil.getSchemaNameFromFullName(physicalTableName)).setTableName(SchemaUtil.getTableNameFromFullName(physicalTableName)).build().buildException();
      }
      newDesc.removeValue(Bytes.toBytes(PhoenixTransactionContext.READ_NON_TX_DATA));
    }
    TableDescriptor result=newDesc.build();
    if (existingDesc.equals(result)) {
      return null;
    }
    if (tableType != PTableType.SYSTEM) {
      modifyTable(physicalTableName,newDesc.build(),true);
    }
    return result;
  }
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.INTERRUPTED_EXCEPTION).setRootCause(e).build().buildException();
}
catch (TimeoutException e) {
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.OPERATION_TIMED_OUT).setRootCause(e.getCause() != null ? e.getCause() : e).build().buildException();
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
654,} finally {,"try (Admin admin=getAdmin()){
  if (tableNamesToDelete != null) {
    for (    byte[] tableName : tableNamesToDelete) {
      try {
        TableName tn=TableName.valueOf(tableName);
        TableDescriptor htableDesc=this.getTableDescriptor(tableName);
        admin.disableTable(tn);
        admin.deleteTable(tn);
        tableStatsCache.invalidateAll(htableDesc);
        clearTableRegionCache(TableName.valueOf(tableName));
      }
 catch (      TableNotFoundException ignore) {
      }
    }
  }
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
655,} finally {,"try {
  modifyTable(descriptor.getTableName().getName(),descriptor,pollingNeeded);
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.INTERRUPTED_EXCEPTION).setRootCause(e).build().buildException();
}
catch (TimeoutException e) {
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.OPERATION_TIMED_OUT).setRootCause(e.getCause() != null ? e.getCause() : e).build().buildException();
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
656,} finally {,"try {
  String dml=""UPSERT INTO "" + SYSTEM_CATALOG_NAME + "" (""+ PhoenixDatabaseMetaData.TENANT_ID+ "",""+ PhoenixDatabaseMetaData.TABLE_SCHEM+ "",""+ PhoenixDatabaseMetaData.TABLE_NAME+ "",""+ PhoenixDatabaseMetaData.COLUMN_NAME+ "",""+ PhoenixDatabaseMetaData.NULLABLE+ "") VALUES (null, ?, ?, ?, ?)"";
  PreparedStatement stmt=metaConnection.prepareStatement(dml);
  stmt.setString(1,schemaName);
  stmt.setString(2,tableName);
  stmt.setString(3,columnName);
  stmt.setInt(4,ResultSetMetaData.columnNullable);
  stmt.executeUpdate();
  metaConnection.commit();
}
 catch (NewerTableAlreadyExistsException e) {
  LOGGER.warn(""Table already modified at this timestamp,"" + "" so assuming column already nullable: "" + columnName);
}
catch (SQLException e) {
  LOGGER.warn(""Add column failed due to:"" + e);
  sqlE=e;
}
 finally {
  try {
    oldMetaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
657,} finally {,"try {
  metaConnection.createStatement().executeUpdate(""ALTER TABLE "" + tableName + "" ADD ""+ (addIfNotExists ? "" IF NOT EXISTS "" : """")+ columns);
}
 catch (NewerTableAlreadyExistsException e) {
  LOGGER.warn(""Table already modified at this timestamp,"" + "" so assuming add of these columns already done: "" + columns);
}
catch (SQLException e) {
  LOGGER.warn(""Add column failed due to:"" + e);
  sqlE=e;
}
 finally {
  try {
    oldMetaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
658,} finally {,"try {
  GLOBAL_QUERY_SERVICES_COUNTER.increment();
  LOGGER.info(""An instance of ConnectionQueryServices was created."");
  openConnection();
  hConnectionEstablished=true;
  boolean isDoNotUpgradePropSet=UpgradeUtil.isNoUpgradeSet(props);
  Properties scnProps=PropertiesUtil.deepCopy(props);
  scnProps.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB,Long.toString(getSystemTableVersion()));
  scnProps.remove(PhoenixRuntime.TENANT_ID_ATTRIB);
  String globalUrl=JDBCUtil.removeProperty(url,PhoenixRuntime.TENANT_ID_ATTRIB);
  try (PhoenixConnection metaConnection=new PhoenixConnection(ConnectionQueryServicesImpl.this,globalUrl,scnProps,newEmptyMetaData())){
    try (Statement statement=metaConnection.createStatement()){
      metaConnection.setRunningUpgrade(true);
      statement.executeUpdate(getSystemCatalogTableDDL());
    }
 catch (    NewerTableAlreadyExistsException ignore) {
    }
catch (    TableAlreadyExistsException e) {
      long currentServerSideTableTimeStamp=e.getTable().getTimeStamp();
      if (currentServerSideTableTimeStamp < MIN_SYSTEM_TABLE_TIMESTAMP) {
        setUpgradeRequired();
      }
    }
catch (    PhoenixIOException e) {
      boolean foundAccessDeniedException=false;
      if (inspectIfAnyExceptionInChain(e,Collections.<Class<? extends Exception>>singletonList(AccessDeniedException.class))) {
        LOGGER.warn(""Could not check for Phoenix SYSTEM tables,"" + "" assuming they exist and are properly configured"");
        checkClientServerCompatibility(SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,getProps()).getName());
        success=true;
      }
 else       if (inspectIfAnyExceptionInChain(e,Collections.<Class<? extends Exception>>singletonList(NamespaceNotFoundException.class))) {
        AccessDeniedException ade=new AccessDeniedException(""Insufficient permissions to create SYSTEM namespace and SYSTEM Tables"");
        initializationException=ServerUtil.parseServerException(ade);
      }
 else {
        initializationException=e;
      }
      return null;
    }
catch (    UpgradeRequiredException e) {
      setUpgradeRequired();
    }
    if (!ConnectionQueryServicesImpl.this.upgradeRequired.get()) {
      if (!isDoNotUpgradePropSet) {
        createOtherSystemTables(metaConnection);
        createSchemaIfNotExistsSystemNSMappingEnabled(metaConnection);
      }
    }
 else     if (isAutoUpgradeEnabled && !isDoNotUpgradePropSet) {
      upgradeSystemTables(url,props);
    }
 else {
      LOGGER.error(""Upgrade is required. Must run 'EXECUTE UPGRADE' "" + ""before any other command"");
    }
  }
   scheduleRenewLeaseTasks();
  success=true;
}
 catch (RetriableUpgradeException e) {
  success=true;
  throw e;
}
catch (Exception e) {
  if (e instanceof SQLException) {
    initializationException=(SQLException)e;
  }
 else {
    initializationException=new SQLException(e);
  }
}
 finally {
  try {
    if (!success && hConnectionEstablished) {
      closeConnection();
    }
  }
 catch (  IOException e) {
    SQLException ex=new SQLException(e);
    if (initializationException != null) {
      initializationException.setNextException(ex);
    }
 else {
      initializationException=ex;
    }
  }
 finally {
    try {
      if (initializationException != null) {
        throw initializationException;
      }
    }
  finally {
      setInitialized(true);
    }
  }
}
",0,0,0,,
659,} finally {,"try {
  if (!success && hConnectionEstablished) {
    closeConnection();
  }
}
 catch (IOException e) {
  SQLException ex=new SQLException(e);
  if (initializationException != null) {
    initializationException.setNextException(ex);
  }
 else {
    initializationException=ex;
  }
}
 finally {
  try {
    if (initializationException != null) {
      throw initializationException;
    }
  }
  finally {
    setInitialized(true);
  }
}
",0,0,0,,
660,} finally {,"try {
  if (!isUpgradeRequired()) {
    throw new UpgradeNotRequiredException();
  }
  Properties scnProps=PropertiesUtil.deepCopy(props);
  scnProps.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB,Long.toString(MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP));
  scnProps.remove(PhoenixRuntime.TENANT_ID_ATTRIB);
  String globalUrl=JDBCUtil.removeProperty(url,PhoenixRuntime.TENANT_ID_ATTRIB);
  metaConnection=new PhoenixConnection(ConnectionQueryServicesImpl.this,globalUrl,scnProps,newEmptyMetaData());
  metaConnection.setRunningUpgrade(true);
  try (Admin admin=getAdmin()){
    createSysMutexTableIfNotExists(admin);
  }
   try {
    metaConnection.createStatement().executeUpdate(getSystemCatalogTableDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
catch (  UpgradeRequiredException e) {
    long currentServerSideTableTimeStamp=e.getSystemCatalogTimeStamp();
    if (currentServerSideTableTimeStamp < MIN_SYSTEM_TABLE_TIMESTAMP_4_15_0) {
      moveChildLinks=true;
    }
    sysCatalogTableName=SchemaUtil.getPhysicalName(SYSTEM_CATALOG_NAME_BYTES,this.getProps()).getNameAsString();
    if (SchemaUtil.isNamespaceMappingEnabled(PTableType.SYSTEM,ConnectionQueryServicesImpl.this.getProps())) {
      String snapshotName=null;
      if (acquiredMutexLock=acquireUpgradeMutex(MetaDataProtocol.MIN_SYSTEM_TABLE_MIGRATION_TIMESTAMP)) {
        LOGGER.debug(""Acquired lock in SYSMUTEX table for migrating SYSTEM tables to SYSTEM namespace "" + ""and/or upgrading "" + sysCatalogTableName);
        snapshotName=getSysTableSnapshotName(currentServerSideTableTimeStamp,SYSTEM_CATALOG_NAME);
        createSnapshot(snapshotName,SYSTEM_CATALOG_NAME);
        systemTableToSnapshotMap.put(SYSTEM_CATALOG_NAME,snapshotName);
        LOGGER.info(""Created snapshot {} for {}"",snapshotName,SYSTEM_CATALOG_NAME);
      }
      ensureSystemTablesMigratedToSystemNamespace();
      LOGGER.debug(""Migrated SYSTEM tables to SYSTEM namespace"");
      if (snapshotName != null) {
        deleteSnapshot(snapshotName);
      }
 else {
        snapshotName=getSysTableSnapshotName(currentServerSideTableTimeStamp,SYSTEM_CATALOG_NAME);
      }
      systemTableToSnapshotMap.remove(SYSTEM_CATALOG_NAME);
      createSnapshot(snapshotName,sysCatalogTableName);
      systemTableToSnapshotMap.put(sysCatalogTableName,snapshotName);
      LOGGER.info(""Created snapshot {} for {}"",snapshotName,sysCatalogTableName);
      metaConnection=upgradeSystemCatalogIfRequired(metaConnection,currentServerSideTableTimeStamp);
    }
  }
catch (  TableAlreadyExistsException e) {
    long currentServerSideTableTimeStamp=e.getTable().getTimeStamp();
    sysCatalogTableName=e.getTable().getPhysicalName().getString();
    if (currentServerSideTableTimeStamp < MIN_SYSTEM_TABLE_TIMESTAMP) {
      if (acquiredMutexLock=acquireUpgradeMutex(currentServerSideTableTimeStamp)) {
        LOGGER.debug(""Acquired lock in SYSMUTEX table for upgrading "" + sysCatalogTableName);
        takeSnapshotOfSysTable(systemTableToSnapshotMap,e);
      }
    }
    metaConnection=upgradeSystemCatalogIfRequired(metaConnection,currentServerSideTableTimeStamp);
    if (currentServerSideTableTimeStamp < MIN_SYSTEM_TABLE_TIMESTAMP_4_15_0) {
      moveChildLinks=true;
      syncAllTableAndIndexProps=true;
    }
    if (currentServerSideTableTimeStamp < MIN_SYSTEM_TABLE_TIMESTAMP_4_16_0) {
      try (PhoenixConnection conn=new PhoenixConnection(ConnectionQueryServicesImpl.this,globalUrl,props,newEmptyMetaData())){
        UpgradeUtil.mergeViewIndexIdSequences(metaConnection);
      }
 catch (      Exception mergeViewIndeIdException) {
        LOGGER.warn(""Merge view index id sequence failed! If possible, "" + ""please run MergeViewIndexIdSequencesTool to avoid view index"" + ""id collision. Error: ""+ mergeViewIndeIdException.getMessage());
      }
    }
  }
  metaConnection=upgradeOtherSystemTablesIfRequired(metaConnection,moveChildLinks,systemTableToSnapshotMap);
  if (syncAllTableAndIndexProps) {
    syncTableAndIndexProperties(metaConnection);
  }
  createSchemaIfNotExistsSystemNSMappingEnabled(metaConnection);
  clearUpgradeRequired();
  success=true;
}
 catch (UpgradeInProgressException|UpgradeNotRequiredException e) {
  throw e;
}
catch (Exception e) {
  if (e instanceof SQLException) {
    toThrow=(SQLException)e;
  }
 else {
    toThrow=new SQLException(e);
  }
}
 finally {
  try {
    if (metaConnection != null) {
      metaConnection.close();
    }
  }
 catch (  SQLException e) {
    if (toThrow != null) {
      toThrow.setNextException(e);
    }
 else {
      toThrow=e;
    }
  }
 finally {
    if (!success) {
      LOGGER.warn(""Failed upgrading System tables. "" + ""Snapshots for system tables created so far: {}"",systemTableToSnapshotMap);
    }
    if (acquiredMutexLock) {
      try {
        releaseUpgradeMutex();
      }
 catch (      IOException e) {
        LOGGER.warn(""Release of upgrade mutex failed "",e);
      }
    }
    if (toThrow != null) {
      throw toThrow;
    }
  }
}
",0,0,0,,
661,} finally {,"try {
  if (metaConnection != null) {
    metaConnection.close();
  }
}
 catch (SQLException e) {
  if (toThrow != null) {
    toThrow.setNextException(e);
  }
 else {
    toThrow=e;
  }
}
 finally {
  if (!success) {
    LOGGER.warn(""Failed upgrading System tables. "" + ""Snapshots for system tables created so far: {}"",systemTableToSnapshotMap);
  }
  if (acquiredMutexLock) {
    try {
      releaseUpgradeMutex();
    }
 catch (    IOException e) {
      LOGGER.warn(""Release of upgrade mutex failed "",e);
    }
  }
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
662,} finally {,"try {
  admin=getAdmin();
  admin.snapshot(snapshotName,TableName.valueOf(tableName));
  LOGGER.info(""Successfully created snapshot "" + snapshotName + "" for ""+ tableName);
}
 catch (Exception e) {
  sqlE=new SQLException(e);
}
 finally {
  try {
    if (admin != null) {
      admin.close();
    }
  }
 catch (  Exception e) {
    SQLException adminCloseEx=new SQLException(e);
    if (sqlE == null) {
      sqlE=adminCloseEx;
    }
 else {
      sqlE.setNextException(adminCloseEx);
    }
  }
 finally {
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
663,} finally {,"try {
  if (admin != null) {
    admin.close();
  }
}
 catch (Exception e) {
  SQLException adminCloseEx=new SQLException(e);
  if (sqlE == null) {
    sqlE=adminCloseEx;
  }
 else {
    sqlE.setNextException(adminCloseEx);
  }
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
664,} finally {,"try {
  metaConnection.setAutoCommit(true);
  metaConnection.createStatement().execute(""UPSERT INTO SYSTEM.CATALOG(TENANT_ID, TABLE_SCHEM, TABLE_NAME, COLUMN_NAME, COLUMN_FAMILY, IMMUTABLE_ROWS)\n"" + ""SELECT A.TENANT_ID, A.TABLE_SCHEM,B.COLUMN_FAMILY,null,null,true\n"" + ""FROM SYSTEM.CATALOG A JOIN SYSTEM.CATALOG B ON (\n""+ "" A.TENANT_ID = B.TENANT_ID AND \n""+ "" A.TABLE_SCHEM = B.TABLE_SCHEM AND\n""+ "" A.TABLE_NAME = B.TABLE_NAME AND\n""+ "" A.COLUMN_NAME = B.COLUMN_NAME AND\n""+ "" B.LINK_TYPE = 1\n""+ "")\n""+ ""WHERE A.COLUMN_FAMILY IS NULL AND\n""+ "" B.COLUMN_FAMILY IS NOT NULL AND\n""+ "" A.IMMUTABLE_ROWS = TRUE"");
}
 catch (SQLException e) {
  LOGGER.warn(""exception during upgrading stats table:"" + e);
  sqlE=e;
}
 finally {
  try {
    metaConnection.setAutoCommit(autoCommit);
    oldMetaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
665,} finally {,"try {
  metaConnection.setAutoCommit(true);
  metaConnection.createStatement().execute(""UPSERT INTO SYSTEM.CATALOG(TENANT_ID, TABLE_SCHEM, TABLE_NAME, COLUMN_NAME, COLUMN_FAMILY, DISABLE_WAL)\n"" + ""VALUES (NULL, '"" + QueryConstants.SYSTEM_SCHEMA_NAME + ""','""+ PhoenixDatabaseMetaData.SYSTEM_CATALOG_TABLE+ ""', NULL, NULL, FALSE)"");
}
 catch (SQLException e) {
  LOGGER.warn(""exception during upgrading stats table:"" + e);
  sqlE=e;
}
 finally {
  try {
    metaConnection.setAutoCommit(autoCommit);
    oldMetaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
666,} finally {,"try {
  metaConnection.setAutoCommit(true);
  metaConnection.createStatement().executeUpdate(""DELETE FROM "" + PhoenixDatabaseMetaData.SYSTEM_CATALOG_NAME + "" WHERE ""+ PhoenixDatabaseMetaData.TABLE_NAME+ ""='""+ PhoenixDatabaseMetaData.SYSTEM_STATS_TABLE+ ""' AND ""+ PhoenixDatabaseMetaData.TABLE_SCHEM+ ""='""+ SYSTEM_SCHEMA_NAME+ ""'"");
}
 catch (SQLException e) {
  LOGGER.warn(""exception during upgrading stats table:"" + e);
  sqlE=e;
}
 finally {
  try {
    metaConnection.setAutoCommit(wasCommit);
    oldMetaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
667,} finally {,"try {
  hTable.batch(incrementBatch,resultObjects);
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.INTERRUPTED_EXCEPTION).setRootCause(e).build().buildException();
}
 finally {
  try {
    hTable.close();
  }
 catch (  IOException e) {
    if (sqlE == null) {
      sqlE=ServerUtil.parseServerException(e);
    }
 else {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
668,} finally {,"try {
  htable.coprocessorService(MetaDataService.class,HConstants.EMPTY_START_ROW,HConstants.EMPTY_END_ROW,new Batch.Call<MetaDataService,ClearTableFromCacheResponse>(){
    @Override public ClearTableFromCacheResponse call(    MetaDataService instance) throws IOException {
      ServerRpcController controller=new ServerRpcController();
      BlockingRpcCallback<ClearTableFromCacheResponse> rpcCallback=new BlockingRpcCallback<ClearTableFromCacheResponse>();
      ClearTableFromCacheRequest.Builder builder=ClearTableFromCacheRequest.newBuilder();
      builder.setTenantId(ByteStringer.wrap(tenantId));
      builder.setTableName(ByteStringer.wrap(tableName));
      builder.setSchemaName(ByteStringer.wrap(schemaName));
      builder.setClientTimestamp(clientTS);
      builder.setClientVersion(VersionUtil.encodeVersion(PHOENIX_MAJOR_VERSION,PHOENIX_MINOR_VERSION,PHOENIX_PATCH_NUMBER));
      instance.clearTableFromCache(controller,builder.build(),rpcCallback);
      if (controller.getFailedOn() != null) {
        throw controller.getFailedOn();
      }
      return rpcCallback.get();
    }
  }
);
}
 catch (IOException e) {
  throw ServerUtil.parseServerException(e);
}
catch (Throwable e) {
  sqlE=new SQLException(e);
}
 finally {
  try {
    htable.close();
  }
 catch (  IOException e) {
    if (sqlE == null) {
      sqlE=ServerUtil.parseServerException(e);
    }
 else {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
  }
 finally {
    if (sqlE != null) {
      throw sqlE;
    }
  }
}
",0,0,0,,
669,} finally {,"try {
  htable.close();
}
 catch (IOException e) {
  if (sqlE == null) {
    sqlE=ServerUtil.parseServerException(e);
  }
 else {
    sqlE.setNextException(ServerUtil.parseServerException(e));
  }
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
670,} finally {,"try {
  hTable.batch(mutations,resultObjects);
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.INTERRUPTED_EXCEPTION).setRootCause(e).build().buildException();
}
 finally {
  try {
    hTable.close();
  }
 catch (  IOException e) {
    if (sqlE == null) {
      sqlE=ServerUtil.parseServerException(e);
    }
 else {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
671,} finally {,"try {
  hTable.batch(mutations,null);
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
catch (InterruptedException e) {
  Thread.currentThread().interrupt();
  sqlE=new SQLExceptionInfo.Builder(SQLExceptionCode.INTERRUPTED_EXCEPTION).setRootCause(e).build().buildException();
}
 finally {
  try {
    hTable.close();
  }
 catch (  IOException e) {
    if (sqlE == null) {
      sqlE=ServerUtil.parseServerException(e);
    }
 else {
      sqlE.setNextException(ServerUtil.parseServerException(e));
    }
  }
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
672,} finally {,"try (Admin admin=getAdmin()){
  final String quorum=ZKConfig.getZKQuorumServersString(config);
  final String znode=this.props.get(HConstants.ZOOKEEPER_ZNODE_PARENT);
  LOGGER.debug(""Found quorum: "" + quorum + "":""+ znode);
  boolean nameSpaceExists=true;
  try {
    admin.getNamespaceDescriptor(schemaName);
  }
 catch (  org.apache.hadoop.hbase.NamespaceNotFoundException e) {
    nameSpaceExists=false;
  }
  if (nameSpaceExists) {
    admin.deleteNamespace(schemaName);
  }
}
 catch (IOException e) {
  sqlE=ServerUtil.parseServerException(e);
}
 finally {
  if (sqlE != null) {
    throw sqlE;
  }
}
",0,0,0,,
673,} finally {,"try {
  Properties scnProps=PropertiesUtil.deepCopy(props);
  scnProps.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB,Long.toString(MetaDataProtocol.MIN_SYSTEM_TABLE_TIMESTAMP));
  scnProps.remove(PhoenixRuntime.TENANT_ID_ATTRIB);
  String globalUrl=JDBCUtil.removeProperty(url,PhoenixRuntime.TENANT_ID_ATTRIB);
  metaConnection=new PhoenixConnection(this,globalUrl,scnProps,newEmptyMetaData());
  metaConnection.setRunningUpgrade(true);
  try {
    metaConnection.createStatement().executeUpdate(getSystemCatalogTableDDL());
  }
 catch (  TableAlreadyExistsException ignore) {
  }
  try {
    int nSaltBuckets=getSequenceSaltBuckets();
    String createTableStatement=getSystemSequenceTableDDL(nSaltBuckets);
    metaConnection.createStatement().executeUpdate(createTableStatement);
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(QueryConstants.CREATE_STATS_TABLE_METADATA);
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(getFunctionTableDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(getLogTableDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(getChildLinkDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(getMutexDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
  try {
    metaConnection.createStatement().executeUpdate(getTaskDDL());
  }
 catch (  NewerTableAlreadyExistsException ignore) {
  }
}
 catch (SQLException e) {
  sqlE=e;
}
 finally {
  try {
    if (metaConnection != null)     metaConnection.close();
  }
 catch (  SQLException e) {
    if (sqlE != null) {
      sqlE.setNextException(e);
    }
 else {
      sqlE=e;
    }
  }
 finally {
    try {
      if (sqlE != null) {
        initializationException=sqlE;
        throw sqlE;
      }
    }
  finally {
      initialized=true;
    }
  }
}
",0,0,0,,
674,} finally {,"try {
  if (metaConnection != null)   metaConnection.close();
}
 catch (SQLException e) {
  if (sqlE != null) {
    sqlE.setNextException(e);
  }
 else {
    sqlE=e;
  }
}
 finally {
  try {
    if (sqlE != null) {
      initializationException=sqlE;
      throw sqlE;
    }
  }
  finally {
    initialized=true;
  }
}
",0,0,0,,
675,} finally {,"try {
  MutationState state=newClientAtNextTimeStamp.buildIndex(index,tableRef);
  success=true;
  return state;
}
 catch (SQLException e) {
  sqlException=e;
}
 finally {
  try {
    conn.close();
  }
 catch (  SQLException e) {
    if (sqlException == null) {
      if (success) {
        sqlException=e;
      }
    }
 else {
      sqlException.setNextException(e);
    }
  }
  if (sqlException != null) {
    throw sqlException;
  }
}
",0,0,0,,
676,} finally {,"try {
  Integer bucketNum=this.getBucketNum();
  if (bucketNum != null) {
    i++;
    os.write(QueryConstants.SEPARATOR_BYTE_ARRAY);
  }
  int nColumns=columns.size();
  PDataType type=null;
  SortOrder sortOrder=null;
  boolean wasNull=false;
  while (i < nValues && i < nColumns) {
    if (type != null && !type.isFixedWidth()) {
      os.write(SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable(),wasNull,sortOrder));
    }
    PColumn column=columns.get(i);
    sortOrder=column.getSortOrder();
    type=column.getDataType();
    byte[] byteValue=values[i++];
    if (byteValue == null) {
      if (column.getExpressionStr() != null) {
        try {
          String url=PhoenixRuntime.JDBC_PROTOCOL + PhoenixRuntime.JDBC_PROTOCOL_SEPARATOR + PhoenixRuntime.CONNECTIONLESS;
          PhoenixConnection conn=DriverManager.getConnection(url).unwrap(PhoenixConnection.class);
          StatementContext context=new StatementContext(new PhoenixStatement(conn));
          ExpressionCompiler compiler=new ExpressionCompiler(context);
          ParseNode defaultParseNode=new SQLParser(column.getExpressionStr()).parseExpression();
          Expression defaultExpression=defaultParseNode.accept(compiler);
          defaultExpression.evaluate(null,key);
          column.getDataType().coerceBytes(key,null,defaultExpression.getDataType(),defaultExpression.getMaxLength(),defaultExpression.getScale(),defaultExpression.getSortOrder(),column.getMaxLength(),column.getScale(),column.getSortOrder());
          byteValue=ByteUtil.copyKeyBytesIfNecessary(key);
        }
 catch (        SQLException e) {
          throw new ConstraintViolationException(name.getString() + ""."" + column.getName().getString()+ "" failed to compile default value expression of ""+ column.getExpressionStr());
        }
      }
 else {
        byteValue=ByteUtil.EMPTY_BYTE_ARRAY;
      }
    }
    wasNull=byteValue.length == 0;
    if (byteValue.length == 0 && !column.isNullable()) {
      throw new ConstraintViolationException(name.getString() + ""."" + column.getName().getString()+ "" may not be null"");
    }
    Integer maxLength=column.getMaxLength();
    Integer scale=column.getScale();
    key.set(byteValue);
    if (!type.isSizeCompatible(key,null,type,sortOrder,null,null,maxLength,scale)) {
      throw new DataExceedsCapacityException(column.getDataType(),maxLength,column.getScale(),column.getName().getString());
    }
    key.set(byteValue);
    type.pad(key,maxLength,sortOrder);
    byteValue=ByteUtil.copyKeyBytesIfNecessary(key);
    os.write(byteValue,0,byteValue.length);
  }
  if (type != null && !type.isFixedWidth() && SchemaUtil.getSeparatorByte(rowKeyOrderOptimizable(),wasNull,sortOrder) == QueryConstants.DESC_SEPARATOR_BYTE) {
    os.write(QueryConstants.DESC_SEPARATOR_BYTE);
  }
  if (i < nColumns) {
    PColumn column=columns.get(i);
    if (column.getDataType().isFixedWidth() || !column.isNullable()) {
      throw new ConstraintViolationException(name.getString() + ""."" + column.getName().getString()+ "" may not be null"");
    }
  }
  if (nValues == 0) {
    throw new ConstraintViolationException(""Primary key may not be null ("" + name.getString() + "")"");
  }
  byte[] buf=os.getBuffer();
  int size=os.size();
  if (bucketNum != null) {
    buf[0]=SaltingUtil.getSaltingByte(buf,1,size - 1,bucketNum);
  }
  key.set(buf,0,size);
  return i;
}
  finally {
  try {
    os.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
677,} finally {,"try {
  ArrayList<Mutation> mutations=new ArrayList<Mutation>();
  if (LOGGER.isDebugEnabled()) {
    LOGGER.debug(""Deleting the stats for the region "" + regionInfo.getRegionNameAsString() + "" as part of major compaction"");
  }
  getStatisticsWriter().deleteStatsForRegion(region,tracker,family,mutations);
  if (LOGGER.isDebugEnabled()) {
    LOGGER.debug(""Adding new stats for the region "" + regionInfo.getRegionNameAsString() + "" as part of major compaction"");
  }
  getStatisticsWriter().addStats(tracker,family,mutations,tracker.getGuidePostDepth());
  if (LOGGER.isDebugEnabled()) {
    LOGGER.debug(""Committing new stats for the region "" + regionInfo.getRegionNameAsString() + "" as part of major compaction"");
  }
  getStatisticsWriter().commitStats(mutations,tracker);
}
 catch (IOException e) {
  if (isConnectionClosed()) {
    LOGGER.debug(""Ignoring error updating statistics because region is closing/closed"");
  }
 else {
    LOGGER.error(""Failed to update statistics table!"",e);
    toThrow=e;
  }
}
 finally {
  try {
    collectionTracker.removeCompactingRegion(regionInfo);
    getStatisticsWriter().close();
    getTracker().close();
  }
 catch (  IOException e) {
    if (toThrow == null)     toThrow=e;
    LOGGER.error(""Error while closing the stats table"",e);
  }
 finally {
    try {
      getDelegate().close();
    }
 catch (    IOException e) {
      if (toThrow == null)       toThrow=e;
      LOGGER.error(""Error while closing the scanner"",e);
    }
 finally {
      if (toThrow != null) {
        throw toThrow;
      }
    }
  }
}
",0,0,0,,
678,} finally {,"try {
  collectionTracker.removeCompactingRegion(regionInfo);
  getStatisticsWriter().close();
  getTracker().close();
}
 catch (IOException e) {
  if (toThrow == null)   toThrow=e;
  LOGGER.error(""Error while closing the stats table"",e);
}
 finally {
  try {
    getDelegate().close();
  }
 catch (  IOException e) {
    if (toThrow == null)     toThrow=e;
    LOGGER.error(""Error while closing the scanner"",e);
  }
 finally {
    if (toThrow != null) {
      throw toThrow;
    }
  }
}
",0,0,0,,
679,} finally {,"try {
  getDelegate().close();
}
 catch (IOException e) {
  if (toThrow == null)   toThrow=e;
  LOGGER.error(""Error while closing the scanner"",e);
}
 finally {
  if (toThrow != null) {
    throw toThrow;
  }
}
",0,0,0,,
680,} finally {,"try {
  for (  byte[] b : byteArrays) {
    if (b == null) {
      WritableUtils.writeVInt(out,0);
    }
 else {
      WritableUtils.writeVInt(out,b.length);
      out.write(b);
    }
  }
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    out.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
681,} finally {,"try {
  for (int i=0; i < length; i++) {
    int bLength=WritableUtils.readVInt(in);
    if (bLength == 0) {
      byteArrays[i]=null;
    }
 else {
      byteArrays[i]=new byte[bLength];
      int rLength=in.read(byteArrays[i],0,bLength);
      assert (rLength == bLength);
    }
  }
  if (in.read() != -1) {
    throw new IllegalStateException(""Expected only "" + length + "" byte arrays, but found more"");
  }
  return byteArrays;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    in.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
682,} finally {,"try {
  int length=WritableUtils.readVInt(in);
  return deserializeVIntArray(in,length);
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    in.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
683,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  int numColumns=WritableUtils.readVInt(input);
  ColumnReference[] dataColumns=new ColumnReference[numColumns];
  for (int i=0; i < numColumns; i++) {
    dataColumns[i]=new ColumnReference(Bytes.readByteArray(input),Bytes.readByteArray(input));
  }
  return dataColumns;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
684,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  int numConstants=WritableUtils.readVInt(input);
  byte[][] viewConstants=new byte[numConstants][];
  for (int i=0; i < numConstants; i++) {
    viewConstants[i]=Bytes.readByteArray(input);
  }
  return viewConstants;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
685,} finally {,"try {
  DataInputStream input=new DataInputStream(stream);
  KeyValueSchema schema=new KeyValueSchema();
  schema.readFields(input);
  return schema;
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
686,} finally {,"try {
  (localConnection == null ? globalConnection : localConnection).createStatement().execute(""DROP INDEX IF EXISTS "" + indexTableName + "" ON ""+ SchemaUtil.getTableName(schemaName,dataTableName));
  LOGGER.info(""Recreating the index "" + indexTableName);
  (localConnection == null ? globalConnection : localConnection).createStatement().execute(createIndex.toString());
  LOGGER.info(""Created the index "" + indexTableName);
}
  finally {
  props.remove(PhoenixRuntime.TENANT_ID_ATTRIB);
  if (localConnection != null) {
    sqlEx=closeConnection(localConnection,sqlEx);
    if (sqlEx != null) {
      throw sqlEx;
    }
  }
}
",0,0,0,,
687,} finally {,"try (Admin admin=globalConnection.getQueryServices().getAdmin()){
  ResultSet rs=globalConnection.createStatement().executeQuery(""SELECT TABLE_SCHEM, TABLE_NAME, DATA_TABLE_NAME, TENANT_ID, MULTI_TENANT, SALT_BUCKETS FROM SYSTEM.CATALOG  "" + ""      WHERE COLUMN_NAME IS NULL"" + ""           AND COLUMN_FAMILY IS NULL""+ ""           AND INDEX_TYPE=""+ IndexType.LOCAL.getSerializedValue());
  boolean droppedLocalIndexes=false;
  while (rs.next()) {
    if (!droppedLocalIndexes) {
      TableDescriptor[] localIndexTables=admin.listTables(MetaDataUtil.LOCAL_INDEX_TABLE_PREFIX + "".*"");
      String localIndexSplitter=LocalIndexSplitter.class.getName();
      for (      TableDescriptor table : localIndexTables) {
        TableDescriptor dataTableDesc=admin.getDescriptor(TableName.valueOf(MetaDataUtil.getLocalIndexUserTableName(table.getTableName().getNameAsString())));
        TableDescriptorBuilder dataTableDescBuilder=TableDescriptorBuilder.newBuilder(dataTableDesc);
        ColumnFamilyDescriptor[] columnFamilies=dataTableDesc.getColumnFamilies();
        boolean modifyTable=false;
        for (        ColumnFamilyDescriptor cf : columnFamilies) {
          String localIndexCf=QueryConstants.LOCAL_INDEX_COLUMN_FAMILY_PREFIX + cf.getNameAsString();
          if (dataTableDesc.getColumnFamily(Bytes.toBytes(localIndexCf)) == null) {
            ColumnFamilyDescriptorBuilder colDefBuilder=ColumnFamilyDescriptorBuilder.newBuilder(Bytes.toBytes(localIndexCf));
            for (            Entry<Bytes,Bytes> keyValue : cf.getValues().entrySet()) {
              colDefBuilder.setValue(keyValue.getKey().copyBytes(),keyValue.getValue().copyBytes());
            }
            dataTableDescBuilder.addColumnFamily(colDefBuilder.build());
            modifyTable=true;
          }
        }
        Collection<String> coprocessors=dataTableDesc.getCoprocessors();
        for (        String coprocessor : coprocessors) {
          if (coprocessor.equals(localIndexSplitter)) {
            dataTableDescBuilder.removeCoprocessor(localIndexSplitter);
            modifyTable=true;
          }
        }
        if (modifyTable) {
          admin.modifyTable(dataTableDescBuilder.build());
        }
      }
      admin.disableTables(MetaDataUtil.LOCAL_INDEX_TABLE_PREFIX + "".*"");
      admin.deleteTables(MetaDataUtil.LOCAL_INDEX_TABLE_PREFIX + "".*"");
      droppedLocalIndexes=true;
    }
    String schemaName=rs.getString(1);
    String indexTableName=rs.getString(2);
    String dataTableName=rs.getString(3);
    String tenantId=rs.getString(4);
    boolean multiTenantTable=rs.getBoolean(5);
    int numColumnsToSkip=1 + (multiTenantTable ? 1 : 0);
    String getColumns=""SELECT COLUMN_NAME, COLUMN_FAMILY FROM SYSTEM.CATALOG  WHERE TABLE_SCHEM "" + (schemaName == null ? ""IS NULL "" : ""='"" + schemaName + ""'"") + "" AND TENANT_ID ""+ (tenantId == null ? ""IS NULL "" : ""='"" + tenantId + ""'"")+ "" and TABLE_NAME='""+ indexTableName+ ""' AND COLUMN_NAME IS NOT NULL AND KEY_SEQ > ""+ numColumnsToSkip+ "" ORDER BY KEY_SEQ"";
    ResultSet getColumnsRs=globalConnection.createStatement().executeQuery(getColumns);
    List<String> indexedColumns=new ArrayList<String>(1);
    List<String> coveredColumns=new ArrayList<String>(1);
    while (getColumnsRs.next()) {
      String column=getColumnsRs.getString(1);
      String columnName=IndexUtil.getDataColumnName(column);
      String columnFamily=IndexUtil.getDataColumnFamilyName(column);
      if (getColumnsRs.getString(2) == null) {
        if (columnFamily != null && !columnFamily.isEmpty()) {
          if (SchemaUtil.normalizeIdentifier(columnFamily).equals(QueryConstants.DEFAULT_COLUMN_FAMILY)) {
            indexedColumns.add(columnName);
          }
 else {
            indexedColumns.add(SchemaUtil.getCaseSensitiveColumnDisplayName(columnFamily,columnName));
          }
        }
 else {
          indexedColumns.add(columnName);
        }
      }
 else {
        coveredColumns.add(SchemaUtil.normalizeIdentifier(columnFamily).equals(QueryConstants.DEFAULT_COLUMN_FAMILY) ? columnName : SchemaUtil.getCaseSensitiveColumnDisplayName(columnFamily,columnName));
      }
    }
    StringBuilder createIndex=new StringBuilder(""CREATE LOCAL INDEX "");
    createIndex.append(indexTableName);
    createIndex.append("" ON "");
    createIndex.append(SchemaUtil.getTableName(schemaName,dataTableName));
    createIndex.append(""("");
    for (int i=0; i < indexedColumns.size(); i++) {
      createIndex.append(indexedColumns.get(i));
      if (i < indexedColumns.size() - 1) {
        createIndex.append("","");
      }
    }
    createIndex.append("")"");
    if (!coveredColumns.isEmpty()) {
      createIndex.append("" INCLUDE("");
      for (int i=0; i < coveredColumns.size(); i++) {
        createIndex.append(coveredColumns.get(i));
        if (i < coveredColumns.size() - 1) {
          createIndex.append("","");
        }
      }
      createIndex.append("")"");
    }
    createIndex.append("" ASYNC"");
    LOGGER.info(""Index creation query is : "" + createIndex.toString());
    LOGGER.info(""Dropping the index "" + indexTableName + "" to clean up the index details from SYSTEM.CATALOG."");
    PhoenixConnection localConnection=null;
    if (tenantId != null) {
      props.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB,tenantId);
      localConnection=new PhoenixConnection(globalConnection,globalConnection.getQueryServices(),props);
    }
    try {
      (localConnection == null ? globalConnection : localConnection).createStatement().execute(""DROP INDEX IF EXISTS "" + indexTableName + "" ON ""+ SchemaUtil.getTableName(schemaName,dataTableName));
      LOGGER.info(""Recreating the index "" + indexTableName);
      (localConnection == null ? globalConnection : localConnection).createStatement().execute(createIndex.toString());
      LOGGER.info(""Created the index "" + indexTableName);
    }
  finally {
      props.remove(PhoenixRuntime.TENANT_ID_ATTRIB);
      if (localConnection != null) {
        sqlEx=closeConnection(localConnection,sqlEx);
        if (sqlEx != null) {
          throw sqlEx;
        }
      }
    }
  }
  globalConnection.createStatement().execute(""DELETE FROM SYSTEM.CATALOG WHERE SUBSTR(TABLE_NAME,0,11)='"" + MetaDataUtil.LOCAL_INDEX_TABLE_PREFIX + ""'"");
  if (originalScn != null) {
    props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB,Long.toString(originalScn));
  }
  toReturn=new PhoenixConnection(globalConnection,globalConnection.getQueryServices(),props);
}
 catch (SQLException e) {
  sqlEx=e;
}
 finally {
  sqlEx=closeConnection(metaConnection,sqlEx);
  sqlEx=closeConnection(globalConnection,sqlEx);
  if (sqlEx != null) {
    throw sqlEx;
  }
}
",0,0,0,,
688,} finally {,"try {
  globalConnection=new PhoenixConnection(connParam,connParam.getQueryServices(),props);
  String tenantId=null;
  try (Admin admin=globalConnection.getQueryServices().getAdmin()){
    String fetchViewIndexes=""SELECT "" + TENANT_ID + "", ""+ TABLE_SCHEM+ "", ""+ TABLE_NAME+ "", ""+ DATA_TABLE_NAME+ "" FROM ""+ SYSTEM_CATALOG_NAME+ "" WHERE ""+ VIEW_INDEX_ID+ "" IS NOT NULL"";
    String disableIndexDDL=""ALTER INDEX %s ON %s DISABLE"";
    try (ResultSet rs=globalConnection.createStatement().executeQuery(fetchViewIndexes)){
      while (rs.next()) {
        tenantId=rs.getString(1);
        String indexSchema=rs.getString(2);
        String indexName=rs.getString(3);
        String viewName=rs.getString(4);
        String fullIndexName=SchemaUtil.getTableName(indexSchema,indexName);
        String fullViewName=SchemaUtil.getTableName(indexSchema,viewName);
        PTable viewPTable=null;
        if (tenantId != null && !tenantId.isEmpty()) {
          Properties newProps=PropertiesUtil.deepCopy(globalConnection.getClientInfo());
          newProps.setProperty(PhoenixRuntime.TENANT_ID_ATTRIB,tenantId);
          PTable indexPTable=null;
          try (PhoenixConnection tenantConnection=new PhoenixConnection(globalConnection,globalConnection.getQueryServices(),newProps)){
            viewPTable=PhoenixRuntime.getTable(tenantConnection,fullViewName);
            tenantConnection.createStatement().execute(String.format(disableIndexDDL,indexName,fullViewName));
            indexPTable=PhoenixRuntime.getTable(tenantConnection,fullIndexName);
          }
           int offset=indexPTable.getBucketNum() != null ? 1 : 0;
          int existingTenantIdPosition=++offset;
          int existingViewIdxIdPosition=++offset;
          int newTenantIdPosition=existingViewIdxIdPosition;
          int newViewIdxPosition=existingTenantIdPosition;
          String tenantIdColumn=indexPTable.getColumns().get(existingTenantIdPosition - 1).getName().getString();
          int index=0;
          String updatePosition=""UPSERT INTO "" + SYSTEM_CATALOG_NAME + "" ( ""+ TENANT_ID+ "",""+ TABLE_SCHEM+ "",""+ TABLE_NAME+ "",""+ COLUMN_NAME+ "",""+ COLUMN_FAMILY+ "",""+ ORDINAL_POSITION+ "") SELECT ""+ TENANT_ID+ "",""+ TABLE_SCHEM+ "",""+ TABLE_NAME+ "",""+ COLUMN_NAME+ "",""+ COLUMN_FAMILY+ "",""+ ""?""+ "" FROM ""+ SYSTEM_CATALOG_NAME+ "" WHERE ""+ TENANT_ID+ "" = ? ""+ "" AND ""+ TABLE_NAME+ "" = ? ""+ "" AND ""+ (indexSchema == null ? TABLE_SCHEM + "" IS NULL"" : TABLE_SCHEM + "" = ? "")+ "" AND ""+ COLUMN_NAME+ "" = ? "";
          try (PreparedStatement s=globalConnection.prepareStatement(updatePosition)){
            index=0;
            s.setInt(++index,newViewIdxPosition);
            s.setString(++index,tenantId);
            s.setString(++index,indexName);
            if (indexSchema != null) {
              s.setString(++index,indexSchema);
            }
            s.setString(++index,MetaDataUtil.getViewIndexIdColumnName());
            s.executeUpdate();
          }
           try (PreparedStatement s=globalConnection.prepareStatement(updatePosition)){
            index=0;
            s.setInt(++index,newTenantIdPosition);
            s.setString(++index,tenantId);
            s.setString(++index,indexName);
            if (indexSchema != null) {
              s.setString(++index,indexSchema);
            }
            s.setString(++index,tenantIdColumn);
            s.executeUpdate();
          }
           globalConnection.commit();
        }
 else {
          viewPTable=PhoenixRuntime.getTable(globalConnection,fullViewName);
          globalConnection.createStatement().execute(String.format(disableIndexDDL,indexName,fullViewName));
        }
        String indexPhysicalTableName=MetaDataUtil.getViewIndexPhysicalName(viewPTable.getPhysicalName().getString());
        if (physicalTables.add(indexPhysicalTableName)) {
          final TableName tableName=TableName.valueOf(indexPhysicalTableName);
          if (admin.tableExists(tableName)) {
            admin.disableTable(tableName);
            admin.truncateTable(tableName,false);
          }
        }
      }
    }
   }
   if (originalScn != null) {
    props.setProperty(PhoenixRuntime.CURRENT_SCN_ATTRIB,Long.toString(originalScn));
  }
  toReturn=new PhoenixConnection(globalConnection,globalConnection.getQueryServices(),props);
}
 catch (SQLException e) {
  sqlEx=e;
}
 finally {
  sqlEx=closeConnection(connParam,sqlEx);
  sqlEx=closeConnection(globalConnection,sqlEx);
  if (sqlEx != null) {
    throw sqlEx;
  }
}
",0,0,0,,
689,} finally {,"try {
  while (!shouldStop()) {
    isRunning.set(true);
    List rowValues=new ArrayList<String>();
synchronized (resultHandler) {
      for (      MonitorDetails monitorDetails : MONITOR_DETAILS_LIST) {
        rowValues.clear();
        try {
          StandardMBean bean=new StandardMBean(monitorDetails.getMonitor(),Monitor.class);
          Calendar calendar=new GregorianCalendar();
          rowValues.add(monitorDetails);
          rowValues.add(((Monitor)bean.getImplementation()).getStat());
          rowValues.add(DateUtil.DEFAULT_MS_DATE_FORMATTER.format(calendar.getTime()));
          Result result=new Result(ResultFileDetails.CSV,ResultFileDetails.CSV_MONITOR.getHeader().toString(),rowValues);
          resultHandler.write(result);
        }
 catch (        Exception e) {
          throw new FileLoaderRuntimeException(""Could not log monitor result."",e);
        }
        rowCount.getAndIncrement();
      }
      try {
        resultHandler.flush();
        Thread.sleep(getMonitorFrequency());
      }
 catch (      Exception e) {
        Thread.currentThread().interrupt();
        e.printStackTrace();
        throw e;
      }
    }
  }
}
  finally {
  try {
    isRunning.set(false);
    if (resultHandler != null) {
      resultHandler.close();
    }
  }
 catch (  Exception e) {
    throw new FileLoaderRuntimeException(""Could not close monitor results."",e);
  }
}
",0,0,0,,
690,} finally {,"try {
  connection=pUtil.getConnection(scenario.getTenantId());
  long logStartTime=EnvironmentEdgeManager.currentTimeMillis();
  long maxDuration=(WriteWorkload.this.writeParams == null) ? Long.MAX_VALUE : WriteWorkload.this.writeParams.getExecutionDurationInMs();
  int logPerNRows=PherfConstants.LOG_PER_NROWS;
  String customizedLogPerNRows=connection.getClientInfo().getProperty(PherfConstants.LOG_PER_NROWS_NAME);
  if (customizedLogPerNRows != null) {
    logPerNRows=Integer.valueOf(customizedLogPerNRows);
  }
  last=start=EnvironmentEdgeManager.currentTimeMillis();
  String sql=pUtil.buildSql(columns,tableName);
  stmt=connection.prepareStatement(sql);
  for (long i=rowCount; (i > 0) && ((EnvironmentEdgeManager.currentTimeMillis() - logStartTime) < maxDuration); i--) {
    stmt=pUtil.buildStatement(rulesApplier,scenario,columns,stmt,simpleDateFormat);
    if (useBatchApi) {
      stmt.addBatch();
    }
 else {
      rowsCreated+=stmt.executeUpdate();
    }
    if ((i % getBatchSize()) == 0) {
      if (useBatchApi) {
        int[] results=stmt.executeBatch();
        for (int x=0; x < results.length; x++) {
          int result=results[x];
          if (result < 1) {
            final String msg=""Failed to write update in batch (update count="" + result + "")"";
            throw new RuntimeException(msg);
          }
          rowsCreated+=result;
        }
      }
      connection.commit();
      duration=EnvironmentEdgeManager.currentTimeMillis() - last;
      LOGGER.info(""Writer ("" + Thread.currentThread().getName() + "") committed Batch. Total ""+ getBatchSize()+ "" rows for this thread (""+ this.hashCode()+ "") in (""+ duration+ "") Ms"");
      if (i % logPerNRows == 0 && i != 0) {
        dataLoadThreadTime.add(tableName,Thread.currentThread().getName(),i,EnvironmentEdgeManager.currentTimeMillis() - logStartTime);
      }
      logStartTime=EnvironmentEdgeManager.currentTimeMillis();
      Thread.sleep(threadSleepDuration);
      last=EnvironmentEdgeManager.currentTimeMillis();
    }
  }
}
 catch (SQLException e) {
  LOGGER.error(""Scenario "" + scenario.getName() + "" failed with exception "",e);
  throw e;
}
 finally {
  if (!useBatchApi && stmt != null) {
    stmt.close();
  }
  if (connection != null) {
    if (useBatchApi && stmt != null) {
      int[] results=stmt.executeBatch();
      for (int x=0; x < results.length; x++) {
        int result=results[x];
        if (result < 1) {
          final String msg=""Failed to write update in batch (update count="" + result + "")"";
          throw new RuntimeException(msg);
        }
        rowsCreated+=result;
      }
      stmt.close();
    }
    try {
      connection.commit();
      duration=EnvironmentEdgeManager.currentTimeMillis() - start;
      LOGGER.info(""Writer ( "" + Thread.currentThread().getName() + "") committed Final Batch. Duration (""+ duration+ "") Ms"");
      connection.close();
    }
 catch (    SQLException e) {
      e.printStackTrace();
    }
  }
}
",0,0,0,,
691,} finally {,"try {
  stmt=connection.prepareStatement(sql);
  for (long i=rowCount; i > 0; i--) {
    stmt=phoenixUtil.buildStatement(rulesApplier,scenario,upsert.getColumn(),stmt,simpleDateFormat);
    if (useBatchApi) {
      stmt.addBatch();
    }
 else {
      rowsCreated+=stmt.executeUpdate();
    }
  }
}
 catch (SQLException e) {
  throw e;
}
 finally {
  if (!useBatchApi && stmt != null) {
    stmt.close();
  }
  if (connection != null) {
    if (useBatchApi && stmt != null) {
      int[] results=stmt.executeBatch();
      for (int x=0; x < results.length; x++) {
        int result=results[x];
        if (result < 1) {
          final String msg=""Failed to write update in batch (update count="" + result + "")"";
          throw new RuntimeException(msg);
        }
        rowsCreated+=result;
      }
      stmt.close();
    }
    try {
      connection.commit();
      duration=EnvironmentEdgeManager.currentTimeMillis() - startTime;
      LOGGER.info(""Writer ( "" + Thread.currentThread().getName() + "") committed Final Batch. Duration (""+ duration+ "") Ms"");
      connection.close();
    }
 catch (    SQLException e) {
      LOGGER.error(""Error when closing/committing"",e);
    }
  }
}
",0,0,0,,
692,} finally {,"try {
  conn.commit();
  if (LOG.isInfoEnabled()) {
    LOG.info(""Written row : "" + numRecords);
  }
}
 catch (SQLException e) {
  LOG.error(""SQLException while performing the commit for the task."");
  throw new IOException(e);
}
 finally {
  try {
    if (restoreWalMode && PhoenixUtil.isDisabledWal(metaDataClient,tableName)) {
      try {
        PhoenixUtil.alterTableForWalDisable(conn,tableName,false);
      }
 catch (      ConcurrentTableMutationException e) {
        if (LOG.isWarnEnabled()) {
          LOG.warn(""Concurrent modification of disableWAL"");
        }
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(tableName + ""s wal enabled."");
      }
    }
    String autoFlushConfigName=tableName.toLowerCase() + PhoenixStorageHandlerConstants.AUTO_FLUSH;
    boolean autoFlush=config.getBoolean(autoFlushConfigName,false);
    if (autoFlush) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""autoFlush is "" + autoFlush);
      }
      PhoenixUtil.flush(conn,tableName);
    }
    PhoenixUtil.closeResource(pstmt);
    PhoenixUtil.closeResource(pstmtForDelete);
    PhoenixUtil.closeResource(conn);
  }
 catch (  SQLException ex) {
    LOG.error(""SQLException while closing the connection for the task."");
    throw new IOException(ex);
  }
}
",0,0,0,,
693,} finally {,"try {
  conn.commit();
  if (LOG.isInfoEnabled()) {
    LOG.info(""Wrote row : "" + numRecords);
  }
}
 catch (SQLException e) {
  LOG.error(""SQLException while performing the commit for the task."");
  throw new IOException(e);
}
 finally {
  try {
    if (restoreWalMode && PhoenixUtil.isDisabledWal(metaDataClient,tableName)) {
      try {
        PhoenixUtil.alterTableForWalDisable(conn,tableName,false);
      }
 catch (      ConcurrentTableMutationException e) {
        if (LOG.isWarnEnabled()) {
          LOG.warn(""Another mapper or task processing wal enable"");
        }
      }
      if (LOG.isDebugEnabled()) {
        LOG.debug(tableName + ""s wal enabled."");
      }
    }
    String autoFlushConfigName=tableName.toLowerCase() + PhoenixStorageHandlerConstants.AUTO_FLUSH;
    boolean autoFlush=config.getBoolean(autoFlushConfigName,false);
    if (autoFlush) {
      if (LOG.isDebugEnabled()) {
        LOG.debug(""autoFlush is true."");
      }
      PhoenixUtil.flush(conn,tableName);
    }
    PhoenixUtil.closeResource(pstmt);
    PhoenixUtil.closeResource(pstmtForDelete);
    PhoenixUtil.closeResource(conn);
  }
 catch (  SQLException ex) {
    LOG.error(""SQLException while closing the connection for the task."");
    throw new IOException(ex);
  }
}
",0,0,0,,
694,} finally {,"try {
  connection=ConnectionUtil.getInputConnection(this.configuration);
  final Statement statement=connection.createStatement();
  final PhoenixStatement pstmt=statement.unwrap(PhoenixStatement.class);
  final QueryPlan queryPlan=pstmt.compileQuery(selectStatement);
  isValidStatement(queryPlan);
  final String tableName=queryPlan.getTableRef().getTable().getName().getString();
  final List<? extends ColumnProjector> projectedColumns=queryPlan.getProjector().getColumnProjectors();
  final List<String> columns=Lists.transform(projectedColumns,new Function<ColumnProjector,String>(){
    @Override public String apply(    ColumnProjector column){
      return column.getName();
    }
  }
);
  final String columnsAsStr=Joiner.on("","").join(columns);
  return new Pair<String,String>(tableName,columnsAsStr);
}
 catch (SQLException e) {
  LOG.error(String.format("" Error [%s] parsing SELECT query [%s] "",e.getMessage(),selectStatement));
  throw new RuntimeException(e);
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException sqle) {
      LOG.error("" Error closing connection "");
      throw new RuntimeException(sqle);
    }
  }
}
",0,0,0,,
695,} finally {,"try {
  connection=ConnectionUtil.getInputConnection(this.configuration);
  final Statement statement=connection.createStatement();
  final PhoenixStatement pstmt=statement.unwrap(PhoenixStatement.class);
  final QueryPlan queryPlan=pstmt.compileQuery(sqlQuery);
  final List<? extends ColumnProjector> projectedColumns=queryPlan.getProjector().getColumnProjectors();
  columnInfos=Lists.newArrayListWithCapacity(projectedColumns.size());
  columnInfos=Lists.transform(projectedColumns,new Function<ColumnProjector,ColumnInfo>(){
    @Override public ColumnInfo apply(    final ColumnProjector columnProjector){
      return new ColumnInfo(columnProjector.getName(),columnProjector.getExpression().getDataType().getSqlType());
    }
  }
);
}
 catch (SQLException e) {
  LOG.error(String.format("" Error [%s] parsing SELECT query [%s] "",e.getMessage(),sqlQuery));
  throw new RuntimeException(e);
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException sqle) {
      LOG.error(""Error closing connection!!"");
      throw new RuntimeException(sqle);
    }
  }
}
",0,0,0,,
696,} finally {,"try {
  conn.commit();
}
 catch (SQLException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    statement.close();
    conn.close();
  }
 catch (  SQLException ex) {
    throw new RuntimeException(ex);
  }
}
",0,0,0,,
697,} finally {,"try {
  writer.write(message,this.encoder);
}
 catch (Exception e) {
  throw new SchemaSerializationException(e);
}
 finally {
  try {
    this.encoder.flush();
    outputBytes=this.byteArrayOutputStream.toByteArray();
  }
 catch (  Exception ex) {
    throw new SchemaSerializationException(ex);
  }
  this.byteArrayOutputStream.reset();
}
",0,0,0,,
698,} finally {,"try {
  loader=(URLClassLoader)ClassLoaderUtils.loadJar(jar);
  Class.forName(fqcn,false,loader);
  return true;
}
 catch (ClassNotFoundException|NoClassDefFoundError|IOException e) {
  return false;
}
 finally {
  if (loader != null) {
    try {
      loader.close();
    }
 catch (    IOException e) {
      throw new UncheckedIOException(e);
    }
  }
}
",0,0,0,,
699,} finally {,"try {
  loader=(URLClassLoader)ClassLoaderUtils.loadJar(jar);
  if (xface.isAssignableFrom(Class.forName(fqcn,false,loader))) {
    ret=true;
  }
}
 catch (ClassNotFoundException|NoClassDefFoundError|IOException e) {
  throw new RuntimeException(e);
}
 finally {
  if (loader != null) {
    try {
      loader.close();
    }
 catch (    IOException e) {
      throw new UncheckedIOException(e);
    }
  }
}
",0,0,0,,
700,finally,"try {
  if (environment.isValid()) {
    BDBUtils.runCleaner(environment);
  }
}
  finally {
  try {
    environment.close();
  }
 catch (  EnvironmentFailureException efe) {
    if (!environment.isValid()) {
      LOGGER.debug(""Environment became invalid on close, so ignore"",efe);
    }
 else {
      throw efe;
    }
  }
}
",0,0,0,,
701,finally,"try {
  if (transaction.isValid()) {
    transaction.abort();
  }
}
  finally {
  throw e;
}
",0,0,0,,
702,finally,"try {
  if (source.getState() != State.DELETED) {
    if (source instanceof AbstractConfiguredObject) {
      final AbstractConfiguredObject object=(AbstractConfiguredObject)source;
      object.logCreated(object.getActualAttributes(),Outcome.FAILURE);
      object.deleteNoChecks();
    }
 else     if (source instanceof AbstractConfiguredObjectProxy) {
      ((AbstractConfiguredObjectProxy)source).deleteNoChecks();
    }
 else {
      source.deleteAsync();
    }
  }
}
  finally {
  if (_unregister) {
    if (source instanceof AbstractConfiguredObject) {
      ((AbstractConfiguredObject)source).unregister(false);
    }
 else     if (source instanceof AbstractConfiguredObjectProxy) {
      ((AbstractConfiguredObjectProxy)source).unregister(false);
    }
  }
  throw exception;
}
",0,0,0,,
703,finally,"try {
  if (_current != null) {
    try {
      _current.close();
      _current=null;
    }
 catch (    IOException e) {
      ioException=e;
    }
  }
  for (  InputStream is : _inputStreams) {
    try {
      is.close();
    }
 catch (    IOException e) {
      if (ioException != null) {
        ioException=e;
      }
    }
  }
}
  finally {
  if (ioException != null) {
    throw ioException;
  }
}
",0,0,0,,
704,finally,"try {
  serverSocket=new ServerSocket();
  serverSocket.setReuseAddress(true);
  serverSocket.bind(socketAddress);
  return true;
}
 catch (IOException e) {
  return false;
}
 finally {
  if (serverSocket != null) {
    try {
      serverSocket.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Couldn't close port "" + port + "" that was created to check its availability"",e);
    }
  }
}
",0,0,0,,
705,finally,"try {
  exception(new ConnectionException(t));
}
  finally {
  if (t instanceof Error) {
    throw (Error)t;
  }
  if (t instanceof ServerScopedRuntimeException) {
    throw (ServerScopedRuntimeException)t;
  }
}
",0,0,0,,
706,finally,"try {
  connection=DriverManager.getConnection(getUrl());
}
 catch (SQLException e) {
  if (e.getSQLState().equalsIgnoreCase(""08006"")) {
  }
 else {
    throw new RuntimeException(e);
  }
}
 finally {
  if (connection != null) {
    try {
      connection.close();
    }
 catch (    SQLException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
707,finally,"try {
  connection.close();
}
  finally {
  throw sqlEx;
}
",0,0,0,,
708,finally,"try {
  connection.close();
}
  finally {
  throw sqlEx;
}
",0,0,0,,
709,finally,"try {
  connection.close();
}
  finally {
  throw sqlEx;
}
",0,0,0,,
710,finally,"try {
  connection.close();
}
  finally {
  throw sqlEx;
}
",0,0,0,,
711,finally,"try {
  in=url.openStream();
  FileUtils.copy(in,destinationFile);
}
 catch (IOException e) {
  throw new IllegalConfigurationException(""Cannot create file "" + destinationFile + "" by copying initial config from ""+ initialConfigLocation,e);
}
 finally {
  if (in != null) {
    try {
      in.close();
    }
 catch (    IOException e) {
      throw new IllegalConfigurationException(""Cannot close initial config input stream: "" + initialConfigLocation,e);
    }
  }
}
",0,0,0,,
712,finally,"try {
  producer=_commandSession.createProducer(clientQueue);
  Message message=JmsMessageAdaptor.commandToMessage(_commandSession,command);
  producer.send(message);
}
 catch (final JMSException e) {
  throw new DistributedTestException(e);
}
 finally {
  if (producer != null) {
    try {
      producer.close();
    }
 catch (    final JMSException e) {
      throw new DistributedTestException(e);
    }
  }
}
",0,0,0,,
713,finally,"try {
  reader=new BufferedReader(new FileReader(file));
  Properties props=new Properties();
  props.load(reader);
  final String chartStemName=getStemNameFrom(file);
  final ChartType chartType=ChartType.valueOf(Strings.expand(props.getProperty(CHART_TYPE_KEY),false,Strings.SYSTEM_RESOLVER));
  final String chartTitle=Strings.expand(props.getProperty(CHART_TITLE_KEY),false,Strings.SYSTEM_RESOLVER);
  final String chartSubtitle=Strings.expand(props.getProperty(CHART_SUBTITLE_KEY),false,Strings.SYSTEM_RESOLVER);
  final String chartDescription=Strings.expand(props.getProperty(CHART_DESCRIPTION_KEY),false,Strings.SYSTEM_RESOLVER);
  final String xAxisTitle=Strings.expand(props.getProperty(XAXIS_TITLE_KEY),false,Strings.SYSTEM_RESOLVER);
  final String yAxisTitle=Strings.expand(props.getProperty(YAXIS_TITLE_KEY),false,Strings.SYSTEM_RESOLVER);
  String yAxisLowerBoundStr=Strings.expand(props.getProperty(Y_AXIS_LOWER_BOUND_KEY),false,Strings.SYSTEM_RESOLVER);
  String yAxisUpperBoundStr=Strings.expand(props.getProperty(Y_AXIS_UPPER_BOUND_KEY),false,Strings.SYSTEM_RESOLVER);
  final Integer yAxisLowerBound=yAxisLowerBoundStr == null ? null : Integer.valueOf(yAxisLowerBoundStr);
  final Integer yAxisUpperBound=yAxisUpperBoundStr == null ? null : Integer.valueOf(yAxisUpperBoundStr);
  final List<SeriesDefinition> seriesDefinitions=createSeriesDefinitions(props);
  final ChartingDefinition chartDefinition=new ChartingDefinition(chartStemName,chartType,chartTitle,chartSubtitle,chartDescription,xAxisTitle,yAxisTitle,yAxisLowerBound,yAxisUpperBound,seriesDefinitions);
  return chartDefinition;
}
 catch (IOException e) {
  throw new ChartingException(""Unable to open file "" + file,e);
}
 finally {
  if (reader != null) {
    try {
      reader.close();
    }
 catch (    IOException e) {
      throw new ChartingException(e);
    }
  }
}
",0,0,0,,
714,finally,"try {
  String jdbcUrl=_jdbcUrlGenerator.getJdbcUrl(seriesDefinition);
  conn=DriverManager.getConnection(jdbcUrl);
  final String seriesStatement=seriesDefinition.getSeriesStatement();
  stmt=conn.createStatement();
  ResultSet results=stmt.executeQuery(seriesStatement);
  int columnCount=results.getMetaData().getColumnCount();
  _datasetHolder.beginSeries(seriesDefinition);
  while (results.next()) {
    Object[] row=new Object[columnCount];
    for (int i=0; i < row.length; i++) {
      row[i]=results.getObject(i + 1);
    }
    SeriesRow seriesRow=SeriesRow.createValidSeriesRow(_datasetHolder.getNumberOfDimensions(),row);
    _datasetHolder.addDataPointToSeries(seriesDefinition,seriesRow);
  }
  _datasetHolder.endSeries(seriesDefinition);
}
 catch (SQLException e) {
  throw new ChartingException(""Failed to create chart dataset"",e);
}
 finally {
  if (stmt != null) {
    try {
      stmt.close();
    }
 catch (    SQLException e) {
      throw new RuntimeException(""Failed to close statement"",e);
    }
  }
  if (conn != null) {
    try {
      conn.close();
    }
 catch (    SQLException e) {
      throw new RuntimeException(""Failed to close connection"",e);
    }
  }
}
",0,0,0,,
715,finally,"try {
  File pngFile=new File(_chartDirectory,chartDef.getChartStemName() + "".png"");
  pngOutputStream=new BufferedOutputStream(new FileOutputStream(pngFile));
  ChartUtilities.writeChartAsPNG(pngOutputStream,chart,600,400,true,0);
  pngOutputStream.close();
  _chartFilesToChartDef.put(pngFile,chartDef);
  LOGGER.info(""Written {} chart"",pngFile);
}
 catch (IOException e) {
  throw new ChartingException(""Failed to create chart"",e);
}
 finally {
  if (pngOutputStream != null) {
    try {
      pngOutputStream.close();
    }
 catch (    IOException e) {
      throw new ChartingException(""Failed to create chart"",e);
    }
  }
}
",0,0,0,,
716,finally,"try {
  serverSocket=new ServerSocket();
  serverSocket.setReuseAddress(true);
  serverSocket.bind(new InetSocketAddress(port));
  return true;
}
 catch (IOException e) {
  LOGGER.debug(""port "" + port + "" is not free"");
  return false;
}
 finally {
  if (serverSocket != null) {
    try {
      serverSocket.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Couldn't close port "" + port + "" that we created to check its availability"",e);
    }
  }
}
",0,0,0,,
717,finally,"try {
  closeServerSocket();
}
  finally {
  throw new RuntimeException(""Cannot start acceptor thread for TCPTunneler on port "" + _actualLocalPort,e);
}
",0,0,0,,
718,finally,"try {
  fos=new FileOutputStream(file);
  fos.write(content.getBytes(""UTF-8""));
  fos.flush();
}
 catch (Exception e) {
  throw new RuntimeException(""Cannot add the content into temp file "" + file.getAbsolutePath(),e);
}
 finally {
  if (fos != null) {
    try {
      fos.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Cannot close output stream into temp file "" + file.getAbsolutePath(),e);
    }
  }
}
",0,0,0,,
719,finally,"try {
  _driverThread.join(30000);
}
 catch (InterruptedException e) {
  Thread.currentThread().interrupt();
}
 finally {
  AssertionError ae=_firstAssertionError;
  if (ae != null) {
    String message=""Assertion failure during test run"";
    if (ae.getMessage() != null) {
      message+="": "" + ae.getMessage();
    }
    throw new AssertionError(message,_firstAssertionError);
  }
  Throwable throwable=getThrowable();
  if (throwable == null) {
synchronized (_handlersLock) {
      assertThat(_handlers,Matchers.empty());
    }
  }
 else {
    throw new RuntimeException(""TestPeer caught throwable during run"",throwable);
  }
}
",0,0,0,,
720,finally,"try {
  _underlyingConnection.close();
}
  finally {
  throw e;
}
",0,0,0,,
721,finally,"try {
  if (_current != null) {
    try {
      _current.close();
      _current=null;
    }
 catch (    IOException e) {
      ioException=e;
    }
  }
  for (  InputStream is : _inputStreams) {
    try {
      is.close();
    }
 catch (    IOException e) {
      if (ioException != null) {
        ioException=e;
      }
    }
  }
}
  finally {
  if (ioException != null) {
    throw ioException;
  }
}
",0,0,0,,
722,finally,"try {
  serverSocket=new ServerSocket();
  serverSocket.setReuseAddress(true);
  serverSocket.bind(new InetSocketAddress(port));
  return true;
}
 catch (IOException e) {
  _logger.debug(""port "" + port + "" is not free"");
  return false;
}
 finally {
  if (serverSocket != null) {
    try {
      serverSocket.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Couldn't close port "" + port + "" that we created to check its availability"",e);
    }
  }
}
",0,0,0,,
723,finally,"try {
  fos=new FileOutputStream(file);
  fos.write(content.getBytes(""UTF-8""));
  fos.flush();
}
 catch (Exception e) {
  throw new RuntimeException(""Cannot add the content into temp file "" + file.getAbsolutePath(),e);
}
 finally {
  if (fos != null) {
    try {
      fos.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Cannot close output stream into temp file "" + file.getAbsolutePath(),e);
    }
  }
}
",0,0,0,,
724,finally,"try {
  serverSocket=new ServerSocket();
  serverSocket.setReuseAddress(true);
  serverSocket.bind(new InetSocketAddress(port));
  return true;
}
 catch (IOException e) {
  _logger.debug(""port "" + port + "" is not free"");
  return false;
}
 finally {
  if (serverSocket != null) {
    try {
      serverSocket.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(""Couldn't close port "" + port + "" that we created to check its availability"",e);
    }
  }
}
",0,0,0,,
725,finally,"try {
  closeServerSocket();
}
  finally {
  throw new RuntimeException(""Cannot start acceptor thread for TCPTunneler on port "" + _actualLocalPort,e);
}
",0,0,0,,
726,} finally {,"try {
  if (logger.isDebugEnabled()) {
    logger.debug(""UGI="" + MiscUtil.getUGILoginUser() + "". Will write to HDFS file=""+ currentFileName);
  }
  out=MiscUtil.executePrivilegedAction(new PrivilegedExceptionAction<Writer>(){
    @Override public Writer run() throws Exception {
      Writer out=getORCFileWrite();
      orcFileUtil.log(out,events);
      return out;
    }
  }
);
}
 catch (Exception e) {
  orcLogWriter=null;
  logger.error(""Error while writing into ORC FileWriter"",e);
  throw e;
}
 finally {
  if (logger.isDebugEnabled()) {
    logger.debug(""Flushing HDFS audit in ORC Format. Event Size:"" + events.size());
  }
  if (out != null) {
    try {
      orcFileUtil.close(out);
      ret=true;
    }
 catch (    Exception e) {
      logger.error(""Error while closing the ORC FileWriter"",e);
      throw e;
    }
    orcLogWriter=null;
  }
}
",0,0,0,,
727,} finally {,"try {
  in=new FileInputStream(new File(keyStoreFileName));
  dbStore.engineLoadKeyStoreFile(in,keyStorePassword,keyPassword,masterKey,keyStoreType);
  dbStore.engineStore(null,masterKey);
}
  finally {
  if (in != null) {
    try {
      in.close();
    }
 catch (    Exception e) {
      throw new RuntimeException(""ERROR:  Unable to close file stream for ["" + keyStoreFileName + ""]"",e);
    }
  }
}
",0,0,0,,
728,} finally {,"try {
  out=new FileOutputStream(new File(keyStoreFileName));
  dbStore.engineLoadToKeyStoreFile(out,keyStorePassword,keyPassword,masterKey,keyStoreType);
}
  finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    Exception e) {
      throw new RuntimeException(""ERROR:  Unable to close file stream for ["" + keyStoreFileName + ""]"",e);
    }
  }
}
",0,0,0,,
729,} finally {,"try {
  Subject loginSubj=null;
  if (!StringUtils.isEmpty(lookupPrincipal) && !StringUtils.isEmpty(lookupKeytab)) {
    LOG.info(""Init Lookup Login: security enabled, using lookupPrincipal/lookupKeytab"");
    if (StringUtils.isEmpty(nameRules)) {
      nameRules=""DEFAULT"";
    }
    loginSubj=SecureClientLogin.loginUserFromKeytab(lookupPrincipal,lookupKeytab,nameRules);
  }
 else {
    subject=new Subject();
    LOG.debug(""executeUnderKerberos():user="" + userName + "",pass="");
    LOG.debug(""executeUnderKerberos():Creating config.."");
    MySecureClientLoginConfiguration loginConf=new MySecureClientLoginConfiguration(userName,password);
    LOG.debug(""executeUnderKerberos():Creating Context.."");
    loginContext=new LoginContext(""hadoop-keytab-kerberos"",subject,null,loginConf);
    LOG.debug(""executeUnderKerberos():Logging in.."");
    loginContext.login();
    LOG.info(""Init Login: using username/password"");
    loginSubj=loginContext.getSubject();
  }
  if (loginSubj != null) {
    ret=Subject.doAs(loginSubj,action);
  }
}
 catch (LoginException le) {
  String msgDesc=""executeUnderKerberos: Login failure using given"" + "" configuration parameters, username : `"" + userName + ""`."";
  HadoopException hdpException=new HadoopException(msgDesc,le);
  LOG.error(msgDesc,le);
  hdpException.generateResponseDataMap(false,BaseClient.getMessage(le),msgDesc + errMessage,null,null);
  throw hdpException;
}
catch (SecurityException se) {
  String msgDesc=""executeUnderKerberos: Exception while getting Storm TopologyList."";
  HadoopException hdpException=new HadoopException(msgDesc,se);
  LOG.error(msgDesc,se);
  hdpException.generateResponseDataMap(false,BaseClient.getMessage(se),msgDesc + errMessage,null,null);
  throw hdpException;
}
 finally {
  if (loginContext != null) {
    if (subject != null) {
      try {
        loginContext.logout();
      }
 catch (      LoginException e) {
        throw new IOException(""logout failure"",e);
      }
    }
  }
}
",0,0,0,,
730,} finally {,"try {
  if (userSBase == null || userSBase.isEmpty()) {
    if (bindDn.contains(""@"")) {
      userSBase=bindDn.substring(bindDn.indexOf(""@"") + 1);
      userSBase=""dc="".concat(userSBase);
      userSBase=userSBase.replaceAll(""\\."","",dc="");
    }
 else {
      userSBase=bindDn.substring(bindDn.indexOf("","") + 1);
    }
  }
  if (userSFilter == null || userSFilter.isEmpty()) {
    if (bindDn.contains(""@"")) {
      userSFilter=""userPrincipalName="" + bindDn;
    }
 else {
      int cnEndIndex=bindDn.indexOf("","");
      userSFilter=bindDn.substring(0,cnEndIndex);
    }
  }
  try {
    userSearchResultEnum=ldapContext.search(userSBase,userSFilter,userSearchControls);
    while (userSearchResultEnum.hasMore()) {
      if (noOfUsers >= 5) {
        break;
      }
      final SearchResult userEntry=userSearchResultEnum.next();
      if (userEntry == null) {
        logFile.println(""WARN: userEntry null"");
        continue;
      }
      Attributes attributes=userEntry.getAttributes();
      if (attributes == null) {
        logFile.println(""WARN: Attributes missing for entry "" + userEntry.getNameInNamespace());
        continue;
      }
      if (userNameAttribute == null || userNameAttribute.isEmpty()) {
        for (int i=0; i < userNameAttrValues.length; i++) {
          userNameAttr=attributes.get(userNameAttrValues[i]);
          if (userNameAttr != null) {
            userNameAttribute=userNameAttrValues[i];
            break;
          }
        }
        if (userNameAttr == null) {
          logFile.print(""WARN: Failed to find any of ( "");
          for (int i=0; i < userNameAttrValues.length; i++) {
            logFile.print(userNameAttrValues[i] + "" "");
          }
          logFile.println("") for entry "" + userEntry.getNameInNamespace());
          continue;
        }
      }
 else {
        userNameAttr=attributes.get(userNameAttribute);
        if (userNameAttr == null) {
          logFile.println(""WARN: Failed to find "" + userNameAttribute + "" for entry ""+ userEntry.getNameInNamespace());
          continue;
        }
      }
      String userName=(String)userNameAttr.get();
      if (userName == null || userName.trim().isEmpty()) {
        logFile.println(""WARN: "" + userNameAttribute + "" empty for entry ""+ userEntry.getNameInNamespace());
        continue;
      }
      userName=userName.toLowerCase();
      Attribute userObjClassAttr=attributes.get(""objectClass"");
      NamingEnumeration<?> userObjClassEnum=userObjClassAttr.getAll();
      String userObjClass=null;
      while (userObjClassEnum.hasMore()) {
        userObjClass=userObjClassEnum.next().toString();
        if (userObjClassName == null || userObjClassName.isEmpty()) {
          if (userObjClass != null) {
            for (int i=0; i < userObjClassValues.length; i++) {
              if (userObjClass.equalsIgnoreCase(userObjClassValues[i])) {
                userObjClassName=userObjClass;
                break;
              }
            }
          }
 else {
            logFile.println(""WARN: Failed to find objectClass attribute for "" + userName);
          }
        }
      }
      if (userObjClassName == null || userObjClassName.isEmpty()) {
        userObjClassName=userObjClass;
      }
      for (int i=0; i < userGroupMemAttrValues.length; i++) {
        groupMemberAttr=attributes.get(userGroupMemAttrValues[i]);
        if (groupMemberAttr != null) {
          userGroupMemberName=userGroupMemAttrValues[i];
          groupName=groupMemberAttr.get(0).toString();
          break;
        }
      }
      noOfUsers++;
    }
  }
 catch (  NamingException ne) {
    String msg=""Exception occured while discovering basic user properties:\n"" + ""ranger.usersync.ldap.user.nameattribute\n"" + ""ranger.usersync.ldap.user.objectclass\n""+ ""ranger.usersync.ldap.user.groupnameattribute\n"";
    if ((config.getUserSearchBase() != null && !config.getUserSearchBase().isEmpty()) || (config.getUserSearchFilter() != null && !config.getUserSearchFilter().isEmpty())) {
      throw new Exception(msg + ""Please verify values for ranger.usersync.ldap.user.searchbase and ranger.usersync.ldap.user.searchfilter"");
    }
 else {
      throw new Exception(msg + ne);
    }
  }
  if (isOutputNeeded) {
    installProps.println(""# Possible values for user search related properties:"");
    installProps.println(""SYNC_LDAP_USER_NAME_ATTRIBUTE="" + userNameAttribute);
    installProps.println(""SYNC_LDAP_USER_OBJECT_CLASS="" + userObjClassName);
    installProps.println(""SYNC_LDAP_USER_GROUP_NAME_ATTRIBUTE="" + userGroupMemberName);
    ambariProps.println(""# Possible values for user search related properties:"");
    ambariProps.println(""ranger.usersync.ldap.user.nameattribute="" + userNameAttribute);
    ambariProps.println(""ranger.usersync.ldap.user.objectclass="" + userObjClassName);
    ambariProps.println(""ranger.usersync.ldap.user.groupnameattribute="" + userGroupMemberName);
  }
}
  finally {
  try {
    if (userSearchResultEnum != null) {
      userSearchResultEnum.close();
    }
  }
 catch (  NamingException ne) {
    throw new Exception(""Exception occured while closing user search result: "" + ne);
  }
}
",0,0,0,,
731,} finally {,"try {
  FileObject configFile=rootDirectory.resolveFile(options[0]);
  reader=new InputStreamReader(configFile.getContent().getInputStream());
  delegate=new MyConfigurationFile(reader,options,cl);
}
 catch (FileSystemException ex) {
  throw new ConfigurationNotFoundException(options[0],ex);
}
 finally {
  if (reader != null) {
    try {
      reader.close();
    }
 catch (    IOException ex) {
      throw new ConfigurationException(Strings.ERROR_CLOSING_FILE,ex);
    }
  }
}
",0,0,0,,
732,} finally {,"try {
  configWriter=new FileWriter(configFile);
  configTemplate.merge(context,configWriter);
}
 catch (IOException e) {
  throw new MojoExecutionException(""Error creating config file at "" + configFile.getPath());
}
 finally {
  if (configWriter != null) {
    try {
      configWriter.close();
    }
 catch (    IOException e) {
      throw new MojoExecutionException(""Error creating config file at "" + configFile.getPath());
    }
  }
}
",0,0,0,,
733,} finally {,"try {
  manifestWriter=new FileWriter(manifestFile);
  manifestTemplate.merge(context,manifestWriter);
}
 catch (IOException e) {
  throw new MojoExecutionException(""Error creating manifest file at "" + manifestFile.getPath());
}
 finally {
  if (manifestWriter != null) {
    try {
      manifestWriter.close();
    }
 catch (    IOException e) {
      throw new MojoExecutionException(""Error creating manifest file at "" + manifestFile.getPath());
    }
  }
}
",0,0,0,,
734,finally,"try {
  server.start();
  parseInboundMessages();
}
 catch (IOException e) {
  throw new BuildException(""error receiving report from royaleunit"",e);
}
 finally {
  try {
    server.stop();
  }
 catch (  IOException e) {
    throw new BuildException(""could not close client/server socket"");
  }
}
",0,0,0,,
735,} finally {,"try {
  writer=connector.createBatchWriter(detailsTableName,new BatchWriterConfig());
  final byte[] bytes=serializer.serialize(details);
  final Mutation mutation=new Mutation(ROW_ID);
  mutation.put(COL_FAMILY,COL_QUALIFIER,new Value(bytes));
  writer.addMutation(mutation);
}
 catch (final TableNotFoundException|MutationsRejectedException e) {
  throw new RyaDetailsRepositoryException(""Could not initialize the Rya instance details for the instance named '"" + instanceName + ""'."",e);
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new RyaDetailsRepositoryException(""Could not initialize the Rya instance details for the instance named '"" + instanceName + ""'."",e);
    }
  }
}
",0,0,0,,
736,} finally {,"try {
  writer=accumuloConn.createBatchWriter(pcjTableName,new BatchWriterConfig());
  for (  final BindingSet result : results) {
    final Set<Mutation> addResultMutations=makeWriteResultMutations(metadata.getVarOrders(),result);
    writer.addMutations(addResultMutations);
  }
}
 catch (TableNotFoundException|MutationsRejectedException e) {
  throw new PcjException(""Could not add results to the PCJ table named: "" + pcjTableName,e);
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new PcjException(""Could not add results to a PCJ table because some of the mutations were rejected."",e);
    }
  }
}
",0,0,0,,
737,} finally {,"try {
  final List<Mutation> mutations=makeWriteMetadataMutations(metadata);
  writer=connector.createBatchWriter(mergeParentMetadataTableName,new BatchWriterConfig());
  writer.addMutations(mutations);
}
 catch (final AccumuloException|TableNotFoundException e) {
  throw new MergerException(""Unable to set MergeParentMetadata in Accumulo"",e);
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new MergerException(""Could not add results to a MergeParentMetadata table because some of the mutations were rejected."",e);
    }
  }
}
",0,0,0,,
738,} finally {,"try {
  final Text prefix=getRowPrefix(binId);
  deleter=accumuloConn.createBatchDeleter(tableName,auths,1,new BatchWriterConfig());
  deleter.setRanges(Collections.singleton(Range.prefix(prefix)));
  deleter.delete();
}
 catch (final Exception e) {
  throw new PeriodicQueryStorageException(e.getMessage());
}
 finally {
  try {
    if (deleter != null) {
      deleter.close();
    }
  }
 catch (  final Exception e) {
    throw new PeriodicQueryStorageException(e.getMessage());
  }
}
",0,0,0,,
739,} finally {,"try {
  writer=accumuloConn.createBatchWriter(pcjTableName,new BatchWriterConfig());
  for (  final VisibilityBindingSet result : results) {
    final Set<Mutation> addResultMutations=makeWriteResultMutations(metadata.getVarOrders(),result);
    writer.addMutations(addResultMutations);
  }
}
 catch (TableNotFoundException|MutationsRejectedException e) {
  throw new PCJStorageException(""Could not add results to the PCJ table named: "" + pcjTableName,e);
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new PCJStorageException(""Could not add results to a PCJ table because some of the mutations were rejected."",e);
    }
  }
}
",0,0,0,,
740,} finally {,"try {
  batchWriter=accumuloConn.createBatchWriter(pcjTableName,new BatchWriterConfig());
  final long cardinality=getPcjMetadata(accumuloConn,pcjTableName).getCardinality();
  final Mutation mutation=new Mutation(PCJ_METADATA_ROW_ID);
  final Value newCardinality=new Value(longLexicoder.encode(cardinality + delta));
  mutation.put(PCJ_METADATA_FAMILY,PCJ_METADATA_CARDINALITY,newCardinality);
  batchWriter.addMutation(mutation);
}
 catch (TableNotFoundException|MutationsRejectedException e) {
  throw new PCJStorageException(""Could not update the cardinality value of the PCJ Table named: "" + pcjTableName,e);
}
 finally {
  if (batchWriter != null) {
    try {
      batchWriter.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new PCJStorageException(""Could not update the cardinality value of the PCJ Table named: "" + pcjTableName,e);
    }
  }
}
",0,0,0,,
741,} finally {,"try {
  writer=accumuloConn.createBatchWriter(pcjTableName,new BatchWriterConfig());
  writer.addMutations(mutations);
  writer.flush();
}
 catch (final TableNotFoundException|MutationsRejectedException e) {
  throw new PCJStorageException(""Could not rewrite the PCJ cardinality for table named '"" + pcjTableName + ""'. This table will not work anymore."",e);
}
 finally {
  if (writer != null) {
    try {
      writer.close();
    }
 catch (    final MutationsRejectedException e) {
      throw new PCJStorageException(""Could not close the batch writer."",e);
    }
  }
}
",0,0,0,,
742,} finally {,"try {
  subjIter=queryDao(subj,OWL.SAMEAS,null,contxts);
  while (subjIter.hasNext()) {
    final Statement st=subjIter.next();
    if (!currentSameAs.contains(st.getObject())) {
      final Resource castedObj=(Resource)st.getObject();
      currentSameAs.add(castedObj);
      findSameAsChaining(castedObj,currentSameAs,contxts);
    }
  }
  objIter=queryDao(null,OWL.SAMEAS,subj,contxts);
  while (objIter.hasNext()) {
    final Statement st=objIter.next();
    if (!currentSameAs.contains(st.getSubject())) {
      final Resource sameAsSubj=st.getSubject();
      currentSameAs.add(sameAsSubj);
      findSameAsChaining(sameAsSubj,currentSameAs,contxts);
    }
  }
}
 catch (final QueryEvaluationException e) {
  throw new InferenceEngineException(e);
}
 finally {
  if (subjIter != null) {
    try {
      subjIter.close();
    }
 catch (    final QueryEvaluationException e) {
      throw new InferenceEngineException(""Error while closing \""same as chaining\"" statement subject iterator."",e);
    }
  }
  if (objIter != null) {
    try {
      objIter.close();
    }
 catch (    final QueryEvaluationException e) {
      throw new InferenceEngineException(""Error while closing \""same as chaining\"" statement object iterator."",e);
    }
  }
}
",0,0,0,,
743,} finally {,"try {
  iter=queryDao(subj,prop,obj,contxts);
  while (iter.hasNext()) {
    final Statement st=iter.next();
    sts.add(VF.createStatement((goUp) ? (st.getSubject()) : (Resource)(core),prop,(!goUp) ? (st.getObject()) : (core)));
    if (goUp) {
      chainTransitiveProperty(null,prop,st.getSubject(),core,sts,goUp,contxts);
    }
 else {
      chainTransitiveProperty((Resource)st.getObject(),prop,null,core,sts,goUp,contxts);
    }
  }
}
 catch (final QueryEvaluationException e) {
  throw new InferenceEngineException(e);
}
 finally {
  if (iter != null) {
    try {
      iter.close();
    }
 catch (    final QueryEvaluationException e) {
      throw new InferenceEngineException(""Error while closing \""chain transitive\"" property statement iterator."",e);
    }
  }
}
",0,0,0,,
744,} finally {,"try {
  oos=new ObjectOutputStream(bos);
  oos.writeObject(obj);
}
 catch (IOException e) {
  throw new SamzaException(""Error writing to output stream"",e);
}
 finally {
  try {
    if (oos != null) {
      oos.close();
    }
  }
 catch (  IOException e) {
    throw new SamzaException(""Error closing output stream"",e);
  }
}
",0,0,0,,
745,} finally {,"try {
  ois=new ObjectInputStream(bis);
  return (T)ois.readObject();
}
 catch (IOException|ClassNotFoundException e) {
  throw new SamzaException(""Error reading from input stream."",e);
}
 finally {
  try {
    if (ois != null) {
      ois.close();
    }
  }
 catch (  IOException e) {
    throw new SamzaException(""Error closing input stream"",e);
  }
}
",0,0,0,,
746,} finally {,"try {
  byteArrayOutputStream=new ByteArrayOutputStream(input.length);
  gzipOutputStream=new GZIPOutputStream(byteArrayOutputStream);
  gzipOutputStream.write(input);
  gzipOutputStream.close();
  return byteArrayOutputStream.toByteArray();
}
 catch (IOException e) {
  throw new SamzaException(""Failed to compress."",e);
}
 finally {
  try {
    if (gzipOutputStream != null) {
      gzipOutputStream.close();
    }
    if (byteArrayOutputStream != null) {
      byteArrayOutputStream.close();
    }
  }
 catch (  Exception e) {
    throw new SamzaException(""Failed to close output streams during compression."",e);
  }
}
",0,0,0,,
747,} finally {,"try {
  json=factory.createJsonGenerator(stringWriter);
  json.writeStartObject();
  json.writeStringField(Constants.LOG_FIELD_SERVICE_NAME,getServiceName());
  json.writeStringField(Constants.LOG_FIELD_USER_NAME,getUserName());
  json.writeStringField(Constants.LOG_FIELD_IMPERSONATOR,getImpersonator());
  json.writeStringField(Constants.LOG_FIELD_IP_ADDRESS,getIpAddress());
  json.writeStringField(Constants.LOG_FIELD_OPERATION,getOperation());
  json.writeStringField(Constants.LOG_FIELD_EVENT_TIME,getEventTime());
  json.writeStringField(Constants.LOG_FIELD_OPERATION_TEXT,getOperationText());
  json.writeStringField(Constants.LOG_FIELD_ALLOWED,getAllowed());
  json.writeStringField(Constants.LOG_FIELD_DATABASE_NAME,databaseName);
  json.writeStringField(Constants.LOG_FIELD_TABLE_NAME,tableName);
  json.writeStringField(Constants.LOG_FIELD_COLUMN_NAME,columnName);
  json.writeStringField(Constants.LOG_FIELD_RESOURCE_PATH,resourcePath);
  json.writeStringField(Constants.LOG_FIELD_OBJECT_TYPE,getObjectType());
  json.writeEndObject();
  json.flush();
}
 catch (IOException e) {
  String msg=""Error creating audit log in json format: "" + e.getMessage();
  LOGGER.error(msg,e);
  throw e;
}
 finally {
  try {
    if (json != null) {
      json.close();
    }
  }
 catch (  IOException e) {
    String msg=""Error when close json object: "" + e.getMessage();
    LOGGER.error(msg,e);
    throw e;
  }
}
",0,0,0,,
748,} finally {,"try {
  json=factory.createJsonGenerator(stringWriter);
  json.writeStartObject();
  json.writeStringField(Constants.LOG_FIELD_SERVICE_NAME,getServiceName());
  json.writeStringField(Constants.LOG_FIELD_USER_NAME,getUserName());
  json.writeStringField(Constants.LOG_FIELD_IMPERSONATOR,getImpersonator());
  json.writeStringField(Constants.LOG_FIELD_IP_ADDRESS,getIpAddress());
  json.writeStringField(Constants.LOG_FIELD_OPERATION,getOperation());
  json.writeStringField(Constants.LOG_FIELD_EVENT_TIME,getEventTime());
  json.writeStringField(Constants.LOG_FIELD_OPERATION_TEXT,getOperationText());
  json.writeStringField(Constants.LOG_FIELD_ALLOWED,getAllowed());
  for (  Map.Entry<String,String> entry : privilegesMap.entrySet()) {
    json.writeStringField(entry.getKey(),entry.getValue());
  }
  json.writeStringField(Constants.LOG_FIELD_OBJECT_TYPE,getObjectType());
  json.writeStringField(Constants.LOG_FIELD_COMPONENT,getComponent());
  json.writeEndObject();
  json.flush();
}
 catch (IOException e) {
  String msg=""Error creating audit log in json format: "" + e.getMessage();
  LOGGER.error(msg,e);
  throw e;
}
 finally {
  try {
    if (json != null) {
      json.close();
    }
  }
 catch (  IOException e) {
    String msg=""Error when close json object: "" + e.getMessage();
    LOGGER.error(msg,e);
    throw e;
  }
}
",0,0,0,,
749,} finally {,"try {
  name=marshaler.getOutputName(exchange,in);
  if (name == null) {
    newFile=File.createTempFile("""" + System.currentTimeMillis(),""tmp"",directory);
  }
 else {
    newFile=new File(directory,name);
    if (newFile.exists()) {
      if (isOverwrite()) {
        newFile.delete();
      }
 else       if (isAppend()) {
      }
 else {
        newFile=null;
        throw new IOException(""Can not write "" + name + "" : file already exists and overwrite has not been enabled"");
      }
    }
    writeTempName=marshaler.getTempOutputName(exchange,in) != null ? marshaler.getTempOutputName(exchange,in) : name;
    newFile=new File(directory,writeTempName);
  }
  if (!newFile.getParentFile().exists() && isAutoCreateDirectory()) {
    newFile.getParentFile().mkdirs();
  }
  logger.debug(""Writing to file: {}"",newFile.getCanonicalPath());
  out=new BufferedOutputStream(new FileOutputStream(newFile,append));
  marshaler.writeMessage(exchange,in,out,name);
  success=true;
}
  finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException e) {
      logger.error(""Caught exception while closing stream on error: {}"",e,e);
    }
  }
  if (success) {
    if (name != null && !name.equals(newFile.getName())) {
      if (isAppend()) {
        File targetFile=new File(directory,name);
        BufferedInputStream bis=new BufferedInputStream(new FileInputStream(newFile));
        out=new BufferedOutputStream(new FileOutputStream(targetFile,append));
        try {
          FileUtil.copyInputStream(bis,out);
        }
 catch (        IOException ioex) {
          logger.error(""Unable to append to file {}"",targetFile.getName(),ioex);
        }
 finally {
          try {
            out.close();
          }
 catch (          IOException e) {
            logger.error(""Caught exception while closing stream on error: {}"",e,e);
          }
          if (!newFile.delete()) {
            throw new IOException(""File "" + newFile.getName() + "" could not be deleted..."");
          }
        }
      }
 else {
        if (!newFile.renameTo(new File(directory,name))) {
          throw new IOException(""File "" + newFile.getName() + "" could not be renamed to ""+ name);
        }
      }
    }
  }
 else {
    if (newFile != null) {
      logger.error(""An error occured while writing file {}, deleting the invalid file"",newFile.getCanonicalPath());
      if (!newFile.delete()) {
        logger.warn(""Unable to delete file {} after an error had occured"",newFile.getCanonicalPath());
      }
    }
 else {
      logger.error(""An error occured while creating file or creating name of this file"");
    }
  }
}
",0,0,0,,
750,} finally {,"try {
  FileUtil.copyInputStream(bis,out);
}
 catch (IOException ioex) {
  logger.error(""Unable to append to file {}"",targetFile.getName(),ioex);
}
 finally {
  try {
    out.close();
  }
 catch (  IOException e) {
    logger.error(""Caught exception while closing stream on error: {}"",e,e);
  }
  if (!newFile.delete()) {
    throw new IOException(""File "" + newFile.getName() + "" could not be deleted..."");
  }
}
",0,0,0,,
751,} finally {,"try {
  client=borrowClient();
  if (uri != null && uri.getPath() != null) {
    if (!client.changeWorkingDirectory(uri.getPath())) {
      logger.warn(""Unable to change ftp directory to '{}'"",uri.getPath());
    }
  }
  name=marshaler.getOutputName(exchange,message);
  if (name == null) {
    if (uniqueFileName != null) {
      out=client.storeUniqueFileStream(uniqueFileName);
    }
 else {
      out=client.storeUniqueFileStream();
    }
  }
 else {
    if (checkDuplicates && client.listFiles(name).length > 0) {
      if (overwrite) {
        client.deleteFile(name);
      }
 else {
        throw new IOException(""Can not send "" + name + "" : file already exists and overwrite has not been enabled"");
      }
    }
    uploadName=marshaler.getTempOutputName(exchange,message) != null ? marshaler.getTempOutputName(exchange,message) : name;
    out=client.storeFileStream(uploadName);
  }
  if (out == null) {
    throw new IOException(""No output stream available for output name: "" + uploadName + "". Maybe the file already exists?"");
  }
  marshaler.writeMessage(exchange,message,out,uploadName);
}
  finally {
  if (out != null) {
    try {
      out.close();
      client.completePendingCommand();
      if (name != null && !name.equals(uploadName) && !client.rename(uploadName,name)) {
        throw new IOException(""File "" + uploadName + "" could not be renamed to ""+ name);
      }
    }
 catch (    IOException e) {
      logger.error(""Caught exception while closing stream on error: {}"",e.getMessage(),e);
    }
  }
  returnClient(client);
}
",0,0,0,,
752,finally {,"try {
  name=marshaler.getOutputName(exchange,in);
  if (name == null) {
    throw new MessagingException(""No output name available. Cannot output message!"");
  }
  tmpName=marshaler.getTempOutputName(exchange,in);
  file.close();
  if (tmpName != null) {
    tmpFile=tmpName != null ? file.resolveFile(tmpName) : null;
    tmpFile.close();
    content=tmpFile.getContent();
  }
 else {
    newFile=file.resolveFile(name);
    newFile.close();
    content=newFile.getContent();
  }
  content.close();
  if (content != null) {
    out=content.getOutputStream();
  }
  if (out == null) {
    throw new MessagingException(""No output stream available for output name: "" + name);
  }
  marshaler.writeMessage(exchange,in,out,name);
}
  finally {
  if (out != null) {
    try {
      out.close();
    }
 catch (    IOException e) {
      logger.error(""Caught exception while closing stream on error: {}"",e.getMessage(),e);
    }
  }
  if (tmpName != null && name != null && !name.equals(tmpName)) {
    if (!tmpFile.canRenameTo(newFile)) {
      throw new IOException(""File "" + tmpName + "" could not be renamed to ""+ name);
    }
 else {
      tmpFile.moveTo(newFile);
    }
  }
}
",0,0,0,,
753,} finally {,"try {
  DOMSource inMessageXml=(DOMSource)sourceTransformer.toDOMSource(msg.getContent());
  CachedXPathAPI xpath=new CachedXPathAPI();
  Node exampleNode=xpath.selectSingleNode(inMessageXml.getNode(),""/example"");
  if (exampleNode != null) {
    String value=exampleNode.getTextContent();
    logger.info(""Received content: {}"",value);
    propertySet.setString(""ExampleKey"",value);
  }
 else {
    throw new WorkflowException(""ExampleFunction: Missing tag: example"");
  }
}
 catch (Exception ex) {
  throw new WorkflowException(ex);
}
 finally {
  try {
    if (isAsynchron) {
      ep.done(exchange);
    }
  }
 catch (  MessagingException mex) {
    throw new WorkflowException(mex);
  }
}
",0,0,0,,
754,} finally {,"try {
  fis=new java.io.FileInputStream(f);
  users.load(fis);
}
 catch (IOException ioe) {
  throw new LoginException(""Unable to load user properties file "" + f);
}
 finally {
  if (fis != null) {
    try {
      fis.close();
      fis=null;
    }
 catch (    IOException e) {
      throw new LoginException(""Unable to close user properties file "" + f);
    }
  }
}
",0,0,0,,
755,} finally {,"try {
  fis=new java.io.FileInputStream(f);
  groups.load(fis);
}
 catch (IOException ioe) {
  throw new LoginException(""Unable to load group properties file "" + f);
}
 finally {
  if (fis != null) {
    try {
      fis.close();
      fis=null;
    }
 catch (    IOException e) {
      throw new LoginException(""Unable to close group properties file "" + f);
    }
  }
}
",0,0,0,,
756,} finally {,"try {
  fis=new java.io.FileInputStream(f);
  users.load(fis);
}
 catch (IOException ioe) {
  throw new LoginException(""Unable to load user properties file "" + f);
}
 finally {
  if (fis != null) {
    try {
      fis.close();
      fis=null;
    }
 catch (    IOException e) {
      throw new LoginException(""Unable to close user properties file "" + f);
    }
  }
}
",0,0,0,,
757,} finally {,"try {
  fis=new java.io.FileInputStream(f);
  groups.load(fis);
}
 catch (IOException ioe) {
  throw new LoginException(""Unable to load group properties file "" + f);
}
 finally {
  if (fis != null) {
    try {
      fis.close();
      fis=null;
    }
 catch (    IOException e) {
      throw new LoginException(""Unable to close group properties file "" + f);
    }
  }
}
",0,0,0,,
758,} finally {,"try {
  afterUnbound(s,o);
}
  finally {
  throw new IllegalStateException(e);
}
",0,0,0,,
759,} finally {,"try {
  int length=ois.readInt();
  for (int i=0; i < length; i++) {
    final String key=(String)ois.readObject();
    final Object value=ois.readObject();
    binaryProperties.put(key,value);
  }
}
 catch (final ClassNotFoundException cnfe) {
  throw new PersistenceException(""Class not found."",cnfe);
}
catch (final java.io.InvalidClassException ice) {
  throw new PersistenceException(""Invalid class."",ice);
}
catch (final IOException ioe) {
  throw new PersistenceException(""Unable to deserialize job properties."",ioe);
}
 finally {
  try {
    ois.close();
  }
 catch (  final IOException ioe) {
    throw new PersistenceException(""Unable to deserialize job properties."",ioe);
  }
}
",0,0,0,,
760,} finally {,"try {
  for (int avail=stream.available(); avail > 0; avail=stream.available()) {
    streamLength+=avail;
    stream.skip(avail);
  }
}
 catch (IOException e) {
  throw new ClientException(""Could not read "" + resourcePath + ""!"",e);
}
 finally {
  try {
    stream.close();
  }
 catch (  IOException e) {
    throw new ClientException(""Could not close Inputstream for "" + resourcePath + ""!"",e);
  }
}
",0,0,0,,
761,} finally {,"try {
  String copyCmd=getCopyCommand(tableName);
  commandFilename=writeCopyCommand(copyCmd);
  ArrayList<String> args=new ArrayList<String>();
  List<String> envp=Executor.getCurEnvpStrings();
  String connectString=options.getConnectString();
  String databaseName=JdbcUrl.getDatabaseName(connectString);
  String hostname=JdbcUrl.getHostName(connectString);
  int port=JdbcUrl.getPort(connectString);
  if (null == databaseName) {
    throw new ImportException(""Could not determine database name"");
  }
  LOG.info(""Performing import of table "" + tableName + "" from database ""+ databaseName);
  args.add(PSQL_CMD);
  args.add(""--tuples-only"");
  args.add(""--quiet"");
  String username=options.getUsername();
  if (username != null) {
    args.add(""--username"");
    args.add(username);
    String password=options.getPassword();
    if (null != password) {
      passwordFilename=PostgreSQLUtils.writePasswordFile(options.getTempDir(),password);
      envp.add(""PGPASSFILE="" + passwordFilename);
    }
  }
  args.add(""--host"");
  args.add(hostname);
  if (port != -1) {
    args.add(""--port"");
    args.add(Integer.toString(port));
  }
  if (null != databaseName && databaseName.length() > 0) {
    args.add(databaseName);
  }
  args.add(""-f"");
  args.add(commandFilename);
  LOG.debug(""Starting psql with arguments:"");
  for (  String arg : args) {
    LOG.debug(""  "" + arg);
  }
  SplittableBufferedWriter w=DirectImportUtils.createHdfsSink(options.getConf(),options,context);
  p=Runtime.getRuntime().exec(args.toArray(new String[0]),envp.toArray(new String[0]));
  InputStream is=p.getInputStream();
  sink=new PostgresqlAsyncSink(w,options,counters);
  LOG.debug(""Starting stream sink"");
  counters.startClock();
  sink.processStream(is);
  errSink=new LoggingAsyncSink(LOG);
  errSink.processStream(p.getErrorStream());
}
  finally {
  LOG.debug(""Waiting for process completion"");
  int result=0;
  if (null != p) {
    while (true) {
      try {
        result=p.waitFor();
      }
 catch (      InterruptedException ie) {
        continue;
      }
      break;
    }
  }
  if (null != passwordFilename) {
    if (!new File(passwordFilename).delete()) {
      LOG.error(""Could not remove postgresql password file "" + passwordFilename);
      LOG.error(""You should remove this file to protect your credentials."");
    }
  }
  if (null != commandFilename) {
    if (!new File(commandFilename).delete()) {
      LOG.info(""Could not remove temp file: "" + commandFilename);
    }
  }
  int streamResult=0;
  if (null != sink) {
    while (true) {
      try {
        streamResult=sink.join();
      }
 catch (      InterruptedException ie) {
        continue;
      }
      break;
    }
  }
  if (null != errSink) {
    try {
      if (0 != errSink.join()) {
        LOG.info(""Encountered exception reading stderr stream"");
      }
    }
 catch (    InterruptedException ie) {
      LOG.info(""Thread interrupted waiting for stderr to complete: "" + ie.toString());
    }
  }
  LOG.info(""Transfer loop complete."");
  if (0 != result) {
    throw new IOException(""psql terminated with status "" + Integer.toString(result));
  }
  if (0 != streamResult) {
    throw new IOException(""Encountered exception in stream sink"");
  }
  counters.stopClock();
  LOG.info(""Transferred "" + counters.toString());
}
",0,0,0,,
762,} finally {,"try {
  try {
    execUpdate(true,true);
    execThread.join();
  }
 catch (  SQLException sqle) {
    throw new IOException(sqle);
  }
  SQLException lastErr=execThread.getLastError();
  if (null != lastErr) {
    throw new IOException(lastErr);
  }
}
  finally {
  try {
    closeConnection(context);
  }
 catch (  SQLException sqle) {
    throw new IOException(sqle);
  }
}
",0,0,0,,
763,} finally {,"try {
  if (null != password && password.length() > 0) {
    passwordFile=MySQLUtils.writePasswordFile(conf);
    args.add(""--defaults-file="" + passwordFile);
  }
  String whereClause=conf.get(MySQLUtils.WHERE_CLAUSE_KEY,""(1=1)"") + "" AND ("" + splitConditions+ "")"";
  args.add(""-w"");
  args.add(whereClause);
  args.add(""--host="" + hostname);
  if (-1 != port) {
    args.add(""--port="" + Integer.toString(port));
  }
  args.add(""--skip-opt"");
  args.add(""--compact"");
  args.add(""--no-create-db"");
  args.add(""--no-create-info"");
  args.add(""--quick"");
  args.add(""--single-transaction"");
  String username=conf.get(MySQLUtils.USERNAME_KEY);
  if (null != username) {
    args.add(""--user="" + username);
  }
  String[] extra=conf.getStrings(MySQLUtils.EXTRA_ARGS_KEY);
  if (null != extra) {
    for (    String arg : extra) {
      args.add(arg);
    }
  }
  args.add(databaseName);
  args.add(tableName);
  LOG.debug(""Starting mysqldump with arguments:"");
  for (  String arg : args) {
    LOG.debug(""  "" + arg);
  }
  p=Runtime.getRuntime().exec(args.toArray(new String[0]));
  InputStream is=p.getInputStream();
  if (MySQLUtils.outputDelimsAreMySQL(conf)) {
    LOG.debug(""Output delimiters conform to mysqldump; "" + ""using straight copy"");
    sink=new CopyingAsyncSink(context,counters);
  }
 else {
    LOG.debug(""User-specified delimiters; using reparsing import"");
    LOG.info(""Converting data to use specified delimiters."");
    LOG.info(""(For the fastest possible import, use"");
    LOG.info(""--mysql-delimiters to specify the same field"");
    LOG.info(""delimiters as are used by mysqldump.)"");
    sink=new ReparsingAsyncSink(context,conf,counters);
  }
  counters.startClock();
  sink.processStream(is);
  errSink=new LoggingAsyncSink(LOG);
  errSink.processStream(p.getErrorStream());
}
  finally {
  int result=0;
  if (null != p) {
    while (true) {
      try {
        result=p.waitFor();
      }
 catch (      InterruptedException ie) {
        continue;
      }
      break;
    }
  }
  if (null != passwordFile) {
    if (!new File(passwordFile).delete()) {
      LOG.error(""Could not remove mysql password file "" + passwordFile);
      LOG.error(""You should remove this file to protect your credentials."");
    }
  }
  int streamResult=0;
  if (null != sink) {
    while (true) {
      try {
        streamResult=sink.join();
      }
 catch (      InterruptedException ie) {
        continue;
      }
      break;
    }
  }
  if (null != errSink) {
    try {
      if (0 != errSink.join()) {
        LOG.info(""Encountered exception reading stderr stream"");
      }
    }
 catch (    InterruptedException ie) {
      LOG.info(""Thread interrupted waiting for stderr to complete: "" + ie.toString());
    }
  }
  LOG.info(""Transfer loop complete."");
  if (0 != result) {
    throw new IOException(""mysqldump terminated with status "" + Integer.toString(result));
  }
  if (0 != streamResult) {
    throw new IOException(""Encountered exception in stream sink"");
  }
  counters.stopClock();
  LOG.info(""Transferred "" + counters.toString());
}
",0,0,0,,
764,} finally {,"try {
  while (context.nextKeyValue()) {
    if (jdbcFailed.get()) {
      break;
    }
    map(context.getCurrentKey(),context.getCurrentValue(),context);
  }
  cleanup(context);
}
  finally {
  try {
    recordWriter.close();
    extTableThread.join();
  }
 catch (  Exception e) {
    LOG.debug(""Exception cleaning up mapper operation : "" + e.getMessage());
  }
  counter.stopClock();
  LOG.info(""Transferred "" + counter.toString());
  FileUploader.uploadFilesToDFS(taskAttemptDir.getAbsolutePath(),localLogDir,logDir,context.getJobID().toString(),conf);
  if (extTableThread.hasExceptions()) {
    extTableThread.printException();
    throw new IOException(extTableThread.getException());
  }
}
",0,0,0,,
765,} finally {,"try {
  String inputRecord=recordReader.readLine();
  while (inputRecord != null) {
    if (jdbcFailed.get()) {
      break;
    }
    outputRecord.set(inputRecord + rd);
    writeRecord(outputRecord,context);
    counter.addBytes(1 + inputRecord.length());
    inputRecord=recordReader.readLine();
  }
}
  finally {
  recordReader.close();
  extTableThread.join();
  counter.stopClock();
  LOG.info(""Transferred "" + counter.toString());
  if (extTableThread.hasExceptions()) {
    extTableThread.printException();
    throw new IOException(extTableThread.getException());
  }
}
",0,0,0,,
766,} finally {,"try {
  if (thread != null) {
    thread.join();
  }
}
  finally {
  if (null != process) {
    while (true) {
      try {
        int returnValue=process.waitFor();
        if (returnValue != 0) {
          throw new RuntimeException(""Unexpected return value from pg_bulkload: "" + returnValue);
        }
      }
 catch (      InterruptedException ie) {
        LOG.debug(""Caught interrupted exception waiting for process "" + ""pg_bulkload.bin to exit"");
        Thread.interrupted();
        continue;
      }
      break;
    }
  }
}
",0,0,0,,
767,} finally {,"try {
  threads=startThreads(100,locksDir);
  for (  DirLockingThread thd : threads) {
    thd.join(30_000);
    Assert.assertTrue(thd.getName() + "" did not exit cleanly"",thd.cleanExit);
  }
  Path lockFile=new Path(locksDir + Path.SEPARATOR + DirLock.DIR_LOCK_FILE);
  Assert.assertFalse(fs.exists(lockFile));
}
  finally {
  if (threads != null) {
    for (    DirLockingThread thread : threads) {
      thread.interrupt();
      thread.join(30_000);
      if (thread.isAlive()) {
        throw new RuntimeException(""Failed to stop threads within 30 seconds, threads may leak into other tests"");
      }
    }
  }
}
",0,0,0,,
768,} finally {,"try {
  threads=startThreads(100,file1,locksDir);
  for (  FileLockingThread thd : threads) {
    thd.join(30_000);
    Assert.assertTrue(thd.getName() + "" did not exit cleanly"",thd.cleanExit);
  }
  Path lockFile=new Path(locksDir + Path.SEPARATOR + file1.getName());
  Assert.assertFalse(fs.exists(lockFile));
}
  finally {
  if (threads != null) {
    for (    FileLockingThread thread : threads) {
      thread.interrupt();
      thread.join(30_000);
      if (thread.isAlive()) {
        throw new RuntimeException(""Failed to stop threads within 30 seconds, threads may leak into other tests"");
      }
    }
  }
}
",0,0,0,,
769,} finally {,"try {
  threads=startThreads(10,file);
  int successCount=0;
  for (  FileDeletionThread thd : threads) {
    thd.join(30_000);
    if (thd.succeeded) {
      successCount++;
    }
    if (thd.exception != null) {
      Assert.assertNotNull(thd.exception);
    }
  }
  System.err.println(successCount);
  Assert.assertEquals(1,successCount);
}
  finally {
  if (threads != null) {
    for (    FileDeletionThread thread : threads) {
      thread.interrupt();
      thread.join(30_000);
      if (thread.isAlive()) {
        throw new RuntimeException(""Failed to stop threads within 30 seconds, threads may leak into other tests"");
      }
    }
  }
}
",0,0,0,,
770,} finally {,"try {
  in=getConfigFileInputStream(name);
  if (null != in) {
    Yaml yaml=new Yaml(new SafeConstructor());
    @SuppressWarnings(""unchecked"") Map<String,Object> ret=(Map<String,Object>)yaml.load(new InputStreamReader(in));
    if (null != ret) {
      return new HashMap<>(ret);
    }
 else {
      confFileEmpty=true;
    }
  }
  if (mustExist) {
    if (confFileEmpty) {
      throw new RuntimeException(""Config file "" + name + "" doesn't have any valid storm configs"");
    }
 else {
      throw new RuntimeException(""Could not find config file on classpath "" + name);
    }
  }
 else {
    return new HashMap<>();
  }
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  if (null != in) {
    try {
      in.close();
    }
 catch (    IOException e) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
771,finally {,"try {
  super.start();
}
  finally {
  boolean overallError=false;
  if (_buildMessages != null) {
    Iterator i=_buildMessages.keySet().iterator();
    while (i.hasNext()) {
      String sourceFile=(String)i.next();
      List messages=(List)_buildMessages.get(sourceFile);
      int errorCount=0;
      int warningCount=0;
      for (Iterator j=messages.iterator(); j.hasNext(); ) {
        BuildMessage message=(BuildMessage)j.next();
        System.err.println();
        System.err.print(sourceFile);
        System.err.print("": "");
        if (message.getLine() > 0) {
          String[] args={new Integer(message.getLine()).toString()};
          System.err.println(XDocletCompilerUtils.getMessage(""compiler.line"",args));
        }
        if (message.isError()) {
          overallError=true;
          ++errorCount;
        }
 else {
          System.err.print(XDocletCompilerUtils.getMessage(""compiler.warning"",null));
          ++warningCount;
        }
        System.err.println(message.getMessage());
      }
      System.err.println(XDocletCompilerUtils.getMessage(""compiler.build.results"",new String[]{new Integer(errorCount).toString(),new Integer(warningCount).toString(),sourceFile}));
    }
  }
  _buildMessages=null;
  if (overallError) {
    System.err.println(XDocletCompilerUtils.getMessage(""compiler.build.failed"",null));
    throw new PageFlowDocletBuildException();
  }
}
",0,0,0,,
772,} finally {,"try {
  digester.parse(input);
}
 catch (IOException e) {
  log.error(err,e);
  throw new ServletException(e);
}
catch (SAXException e) {
  log.error(err,e);
  throw new ServletException(e);
}
 finally {
  try {
    input.close();
  }
 catch (  IOException e) {
    log.error(err,e);
    throw new ServletException(e);
  }
}
",0,0,0,,
773,} finally {,"try {
  digester.parse(input);
}
 catch (IOException e) {
  log.error(internal.getMessage(""configWebXml""),e);
  throw new ServletException(e);
}
catch (SAXException e) {
  log.error(internal.getMessage(""configWebXml""),e);
  throw new ServletException(e);
}
 finally {
  try {
    input.close();
  }
 catch (  IOException e) {
    log.error(internal.getMessage(""configWebXml""),e);
    throw new ServletException(e);
  }
}
",0,0,0,,
774,} finally {,"try {
  _server.push(call.getWorkerID(),call.getData());
  response=new PSRpcResponse(Type.SUCCESS_EMPTY);
}
 catch (DMLRuntimeException exception) {
  response=new PSRpcResponse(Type.ERROR,ExceptionUtils.getFullStackTrace(exception));
}
 finally {
  try {
    callback.onSuccess(response.serialize());
  }
 catch (  IOException e) {
    throw new DMLRuntimeException(""PSRpcHandler: some error occrred when wrapping the rpc response."",e);
  }
}
",0,0,0,,
775,} finally {,"try {
  data=_server.pull(call.getWorkerID());
  response=new PSRpcResponse(Type.SUCCESS,data);
}
 catch (DMLRuntimeException exception) {
  response=new PSRpcResponse(Type.ERROR,ExceptionUtils.getFullStackTrace(exception));
}
 finally {
  try {
    callback.onSuccess(response.serialize());
  }
 catch (  IOException e) {
    throw new DMLRuntimeException(""PSRpcHandler: some error occrred when wrapping the rpc response."",e);
  }
}
",0,0,0,,
776,finally {,"try {
  while (HDFSTool.existsFileOnHDFS(randFName)) {
    randFName=fname + ""_"" + rand.nextLong()+ ""_""+ rand.nextLong();
  }
  rdd.saveAsTextFile(randFName);
  HDFSTool.mergeIntoSingleFile(randFName,fname);
}
 catch (IOException e) {
  throw new DMLRuntimeException(""Cannot merge the output into single file: "" + e.getMessage());
}
 finally {
  try {
    HDFSTool.deleteFileIfExistOnHDFS(randFName);
  }
 catch (  IOException e) {
    throw new DMLRuntimeException(""Cannot merge the output into single file: "" + e.getMessage());
  }
}
",0,0,0,,
777,finally {,"try {
  getAndLoadTestConfiguration(SqlTest.TEST_NAME);
  String HOME=SCRIPT_DIR + TEST_DIR;
  fullDMLScriptName=HOME + SqlTest.TEST_NAME + "".dml"";
  programArgs=new String[]{""-explain"",""-args"",DB_CONNECTION,_query};
  Statement st=db.createStatement();
  st.execute(""CREATE TABLE test(id INTEGER PRIMARY KEY, name VARCHAR(256), value DECIMAL(10,2))"");
  StringBuilder sb=new StringBuilder(""INSERT INTO test VALUES "");
  for (int i=0; i < DB_SIZE; i++) {
    char letter=(char)('a' + (i % ('z' - 'a' + 1)));
    sb.append(""("").append(i).append("",'"").append(letter).append(""',"").append(i).append(""),"");
  }
  sb.setLength(sb.length() - 1);
  st.execute(sb.toString());
  runTest(true,false,null,-1);
}
 catch (SQLException e) {
  throw new RuntimeException(e);
}
 finally {
  rtplatform=platformOld;
  DMLScript.USE_LOCAL_SPARK_CONFIG=sparkConfigOld;
  try {
    DriverManager.getConnection(DB_CONNECTION + "";drop=true"");
  }
 catch (  SQLException e) {
    if (!e.getSQLState().equals(DB_DROP_SUCCESS)) {
      throw new RuntimeException(e);
    }
  }
}
",0,0,0,,
778,} finally {,"try {
  FileUtils.deleteDirectory(testInput.toFile());
}
 catch (IOException e) {
  throw new RuntimeException(e);
}
 finally {
  try {
    Files.deleteIfExists(testFile);
  }
 catch (  IOException e) {
    throw new RuntimeException(e);
  }
}
",0,0,0,,
779,} finally {,"try {
  parse(fileResource.getResourceId(),parser,is,handler,containerMetadata,context);
}
 catch (Throwable t) {
  thrown=t;
}
 finally {
  try {
    writer.close();
  }
 catch (  IOException e) {
    LOG.error(""{}"",getXMLifiedLogMsg(IO_OS + ""json"",fileResource.getResourceId(),e));
    throw new RuntimeException(e);
  }
 finally {
    IOUtils.closeQuietly(is);
  }
}
",0,0,0,,
780,} finally {,"try {
  sendStdErrToOutputStream(process,stdErrOutputStream);
  if (inputToStdIn) {
    sendInputStreamToStdIn(inputStream,process);
  }
 else {
    process.getOutputStream().close();
  }
  if (outputFromStdOut) {
    sendStdOutToOutputStream(process,outputStream);
  }
 else {
    tmp.dispose();
    try {
      process.waitFor();
    }
 catch (    InterruptedException ignore) {
    }
    InputStream tempOutputFileInputStream=TikaInputStream.get(tempOutputFile);
    IOUtils.copy(tempOutputFileInputStream,outputStream);
  }
}
  finally {
  if (outputFromStdOut) {
    try {
      process.waitFor();
    }
 catch (    InterruptedException ignore) {
    }
  }
 else {
    try {
      tempOutputFile.delete();
    }
 catch (    Exception e) {
    }
  }
  if (!inputToStdIn) {
    IOUtils.closeQuietly(tikaInputStream);
  }
  IOUtils.closeQuietly(outputStream);
  IOUtils.closeQuietly(stdErrOutputStream);
  if (process.exitValue() != 0) {
    throw new TikaException(""There was an error executing the command line"" + ""\nExecutable Command:\n\n"" + cmd + ""\nExecutable Error:\n\n""+ stdErrOutputStream.toString(UTF_8.name()));
  }
}
",0,0,0,,
781,} finally {,"try {
  XMLReaderUtils.parseSAX(stream,new TeeContentHandler(tagged,new MetaHandler(metadata)),context);
}
 catch (SAXException e) {
  tagged.throwIfCauseOf(e);
  throw new TikaException(""Invalid network parser output"",e);
}
catch (IOException e) {
  throw new TikaException(""Unable to read network parser output"",e);
}
 finally {
  try {
    thread.join(1000);
  }
 catch (  InterruptedException e) {
    throw new TikaException(""Network parser interrupted"",e);
  }
  if (exception != null) {
    input.throwIfCauseOf(exception);
    throw new TikaException(""Unexpected network parser error"",exception);
  }
}
",0,0,0,,
782,} finally {,"try {
  for (  DigestingParser.Digester digester : digesters) {
    digester.digest(tis,m,parseContext);
  }
}
  finally {
  try {
    tmp.dispose();
  }
 catch (  TikaException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
783,} finally {,"try {
  TikaInputStream tmpTikaInputStream=TikaInputStream.get(is,tmp);
  digestFile(tmpTikaInputStream.getFile(),metadata);
}
  finally {
  try {
    tmp.dispose();
  }
 catch (  TikaException e) {
    throw new IOException(e);
  }
}
",0,0,0,,
784,} finally {,"try (InputStream is=Files.newInputStream(xmlLogFile)){
  reader.read(is,new ErrorMsgUpdater(tableInfo.getName()));
}
 catch (IOException e) {
  throw new RuntimeException(""Problem reading: "" + xmlLogFile.toAbsolutePath().toString());
}
 finally {
  try {
    connection.commit();
    statement.close();
  }
 catch (  SQLException e) {
    throw new RuntimeException(""Failed to close db connection!"",e);
  }
}
",0,0,0,,
785,} finally {,"try {
  lastModifiedDates.put(resource.getLocalePath(),resource.getLastModified());
  stream=resource.getInputStream();
  defsMap=reader.read(stream);
}
 catch (FileNotFoundException e) {
  if (log.isDebugEnabled()) {
    log.debug(""File "" + resource.toString() + "" not found, continue"");
  }
}
catch (IOException e) {
  throw new DefinitionsFactoryException(""I/O error processing configuration."",e);
}
 finally {
  try {
    if (stream != null) {
      stream.close();
    }
  }
 catch (  IOException e) {
    throw new DefinitionsFactoryException(""I/O error closing "" + resource.toString(),e);
  }
}
",0,0,0,,
786,} finally {,"try {
  k=KRYOS.take();
  return k.readClassAndObject(new Input(inputStream));
}
 catch (final InterruptedException e) {
  throw new IllegalStateException(e);
}
 finally {
  try {
    KRYOS.put(k);
  }
 catch (  final InterruptedException e) {
    throw new IllegalStateException(e);
  }
}
",0,0,0,,
787,} finally {,"try {
  k=KRYOS.take();
  final Output kryoOutput=new Output(outputStream);
  k.writeClassAndObject(kryoOutput,object);
  kryoOutput.flush();
}
 catch (final InterruptedException e) {
  throw new IllegalStateException(e);
}
 finally {
  try {
    KRYOS.put(k);
  }
 catch (  final InterruptedException e) {
    throw new IllegalStateException(e);
  }
}
",0,0,0,,
788,} finally {,"try {
  if (!parser.readFrame(false)) {
    break;
  }
}
 catch (StreamException se) {
  Stream stream=getStream(se.getStreamId(),false);
  if (stream == null) {
    sendStreamReset(se);
  }
 else {
    stream.close(se);
  }
}
 finally {
  if (overheadCount.get() > 0) {
    throw new ConnectionException(sm.getString(""upgradeHandler.tooMuchOverhead"",connectionId),Http2Error.ENHANCE_YOUR_CALM);
  }
}
",0,0,0,,
789,} finally {,"try {
  if (connection != null) {
    connection.removeTrace(this);
    connection=null;
  }
  final List<AbandonedTrace> resultSetList=getTrace();
  if (resultSetList != null) {
    final ResultSet[] resultSets=resultSetList.toArray(Utils.EMPTY_RESULT_SET_ARRAY);
    for (    final ResultSet resultSet : resultSets) {
      if (resultSet != null) {
        try {
          resultSet.close();
        }
 catch (        final Exception e) {
          if (connection != null) {
            connection.handleExceptionNoThrow(e);
          }
          thrownList.add(e);
        }
      }
    }
    clearTrace();
  }
  if (statement != null) {
    try {
      statement.close();
    }
 catch (    final Exception e) {
      if (connection != null) {
        connection.handleExceptionNoThrow(e);
      }
      thrownList.add(e);
    }
  }
}
  finally {
  closed=true;
  statement=null;
  if (!thrownList.isEmpty()) {
    throw new SQLExceptionList(thrownList);
  }
}
",0,0,0,,
790,} finally {,"try {
  ps=conn.prepareStatement(sqlStatement);
  setParameters(ps,parameters);
  rs=ps.executeQuery();
  result=new ResultImpl(rs,startRow,maxRows);
}
 catch (Throwable e) {
  queryError=e;
}
 finally {
  SQLException rsCloseExc=null;
  SQLException psCloseExc=null;
  if (rs != null) {
    try {
      rs.close();
    }
 catch (    SQLException sqe) {
      rsCloseExc=sqe;
    }
  }
  if (ps != null) {
    try {
      ps.close();
    }
 catch (    SQLException sqe) {
      psCloseExc=sqe;
    }
  }
  if (queryError != null) {
    throw new JspException(sqlStatement + "": "" + queryError.getMessage(),queryError);
  }
 else   if (rsCloseExc != null) {
    throw new JspException(rsCloseExc.getMessage(),rsCloseExc);
  }
 else   if (psCloseExc != null) {
    throw new JspException(psCloseExc.getMessage(),psCloseExc);
  }
}
",0,0,0,,
791,} finally {,"try {
  writeData(data);
  messageTransfered=true;
}
 catch (java.io.IOException x) {
  if (data.getResend() == ClusterMessage.FLAG_ALLOWED || (data.getResend() == ClusterMessage.FLAG_DEFAULT && isResend())) {
    dataResendCounter++;
    if (log.isTraceEnabled())     log.trace(sm.getString(""IDataSender.send.again"",address.getHostAddress(),new Integer(port)),x);
synchronized (this) {
      closeSocket();
      openSocket();
    }
    try {
      writeData(data);
      messageTransfered=true;
    }
 catch (    IOException xx) {
      exception=xx;
      throw xx;
    }
  }
 else {
synchronized (this) {
      closeSocket();
    }
    exception=x;
    throw x;
  }
}
 finally {
  this.keepAliveCount++;
  checkKeepAlive();
  if (doProcessingStats) {
    addProcessingStats(time);
  }
  if (messageTransfered) {
    addStats(data.getMessage().length);
    if (log.isTraceEnabled()) {
      log.trace(sm.getString(""IDataSender.send.message"",address.getHostAddress(),new Integer(port),data.getUniqueId(),new Long(data.getMessage().length)));
    }
  }
 else {
    dataFailureCounter++;
    throw exception;
  }
}
",0,0,0,,
792,} finally {,"try {
  pushMessage(data,false,waitForAck);
  messageTransfered=true;
}
 catch (IOException x) {
  SenderState.getSenderState(getDestination()).setSuspect();
  exception=x;
  if (log.isTraceEnabled())   log.trace(sm.getString(""IDataSender.send.again"",getAddress().getHostAddress(),new Integer(getPort())),x);
  while (getAttempt() < getMaxRetryAttempts()) {
    try {
      setAttempt(getAttempt() + 1);
      pushMessage(data,true,waitForAck);
      messageTransfered=true;
      exception=null;
    }
 catch (    IOException xx) {
      exception=xx;
      closeSocket();
    }
  }
}
 finally {
  setRequestCount(getRequestCount() + 1);
  keepalive();
  if (messageTransfered) {
  }
 else {
    if (exception != null)     throw exception;
  }
}
",0,0,0,,
793,} finally {,"try {
  storeXMLHead(writer);
  super.store(writer,-2,aContext);
}
  finally {
  try {
    writer.flush();
  }
 catch (  Exception e) {
    log.error(e);
  }
  try {
    writer.close();
  }
 catch (  Exception e) {
    throw (e);
  }
}
",0,0,0,,
794,} finally {,"try {
  store(writer,-2,aServer);
}
  finally {
  try {
    writer.flush();
  }
 catch (  Exception e) {
    log.error(e);
  }
  try {
    writer.close();
  }
 catch (  Exception e) {
    throw (e);
  }
}
",0,0,0,,
795,} finally {,"try {
  storeXMLHead(writer);
  super.store(writer,-2,aContext);
}
  finally {
  try {
    writer.flush();
  }
 catch (  Exception e) {
    log.error(e);
  }
  try {
    writer.close();
  }
 catch (  Exception e) {
    throw (e);
  }
}
",0,0,0,,
796,} finally {,"try {
  store(writer,-2,aServer);
}
  finally {
  try {
    writer.flush();
  }
 catch (  Exception e) {
    log.error(e);
  }
  try {
    writer.close();
  }
 catch (  Exception e) {
    throw (e);
  }
}
",0,0,0,,
797,} finally {,"try {
  pushMessage(data,false,waitForAck);
}
 catch (IOException x) {
  SenderState.getSenderState(getDestination()).setSuspect();
  exception=x;
  if (log.isTraceEnabled())   log.trace(sm.getString(""bioSender.send.again"",getAddress().getHostAddress(),Integer.valueOf(getPort())),x);
  while (getAttempt() < getMaxRetryAttempts()) {
    try {
      setAttempt(getAttempt() + 1);
      pushMessage(data,true,waitForAck);
      exception=null;
    }
 catch (    IOException xx) {
      exception=xx;
      closeSocket();
    }
  }
}
 finally {
  setRequestCount(getRequestCount() + 1);
  keepalive();
  if (exception != null)   throw exception;
}
",0,0,0,,
798,} finally {,"try {
  ctx=new InitialContext();
  testHome=(FinderTestHome)ctx.lookup(""java:comp/env/ejb/FinderTest"");
  resp.getWriter().println(testHome.create().runTest());
  resp.getWriter().flush();
}
 catch (final Exception e) {
  throw new ServletException(e);
}
 finally {
  try {
    if (ctx != null) {
      ctx.close();
    }
  }
 catch (  final Exception e) {
    throw new ServletException(e);
  }
}
",0,0,0,,
799,} finally {,"try {
  ctx=new InitialContext();
  testHome=(FinderTestHome)ctx.lookup(""java:comp/env/ejb/FinderTest"");
  resp.getWriter().println(testHome.create().runTest());
  resp.getWriter().flush();
}
 catch (final Exception e) {
  throw new ServletException(e);
}
 finally {
  try {
    if (ctx != null) {
      ctx.close();
    }
  }
 catch (  final Exception e) {
    throw new ServletException(e);
  }
}
",0,0,0,,
800,} finally {,"try {
  afterInvoke(mdbCallContext.txPolicy,callContext);
}
 catch (final ApplicationException e) {
  callContext.setDiscardInstance(true);
  throw new SystemException(""Should never get an Application exception"",e);
}
 finally {
  if (instance != null) {
    if (callContext.isDiscardInstance()) {
      this.instanceManager.discardInstance(callContext,instance);
    }
 else {
      try {
        this.instanceManager.poolInstance(callContext,instance);
      }
 catch (      OpenEJBException e) {
        throw new SystemException(""Should never get an OpenEJBException exception"",e);
      }
    }
  }
  ThreadContext.exit(mdbCallContext.oldCallContext);
}
",0,0,0,,
801,} finally {,"try {
  if (type == InterfaceType.SERVICE_ENDPOINT) {
    callContext.setCurrentOperation(Operation.BUSINESS_WS);
    returnValue=invokeWebService(args,beanContext,runMethod,instance);
  }
 else {
    final List<InterceptorData> interceptors=beanContext.getMethodInterceptors(runMethod);
    final Operation operation=type == InterfaceType.TIMEOUT ? Operation.TIMEOUT : Operation.BUSINESS;
    final InterceptorStack interceptorStack=new InterceptorStack(instance.bean,runMethod,operation,interceptors,instance.interceptors);
    returnValue=interceptorStack.invoke(args);
  }
}
 catch (final Throwable re) {
  final ExceptionType exceptionType=beanContext.getExceptionType(re);
  if (exceptionType == ExceptionType.SYSTEM) {
    callContext.setDiscardInstance(true);
    handleSystemException(txPolicy,re,callContext);
  }
 else {
    handleApplicationException(txPolicy,re,exceptionType == ExceptionType.APPLICATION_ROLLBACK);
  }
}
 finally {
  try {
    afterInvoke(txPolicy,callContext);
  }
 catch (  final SystemException|RuntimeException e) {
    callContext.setDiscardInstance(true);
    throw e;
  }
}
",0,0,0,,
802,finally,"try {
  fos=new FileOutputStream(resourceFile);
  this.write(fos,byteContent);
  fos.flush();
  this.createResourceFileNameList();
}
  finally {
  try {
    if (fos != null)     fos.close();
  }
 catch (  IOException warn) {
    throw warn;
  }
}
",0,0,0,,
803,finally,"try {
  fis=new FileInputStream(resourceFile);
  result=this.read(fis);
}
  finally {
  try {
    if (fis != null)     fis.close();
  }
 catch (  IOException warn) {
    throw warn;
  }
}
",0,0,0,,
804,} finally {,"try {
  invocationResult=doInvokeTarget(payload);
}
 catch (InvocationTargetException e) {
  rethrow=e;
  Throwable cause=e.getCause();
  if (cause instanceof UndeclaredThrowableException) {
    cause=cause.getCause();
    if (cause instanceof UnexpectedException) {
      cause=cause.getCause();
      if (cause instanceof ConnectException) {
        rethrow=null;
        proxy=rmiHost.findService(host,port,svcName);
        invocationResult=doInvokeTarget(payload);
      }
    }
  }
}
 finally {
  if (rethrow != null) {
    throw rethrow;
  }
}
",0,0,0,,
805,} finally {,"try {
  conversationPreinvoke(msg);
  Message resp=headInvoker.invoke(msg);
  Object body=resp.getBody();
  if (resp.isFault()) {
    throw new InvocationTargetException((Throwable)body);
  }
  return body;
}
 catch (InvocationTargetException e) {
  throw e;
}
catch (Throwable e) {
  throw new ServiceRuntimeException(e);
}
 finally {
  try {
    conversationPostInvoke(msg);
  }
 catch (  TargetDestructionException e) {
    throw new ServiceRuntimeException(e);
  }
 finally {
    ThreadMessageContext.setMessageContext(msgContext);
  }
}
",0,0,0,,
806,} finally {,"try {
  setWriterOutputStream(ctx.getWriter());
  setErrorWriter(ctx.getErrorWriter());
  setGlobalVariables(ctx);
  return rubyToJava(runtime.runNormally(node,false));
}
 catch (Exception exp) {
  throw new ScriptException(exp);
}
 finally {
  try {
    JavaEmbedUtils.terminate(runtime);
  }
 catch (  RaiseException e) {
    RubyException re=e.getException();
    runtime.printError(re);
    if (!runtime.fastGetClass(""SystemExit"").isInstance(re)) {
      throw new ScriptException(e);
    }
  }
 finally {
    if (oldGlobals != null) {
      setGlobalVariables(oldGlobals);
    }
  }
}
",0,0,0,,
807,} finally {,"try {
  setWriterOutputStream(context.getWriter());
  setErrorWriter(context.getErrorWriter());
  setGlobalVariables(context);
  IRubyObject rubyRecv=obj != null ? JavaUtil.convertJavaToRuby(runtime,obj) : runtime.getTopSelf();
  IRubyObject result;
  if (args != null && args.length > 0) {
    IRubyObject[] rubyArgs=JavaUtil.convertJavaArrayToRuby(runtime,args);
    IRubyObject javaUtilities=runtime.getObject().getConstant(""JavaUtilities"");
    for (int i=0; i < rubyArgs.length; i++) {
      IRubyObject tmp=rubyArgs[i];
      if (tmp instanceof JavaObject) {
        rubyArgs[i]=javaUtilities.callMethod(runtime.getCurrentContext(),""wrap"",tmp);
      }
    }
    result=rubyRecv.callMethod(runtime.getCurrentContext(),method,rubyArgs);
  }
 else {
    result=rubyRecv.callMethod(runtime.getCurrentContext(),method);
  }
  return rubyToJava(result,returnType);
}
 catch (Exception exp) {
  throw new ScriptException(exp);
}
 finally {
  try {
    JavaEmbedUtils.terminate(runtime);
  }
 catch (  RaiseException e) {
    RubyException re=e.getException();
    runtime.printError(re);
    if (!runtime.fastGetClass(""SystemExit"").isInstance(re)) {
      throw new ScriptException(e);
    }
  }
 finally {
    if (oldGlobals != null) {
      setGlobalVariables(oldGlobals);
    }
  }
}
",0,0,0,,
808,} finally {,"try {
  try {
    InvocationResult result=invoker.execute(request);
    CommandLineException cle=result.getExecutionException();
    if (cle != null) {
      throw new MojoExecutionException(cle.getMessage(),cle);
    }
    int ec=result.getExitCode();
    if (ec != 0) {
      throw new MojoExecutionException(""Maven invocation exit code: "" + ec);
    }
    success=true;
  }
 catch (  MavenInvocationException e) {
    throw new MojoExecutionException(e.getMessage(),e);
  }
}
  finally {
  if (!success) {
    try {
      if (!testMarkerFile.exists()) {
        testMarkerFile.createNewFile();
      }
    }
 catch (    IOException e) {
      throw new MojoExecutionException(e.getMessage(),e);
    }
  }
 else {
    if (testMarkerFile.exists()) {
      testMarkerFile.delete();
    }
  }
}
",0,0,0,,
809,} finally {,"try {
  invocationResult=doInvokeTarget(payload);
}
 catch (InvocationTargetException e) {
  rethrow=e;
  Throwable cause=e.getCause();
  if (cause instanceof UndeclaredThrowableException) {
    cause=cause.getCause();
    if (cause instanceof UnexpectedException) {
      cause=cause.getCause();
      if (cause instanceof ConnectException) {
        rethrow=null;
        proxy=rmiHost.findService(uri);
        invocationResult=doInvokeTarget(payload);
      }
    }
  }
}
 finally {
  if (rethrow != null) {
    throw rethrow;
  }
}
",0,0,0,,
810,} finally {,"try {
  URL base=IOHelper.getLocationAsURL(configURL);
  xml=IOHelper.openStream(base);
  InputStreamReader reader=new InputStreamReader(xml,""UTF-8"");
  ProcessorContext context=deployer.createProcessorContext();
  NodeConfiguration config=deployer.loadXMLDocument(reader,context.getMonitor());
  if (base != null && config != null) {
    for (    ContributionConfiguration c : config.getContributions()) {
      String location=c.getLocation();
      if (location != null) {
        URL url=new URL(base,location);
        url=IOHelper.normalize(url);
        c.setLocation(url.toString());
      }
    }
  }
  return config;
}
 catch (Throwable e) {
  throw new ServiceRuntimeException(e);
}
 finally {
  try {
    if (xml != null)     xml.close();
  }
 catch (  IOException e) {
    throw new ServiceRuntimeException(e);
  }
}
",0,0,0,,
811,finally,"try {
  if (!lock.tryLock(lockTimeout,TimeUnit.SECONDS)) {
    throw new QueueException(""Unable to obtain a lock on queue '"" + queuePath + ""' after '""+ lockTimeout+ ""'seconds"");
  }
  long startTime=System.currentTimeMillis();
  UUID startTimeUUID=UUIDUtils.newTimeUUID(startTime,0);
  QueueBounds bounds=getQueueBounds(queueId);
  if (bounds == null) {
    return createResults(new ArrayList<Message>(0),queuePath,queueId,consumerId);
  }
  bounds=new QueueBounds(bounds.getOldest(),startTimeUUID);
  SearchParam params=getParams(queueId,consumerId,query);
  if (params.startId != null && UUIDUtils.compare(params.startId,startTimeUUID) > 0) {
    logger.warn(""Our cursor has advanced beyond the end of the queue due to transactions.  Was {}, resetting to {}"",params.startId,startTimeUUID);
    params=new SearchParam(startTimeUUID,params.reversed,false,params.limit);
  }
  List<UUID> ids=getQueueRange(queueId,bounds,params);
  List<TransactionPointer> pointers=getConsumerIds(queueId,consumerId,params,startTimeUUID);
  TransactionPointer pointer;
  int lastTransactionIndex=-1;
  for (int i=0; i < pointers.size(); i++) {
    pointer=pointers.get(i);
    int insertIndex=Collections.binarySearch(ids,pointer.expiration);
    if (insertIndex <= params.limit * -1 - 1) {
      break;
    }
    insertIndex=(insertIndex + 1) * -1;
    ids.add(insertIndex,pointer.targetMessage);
    lastTransactionIndex=i;
  }
  if (ids.size() > params.limit) {
    ids=ids.subList(0,params.limit);
  }
  List<Message> messages=loadMessages(ids,params.reversed);
  writeTransactions(messages,query.getTimeout() + startTime,queueId,consumerId);
  deleteTransactionPointers(pointers,lastTransactionIndex + 1,queueId,consumerId);
  results=createResults(messages,queuePath,queueId,consumerId);
  UUID lastReadTransactionPointer=lastTransactionIndex == -1 ? null : pointers.get(lastTransactionIndex).expiration;
  UUID lastId=messages.size() == 0 ? null : messages.get(messages.size() - 1).getUuid();
  UUID lastReadId=UUIDUtils.max(lastReadTransactionPointer,lastId);
  lastReadId=UUIDUtils.min(lastReadId,bounds.getNewest());
  writeClientPointer(queueId,consumerId,lastReadId);
}
 catch (UGLockException e) {
  if (logger.isDebugEnabled()) {
    logger.debug(""Unable to acquire lock"",e);
  }
  throw new QueueException(""Unable to acquire lock"",e);
}
 finally {
  try {
    lock.unlock();
  }
 catch (  UGLockException e) {
    if (logger.isDebugEnabled()) {
      logger.debug(""Unable to release lock"",e);
    }
    throw new QueueException(""Unable to release lock"",e);
  }
}
",0,0,0,,
812,finally,"try {
  BufferedReader br=new BufferedReader(reader);
  data=rsvc.parse(br,this);
  initDocument();
  return true;
}
 catch (ParseException pex) {
  errorCondition=new ParseErrorException(pex,name);
  throw errorCondition;
}
catch (TemplateInitException pex) {
  errorCondition=new ParseErrorException(pex,name);
  throw errorCondition;
}
catch (RuntimeException e) {
  errorCondition=new VelocityException(""Exception thrown processing Template "" + getName(),e,rsvc.getLogContext().getStackTrace());
  throw errorCondition;
}
 finally {
  try {
    reader.close();
  }
 catch (  IOException e) {
    if (errorCondition == null) {
      throw new VelocityException(e,rsvc.getLogContext().getStackTrace());
    }
  }
}
",0,0,0,,
813,finally,"try {
  inputStream=getClass().getClassLoader().getResourceAsStream(DEFAULT_RUNTIME_PROPERTIES);
  if (inputStream == null)   throw new IOException(""Resource not found: "" + DEFAULT_RUNTIME_PROPERTIES);
  configuration.load(inputStream);
  defaultEncoding=getString(INPUT_ENCODING,ENCODING_DEFAULT);
  log.debug(""Default Properties resource: {}"",DEFAULT_RUNTIME_PROPERTIES);
}
 catch (IOException ioe) {
  String msg=""Cannot get Velocity Runtime default properties!"";
  log.error(msg,ioe);
  throw new RuntimeException(msg,ioe);
}
 finally {
  try {
    if (inputStream != null) {
      inputStream.close();
    }
  }
 catch (  IOException ioe) {
    String msg=""Cannot close Velocity Runtime default properties!"";
    log.error(msg,ioe);
    throw new RuntimeException(msg,ioe);
  }
}
",0,0,0,,
814,finally,"try {
  inputStream=getClass().getResourceAsStream('/' + DEFAULT_RUNTIME_DIRECTIVES);
  if (inputStream == null) {
    throw new VelocityException(""Error loading directive.properties! "" + ""Something is very wrong if these properties "" + ""aren't being located. Either your Velocity ""+ ""distribution is incomplete or your Velocity ""+ ""jar file is corrupted!"");
  }
  directiveProperties.load(inputStream);
}
 catch (IOException ioe) {
  String msg=""Error while loading directive properties!"";
  log.error(msg,ioe);
  throw new RuntimeException(msg,ioe);
}
 finally {
  try {
    if (inputStream != null) {
      inputStream.close();
    }
  }
 catch (  IOException ioe) {
    String msg=""Cannot close directive properties!"";
    log.error(msg,ioe);
    throw new RuntimeException(msg,ioe);
  }
}
",0,0,0,,
815,finally,"try {
  reader=getResourceReader(resourceName,null);
}
 catch (ResourceNotFoundException e) {
  log.debug(""Could not load resource '{}' from ResourceLoader {}"",resourceName,this.getClass().getName());
}
 finally {
  try {
    if (reader != null) {
      reader.close();
    }
  }
 catch (  Exception e) {
    String msg=""While closing InputStream for resource '"" + resourceName + ""' from ResourceLoader ""+ this.getClass().getName();
    log.error(msg,e);
    throw new VelocityException(msg,e);
  }
}
",0,0,0,,
816,} finally {,"try {
  fta.reset(buffer);
  for (int tIndex=0; tIndex < fta.getTupleCount(); tIndex++) {
    int start=fta.getTupleStartOffset(tIndex);
    int length=fta.getTupleEndOffset(tIndex) - start;
    bbis.setByteBuffer(buffer,start);
    byte[] recordBytes=new byte[length];
    bbis.read(recordBytes,0,length);
    resultRecords+=new String(recordBytes,0,length);
  }
}
  finally {
  try {
    bbis.close();
  }
 catch (  IOException e) {
    throw new HyracksDataException(e);
  }
}
",0,0,0,,
817,finally,"try {
  IMarkupFragment markup=MarkupFactory.get().newMarkupParser(markupResourceStream).parse();
  return new MarkupStream(markup);
}
 catch (Exception e) {
  throw new WicketRuntimeException(""Could not parse markup from markup resource stream: "" + markupResourceStream.toString(),e);
}
 finally {
  try {
    markupResourceStream.close();
  }
 catch (  IOException e) {
    throw new WicketRuntimeException(""Cannot close markup resource stream: "" + markupResourceStream,e);
  }
}
",0,0,0,,
818,finally,"try {
  if (previousClassLoader != newClassLoader) {
    Thread.currentThread().setContextClassLoader(newClassLoader);
  }
  String filterPath=getFilterPath(httpServletRequest);
  if (filterPath == null) {
    throw new IllegalStateException(""filter path was not configured"");
  }
  if (shouldIgnorePath(httpServletRequest)) {
    log.debug(""Ignoring request {}"",httpServletRequest.getRequestURL());
    if (chain != null) {
      chain.doFilter(request,response);
    }
    return false;
  }
  if (""OPTIONS"".equalsIgnoreCase(httpServletRequest.getMethod())) {
    httpServletResponse.setStatus(HttpServletResponse.SC_OK);
    httpServletResponse.setHeader(""Allow"",""GET,POST,OPTIONS,PUT,HEAD,PATCH,DELETE,TRACE"");
    httpServletResponse.setHeader(""Content-Length"",""0"");
    return true;
  }
  String redirectURL=checkIfRedirectRequired(httpServletRequest);
  if (redirectURL == null) {
    ThreadContext.setApplication(application);
    WebRequest webRequest=application.createWebRequest(httpServletRequest,filterPath);
    WebResponse webResponse=application.createWebResponse(webRequest,httpServletResponse);
    RequestCycle requestCycle=application.createRequestCycle(webRequest,webResponse);
    res=processRequestCycle(requestCycle,webResponse,httpServletRequest,httpServletResponse,chain);
  }
 else {
    if (Strings.isEmpty(httpServletRequest.getQueryString()) == false) {
      redirectURL+=""?"" + httpServletRequest.getQueryString();
    }
    httpServletResponse.sendRedirect(httpServletResponse.encodeRedirectURL(redirectURL));
  }
}
 catch (IOException e) {
  ioExceptionOccurred=true;
  throw e;
}
catch (ResponseIOException e) {
  ioExceptionOccurred=true;
  throw e.getCause();
}
 finally {
  ThreadContext.restore(previousThreadContext);
  if (newClassLoader != previousClassLoader) {
    Thread.currentThread().setContextClassLoader(previousClassLoader);
  }
  if (!ioExceptionOccurred && response.isCommitted() && !httpServletRequest.isAsyncStarted()) {
    try {
      response.flushBuffer();
    }
 catch (    ResponseIOException e) {
      throw e.getCause();
    }
  }
}
",0,0,0,,
819,finally,"try {
  FileReader fileReader=new FileReader(file);
  lineNumberReader=new LineNumberReader(fileReader);
  for (int i=start; i < length; i++) {
    header.append(lineNumberReader.readLine());
    header.append(LINE_ENDING);
  }
}
 catch (Exception e) {
  throw new AssertionError(e.getMessage());
}
 finally {
  try {
    IOUtils.close(lineNumberReader);
  }
 catch (  IOException e) {
    throw new AssertionError(e.getMessage());
  }
}
",0,0,0,,
820,} finally {,"try {
  return IOUtils.copy(in,out,-1);
}
  finally {
  try {
    out.close();
  }
 catch (  IOException ex) {
    throw new StreamCopyException(StreamCopyException.WRITE,ex);
  }
}
",0,0,0,,
821,} finally {,"try {
  IOUtils.copy(in,out,-1);
}
  finally {
  try {
    in.close();
  }
 catch (  IOException ex) {
    throw new StreamCopyException(StreamCopyException.READ,ex);
  }
}
",0,0,0,,
822,} finally {,"try {
  if (out instanceof ReadFromSupport) {
    ((ReadFromSupport)out).readFrom(in,-1);
  }
 else {
    byte[] buf=new byte[4096];
    while (true) {
      int c;
      try {
        c=in.read(buf);
      }
 catch (      IOException ex) {
        throw new StreamCopyException(StreamCopyException.READ,ex);
      }
      if (c == -1) {
        break;
      }
      try {
        out.write(buf,0,c);
      }
 catch (      IOException ex) {
        throw new StreamCopyException(StreamCopyException.WRITE,ex);
      }
    }
  }
}
  finally {
  try {
    in.close();
  }
 catch (  IOException ex) {
    throw new StreamCopyException(StreamCopyException.READ,ex);
  }
}
",0,0,0,,
823,finally,"try {
  SerializationHandler rth=transformer.getResultTreeHandler();
  if (transformer.getDebug()) {
    rth.flushPending();
    transformer.getTraceManager().fireTraceEvent(this);
  }
  if (m_disableOutputEscaping) {
    rth.processingInstruction(javax.xml.transform.Result.PI_DISABLE_OUTPUT_ESCAPING,"""");
  }
  rth.characters(m_ch,0,m_ch.length);
  if (m_disableOutputEscaping) {
    rth.processingInstruction(javax.xml.transform.Result.PI_ENABLE_OUTPUT_ESCAPING,"""");
  }
}
 catch (SAXException se) {
  throw new TransformerException(se);
}
 finally {
  if (transformer.getDebug()) {
    try {
      transformer.getResultTreeHandler().flushPending();
      transformer.getTraceManager().fireTraceEndEvent(this);
    }
 catch (    SAXException se) {
      throw new TransformerException(se);
    }
  }
}
",0,0,0,,
824,finally,"try {
  SerializationHandler rth=transformer.getResultTreeHandler();
  if (transformer.getDebug()) {
    rth.flushPending();
    transformer.getTraceManager().fireTraceEvent(this);
  }
  if (m_disableOutputEscaping) {
    rth.processingInstruction(javax.xml.transform.Result.PI_DISABLE_OUTPUT_ESCAPING,"""");
  }
  rth.characters(m_ch,0,m_ch.length);
  if (m_disableOutputEscaping) {
    rth.processingInstruction(javax.xml.transform.Result.PI_ENABLE_OUTPUT_ESCAPING,"""");
  }
}
 catch (SAXException se) {
  throw new TransformerException(se);
}
 finally {
  if (transformer.getDebug()) {
    try {
      transformer.getResultTreeHandler().flushPending();
      transformer.getTraceManager().fireTraceEndEvent(this);
    }
 catch (    SAXException se) {
      throw new TransformerException(se);
    }
  }
}
",0,0,0,,
825,} finally {,"try {
  while (idx < offset) {
    int rn=(int)is.skip(offset - idx);
    if (rn == -1) {
      return false;
    }
    idx+=rn;
  }
  idx=0;
  while (idx < buffer.length) {
    int rn=is.read(buffer,idx,buffer.length - idx);
    if (rn == -1) {
      return false;
    }
    idx+=rn;
  }
  for (int i=0; i < magicNumber.length; i++) {
    if (magicNumber[i] != buffer[i]) {
      return false;
    }
  }
}
 catch (IOException ioe) {
  return false;
}
 finally {
  try {
    is.reset();
  }
 catch (  IOException ioe) {
    throw new StreamCorruptedException(ioe.getMessage());
  }
}
",0,0,0,,
826,}finally{,"try {
  if (!dir.exists()) {
    dirOK=dir.mkdir();
  }
 else   if (dir.isDirectory()) {
    dirOK=true;
  }
}
  finally {
  if (!dirOK) {
    throw new TestException(errorCode,new Object[]{dir.getAbsolutePath()},null);
  }
}
",0,0,0,,
827,}finally{,"try {
  if (!dir.exists()) {
    dirOK=dir.mkdir();
  }
 else   if (dir.isDirectory()) {
    dirOK=true;
  }
}
  finally {
  if (!dirOK) {
    throw new TestException(ERROR_OUTPUT_DIRECTORY_UNUSABLE,new Object[]{dir.getAbsolutePath()},null);
  }
}
",0,0,0,,
828,} finally {,"try {
  DocumentBuilder builder=DefaultConfiguration.DBF.newDocumentBuilder();
  Document document=builder.parse(confStream);
  return new DefaultConfiguration(document.getDocumentElement());
}
 catch (DOMException e) {
  throw new ConfigurationException(""xml parse error"",e);
}
catch (ParserConfigurationException e) {
  throw new ConfigurationException(""xml parse error"",e);
}
catch (IOException e) {
  throw new ConfigurationException(""xml parse error"",e);
}
catch (SAXException e) {
  throw new ConfigurationException(""xml parse error"",e);
}
 finally {
  try {
    confStream.close();
  }
 catch (  IOException e) {
    throw new IllegalStateException(e);
  }
}
",0,0,0,,
829,} finally {,"try {
  flush();
  ((FileOutputStream)out).getFD().sync();
  triedToClose=true;
  super.close();
  success=true;
}
  finally {
  if (success) {
    boolean renamed=tmpFile.renameTo(origFile);
    if (!renamed) {
      if (!origFile.delete() || !tmpFile.renameTo(origFile)) {
        throw new IOException(""Could not rename temporary file "" + tmpFile + "" to ""+ origFile);
      }
    }
  }
 else {
    if (!triedToClose) {
      IOUtils.closeStream(out);
    }
    if (!tmpFile.delete()) {
      LOG.warn(""Unable to delete tmp file {}"",tmpFile);
    }
  }
}
",0,0,0,,

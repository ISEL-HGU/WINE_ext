96000,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageReconstructor.java,622,,"      inodeBld.setName(ByteString.copyFrom(name, ""UTF8""));"
96001,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/OfflineImageReconstructor.java,963,,"          throw new IOException(""Only read "" + actualNumKeys +"
96002,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/PBImageXmlWriter.java,392,,"      out.print(""</"" + CACHE_MANAGER_SECTION_POOL + "">\n"");"
96003,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/util/LightWeightHashSet.java,108,,"  @SuppressWarnings(""unchecked"")"
96004,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java,127,,"    m.put(""length"", status.getLen());"
96005,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/web/JsonUtil.java,165,,"    builder.put(""name"", ecPolicy.getName())"
96006,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,77,,"    RefreshRegistry.defaultRegistry().register(""firstHandler"", firstHandler);"
96007,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,81,,"    Mockito.when(secondHandler.handleRefresh(""secondHandler"", new String[]{""one"", ""two""}))"
96008,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,81,,"    Mockito.when(secondHandler.handleRefresh(""secondHandler"", new String[]{""one"", ""two""}))"
96009,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,81,,"    Mockito.when(secondHandler.handleRefresh(""secondHandler"", new String[]{""one"", ""two""}))"
96010,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,97,,"    String [] args = new String[]{""-refresh"", ""nn""};"
96011,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,105,,"    String [] args = new String[]{""-refresh"", ""localhost:"" + "
96012,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,163,,"    RefreshRegistry.defaultRegistry().register(""sharedId"", firstHandler);"
96013,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,192,,"    RefreshRegistry.defaultRegistry().register(""shared"", handlerOne);"
96014,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java,220,,"    RefreshRegistry.defaultRegistry().register(""exceptional"", exceptionalHandler);"
96015,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java,155,,"        Assert.fail(""unexpected InterruptedException during "" +"
96016,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java,156,,"            ""waitReplication: "" + e);"
96017,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestEnhancedByteBufferAccess.java,158,,"        Assert.fail(""unexpected TimeoutException during "" +"
96018,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java,458,,"      String[] files = new String[] { USER_DIR + ""/a"", USER_DIR + ""/a/b"" };"
96019,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java,886,,"      wrap.mkdir(new Path(USER_DIR + ""/alpha""), FsPermission.getDirDefault(),"
96020,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java,889,,"          + ""/alphaLink""), false);"
96021,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java,896,,"      Assert.assertEquals(USER_DIR + ""/alpha/beta"", statuses[0].getPath()"
96022,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java,1036,,"      statuses = wrap.globStatus(new Path(USER_DIR + ""/alphaLinkz/betaz""),"
96023,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java,111,,"    Path link      = new Path(testBaseDir1(), ""linkToFile"");"
96024,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java,128,,"    Path hdfsFile    = new Path(testBaseDir1(), ""file"");"
96025,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java,203,,"    wrapper.setOwner(linkToFile, ""user"", ""group"");"
96026,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfs.java,203,,"    wrapper.setOwner(linkToFile, ""user"", ""group"");"
96027,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestSymlinkHdfsFileSystem.java,53,,"    Path link = new Path(testBaseDir1(), ""link"");"
96028,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java,111,,"    Path file = new Path(p, ""foo"");"
96029,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java,205,,"    Path p = new Path(baseDir, ""tmp"");"
96030,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/permission/TestStickyBit.java,371,,"    LOG.info(""Dir: {}, permission: {}"", sbExplicitTestDir.getName(),"
96031,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/shell/TestHdfsTextCommand.java,94,,"      System.getProperty(""line.separator"") +"
96032,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java,352,,"        assertEquals(""Wrong file content"", testString, fsdis.readUTF());"
96033,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java,437,,"        map.put(""user1"", viewFS);"
96034,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,182,,"    Assert.assertEquals(""Unexpected file length for "" + testBaseFile,"
96035,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,294,,"        new Path(targetTestRoot, ""fallbackDir"").toUri());"
96036,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,311,,"      Path childDir = new Path(fallbackArray[0], ""child"");"
96037,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,396,,"    ConfigUtil.addLink(conf, ""/user1/hive/warehouse/partition-0"","
96038,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,402,,"        ""fallbackDir/user1/hive/warehouse/partition-0"");"
96039,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,407,,"        FsPermission.valueOf(""-rwxr--r--""));"
96040,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,412,,"          new Path(viewFsDefaultClusterUri.toString(), ""/user1/hive/""))) {"
96041,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,478,,"    fsTarget.setPermission(targetTestRoot, FsPermission.valueOf(""-rwxr--rw-""));"
96042,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLinkFallback.java,532,,"        .addLink(conf, ""/user1"", new Path(targetTestRoot.toString()).toUri());"
96043,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAcls.java,123,,"        aclEntry(ACCESS, USER, ""foo"", READ),"
96044,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java,122,,"        map.put(""user1"", viewFS);"
96045,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,121,,"    ConfigUtil.addLink(conf, ""/user1/hive/warehouse/partition-0"","
96046,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,126,,"    Path fallbackTarget = new Path(targetTestRoot, ""fallbackDir"");"
96047,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,147,,"        .addLink(conf, ""/user1"", new Path(targetTestRoot.toString()).toUri());"
96048,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,195,,"    ConfigUtil.addLink(conf, ""/user1/hive"","
96049,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,374,,"    ConfigUtil.addLink(conf, ""/user1/hive/"","
96050,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsLinkFallback.java,487,,"        new Path(targetTestRoot.toString() + ""/newUser1"").toUri());"
96051,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsWithAcls.java,123,,"        aclEntry(ACCESS, USER, ""foo"", READ),"
96052,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java,757,,"          + "" Live = ""+live.size()+"" Expected = ""+expectedLive"
96053,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java,1503,,"    filesystem.addCachePool(new CachePoolInfo(""pool1""));"
96054,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/MiniDFSCluster.java,1672,,"          + ""] is less than the number of datanodes ["" + numDataNodes + ""]."");"
96055,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/MiniDFSCluster.java,3385,,"        conf.setIfUnset(DFS_DATANODE_ADDRESS_KEY, ""127.0.0.1:0"");"
96056,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/MiniDFSClusterWithNodeGroup.java,86,,"          + ""] is less than the number of datanodes ["" + numDataNodes + ""]."");"
96057,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,231,,"    conf.set(KMSConfiguration.CONFIG_PREFIX + ""acl.CREATE"","
96058,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,233,,"    conf.set(KMSConfiguration.CONFIG_PREFIX + ""acl.DELETE"","
96059,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,240,,"    conf.set(KMSConfiguration.CONFIG_PREFIX + ""acl.GET_METADATA"","
96060,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,243,,"    conf.set(KMSConfiguration.CONFIG_PREFIX + ""acl.GENERATE_EEK"","
96061,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,245,,"    conf.set(KMSConfiguration.CONFIG_PREFIX + ""acl.DECRYPT_EEK"", ""*"");"
96062,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,287,,"    conf.set(prefix + ""MANAGEMENT"", keyadminUgi.getUserName());"
96063,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,288,,"    conf.set(prefix + ""READ"", hdfsUgi.getUserName());"
96064,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,289,,"    conf.set(prefix + ""GENERATE_EEK"", hdfsUgi.getUserName());"
96065,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,290,,"    conf.set(KeyAuthorizationKeyProvider.KEY_ACL + KEY1 + "".DECRYPT_EEK"","
96066,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,304,,"        UserGroupInformation.createProxyUserForTesting(""hdfs"","
96067,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,305,,"          realUgi, new String[] {""supergroup""});"
96068,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,307,,"        UserGroupInformation.createProxyUserForTesting(""keyadmin"","
96069,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,310,,"        UserGroupInformation.createProxyUserForTesting(""user"","
96070,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,311,,"          realUgi,  new String[] {""staff""});"
96071,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,415,,"      assertTrue(""Exception during creation of key "" + KEY1 + "" by """
96072,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,585,,"          + "" overridden by key ACL"", createKey(realUgi, KEY3, conf));"
96073,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,623,,"      assertTrue(""Exception during key creation"","
96074,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,902,,"      assertTrue(""Exception during zone creation"","
96075,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAclsEndToEnd.java,938,,"    conf.set(KMSConfiguration.WHITELIST_KEY_ACL_PREFIX + ""DECRYPT_EEK"","
96076,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestAppendDifferentChecksum.java,73,,"    FileSystem fsWithSmallChunk = createFsWithChecksum(""CRC32"", 512);"
96077,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestApplyingStoragePolicy.java,64,,"    final Path foo = new Path(""/foo"");"
96078,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestApplyingStoragePolicy.java,65,,"    final Path bar = new Path(foo, ""bar"");"
96079,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestApplyingStoragePolicy.java,72,,"    final BlockStoragePolicy hot = suite.getPolicy(""HOT"");"
96080,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBalancerBandwidth.java,78,,"      String[] args = new String[] { ""-getBalancerBandwidth"", dn1Address };"
96081,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBatchedListDirectories.java,197,,"    paths.add(new Path(""/does/not/exist""));"
96082,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,941,,"      final Path fooFile = new Path(dir, ""foo"");"
96083,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,1259,,"    final String[] racks = {""/d1/r1"", ""/d1/r2"", ""/d1/r2""};"
96084,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,1284,,"    DatanodeStorageInfo[] targets = replicator.chooseTarget(""/foo"", 3,"
96085,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,1550,,"        new String[]{""DN1-Storage1""},"
96086,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,1553,,"    testStorageIDCheckAccessResult(new String[]{""DN1-Storage1"", ""DN2-Storage1""},"
96087,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestBlockStoragePolicy.java,1558,,"        new String[]{""DN1-Storage1"", ""DN1-Storage2""}, false);"
96088,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestClientProtocolForPipelineRecovery.java,325,,"          ""Async datanode shutdown thread"", 100, 10000);"
96089,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestCrcCorruption.java,164,,"      util.createFiles(fs, ""/srcdat"", replFactor);"
96090,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientFailover.java,117,,"    Path withPort = new Path(""hdfs://"" +"
96091,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSClientRetries.java,623,,"      LOG.info(""Test 1 succeeded! Time spent: "" + (timestamp2-timestamp)/1000.0 + "" sec."");"
96092,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSFinalize.java,70,,"      File curDir = new File(nameNodeDirs[i], ""current"");"
96093,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSFinalize.java,85,,"      assertFalse(new File(nameNodeDirs[i],""previous"").isDirectory());"
96094,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInotifyEventInputStream.java,105,,"      DFSTestUtil.createFile(fs, new Path(""/file5""), BLOCK_SIZE, (short) 1, 0L);"
96095,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInotifyEventInputStream.java,109,,"      client.rename(""/file"", ""/file4"", null); // RenameOp -> RenameEvent"
96096,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInotifyEventInputStream.java,110,,"      client.rename(""/file4"", ""/file2""); // RenameOldOp -> RenameEvent"
96097,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInotifyEventInputStream.java,127,,"      client.mkdirs(""/dir"", null, false); // MkdirOp -> CreateEvent"
96098,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInputStream.java,57,,"    Path file = new Path(""/testfile"");"
96099,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSInputStream.java,246,,"      DatanodeID nodeId = new DatanodeID(""localhost"", ""localhost"", ""dn0"", 1111,"
96100,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSPermission.java,327,,"        assertTrue(""Permission denied messages must carry the username"","
96101,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSRollback.java,76,,"      File curDir = new File(baseDir, ""current"");"
96102,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSRollback.java,94,,"      assertFalse(new File(baseDirs[i],""previous"").isDirectory());"
96103,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,100,,"  private static final String USER_A1 = ""user.a1"";"
96104,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,252,,"      final Path myFile = new Path(myPath, ""file"");"
96105,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,255,,"      final Path myFile2 = new Path(myPath, ""file2"");"
96106,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,264,,"      args[0] = ""-du"";"
96107,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,270,,"        System.err.println(""Exception raised from DFSShell.run "" +"
96108,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,506,,"        val = shell.run(new String[] {""-count"", ""-v"", parent.toString() });"
96109,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,635,,"      Path root = new Path(""/nonexistentfile"");"
96110,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,641,,"      argv[0] = ""-cat"";"
96111,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,649,,"      argv[0] = ""-rm"";"
96112,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,657,,"          (returned.lastIndexOf(""No such file or directory"") != -1));"
96113,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,680,,"      argv[0] = ""-ls"";"
96114,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,705,,"      argv[0] = ""-mkdir"";"
96115,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,712,,"      Path testFile = new Path(""/testfile"");"
96116,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,734,,"      argv[0] = ""-mv"";"
96117,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,767,,"      argv[0] = ""-test"";"
96118,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,851,,"      argv[0] = ""-put"";"
96119,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,853,,"      argv[2] = dstFs.getUri().toString() + ""/furi"";"
96120,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,857,,"      argv[0] = ""-cp"";"
96121,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,877,,"      runCmd(shell, ""-chgrp"", ""-R"", ""herbivores"", dstFs.getUri().toString() +""/*"");"
96122,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,877,,"      runCmd(shell, ""-chgrp"", ""-R"", ""herbivores"", dstFs.getUri().toString() +""/*"");"
96123,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,879,,"      runCmd(shell, ""-chown"", ""-R"", "":reptiles"", dstFs.getUri().toString() + ""/"");"
96124,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,912,,"    final Path testFile = new Path(""testHead"", ""file1"");"
96125,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,922,,"    assertEquals(Arrays.toString(argv) + "" returned "" + ret, 0, ret);"
96126,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1023,,"          fs.create(new Path(root, ""file.gz"")));"
96127,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1038,,"      argv[0] = ""-text"";"
96128,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1041,,"      assertEquals(""'-text "" + argv[1] + "" returned "" + ret, 0, ret);"
96129,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1042,,"      assertTrue(""Output doesn't match input"","
96130,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1068,,"      byte[] outbytes = ""foo"".getBytes();"
96131,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1105,,"      writebytes = ""bar"".getBytes();"
96132,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1170,,"      assertTrue(""Copying failed."", f1.isFile());"
96133,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1175,,"      File sub = new File(localroot, ""sub"");"
96134,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1339,,"      runCmd(shell, ""-chmod"", ""-R"", ""a+rwX"", chmodDir);"
96135,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1932,,"      Path p = new Path(""/foo"");"
96136,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,1951,,"                     str.indexOf(""Permission denied"") != -1);"
96137,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,2214,,"      Path src = new Path(hdfsTestDir, ""srcfile"");"
96138,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,2347,,"    final Path rawHdfsTestDir = new Path(""/.reserved/raw"" + testdir);"
96139,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,2709,,"    final File localFile = new File(TEST_ROOT_DIR, ""testFileForPut"");"
96140,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3065,,"              ""-setfattr"", ""-n"", ""user.a1"", ""-v"", ""1234"", ""/foo""});"
96141,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3065,,"              ""-setfattr"", ""-n"", ""user.a1"", ""-v"", ""1234"", ""/foo""});"
96142,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3066,,"          assertEquals(""Returned should be 1"", 1, ret);"
96143,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3068,,"          assertTrue(""Permission denied printed"","
96144,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3077,,"      assertEquals(""Returned should be 0"", 0, ret);"
96145,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3087,,"              ""-getfattr"", ""-n"", ""user.a1"", ""/foo""});"
96146,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3116,,"      Path p = new Path(""/mydir"");"
96147,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3127,,"        new String[] {""user.Foo""},"
96148,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3131,,"        new String[] {""-setfattr"", ""-n"", ""user.FOO"", ""/mydir""},"
96149,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3495,,"    FileStatus test = fs.getFileStatus(new Path(""/.reserved""));"
96150,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java,3547,,"      assertTrue(e.getMessage().contains(""Invalid path name /.reserved""));"
96151,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStorageStateRecovery.java,143,,"      UpgradeUtilities.createNameNodeStorageDirs(baseDirs, ""current"");"
96152,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStorageStateRecovery.java,145,,"      UpgradeUtilities.createNameNodeStorageDirs(baseDirs, ""previous"");"
96153,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStreamWithFailure.java,258,,"            + Arrays.toString(killPos) + "", dnIndex="""
96154,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSStripedOutputStreamWithFailureBase.java,241,,"        LOG.info(""runTest: dn="" + dn + "", length="" + length);"
96155,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java,91,,"          Joiner.on(""  \n"").join(new File(baseDir, ""current"").list()));"
96156,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUpgrade.java,96,,"      assertExists(new File(baseDir,""current/"" "
96157,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,91,,"  static final String NS1_NN1_ADDR   = ""ns1-nn1.example.com:8020"";"
96158,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,165,,"    conf.set(DFS_NAMESERVICES, ""nn1"");"
96159,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,166,,"    conf.set(DFSUtil.addKeySuffixes(key, ""nn1""), ""localhost:9000"");"
96160,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,222,,"    conf.set(DFS_NAMESERVICES, ""nn1,nn2"");"
96161,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,225,,"    conf.set(DFSUtil.addKeySuffixes(DFS_NAMENODE_RPC_ADDRESS_KEY, ""nn2""),"
96162,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,252,,"    conf.set(DFS_NAMESERVICES, ""ns1"");"
96163,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,417,,"    NameNode.initializeGenericKeys(newConf, ""ns2"", ""nn1"");"
96164,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,526,,"    conf.set(CommonConfigurationKeys.FS_DEFAULT_NAME_KEY, ""hdfs://ns1"");"
96165,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,535,,"          DFS_NAMENODE_RPC_ADDRESS_KEY, ""ns1"", ""ns1-nn1""),"
96166,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,576,,"    conf.set(proxyProviderKey, ""org.apache.hadoop.hdfs.server.namenode.ha."""
96167,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,683,,"    conf.set(DFS_NAMENODE_SERVICE_RPC_ADDRESS_KEY, ""hdfs://"" + NN2_ADDR);"
96168,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,687,,"    assertEquals(""Incorrect number of URIs returned"", 2, uris.size());"
96169,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,688,,"    assertTrue(""Missing URI for name service ns1"","
96170,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,725,,"    assertTrue(""Missing URI for RPC address"","
96171,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSUtil.java,727,,"    assertTrue(""Missing URI for name service ns2"","
96172,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDatanodeLayoutUpgrade.java,48,,"            ""dfs"" + File.separator + ""data"").toURI().toString());"
96173,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDeadNodeDetection.java,355,,"        .newInstance(new URI(""hdfs://127.0.0.1:2001/""), conf);"
96174,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDecommission.java,226,,"    assertEquals(""All datanodes must be alive"", numDatanodes,"
96175,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,258,,"      GenericTestUtils.assertExceptionContains(""Filesystem closed"", ioe);"
96176,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,824,,"    final Path jksPath = new Path(tmpDir.toString(), ""test.jks"");"
96177,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,826,,"        JavaKeyStoreProvider.SCHEME_NAME + ""://file"" + jksPath.toUri());"
96178,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,911,,"      provider.createKey(""key"", options);"
96179,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,959,,"      dfs.enableErasureCodingPolicy(""RS-10-4-1024k"");"
96180,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,1510,,"      fs.mkdirs(new Path(""/tmp""));"
96181,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,1603,,"          throw new IOException(""read timedout too soon in "" + delta + "" ms."","
96182,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,1883,,"          ""Superuser privilege is required"","
96183,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,2156,,"    conf.setBoolean(""dfs.namenode.snapshot.trashroot.enabled"", true);"
96184,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java,2163,,"      Path file0path = new Path(testDir, ""file-0"");"
96185,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystemWithECFile.java,90,,"    fs.mkdirs(new Path(""/ec""));"
96186,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,277,,"    final Path zoneParent = new Path(""/zones"");"
96187,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,278,,"    final Path zone1 = new Path(zoneParent, ""zone1"");"
96188,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,288,,"    final Path ezfile1 = new Path(zone1, ""file1"");"
96189,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,310,,"        createUserForTesting(""user"", new String[] { ""mygroup"" });"
96190,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,310,,"        createUserForTesting(""user"", new String[] { ""mygroup"" });"
96191,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,344,,"    final Path zone1 = new Path(""/zone1"");"
96192,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,345,,"    final Path zone1File = new Path(zone1, ""file"");"
96193,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,745,,"        assertEquals(""expected ez path"", allPath.toString(),"
96194,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,867,,"    final Path zone = new Path(""/zone"");"
96195,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1130,,"    final Path zone = new Path(prefix, ""zone"");"
96196,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1402,,"    UserGroupInformation.createRemoteUser(""JobTracker"");"
96197,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1472,,"    final Path zoneFile = new Path(zone, ""zoneFile"");"
96198,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1478,,"    final Path snap1 = fs.createSnapshot(zoneParent, ""snap1"");"
96199,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1480,,"    assertEquals(""Got unexpected ez path"", zone.toString(),"
96200,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1487,,"    final Path snap2 = fs.createSnapshot(zoneParent, ""snap2"");"
96201,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1499,,"    assertEquals(""Unexpected ez key"", TEST_KEY, ezSnap1.getKeyName());"
96202,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,1941,,"    String dummyKeyProvider = ""dummy://foo:bar@test_provider1"";"
96203,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,2004,,"    Assert.assertEquals(""Key Provider for client and namenode are different"","
96204,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,2219,,"    Path zonePath = new Path(""/TestEncryptionZone"");"
96205,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,2226,,"    final String content = ""hello world"";"
96206,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,2296,,"    HttpURLConnection namenodeConnection = returnConnection(url, ""GET"", false);"
96207,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZones.java,2297,,"    String location = namenodeConnection.getHeaderField(""Location"");"
96208,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingExerciseAPIs.java,175,,"    fs.addCachePool(new CachePoolInfo(""pool1""));"
96209,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingExerciseAPIs.java,376,,"      dos.writeBytes(""create with some content"");"
96210,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicies.java,106,,"    final Path dir = new Path(""/ec"");"
96211,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicies.java,180,,"    final Path ECFilePath = new Path(testDir, ""foo"");"
96212,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicies.java,328,,"    assertNull(""Got unexpected erasure coding policy"", policy);"
96213,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicies.java,662,,"    final Path filePath = new Path(dirPath, ""file"");"
96214,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicies.java,879,,"    assertEquals(""File should not have EC policy."", null, fileStatus"
96215,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicyWithSnapshot.java,92,,"    final Path snap1 = fs.createSnapshot(ecDirParent, ""snap1"");"
96216,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicyWithSnapshot.java,94,,"    assertEquals(""Got unexpected erasure coding policy"", ecPolicy,"
96217,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicyWithSnapshot.java,103,,"    assertNull(""Expected null erasure coding policy"","
96218,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestErasureCodingPolicyWithSnapshot.java,144,,"    final Path ecDir = new Path(""/ecdir"");"
96219,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,97,,"        aclEntry(DEFAULT, USER, ""foo"", ALL));"
96220,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,103,,"    Path childDir = new Path(parent, ""childDir"");"
96221,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,119,,"    Path childFile = new Path(parent, ""childFile"");"
96222,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,220,,"        aclEntry(ACCESS, USER, ""bar"", ALL));"
96223,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,322,,"    assertFalse(tryAccess(parentFile, ""barUser"", new String[]{""bar""}, READ));"
96224,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestExtendedAcls.java,326,,"    assertTrue(tryAccess(parentFile, ""foo"", new String[]{""fooGroup""}, READ));"
96225,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFSInputChecker.java,94,,"    checkAndEraseData(actual, 0, expected, ""Read Sanity Test"");"
96226,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java,96,,"        System.out.println(""Writing "" + mid + "" bytes to file "" + file1);"
96227,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java,96,,"        System.out.println(""Writing "" + mid + "" bytes to file "" + file1);"
96228,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java,107,,"        System.out.println(""Wrote and Closed second part of file."");"
96229,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend2.java,134,,"          System.out.println(""Good: got "" + fnfe);"
96230,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java,232,,"      fail(""This should fail."");"
96231,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend3.java,234,,"      AppendTestUtil.LOG.info(""GOOD: got an exception"", ioe);"
96232,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileAppend4.java,302,,"      Path f = new Path(""/testAppend"");"
96233,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java,193,,"    LOG.info(""stripedFileChecksum1:"" + stripedFileChecksum1);"
96234,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java,248,,"    Assert.assertTrue(""Checksum mismatches!"","
96235,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileChecksum.java,463,,"    String stripedFile3 = ecDir + ""/stripedFileChecksum3"";"
96236,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java,600,,"      System.out.println(""locations = "" + locations.locatedBlockCount());"
96237,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java,635,,"      System.out.println(""testFileCreationError2: """
96238,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java,735,,"      System.out.println(""testFileCreationNamenodeRestart: """
96239,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileCreation.java,736,,"                         + ""Created file "" + file1);"
96240,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFileStatus.java,258,,"    assertFalse(""Unexpected addtional file"", itor.hasNext());"
96241,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFsShellPermission.java,142,,"      doAsGroup = doAsUser.equals(""hdfs"")? ""supergroup"" : ""users"";"
96242,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFsShellPermission.java,175,,"        new FileEntry(""userA"", true, ""userA"", ""users"", ""755""),"
96243,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFsShellPermission.java,176,,"        new FileEntry(""userA/userB"", true, ""userB"", ""users"", targetPerm)"
96244,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFsShellPermission.java,185,,"    return genDeleteEmptyDirHelper(""-rm -r"", ""744"", ""userA"", true);"
96245,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestFsShellPermission.java,190,,"    return genDeleteEmptyDirHelper(""-rm -r"", ""700"", ""userA"", true);"
96246,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHAAuxiliaryPort.java,81,,"    URI nn0URI = new URI(""hdfs://localhost:"" +"
96247,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHAAuxiliaryPort.java,84,,"      client0.mkdirs(""/test"", null, true);"
96248,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSServerPorts.java,103,,"    FileSystem.setDefaultUri(config, ""hdfs://"" + THIS_HOST);"
96249,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLease.java,173,,"      out.writeBytes(""something"");"
96250,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLease.java,187,,"      Assert.assertTrue(pRenamed+"" not found"", fs2.exists(pRenamed));"
96251,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLease.java,188,,"      Assert.assertFalse(""has lease for ""+p, hasLease(cluster, p));"
96252,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLease.java,189,,"      Assert.assertTrue(""no lease for ""+pRenamed, hasLease(cluster, pRenamed));"
96253,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,177,,"    AppendTestUtil.LOG.info(""filestr="" + filestr);"
96254,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,184,,"    AppendTestUtil.LOG.info(""hflush"");"
96255,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,200,,"    AppendTestUtil.LOG.info(""size="" + size);"
96256,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,258,,"      AppendTestUtil.LOG.info(""leasechecker.interruptAndJoin()"");"
96257,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMiniDFSCluster.java,290,,"          DFSUtil.addKeySuffixes(DFS_NAMENODE_HTTP_ADDRESS_KEY, ""ns0"", ""nn0""));"
96258,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMiniDFSCluster.java,290,,"          DFSUtil.addKeySuffixes(DFS_NAMENODE_HTTP_ADDRESS_KEY, ""ns0"", ""nn0""));"
96259,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMiniDFSCluster.java,292,,"          DFSUtil.addKeySuffixes(DFS_NAMENODE_HTTP_ADDRESS_KEY, ""ns0"", ""nn1""));"
96260,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMiniDFSCluster.java,294,,"          DFSUtil.addKeySuffixes(DFS_NAMENODE_HTTP_ADDRESS_KEY, ""ns1"", ""nn0""));"
96261,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMissingBlocksAlert.java,155,,"    String[] racks = new String[] {""/default/rack1"", ""/default/rack1"","
96262,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMultipleNNPortQOP.java,77,,"    clusterConf.set(""ingress.port.sasl.prop.12000"", ""authentication"");"
96263,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMultipleNNPortQOP.java,78,,"    clusterConf.set(""ingress.port.sasl.prop.12100"", ""integrity"");"
96264,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMultipleNNPortQOP.java,79,,"    clusterConf.set(""ingress.port.sasl.prop.12200"", ""privacy"");"
96265,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMultipleNNPortQOP.java,104,,"      URI uriAuthPort = new URI(currentURI.getScheme() + ""://"" +"
96266,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestMultipleNNPortQOP.java,209,,"        assertEquals(""auth"", saslServer.getNegotiatedQOP());"
96267,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,206,,"    args = new String[]{""-setQuota"", ""3K"", parent.toString()};"
96268,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,216,,"    runCommand(admin, false, ""-setSpaceQuota"", ""2t"", parent.toString());"
96269,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,272,,"    runCommand(admin, new String[]{""-clrQuota"", parent.toString()}, false);"
96270,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,300,,"    runCommand(admin, false, ""-clrSpaceQuota"", parent.toString());"
96271,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,522,,"    Path tempPath = new Path(quotaDir3, ""nqdir32"");"
96272,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,1201,,"          dfs.create(new Path(parent, ""Folder1/"" + ""file"" + i),(short)1);"
96273,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,1248,,"        is(allOf(containsString(""setSpaceQuota""),"
96274,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuota.java,1265,,"        new String[] {""-setSpaceQuota"", ""1024"", dir.toString()},"
96275,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,82,,"    final String userName = ""user1"";"
96276,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,83,,"    final String groupName = ""hadoop"";"
96277,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,85,,"    final String subDir = parentDir + ""/subdir"";"
96278,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,91,,"    String[] args = new String[]{""-setQuota"", ""10"", parentDir.toString()};"
96279,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,93,,"    args = new String[]{""-setSpaceQuota"", ""128"", parentDir.toString()};"
96280,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestQuotaAllowOwner.java,99,,"      assertEquals(""Not running as new user"", userName,"
96281,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,53,,"    conf.setInt(""ipc.client.connection.maxidletime"", MAX_IDLE_TIME);"
96282,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,77,,"      Path file1 = new Path(dir1, ""file1"");"
96283,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,79,,"      System.out.println(""testFileCreationDeleteParent: """
96284,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,80,,"          + ""Created file "" + file1);"
96285,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,85,,"      Path dir2 = new Path(""/user/dir2"");"
96286,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReplaceDatanodeOnFailure.java,300,,"        LOG.info(""append "" + bytes.length + "" bytes to "" + f);"
96287,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReplication.java,232,,"    dfsClient = new DFSClient(new InetSocketAddress(""localhost"","
96288,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReservedRawPaths.java,122,,"    iip = fsd.resolvePath(null, ""/.reserved/raw"" + path, DirOp.READ);"
96289,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestReservedRawPaths.java,155,,"    final Path baseFileRaw = new Path(zone, ""/.reserved/raw/base"");"
96290,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRestartDFS.java,60,,"      fs.setOwner(rootpath, rootstatus.getOwner() + ""_XXX"", null);"
96291,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRollingUpgrade.java,94,,"      final Path foo = new Path(""/foo"");"
96292,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRollingUpgrade.java,95,,"      final Path bar = new Path(""/bar"");"
96293,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRollingUpgrade.java,104,,"        runCmd(dfsadmin, false, ""-rollingUpgrade"", ""abc"");"
96294,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestRollingUpgradeRollback.java,107,,"          dfsadmin.run(new String[] { ""-rollingUpgrade"", ""prepare"" }));"
96295,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSetTimes.java,136,,"      System.out.println(""atime on "" + file1 + "" is "" + adate + "
96296,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,66,,"    fs.mkdirs(new Path(""/sub1""));"
96297,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,67,,"    fs.mkdirs(new Path(""/Fully/QPath""));"
96298,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,203,,"        ""Allowing snapshot on "" + path + "" succeeded"", config);"
96299,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,204,,"    DFSTestUtil.FsShellRun(""-createSnapshot "" + path + "" sn1"", config);"
96300,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,204,,"    DFSTestUtil.FsShellRun(""-createSnapshot "" + path + "" sn1"", config);"
96301,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestSnapshotCommands.java,220,,"    DFSTestUtil.FsShellRun(""-deleteSnapshot "" + path + "" sn1"", config);"
96302,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java,254,,"    final Path zone1 = new Path(""/zone"" + zoneCounter.getAndIncrement());"
96303,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java,261,,"    final Path encFile1 = new Path(zone2, ""encFile"" + fileCounter"
96304,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java,345,,"    String[] argv1 = new String[]{""-rm"", ""-r"", zone1.toString()};"
96305,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestTrashWithSecureEncryptionZones.java,347,,"    assertEquals(""rm failed"", 0, res);"
96306,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestUnsetAndChangeDirectoryEcPolicy.java,117,,"    Assert.assertTrue(""Erasure coding policy mismatch!"","
96307,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestUnsetAndChangeDirectoryEcPolicy.java,122,,"    Assert.assertNull(""Replicate file should not have erasure coding policy!"","
96308,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestViewDistributedFileSystemWithMountLinks.java,87,,"      Path src = new Path(""/newFileOnRoot"");"
96309,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/UpgradeUtilities.java,161,,"        new File(namenodeStorage, ""current""), false);"
96310,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/UpgradeUtilities.java,309,,"          (list[i].getName().equals(""VERSION"") ||"
96311,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderFactory.java,140,,"    String TEST_FILE = ""/test_file"";"
96312,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/client/impl/TestBlockReaderLocal.java,174,,"            ""waitReplication: "" + e);"
96313,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,65,,"        ""/l1/d1/r1"", ""/l1/d1/r1"", ""/l1/d1/r2"", ""/l1/d1/r2"", ""/l1/d1/r2"","
96314,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,67,,"        ""/l1/d2/r3"", ""/l1/d2/r3"", ""/l1/d2/r3"", ""/l1/d2/r3"","
96315,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,69,,"        ""/l2/d3/r1"", ""/l2/d3/r2"", ""/l2/d3/r3"", ""/l2/d3/r4"", ""/l2/d3/r5"","
96316,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,71,,"        ""/l2/d4/r1"", ""/l2/d4/r1"", ""/l2/d4/r1"", ""/l2/d4/r1"", ""/l2/d4/r1"","
96317,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,76,,"        ""host1"", ""host2"", ""host3"", ""host4"", ""host5"","
96318,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,76,,"        ""host1"", ""host2"", ""host3"", ""host4"", ""host5"","
96319,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,77,,"        ""host6"", ""host7"", ""host8"", ""host9"","
96320,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,78,,"        ""host10"", ""host11"", ""host12"", ""host13"", ""host14"","
96321,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,78,,"        ""host10"", ""host11"", ""host12"", ""host13"", ""host14"","
96322,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,136,,"        (DFSTopologyNodeImpl) CLUSTER.getNode(""/l2/d3"");"
96323,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,169,,"        (DFSTopologyNodeImpl) CLUSTER.getNode(""/l1"");"
96324,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopology.java,466,,"          ""~/l2/d4"", null, StorageType.RAM_DISK);"
96325,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java,141,,"    printMemUsage(""before test1"");"
96326,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java,175,,"    LOG.info(""total time: {} avg time: {} avg trials: {}"","
96327,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java,180,,"    printMemUsage(""after test1 before test2"");"
96328,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java,196,,"    LOG.info(""total time: {} avg time: {}"", totalMs, totalMs / OP_NUM);"
96329,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/net/TestDFSNetworkTopologyPerformance.java,198,,"    printMemUsage(""after test2"");"
96330,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java,93,,"      ""authentication,integrity,privacy"");"
96331,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocol/datatransfer/sasl/TestSaslDataTransfer.java,301,,"          .thenThrow(new IOException(""Encryption enabled""));"
96332,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java,524,,"        DFSTestUtil.getLocalDatanodeInfo(""127.0.0.1"", ""h1"","
96333,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java,813,,"        ""Expected map:"" + slowPeers + "", got map:"" +"
96334,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java,939,,"      assertFalse(""Unnecessary field is set."", proto.hasErrorMsg());"
96335,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/protocolPB/TestPBHelper.java,943,,"      assertEquals(""Converted policy not equal"", response.getPolicy(),"
96336,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/TestNNWithQJM.java,72,,"        mjc.getQuorumJournalURI(""myjournal"").toString());"
96337,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumCall.java,45,,"    q.waitFor(1, 0, 0, 100000, ""test""); // wait for 1 response"
96338,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java,344,,"        GenericTestUtils.assertExceptionContains(""mock failure"", qe);"
96339,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java,359,,"        ""edits_.*"","
96340,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java,481,,"    futureThrows(new IOException(""injected"")).when(spies.get(0))"
96341,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManager.java,672,,"    File paxos0 = new File(cluster.getCurrentDir(0, JID), ""paxos"");"
96342,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/client/TestQuorumJournalManagerUnit.java,152,,"    futureThrows(new IOException(""logger failed""))"
96343,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,64,,"      12345, ""mycluster"", ""my-bp"", 0L);"
96344,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,84,,"        File.separator + ""TestJournalNode"");"
96345,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,86,,"    journalId = ""test-journalid-"" + GenericTestUtils.uniqueSequenceId();"
96346,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,90,,"      conf.set(DFSConfigKeys.DFS_JOURNALNODE_EDITS_DIR_KEY+ "".ns1"","
96347,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,91,,"          editsDir + File.separator + ""ns1"");"
96348,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,92,,"      conf.set(DFSConfigKeys.DFS_JOURNALNODE_EDITS_DIR_KEY+ "".ns2"","
96349,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/qjournal/server/TestJournalNode.java,199,,"    setupStaticHostResolution(2, ""journalnode"");"
96350,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationToken.java,104,,"        ""SomeUser"", ""JobTracker"");"
96351,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationToken.java,104,,"        ""SomeUser"", ""JobTracker"");"
96352,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java,186,,"        blockKeyUpdateInterval, blockTokenLifetime, 0, 1, ""fake-pool"", null,"
96353,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java,630,,"    BlockTokenIdentifier identifier = new BlockTokenIdentifier(""user"","
96354,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/token/block/TestBlockToken.java,747,,"        new String[] {""fake-storage-id""}, true);"
96355,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,871,,"    args.add(""-policy"");"
96356,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,876,,"      args.add(""-exclude"");"
96357,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,893,,"      args.add(""-include"");"
96358,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,1016,,"    String parameters[] = new String[] { ""-threshold"", ""0"" };"
96359,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,1185,,"    parameters = new String[] { ""-blockpools"" };"
96360,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,1244,,"    excludeHosts.add( ""datanodeY"");"
96361,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,1245,,"    excludeHosts.add( ""datanodeZ"");"
96362,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancer.java,1247,,"        new HostNameBasedNodes(new String[] {""datanodeX"", ""datanodeY"", ""datanodeZ""},"
96363,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerLongRunningTasks.java,328,,"          ""-policy"", BalancingPolicy.Node.INSTANCE.getName(),"
96364,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestBalancerLongRunningTasks.java,329,,"          ""-threshold"", ""1"""
96365,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockInfoStriped.java,109,,"    byte[] indices = (byte[]) Whitebox.getInternalState(info, ""indices"");"
96366,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java,178,,"        ""/rackA"","
96367,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java,232,,"    assertTrue(""Source of replication should be one of the nodes the block "" +"
96368,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java,233,,"        ""was on. Was: "" + pipeline[0],"
96369,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java,1493,,"    File file = new File(""test.log"");"
96370,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManager.java,1634,,"    LOG.info(""Block "" + blockInfo + "" storages: "");"
96371,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManagerSafeMode.java,156,,"    Whitebox.setInternalState(bmSafeMode, ""extension"", Integer.MAX_VALUE);"
96372,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlocksWithNotEnoughRacks.java,94,,"    final Path filePath = new Path(""/testFile"");"
96373,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlocksWithNotEnoughRacks.java,96,,"    String racks[] = {""/rack1"", ""/rack1"", ""/rack1""};"
96374,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlocksWithNotEnoughRacks.java,108,,"      String newRacks[] = {""/rack2""};"
96375,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,322,,"    HelperFunction(""/"" + Shell.appendScriptExtension(""topology-script""), 0);"
96376,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,400,,"      String uuid = ""UUID-"" + i;"
96377,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,401,,"      String ip = ""IP-"" + i;"
96378,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,412,,"      storageIDs[i] = ""storageID-"" + i;"
96379,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,420,,"    ExtendedBlock b = new ExtendedBlock(""somePoolID"", 1234);"
96380,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,517,,"    final String targetIpNotInCluster = locs[4].getIpAddr() + ""-client"";"
96381,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,865,,"      new DatanodeID(""127.0.0.1"", ""127.0.0.1"", ""someStorageID-123"","
96382,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,876,,"    twoNodes.add(entry(""127.0.0.1:23456""));"
96383,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java,898,,"    Assert.assertEquals(""Unexpected host or host in unexpected position"","
96384,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHost2NodesMap.java,37,,"        DFSTestUtil.getDatanodeDescriptor(""1.1.1.1"", ""/d1/r1""),"
96385,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHost2NodesMap.java,38,,"        DFSTestUtil.getDatanodeDescriptor(""2.2.2.2"", ""/d1/r1""),"
96386,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHost2NodesMap.java,39,,"        DFSTestUtil.getDatanodeDescriptor(""3.3.3.3"", ""/d1/r2""),"
96387,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,45,,"    s.add(entry(""127.0.0.1:12345""));"
96388,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,54,,"    s.add(entry(""127.0.0.1""));"
96389,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,63,,"    s.add(entry(""127.0.0.1:123""));"
96390,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,65,,"    Assert.assertFalse(s.match(entry(""127.0.0.1:12"")));"
96391,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,70,,"    Assert.assertFalse(s.match(entry(""127.0.0.2"")));"
96392,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java,71,,"    Assert.assertFalse(s.match(entry(""127.0.0.2:123"")));"
96393,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingInvalidateBlock.java,96,,"            .getBlockManager(), ""invalidateBlocks"");"
96394,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingReconstruction.java,176,,"    assertEquals(""Size of pendingReconstructions "", 0, pendingReconstructions.size());"
96395,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestRBWBlockInvalidation.java,182,,"          out.writeBytes(""old gs data\n"");"
96396,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java,127,,"        ""/d1/r1"","
96397,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java,129,,"        ""/d1/r2"","
96398,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicy.java,131,,"        ""/d2/r3"","
96399,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java,61,,"        ""/d1/r1/n1"","
96400,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java,63,,"        ""/d1/r1/n2"","
96401,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java,64,,"        ""/d1/r2/n3"","
96402,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java,182,,"    assertTrue(status.getErrorDescription().contains(""node group""));"
96403,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReplicationPolicyWithNodeGroup.java,183,,"    assertTrue(status.getErrorDescription().contains(""more rack(s)""));"
96404,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSequentialBlockGroupId.java,117,,"    assertThat(""Wrong BlockGrps"", blocks.size(), is(blockGrpCount));"
96405,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSequentialBlockGroupId.java,129,,"      assertThat(""BlockGrpId mismatches!"", nextBlockGrpId,"
96406,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,113,,"      dn1.getDiskMetrics().addSlowDiskForTesting(""disk1"", ImmutableMap.of("
96407,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,115,,"      dn1.getDiskMetrics().addSlowDiskForTesting(""disk2"", ImmutableMap.of("
96408,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,178,,"    addSlowDiskForTesting(""dn1"", ""disk1"","
96409,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,182,,"    addSlowDiskForTesting(""dn2"", ""disk2"","
96410,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,197,,"    assertTrue(Math.abs(reports.get(""dn1:disk1"")"
96411,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,324,,"    addSlowDiskForTesting(""dn3"", ""disk1"","
96412,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowDiskTracker.java,355,,"    addSlowDiskForTesting(""dn1"", ""disk3"","
96413,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,83,,"    tracker.addReport(""node2"", ""node1"");"
96414,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,83,,"    tracker.addReport(""node2"", ""node1"");"
96415,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,84,,"    tracker.addReport(""node3"", ""node1"");"
96416,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,123,,"    tracker.addReport(""node3"", ""node4"");"
96417,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,169,,"    tracker.addReport(""node3"", ""node5"");"
96418,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,170,,"    tracker.addReport(""node4"", ""node6"");"
96419,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSlowPeerTracker.java,194,,"      tracker.addReport(""node"" + i, ""reporter1"");"
96420,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSortLocatedBlock.java,94,,"        new ExtendedBlock(""pool"", blockID,"
96421,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestHostRestrictingAuthorizationFilter.java,56,,"    Mockito.when(request.getMethod()).thenReturn(""GET"");"
96422,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestHostRestrictingAuthorizationFilter.java,58,,"        .thenReturn(new StringBuffer(WebHdfsFileSystem.PATH_PREFIX + ""/user"" +"
96423,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestHostRestrictingAuthorizationFilter.java,61,,"    Mockito.when(request.getRemoteAddr()).thenReturn(""192.168.1.2"");"
96424,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestHostRestrictingAuthorizationFilter.java,80,,"    configs.put(AuthenticationFilter.AUTH_TYPE, ""simple"");"
96425,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,91,,"    conf.set(DFSConfigKeys.FS_DEFAULT_NAME_KEY, ""hdfs://localhost:4321/"");"
96426,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,94,,"    String user = ""TheDoctor"";"
96427,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,109,,"    conf.set(DFSConfigKeys.HADOOP_SECURITY_AUTHENTICATION, ""kerberos"");"
96428,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,153,,"    String user = ""TheNurse"";"
96429,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,187,,"    request = getMockRequest(""rogue"", null, null);"
96430,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,256,,"      Assert.fail(""bad request allowed"");"
96431,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/TestJspHelper.java,259,,"          ""Security enabled but user not authenticated by filter"","
96432,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/common/blockaliasmap/impl/TestLevelDBFileRegionAliasMap.java,77,,"    regions[3] = new FileRegion(4, new Path(""/file2""), 0, 1024, 1);"
96433,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java,215,,"    Path filePath = new Path(""/"" + METHOD_NAME + "".dat"");"
96434,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java,363,,"    assertThat(""Wrong number of corrupt blocks"","
96435,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java,365,,"    assertThat(""Wrong number of PendingDeletion blocks"","
96436,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/BlockReportTestBase.java,469,,"    assertThat(""Wrong number of PendingReplication blocks"","
96437,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java,1105,,"      throw new ReplicaNotFoundException(""Block "" + b"
96438,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java,116,,"    assertEquals(""create #1\n"", log.toString());"
96439,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java,124,,"    addNN(conf, ""ns1"", ""mock1:8020"");"
96440,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java,124,,"    addNN(conf, ""ns1"", ""mock1:8020"");"
96441,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java,125,,"    addNN(conf, ""ns2"", ""mock1:8020"");"
96442,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java,157,,"    addNN(conf, ""ns3"", ""mock1:8020"");"
96443,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java,323,,"      LOG.debug(""Running "" + GenericTestUtils.getMethodName());"
96444,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockReplacement.java,113,,"      Path fileName = new Path(""/tmp.txt"");"
96445,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java,196,,"      BlockIterator iter = volume.newBlockIterator(ctx.bpids[0], ""test"");"
96446,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockScanner.java,766,,"      assertEquals(""Did not expect bad blocks."", 0, info.badBlocks.size());"
96447,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestCachingStrategy.java,221,,"    String TEST_PATH = ""/test"";"
96448,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeErasureCodingMetrics.java,105,,"        blockGroupSize, getLongMetric(""EcReconstructionBytesRead""));"
96449,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeErasureCodingMetrics.java,107,,"        blockSize, getLongMetric(""EcReconstructionBytesWritten""));"
96450,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeErasureCodingMetrics.java,108,,"    Assert.assertEquals(""EcReconstructionRemoteBytesRead should be "","
96451,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeErasureCodingMetrics.java,109,,"        0, getLongMetricWithoutCheck(""EcReconstructionRemoteBytesRead""));"
96452,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java,343,,"        ""DN did not update its own config"","
96453,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeHotSwapVolumes.java,412,,"    Path testFile = new Path(""/test"");"
96454,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMXBean.java,71,,"          ""Hadoop:service=DataNode,name=DataNodeInfo"");"
96455,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeMetrics.java,591,,"    assertCounter(""HeartbeatsNumOps"", 1L, rb);"
96456,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeTcpNoDelay.java,195,,"      LOG.info(""Creating socket for "" + host);"
96457,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailure.java,554,,"    startNewDataNodeWithDiskFailure(new File(failedDir, ""newDir1""), false);"
96458,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java,155,,"    Path file1 = new Path(""/test1"");"
96459,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java,540,,"        ""NumFailedVolumes"");"
96460,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDatanodeRegister.java,76,,"    actor = new BPServiceActor(""test"", ""test"", INVALID_ADDR, null, mockBPOS);"
96461,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDirectoryScanner.java,651,,"      assertTrue(""Throttle appears to be engaged"","
96462,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDirectoryScanner.java,653,,"      assertTrue(""Report complier threads logged no execution time"","
96463,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDirectoryScanner.java,720,,"      LOG.info(""RATIO: "" + ratio);"
96464,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestDirectoryScanner.java,722,,"      assertTrue(""Throttle is too permissive"" + ratio, ratio >= 7f);"
96465,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestFsDatasetCacheRevocation.java,122,,"    dfs.addCachePool(new CachePoolInfo(""pool""));"
96466,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java,144,,"      assertTrue(""Expected an IO exception"", false);"
96467,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/TestAvailableSpaceVolumeChoosingPolicy.java,58,,"    @SuppressWarnings(""unchecked"")"
96468,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetCache.java,309,,"      long cmds = MetricsAsserts.getLongCounter(""BlocksCached"", dnMetrics);"
96469,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetCache.java,532,,"    dfs.addCachePool(new CachePoolInfo(""pool""));"
96470,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsDatasetImpl.java,1135,,"      Path filePath = new Path(""testData"");"
96471,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsVolumeList.java,100,,"          .setStorageID(""storage-id"")"
96472,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsVolumeList.java,136,,"    File volDir = new File(baseDir, ""volume-0"");"
96473,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestFsVolumeList.java,162,,"                StorageLocation.parse(""[RAM_DISK]""+volDir.getPath())))"
96474,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyPersistFiles.java,54,,"    Path path = new Path(""/"" + METHOD_NAME + "".dat"");"
96475,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyPersistLockedMemory.java,62,,"    Path path = new Path(""/"" + METHOD_NAME + "".dat"");"
96476,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyPersistPolicy.java,39,,"    Path path = new Path(""/"" + METHOD_NAME + "".dat"");"
96477,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyPersistReplicaPlacement.java,43,,"    Path path = new Path(""/"" + METHOD_NAME + "".dat"");"
96478,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyWriter.java,47,,"    Path path = new Path(""/"" + METHOD_NAME + "".dat"");"
96479,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyWriter.java,52,,"    waitForMetric(""RamDiskBlocksLazyPersisted"", NUM_BLOCKS);"
96480,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestLazyWriter.java,76,,"    waitForMetric(""RamDiskBlocksEvicted"", 1);"
96481,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestProvidedImpl.java,522,,"            new URI(""file:/a/b/c/d/e.file"")));"
96482,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestReservedSpaceCalculator.java,74,,"    conf.setLong(DFS_DATANODE_DU_RESERVED_KEY + "".disk"", 500);"
96483,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestReservedSpaceCalculator.java,82,,"    conf.setLong(DFS_DATANODE_DU_RESERVED_KEY + "".nvdimm"", 300);"
96484,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestReservedSpaceCalculator.java,140,,"    conf.setLong(DFS_DATANODE_DU_RESERVED_KEY + "".archive"", 1300);"
96485,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java,92,,"    waitForMetric(""RamDiskBlocksLazyPersisted"", 1);"
96486,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestScrLazyPersistFiles.java,121,,"    Path path1 = new Path(""/"" + METHOD_NAME + "".01.dat"");"
96487,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/fsdataset/impl/TestSpaceReservation.java,238,,"    Path file1 = new Path(""/"" + methodName + "".01.dat"");"
96488,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/web/TestHostRestrictingAuthorizationFilterHandler.java,52,,"    EmbeddedChannel channel = new CustomEmbeddedChannel(""127.0.0.1"", 1006,"
96489,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/web/webhdfs/TestDataNodeUGIProvider.java,93,,"        + ""?op=OPEN"""
96490,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,64,,"    planner.balanceVolumeSet(node, node.getVolumeSets().get(""SSD""), plan);"
96491,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,114,,"    DiskBalancerVolume volume30 = createVolume(""volume30"", 100, 30);"
96492,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,138,,"    DiskBalancerVolume volume10 = createVolume(""volume10"", 100, 10);"
96493,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,243,,"    DiskBalancerVolume volume1 = createVolume(""volume100"", 200, 100);"
96494,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,244,,"    DiskBalancerVolume volume2 = createVolume(""volume0-1"", 200, 0);"
96495,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/TestPlanner.java,245,,"    DiskBalancerVolume volume3 = createVolume(""volume0-2"", 200, 0);"
96496,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,139,,"            ""hdfs diskbalancer -%s %s"","
96497,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,405,,"        containsString(""Processing report command""));"
96498,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,413,,"            containsString(""Reporting top""),"
96499,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,416,,"                ""DataNode(s) benefiting from running DiskBalancer""))));"
96500,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,420,,"            containsString(""a87654a9-54c7-4693-8dd9-c9c7021dc340""),"
96501,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,421,,"            containsString(""9 volumes with node data density 1.97""))));"
96502,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,541,,"        is(allOf(containsString(""Reporting volume information for DataNode""),"
96503,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,550,,"        is(allOf(containsString(""DISK""),"
96504,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,611,,"            ""hdfs diskbalancer %s"", planArg);"
96505,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/diskbalancer/command/TestDiskBalancerCommand.java,654,,"    final String planArg = String.format(""-%s %s"", PLAN,"
96506,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,206,,"      dfs.setStoragePolicy(dir, ""HOT"");"
96507,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,218,,"      dfs.setStoragePolicy(dir, ""COLD"");"
96508,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,221,,"      Assert.assertEquals(""Movement to ARCHIVE should be successful"", 0, rc);"
96509,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,354,,"      Assert.assertEquals(""Movement to DISK should be successful"", 0, rc);"
96510,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,533,,"        Mover.Cli.getNameNodePathsToMove(conf, ""-p"", ""/foo"", ""bar"");"
96511,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,547,,"      movePaths = Mover.Cli.getNameNodePathsToMove(conf, ""-p"", ""/foo"", ""/bar"");"
96512,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestMover.java,627,,"          ""-p"", nn1 + ""/foo"", nn1 + ""/bar"", nn2 + ""/foo/bar"");"
96513,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/mover/TestStorageMover.java,442,,"          files.add(new Path(dir, ""file"" + i));"
96514,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,69,,"    UserGroupInformation.createUserForTesting(""bruce"", new String[] { });"
96515,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,71,,"    UserGroupInformation.createUserForTesting(""diana"", new String[] { });"
96516,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,121,,"      aclEntry(ACCESS, USER, ""foo"", ALL),"
96517,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,126,,"    Assert.assertTrue(path + "" should have ACLs in FileStatus!"","
96518,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,325,,"      aclEntry(ACCESS, USER, ""bar"", READ_WRITE),"
96519,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,906,,"    Path filePath = new Path(path, ""file1"");"
96520,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,998,,"    Path dirPath = new Path(path, ""dir1"");"
96521,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,1287,,"    Path bruceFile = new Path(bruceDir, ""file"");"
96522,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSAclBaseTest.java,1576,,"          ""user1"", ALL));"
96523,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,408,,"      Assert.fail(""expected IOException"");"
96524,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,449,,"        createUserForTesting(""user"", new String[] {""mygroup""});"
96525,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,449,,"        createUserForTesting(""user"", new String[] {""mygroup""});"
96526,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,450,,"    fs.setXAttr(path, ""trusted.foo"", ""1234"".getBytes());"
96527,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,450,,"    fs.setXAttr(path, ""trusted.foo"", ""1234"".getBytes());"
96528,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,485,,"      GenericTestUtils.assertExceptionContains(""Permission denied"", e);"
96529,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,491,,"    final Path childDir = new Path(path, ""child"" + pathCount);"
96530,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/FSXAttrBaseTest.java,1077,,"            fail(""getXAttr should have thrown"");"
96531,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,341,,"      if(args.size() < 2 || ! args.get(0).startsWith(""-op""))"
96532,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,381,,"      LOG.info(""--- "" + getOpName() + "" stats  ---"");"
96533,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,504,,"      LOG.info(""--- "" + getOpName() + "" inputs ---"");"
96534,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,547,,"        } else if (args.get(i).equals(""-blockSize"")) {"
96535,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,731,,"      ""-op "" + OP_OPEN_NAME + OP_USAGE_ARGS;"
96536,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,1480,,"        + "" | \n\t"" + CreateFileStats.OP_CREATE_USAGE"
96537,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NameNodeAdapter.java,280,,"          (NameNodeRpcServer)nn.getRpcServer(), ""namesystem"", fsnSpy, true);"
96538,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclConfigFlag.java,67,,"      aclEntry(DEFAULT, USER, ""foo"", READ_WRITE)));"
96539,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclTransformation.java,51,,"      ACL_SPEC_TOO_LARGE.add(aclEntry(ACCESS, USER, ""user"" + i, ALL));"
96540,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclTransformation.java,60,,"      .add(aclEntry(ACCESS, USER, ""bruce"", READ_WRITE))"
96541,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclTransformation.java,61,,"      .add(aclEntry(ACCESS, USER, ""diana"", READ_EXECUTE))"
96542,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclTransformation.java,63,,"      .add(aclEntry(ACCESS, GROUP, ""sales"", READ_EXECUTE))"
96543,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAclTransformation.java,93,,"      aclEntry(ACCESS, USER, ""clark""),"
96544,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAddBlockRetry.java,87,,"        ""clientName"","
96545,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLogger.java,255,,"      CallerContext context = new CallerContext.Builder(""setTimes"").build();"
96546,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLogger.java,257,,"      LOG.info(""Set current caller context as {}"", CallerContext.getCurrent());"
96547,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,91,,"        UserGroupInformation.createUserForTesting(""theDoctor"","
96548,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,124,,"      fail(""The operation should have failed with AccessControlException"");"
96549,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,130,,"      fail(""The operation should have failed with IOException"");"
96550,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,196,,"    Path srcDir = new Path(""/src"");"
96551,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,228,,"    assertTrue(""Unexpected log!"","
96552,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,265,,"            System.getProperty(""user.name"")+"".*cmd=allowSnapshot.*"";"
96553,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,270,,"      fail(""The operation should not have failed with Exception"");"
96554,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,315,,"    proto.addCachePool(new CachePoolInfo(""pool1"")."
96555,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLoggerWithCommands.java,408,,"    Path snapshotDirPath = new Path(""/test"");"
96556,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAuditLogs.java,190,,"    fs.setOwner(file, ""root"", null);"
96557,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestBackupNode.java,107,,"        ""127.0.0.1:0"");"
96558,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,184,,"    final String poolName = ""pool1"";"
96559,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,203,,"      GenericTestUtils.assertExceptionContains(""invalid empty cache pool name"","
96560,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,210,,"      GenericTestUtils.assertExceptionContains(""CachePoolInfo is null"", ioe);"
96561,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,270,,"      fail(""expected to get an exception when "" +"
96562,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,271,,"          ""removing a non-existent pool."");"
96563,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,313,,"    info = new CachePoolInfo(""pool2"");"
96564,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,324,,"      GenericTestUtils.assertExceptionContains(""Filesystem closed"", ioe);"
96565,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,958,,"    final String pool = ""friendlyPool"";"
96566,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,1023,,"    paths.add(new Path(""/foo/bar""));"
96567,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,1027,,"    dfs.mkdir(new Path(""/foo""), FsPermission.getDirDefault());"
96568,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,1384,,"      assertExceptionContains(""exceeds the max relative expiration"", e);"
96569,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,1401,,"      fail(""Modified a directive to exceed pool's max relative expiration"");"
96570,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCacheDirectives.java,1533,,"    dfs.addCachePool(new CachePoolInfo(""pool""));"
96571,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,247,,"      fos = fs.create(new Path(""tmpfile0""));"
96572,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,260,,"        fail(""Fault injection failed."");"
96573,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,1007,,"    conf.set(DFSConfigKeys.DFS_NAMENODE_SECONDARY_HTTP_ADDRESS_KEY, ""0.0.0.0:0"");"
96574,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,1546,,"      Mockito.doThrow(new IOException(""Injecting failure before edit rename""))"
96575,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,2393,,"    opts.parse(""-checkpoint"");"
96576,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,117,,"    assertTrue(""Didn't get new ClusterId"", (cid != null && !cid.equals("""")) );"
96577,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,141,,"    String[] argv = { ""-format"" };"
96578,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,144,,"      fail(""createNameNode() did not call System.exit()"");"
96579,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,146,,"      assertEquals(""Format should have succeeded"", 0, e.status);"
96580,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,163,,"      fail(""Failed to create dir "" + hdfsDir.getPath());"
96581,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,191,,"    String[] argv = { ""-format"", ""-force"" };"
96582,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,217,,"    String[] argv = { ""-format"", ""-force"", ""-clusterid"", myId };"
96583,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,253,,"    File version = new File(hdfsDir, ""current/VERSION"");"
96584,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestClusterId.java,254,,"    assertFalse(""Check version should not exist"", version.exists());"
96585,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java,58,,"    final String[] racks = { ""/RACK0"", ""/RACK0"", ""/RACK2"", ""/RACK3"", ""/RACK2"" };"
96586,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java,58,,"    final String[] racks = { ""/RACK0"", ""/RACK0"", ""/RACK2"", ""/RACK3"", ""/RACK2"" };"
96587,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java,58,,"    final String[] racks = { ""/RACK0"", ""/RACK0"", ""/RACK2"", ""/RACK3"", ""/RACK2"" };"
96588,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDefaultBlockPlacementPolicy.java,59,,"    final String[] hosts = { ""/host0"", ""/host1"", ""/host2"", ""/host3"", ""/host4"" };"
96589,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java,356,,"        assertTrue(""Expect "" + editFile + "" exists"", editFile.exists());"
96590,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java,800,,"          fs.mkdirs(new Path(""/test"" + i));"
96591,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLog.java,824,,"        File currentDir = new File(nameDir, ""current"");"
96592,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogJournalFailures.java,140,,"      assertTrue(re.getClassName().contains(""ExitException""));"
96593,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogRace.java,335,,"        LOG.info(""Save "" + i + "": entering safe mode"");"
96594,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEditLogRace.java,432,,"                new PermissionStatus(""test"",""test"", new FsPermission((short)00755)),"
96595,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEnabledECPolicies.java,150,,"    assertTrue(""The new default policy should be "" +"
96596,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEncryptionZoneManager.java,77,,"        CryptoProtocolVersion.ENCRYPTION_ZONES, ""test_key"");"
96597,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestEncryptionZoneManager.java,82,,"    when(mockedDir.getINodesInPath(""/first"", DirOp.READ_LINK))."
96598,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSDirAttrOp.java,64,,"    return unprotectedSetAttributes(currPerm, newPerm, ""user1"", ""user1"","
96599,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSEditLogLoader.java,491,,"      fs.mkdir(new Path(testDir), new FsPermission(""755""));"
96600,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImage.java,144,,"      out.writeBytes(""hello"");"
96601,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageStorageInspector.java,47,,"        ""/foo/current/"" + getImageFileName(123),"
96602,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithAcl.java,67,,"    AclEntry e = new AclEntry.Builder().setName(""foo"")"
96603,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,245,,"    Path sub1 = new Path(dir, ""sub1"");"
96604,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,619,,"    final Path dir1 = new Path(""/dir1"");"
96605,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,620,,"    final Path dir2 = new Path(""/dir2"");"
96606,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,623,,"    Path dira = new Path(dir1, ""dira"");"
96607,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,624,,"    Path dirx = new Path(dir1, ""dirx"");"
96608,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,625,,"    Path dirb = new Path(dira, ""dirb"");"
96609,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSImageWithSnapshot.java,680,,"    Path file1 = new Path(""/dir1/dira/dirb/diry/file1"");"
96610,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSNamesystemLockReport.java,104,,"        userfs.create(new Path(""/file"")),"
96611,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSNamesystemLockReport.java,106,,"        ""ip=/\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3},src=/file,dst=null,"" +"
96612,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSNamesystemLockReport.java,115,,"        ""perm=null\\) .*"");"
96613,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,70,,"    UserGroupInformation.createUserForTesting(""bruce"", new String[] { });"
96614,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,72,,"    UserGroupInformation.createUserForTesting(""diana"", new String[] { ""sales"" });"
96615,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,72,,"    UserGroupInformation.createUserForTesting(""diana"", new String[] { ""sales"" });"
96616,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,74,,"    UserGroupInformation.createUserForTesting(""clark"", new String[] { ""execs"" });"
96617,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,97,,"    INodeFile inodeFile = createINodeFile(inodeRoot, ""file1"", ""bruce"", ""execs"","
96618,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,104,,"    assertPermissionGranted(BRUCE, ""/file1"", READ);"
96619,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,149,,"    INodeDirectory inodeDir = createINodeDirectory(inodeRoot, ""dir1"", ""bruce"","
96620,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSPermissionChecker.java,159,,"    assertPermissionGranted(BRUCE, ""/dir1/file1"", READ_WRITE);"
96621,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java,171,,"    final Path p = new Path(dir, ""file"");"
96622,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java,354,,"    String[] ss = new String[] {""ss0"", ""ss1"", ""ss2"", ""ss3""};"
96623,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java,384,,"    assertTrue(""Recovery is not expected."", isReady);"
96624,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFileTruncate.java,695,,"    assertThat(""truncate should have triggered block recovery."","
96625,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsLimits.java,76,,"    mkdirs(""/22"", null);"
96626,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsLimits.java,77,,"    mkdirs(""/333"", null);"
96627,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsLimits.java,78,,"    mkdirs(""/4444"", null);"
96628,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,208,,"    DFSTestUtil util = new DFSTestUtil.Builder().setName(""TestFsck"")."
96629,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,219,,"    final String fileName = ""/srcdat"";"
96630,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,385,,"    DFSClient dfsClient = new DFSClient(new InetSocketAddress(""localhost"","
96631,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,441,,"    outStr = runFsck(conf, 1, false, ""/"", ""-move"");"
96632,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,673,,"    assertFalse(outStr.contains(""OPENFORWRITE""));"
96633,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,675,,"    outStr = runFsck(conf, 0, true, topDir, ""-files"", ""-blocks"","
96634,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,675,,"    outStr = runFsck(conf, 0, true, topDir, ""-files"", ""-blocks"","
96635,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,676,,"        ""-locations"", ""-openforwrite"");"
96636,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,676,,"        ""-locations"", ""-openforwrite"");"
96637,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,679,,"    assertTrue(outStr.contains(""Under Construction Block:""));"
96638,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,736,,"    assertTrue(outStr.contains(""Live_repl="" + numAllUnits));"
96639,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,741,,"        ""-locations"", ""-openforwrite"", ""-replicaDetails"");"
96640,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,936,,"    String[] racks = {""/rack1""};"
96641,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,937,,"    String[] hosts = {""host1""};"
96642,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,950,,"    final String testFile = new String(""/testfile"");"
96643,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,957,,"        ""-maintenance"", ""-blocks"", ""-replicaDetails"");"
96644,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,960,,"    assertFalse(fsckOut.contains(""(ENTERING MAINTENANCE)""));"
96645,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,961,,"    assertFalse(fsckOut.contains(""(IN MAINTENANCE)""));"
96646,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,983,,"        new String[] {""/rack2""}, new String[] {""host2""}, null, false);"
96647,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,983,,"        new String[] {""/rack2""}, new String[] {""host2""}, null, false);"
96648,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1006,,"          LOG.warn(""Unexpected exception: "" + e);"
96649,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1016,,"    assertTrue(fsckOut.contains(""(DECOMMISSIONED)""));"
96650,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1132,,"    util.createFiles(fs, ""/corruptData"", (short) 1);"
96651,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1136,,"        ""-list-corruptfileblocks"");"
96652,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1138,,"    assertTrue(outStr.contains(""has 0 CORRUPT blocks""));"
96653,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1152,,"          assertTrue(""Cannot remove file."", blockFile.delete());"
96654,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1233,,"    assertNotNull(""Failed Cluster Creation"", cluster);"
96655,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1236,,"    assertNotNull(""Failed to get FileSystem"", dfs);"
96656,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,1490,,"    String runFsckResult = runFsck(conf, 0, true, ""/"", ""-blockId"","
96657,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGenericJournalConf.java,36,,"  private static final String DUMMY_URI = ""dummy://test"";"
96658,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestGetImageServlet.java,46,,"    conf.set(DFSConfigKeys.DFS_NAMESERVICES, ""ns1"");"
96659,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestHDFSConcat.java,386,,"      Path src = new Path(dir1, ""src"");"
96660,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,83,,"        CALLED.add(""checkPermission|"" + ancestorAccess + ""|"" + parentAccess + ""|"" + access);"
96661,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,119,,"      CALLED.add(""getAttributes"");"
96662,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,136,,"          return (useDefault) ? inode.getUserName() : ""foo"";"
96663,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,267,,"        Assert.assertTrue(CALLED.contains(""checkPermission|null|null|null""));"
96664,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,306,,"    final Path userPath = new Path(""/user"");"
96665,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,307,,"    final Path authz = new Path(""/user/authz"");"
96666,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeAttributeProvider.java,308,,"    final Path authzChild = new Path(""/user/authz/child2"");"
96667,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java,153,,"      LOG.info(""Expected exception: "", iae);"
96668,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java,978,,"    testPath = ""/.reserved/.inodes/"" + INodeId.ROOT_INODE_ID;"
96669,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestINodeFile.java,1157,,"      hdfs.mkdirs(new Path(""/tmp""));"
96670,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestLeaseManager.java,126,,"    lm.addLease(""holder2"", 2);"
96671,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestLeaseManager.java,206,,"        ""user"", ""group"", FsPermission.createImmutable((short)0755));"
96672,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestLeaseManager.java,206,,"        ""user"", ""group"", FsPermission.createImmutable((short)0755));"
96673,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,90,,"      util.createFiles(fs, ""/srcdat10"");"
96674,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,96,,"      assertEquals(""Namenode has "" + badFiles.size()"
96675,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,131,,"      LOG.info(""Namenode has bad files. "" + badFiles.size());"
96676,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,132,,"      assertEquals(""Namenode has "" + badFiles.size() + "" bad files. "" +"
96677,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,290,,"      util.createFiles(fs, ""/corruptData"");"
96678,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,312,,"            LOG.info(""Deliberately removing file "" + blockFile.getName());"
96679,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,313,,"            assertTrue(""Cannot remove file."", blockFile.delete());"
96680,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,361,,"      util.createFiles(fs, ""/goodData"");"
96681,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,479,,"      util.createFiles(fs, ""/srcdat2"", (short) 1);"
96682,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,573,,"      util.createFiles(fs, ""corruptData"");"
96683,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListOpenFiles.java,116,,"        DFSTestUtil.createOpenFiles(fs, ""open-1"", 1));"
96684,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListOpenFiles.java,231,,"                  new String[] {""-listOpenFiles""}));"
96685,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestListOpenFiles.java,289,,"        DFSTestUtil.createOpenFiles(fs, new Path(""/base""), ""open-1"", 1));"
96686,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionFunctional.java,85,,"      assertGlobEquals(cd0, ""fsimage_\\d*"", "
96687,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionFunctional.java,89,,"      assertGlobEquals(cd0, ""edits_.*"","
96688,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionManager.java,78,,"    tc.addRoot(""/foo1"", NameNodeDirType.IMAGE_AND_EDITS);"
96689,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionManager.java,79,,"    tc.addImage(""/foo1/current/"" + getImageFileName(100), true);"
96690,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionManager.java,100,,"    tc.addRoot(""/foo2"", NameNodeDirType.IMAGE_AND_EDITS);"
96691,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNStorageRetentionManager.java,103,,"    tc.addImage(""/foo2/current/"" + getImageFileName(200), true);"
96692,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java,60,,"    NNThroughputBenchmark.runBenchmark(conf, new String[] {""-op"", ""all""});"
96693,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNNThroughputBenchmark.java,60,,"    NNThroughputBenchmark.runBenchmark(conf, new String[] {""-op"", ""all""});"
96694,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameEditsConfigs.java,86,,"      = FileJournalManager.matchEditLogs(new File(dir, ""current"").listFiles()); "
96695,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameEditsConfigs.java,441,,"      assertTrue(new File(nameAndEditsDir, ""current/VERSION"").exists());"
96696,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameEditsConfigs.java,605,,"      assertTrue(DFSConfigKeys.DFS_NAMENODE_NAME_DIR_KEY + "" must be trimmed "","
96697,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java,104,,"  @SuppressWarnings({ ""unchecked"" })"
96698,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java,137,,"          ""Hadoop:service=NameNode,name=NameNodeInfo"");"
96699,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java,171,,"          ""LiveNodes""));"
96700,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java,186,,"        String xferAddr = (String)liveNode.get(""xferaddr"");"
96701,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeMXBean.java,262,,"        assertTrue(statusMap.get(""active"").containsKey("
96702,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeOptionParsing.java,37,,"    opt = NameNode.parseArguments(new String[] {""-upgrade""});"
96703,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeOptionParsing.java,43,,"        ""mycid"" });"
96704,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeOptionParsing.java,49,,"        ""mycid"", ""-renameReserved"","
96705,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeOptionParsing.java,110,,"      final String[] args = {""-rollingUpgrade""};"
96706,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeReconfigure.java,80,,"    nameNode.reconfigureProperty(HADOOP_CALLER_CONTEXT_ENABLED_KEY, ""text"");"
96707,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeReconfigure.java,95,,"    assertEquals(HADOOP_CALLER_CONTEXT_ENABLED_KEY + "" has wrong value"", false,"
96708,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRecovery.java,521,,"    conf.set(DFSConfigKeys.DFS_NAMESERVICES, ""ns1"");"
96709,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRespectsBindHostKeys.java,83,,"    LOG.info(""Testing without "" + DFS_NAMENODE_RPC_BIND_HOST_KEY);"
96710,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRespectsBindHostKeys.java,99,,"    LOG.info(""Testing with "" + DFS_NAMENODE_RPC_BIND_HOST_KEY);"
96711,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNameNodeRespectsBindHostKeys.java,109,,"      assertThat(""Bind address "" + address + "" is not wildcard."","
96712,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java,210,,"    nnRpc.createSymlink(target, ""/a/b"", perm, true);"
96713,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java,233,,"    HdfsFileStatus status = nnRpc.create(src, perm, ""holder"","
96714,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java,380,,"    String name = nnRpc.createSnapshot(dir, ""snap1"");"
96715,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNamenodeRetryCache.java,396,,"    nnRpc.renameSnapshot(dir, ""snap1"", ""snap2"");"
96716,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestNetworkTopologyServlet.java,65,,"    URL url = new URL(httpUri + ""/topology"");"
96717,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestParallelImageWrite.java,81,,"      fs.setOwner(rootpath, rootstatus.getOwner() + ""_XXX"", null);"
96718,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestPathComponents.java,35,,"    testString(""/file"", new String[]{"""", ""file""});"
96719,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestPathComponents.java,36,,"    testString(""/dir/"", new String[]{"""", ""dir""});"
96720,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestPathComponents.java,39,,"    testString(""//dir/dir1//"", new String[]{"""", ""dir"", ""dir1""});"
96721,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestPathComponents.java,76,,"    assertEquals(""1/2/3"", DFSUtil.byteArray2PathString(components, 1, 3));"
96722,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestPersistentStoragePolicySatisfier.java,71,,"  private static final String COLD = ""COLD"";"
96723,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProcessCorruptBlocks.java,67,,"      final Path fileName = new Path(""/foo1"");"
96724,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,118,,"        .addUnprotectedDir(""/1/2"", true)"
96725,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,119,,"        .addUnprotectedDir(""/1/2/3"", true)"
96726,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,120,,"        .addUnprotectedDir(""/1/2/3/4"", true));"
96727,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,242,,"    assertEquals(String.format(""%s has wrong value"", FS_PROTECTED_DIRECTORIES),"
96728,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,268,,"        LOG.info(""Running {}"", testMatrixEntry);"
96729,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestProtectedDirectories.java,273,,"              testMatrixEntry + "": Testing whether "" + path + "" can be deleted"","
96730,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,113,,"    final Path foo = new Path(dir, ""foo"");"
96731,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,114,,"    Path createdFile1 = new Path(foo, ""created_file1.data"");"
96732,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,254,,"      fail(""Should have failed with QuotaByStorageTypeExceededException "");"
96733,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,256,,"      LOG.info(""Got expected exception "", t);"
96734,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,317,,"    final Path parent = new Path(dir, ""parent"");"
96735,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestQuotaByStorageType.java,318,,"    final Path child = new Path(parent, ""child"");"
96736,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,175,,"    final Path zoneParent = new Path(""/zones"");"
96737,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,176,,"    final Path zone = new Path(zoneParent, ""zone"");"
96738,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,184,,"    final Path subdir = new Path(""/dir"");"
96739,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,226,,"      LOG.info(""Expected exception caught."", expected);"
96740,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,227,,"      assertExceptionContains(""not the root of an encryption zone"", expected);"
96741,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,295,,"    Path subdir = new Path(zone, ""dir"");"
96742,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,754,,"        .createFile(fs, new Path(zoneRoot, ""file""), len, (short) 1, 0xFEED);"
96743,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,836,,"          .createFile(fs, new Path(zone, ""file8"" + i), len, (short) 1, 0xFEED);"
96744,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java,876,,"    final Path subdir = new Path(zone, ""subdir"");"
96745,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,113,,"        fileAsURI(new File(hdfsDir, ""name"")).toString());"
96746,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,289,,"        LOG.info(""--image file "" + imf.getAbsolutePath() + ""; len = "" + imf.length() + ""; expected = "" + expectedImgSize);"
96747,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,317,,"        fileAsURI(new File(hdfsDir, ""chkpt"")).toString());"
96748,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,451,,"    namenode.getNamesystem().mkdirs(""/test"","
96749,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupOptionUpgrade.java,120,,"    storage.setClusterID(""currentcid"");"
96750,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,72,,"      .put(""percentComplete"", 0.0f)"
96751,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,75,,"          .put(""name"", ""LoadingFsImage"")"
96752,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,76,,"          .put(""desc"", ""Loading fsimage"")"
96753,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,77,,"          .put(""status"", ""PENDING"")"
96754,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,77,,"          .put(""status"", ""PENDING"")"
96755,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,79,,"          .put(""steps"", Collections.emptyList())"
96756,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,119,,"          .put(""status"", ""COMPLETE"")"
96757,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,125,,"              .put(""count"", 100L)"
96758,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,126,,"              .put(""total"", 100L)"
96759,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStartupProgressServlet.java,139,,"              .put(""file"", ""file"")"
96760,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStoragePolicySummary.java,46,,"    BlockStoragePolicy hot = bsps.getPolicy(""HOT"");"
96761,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStoragePolicySummary.java,58,,"    expectedOutput.put(""HOT|DISK:3(HOT)"", 1l);"
96762,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStorageRestore.java,186,,"        new File(path1, ""current/"" + getInProgressEditsFileName(1)),"
96763,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStorageRestore.java,423,,"      assertTrue(FileUtil.chmod(nameDir2, ""755"") == 0);"
96764,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestStripedINodeFile.java,133,,"      LOG.info(""Expected exception: "", iae);"
96765,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestXAttrConfigFlag.java,63,,"    fs.setXAttr(PATH, ""user.foo"", null);"
96766,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDFSUpgradeWithHA.java,172,,"      assertTrue(fs.mkdirs(new Path(""/foo1"")));"
96767,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDFSUpgradeWithHA.java,186,,"      assertTrue(fs.mkdirs(new Path(""/foo2"")));"
96768,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDFSUpgradeWithHA.java,194,,"      assertTrue(fs.mkdirs(new Path(""/foo3"")));"
96769,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDFSUpgradeWithHA.java,198,,"          new String[]{""-force""},"
96770,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java,137,,"        .createRemoteUser(""JobTracker"");"
96771,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestEditLogTailer.java,128,,"            new PermissionStatus(""test"",""test"", new FsPermission((short)00755)),"
96772,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAConfiguration.java,70,,"    conf.set(DFSConfigKeys.DFS_HA_NAMENODE_ID_KEY, ""nn1"");"
96773,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAConfiguration.java,90,,"    Configuration conf = getHAConf(""ns1"", ""1.2.3.1"", ""1.2.3.2"");"
96774,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAConfiguration.java,90,,"    Configuration conf = getHAConf(""ns1"", ""1.2.3.1"", ""1.2.3.2"");"
96775,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAConfiguration.java,90,,"    Configuration conf = getHAConf(""ns1"", ""1.2.3.1"", ""1.2.3.2"");"
96776,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHAMetrics.java,66,,"      assertEquals(nn0.getHAState(), ""standby"");"
96777,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,133,,"    final Path test = new Path(""/test"");"
96778,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,206,,"    assertTrue(""Bad safemode status: '"" + status + ""'"", status"
96779,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,222,,"    banner(""Starting with NN0 active and NN1 standby, creating some blocks"");"
96780,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,229,,"    DFSTestUtil.createFile(fs, new Path(""/test2""), 5 * BLOCK_SIZE, (short) 3,"
96781,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,233,,"    banner(""Restarting standby"");"
96782,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,283,,"    banner(""Waiting for standby to catch up to active namespace"");"
96783,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java,348,,"    banner(""Removing the blocks without rolling the edit log"");"
96784,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestPipelinesFailover.java,158,,"      LOG.info(""Starting with NN 0 active"");"
96785,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java,1082,,"      client.setXAttr(src, ""user.key"", ""value"".getBytes(),"
96786,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java,1175,,"    AtMostOnceOp op = new CreateOp(client, ""/testfile"");"
96787,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestRetryCacheWithHA.java,1233,,"            setPool(""pool"")."
96788,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyInProgressTail.java,126,,"      cluster.getNameNode(0).getRpcServer().mkdirs(""/test"","
96789,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyInProgressTail.java,151,,"      cluster.getNameNode(0).getRpcServer().mkdirs(""/test2"","
96790,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestStandbyInProgressTail.java,250,,"    cluster.getNameNode(0).getRpcServer().mkdirs(""/test3"","
96791,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestUpdateBlockTailing.java,126,,"    assertEquals(""Global Generation stamps on NN0 and """
96792,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestUpdateBlockTailing.java,186,,"            + ""NN1 should be equal"","
96793,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,312,,"    assertGauge(""NumDecomLiveDataNodes"", 0, getMetrics(NS_METRICS));"
96794,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,313,,"    assertGauge(""NumLiveDataNodes"", DATANODE_COUNT, getMetrics(NS_METRICS));"
96795,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,416,,"        ""CorruptBlocks"", 0L, 500);"
96796,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,420,,"    assertGauge(""LowRedundancyBlocks"", 0L, rb);"
96797,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,421,,"    assertGauge(""PendingReplicationBlocks"", 0L, rb); // Deprecated metric"
96798,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,422,,"    assertGauge(""PendingReconstructionBlocks"", 0L, rb);"
96799,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,425,,"    assertGauge(""LowRedundancyReplicatedBlocks"", 0L, rb);"
96800,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,426,,"    assertGauge(""CorruptReplicatedBlocks"", 0L, rb);"
96801,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,427,,"    assertGauge(""HighestPriorityLowRedundancyReplicatedBlocks"", 0L, rb);"
96802,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,430,,"    assertGauge(""LowRedundancyECBlockGroups"", 0L, rb);"
96803,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,431,,"    assertGauge(""CorruptECBlockGroups"", 0L, rb);"
96804,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,432,,"    assertGauge(""HighestPriorityLowRedundancyECBlocks"", 0L, rb);"
96805,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,775,,"    assertCounter(""GetBlockLocations"", 0L, getMetrics(NN_METRICS));"
96806,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,877,,"    long lastCkptTime = MetricsAsserts.getLongGauge(""LastCheckpointTime"","
96807,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,881,,"    assertGauge(""LastWrittenTransactionId"", 4L, getMetrics(NS_METRICS));"
96808,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,882,,"    assertGauge(""TransactionsSinceLastCheckpoint"", 4L, getMetrics(NS_METRICS));"
96809,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,883,,"    assertGauge(""TransactionsSinceLastLogRoll"", 4L, getMetrics(NS_METRICS));"
96810,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,961,,"    assertGauge(""NumActiveClients"", 0L, getMetrics(NS_METRICS));"
96811,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,962,,"    assertGauge(""NumFilesUnderConstruction"", 0L, getMetrics(NS_METRICS));"
96812,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,966,,"    output2.writeBytes(""Some test data"");"
96813,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,65,,"    UserGroupInformation.createUserForTesting(""bruce"", new String[] { });"
96814,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,67,,"    UserGroupInformation.createUserForTesting(""diana"", new String[] { });"
96815,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,177,,"    Path filePath = new Path(path, ""file1"");"
96816,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,178,,"    Path subdirPath = new Path(path, ""subdir1"");"
96817,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,705,,"      assertEquals(""Reference count should remain same"", 1,"
96818,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestAclWithSnapshot.java,741,,"          ""testNewUser"", ALL));"
96819,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,118,,"    createFile(sub1foo, ""file1"");"
96820,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,198,,"    final Path dir1 = new Path(""/dir1"");"
96821,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,199,,"    final Path dir2 = new Path(""/dir2"");"
96822,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,202,,"    Path dira = new Path(dir1, ""dira"");"
96823,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,203,,"    Path dirx = new Path(dir1, ""dirx"");"
96824,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,204,,"    Path dirb = new Path(dira, ""dirb"");"
96825,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFSImageWithOrderedSnapshotDeletion.java,259,,"    Path file1 = new Path(""/dir1/dira/dirb/diry/file1"");"
96826,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java,90,,"    Path path = new Path(""/test"");"
96827,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java,105,,"    fs.delete(new Path(""/test/test""), true);"
96828,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java,257,,"    final Path level0A = new Path(""/level_0_A"");"
96829,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java,272,,"    final String flumeFileName = ""flume.log"";"
96830,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOpenFilesWithSnapshot.java,273,,"    final String hbaseFileName = ""hbase.log"";"
96831,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOrderedSnapshotDeletion.java,79,,"    final Path sub0 = new Path(snapshottableDir, ""sub0"");"
96832,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestOrderedSnapshotDeletion.java,83,,"    final Path sub1 = new Path(snapshottableDir, ""sub1"");"
96833,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,91,,"  static private final Path file1 = new Path(sub1, ""file1"");"
96834,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,92,,"  static private final Path file2 = new Path(sub1, ""file2"");"
96835,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,131,,"    final Path foo = new Path(abc, ""foo"");"
96836,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,138,,"          + "" is snapshottable and already has snapshots"");"
96837,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,147,,"    final Path bar = new Path(xyz, ""bar"");"
96838,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,215,,"    System.out.println(""DiffList is "" + diffReport.toString());"
96839,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,366,,"    final Path sdir1 = new Path(""/dir1"");"
96840,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,367,,"    final Path sdir2 = new Path(""/dir2"");"
96841,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,372,,"    final Path bar2 = new Path(foo, ""bar2"");"
96842,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,390,,"        ""foo/bar"");"
96843,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,400,,"        ""foo/bar2"");"
96844,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,483,,"        ""foo/bar3"");"
96845,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,673,,"    final Path sdir3 = new Path(""/dir3"");"
96846,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,679,,"    final Path bar1_dir1 = new Path(foo_dir1, ""bar1"");"
96847,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,704,,"        ""foo/bar1"");"
96848,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,893,,"    SnapshotTestHelper.createSnapshot(hdfs, sdir2, ""s22"");"
96849,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,913,,"    SnapshotTestHelper.createSnapshot(hdfs, sdir3, ""s333"");"
96850,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,966,,"    SnapshotTestHelper.createSnapshot(hdfs, sdir2, ""s2222"");"
96851,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,1344,,"    final Path dir2file = new Path(sdir2, ""file"");"
96852,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,1490,,"    final Path foo_dir2 = new Path(sdir2, ""foo2"");"
96853,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,1619,,"    final Path test = new Path(""/test"");"
96854,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,1620,,"    final Path dir1 = new Path(test, ""dir1"");"
96855,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java,1621,,"    final Path dir2 = new Path(test, ""dir2"");"
96856,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java,309,,"    Path dir = new Path(""/dir"");"
96857,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java,310,,"    Path sub = new Path(dir, ""sub"");"
96858,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java,311,,"    Path subFile = new Path(sub, ""file"");"
96859,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshot.java,364,,"    Path file0 = new Path(dir, ""file0"");"
96860,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotBlocksMap.java,206,,"    Path foo = new Path(""/foo"");"
96861,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotBlocksMap.java,239,,"    final Path bar = new Path(foo, ""bar"");"
96862,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,122,,"    Path file0 = new Path(sub, ""file0"");"
96863,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,123,,"    Path file1 = new Path(sub, ""file1"");"
96864,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,281,,"    Path newFileAfterS0 = new Path(subsub, ""newFile"");"
96865,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,503,,"    hdfs.setOwner(metaChangeDir, ""unknown"", ""unknown"");"
96866,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,554,,"      fail(""should throw FileNotFoundException"");"
96867,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,556,,"      GenericTestUtils.assertExceptionContains(""File does not exist: """
96868,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,1133,,"    final Path bar = new Path(foo, ""bar"");"
96869,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDeletion.java,1162,,"    final Path st = new Path(""/st"");"
96870,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,134,,"    Path file10 = new Path(modifyDir, ""file10"");"
96871,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,135,,"    Path file11 = new Path(modifyDir, ""file11"");"
96872,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,136,,"    Path file12 = new Path(modifyDir, ""file12"");"
96873,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,137,,"    Path file13 = new Path(modifyDir, ""file13"");"
96874,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,138,,"    Path link13 = new Path(modifyDir, ""link13"");"
96875,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,140,,"    Path file15 = new Path(modifyDir, ""file15"");"
96876,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,207,,"    Path subsub1 = new Path(sub1, ""subsub1"");"
96877,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,208,,"    Path subsubsub1 = new Path(subsub1, ""subsubsub1"");"
96878,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,270,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1"")),"
96879,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,272,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1/file10"")),"
96880,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,274,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1/file11"")),"
96881,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,276,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1/file13"")),"
96882,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,278,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1/link13"")),"
96883,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,280,,"            DFSUtil.string2Bytes(""subsub1/subsubsub1/file15"")));"
96884,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,409,,"            DFSUtil.string2Bytes(""subsub1/file11"")),"
96885,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,413,,"            DFSUtil.string2Bytes(""subsub1/link13"")),"
96886,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,593,,"    Path file20 = new Path(subSubSub, ""file20"");"
96887,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,840,,"    final Path sdir1 = new Path(root, ""dir1"");"
96888,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,841,,"    final Path sdir2 = new Path(root, ""dir2"");"
96889,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,842,,"    final Path foo = new Path(sdir1, ""foo"");"
96890,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,843,,"    final Path bar = new Path(foo, ""bar"");"
96891,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,865,,"        new DiffReportEntry(DiffType.RENAME, DFSUtil.string2Bytes(""dir1/foo""),"
96892,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,885,,"    final Path fileInFoo = new Path(foo, ""file"");"
96893,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1313,,"      final Path path = new Path(root, ""dir"" + i);"
96894,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1330,,"            DFSUtil.string2Bytes(""dir1/file1"")),"
96895,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1332,,"            DFSUtil.string2Bytes(""dir1/file2"")),"
96896,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1334,,"            DFSUtil.string2Bytes(""dir1/file3"")),"
96897,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1342,,"        new DiffReportEntry(DiffType.MODIFY, DFSUtil.string2Bytes(""dir3"")),"
96898,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1344,,"            DFSUtil.string2Bytes(""dir3/file1"")),"
96899,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1348,,"            DFSUtil.string2Bytes(""dir3/file3"")));"
96900,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotDiffReport.java,1367,,"    Path targetDir = new Path(root, ""dir4"");"
96901,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotMetrics.java,84,,"    assertGauge(""SnapshottableDirectories"", 0, getMetrics(NS_METRICS));"
96902,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotMetrics.java,85,,"    assertCounter(""AllowSnapshotOps"", 0L, getMetrics(NN_METRICS));"
96903,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotMetrics.java,138,,"    assertGauge(""Snapshots"", 0, getMetrics(NS_METRICS));"
96904,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotMetrics.java,139,,"    assertCounter(""CreateSnapshotOps"", 0L, getMetrics(NN_METRICS));"
96905,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotRename.java,63,,"  private final Path file1 = new Path(sub1, ""file1"");"
96906,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotRename.java,127,,"    hdfs.renameSnapshot(sub1, ""s3"", ""s22"");"
96907,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotRename.java,296,,"    hdfs.createSnapshot(dir2, ""snap1"");"
96908,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestSnapshotRename.java,297,,"    Path file2 = new Path(dir2, ""file2"");"
96909,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/sps/TestStoragePolicySatisfierWithStripedFile.java,150,,"      String barDir = ""/bar"";"
96910,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/sps/TestStoragePolicySatisfierWithStripedFile.java,158,,"      final String fooFile = ""/bar/foo"";"
96911,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/sps/TestStoragePolicySatisfierWithStripedFile.java,193,,"      client.setStoragePolicy(barDir, ""COLD"");"
96912,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/startupprogress/TestStartupProgress.java,65,,"    Step loadingEditsFile = new Step(""file"", 1000L);"
96913,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/startupprogress/TestStartupProgress.java,154,,"    startupProgress.setFile(LOADING_FSIMAGE, ""file1"");"
96914,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/startupprogress/TestStartupProgress.java,183,,"    startupProgress.setFile(LOADING_FSIMAGE, ""file2"");"
96915,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/top/window/TestRollingWindowManager.java,117,,"    rollingWindowManager.recordMetric(0, ""op1"", users[0], 3);"
96916,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/top/window/TestRollingWindowManager.java,138,,"    rollingWindowManager.recordMetric(t, ""op2"", users[0], 4);"
96917,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/top/window/TestRollingWindowManager.java,175,,"    String[] ops = {""op1"", ""op2"", ""op3"", ""op4""};"
96918,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/sps/TestExternalStoragePolicySatisfier.java,108,,"  private static final String COLD = ""COLD"";"
96919,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/sps/TestExternalStoragePolicySatisfier.java,193,,"    getConf().setLong(""dfs.block.size"", DEFAULT_BLOCK_SIZE);"
96920,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/sps/TestExternalStoragePolicySatisfier.java,1364,,"      fs.satisfyStoragePolicy(new Path(""/root""));"
96921,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/sps/TestExternalStoragePolicySatisfier.java,1437,,"        Path filePath = new Path(""/file"" + i);"
96922,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java,157,,"        ExtendedBlockId key = new ExtendedBlockId(blockId, ""test_bp1"");"
96923,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitCache.java,936,,"          ""testReleaseSlotReuseDomainSocket_client"");"
96924,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/shortcircuit/TestShortCircuitLocalRead.java,282,,"      Path file1 = fs.makeQualified(new Path(""filelocal.dat""));"
96925,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,502,,"          is(allOf(containsString(""Rack:""), containsString(""/d1/r1""))));"
96926,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,620,,"      assertEquals(0, ToolRunner.run(dfsAdmin, new String[] {""-report""}));"
96927,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,779,,"          new String[]{""-listOpenFiles""}));"
96928,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,822,,"          new String[] {""-listOpenFiles"", ""-path"", ""/tmp/files/a""}));"
96929,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,943,,"        new String[]{""-allowSnapshot"", dirPath.toString()}));"
96930,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,946,,"        new String[]{""-disallowSnapshot"", dirPath.toString()}));"
96931,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdmin.java,1039,,"        new String[]{""-setBalancerBandwidth"", ""10000""}));"
96932,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,137,,"    int exitCode = admin.run(new String[] {""-safemode"", ""enter""});"
96933,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,137,,"    int exitCode = admin.run(new String[] {""-safemode"", ""enter""});"
96934,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,139,,"    String message = ""Safe mode is ON in.*"";"
96935,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,170,,"    exitCode = admin.run(new String[] {""-saveNamespace""});"
96936,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,233,,"    int exitCode = admin.run(new String[] {""-restoreFailedStorage"", ""check""});"
96937,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,233,,"    int exitCode = admin.run(new String[] {""-restoreFailedStorage"", ""check""});"
96938,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,235,,"    String message = ""restoreFailedStorage is set to false for.*"";"
96939,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,239,,"    exitCode = admin.run(new String[] {""-restoreFailedStorage"", ""true""});"
96940,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,244,,"    exitCode = admin.run(new String[] {""-restoreFailedStorage"", ""false""});"
96941,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,257,,"        + ""restoreFailedStorage failed for.*"" + newLine;"
96942,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,323,,"    int exitCode = admin.run(new String[] {""-refreshNodes""});"
96943,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,367,,"    int exitCode = admin.run(new String[] {""-setBalancerBandwidth"", ""10""});"
96944,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,418,,"    int exitCode = admin.run(new String[] {""-metasave"", ""dfs.meta""});"
96945,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,418,,"    int exitCode = admin.run(new String[] {""-metasave"", ""dfs.meta""});"
96946,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,435,,"    String message = ""Created metasave file dfs.meta in the log directory"""
96947,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,471,,"    int exitCode = admin.run(new String[] {""-refreshServiceAcl""});"
96948,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,514,,"    int exitCode = admin.run(new String[] {""-refreshUserToGroupsMappings""});"
96949,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,561,,"        new String[] {""-refreshSuperUserGroupsConfiguration""});"
96950,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,613,,"    int exitCode = admin.run(new String[] {""-refreshCallQueue""});"
96951,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSAdminWithHA.java,655,,"    int exitCode = admin.run(new String[] {""-finalizeUpgrade""});"
96952,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,66,,"  private static final String NSID = ""ns1"";"
96953,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,95,,"    conf.set(DFSConfigKeys.DFS_HA_NAMENODE_ID_KEY, ""nn1"");"
96954,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,100,,"            DFSConfigKeys.DFS_NAMENODE_RPC_ADDRESS_KEY, NSID, ""nn2""),"
96955,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,152,,"    assertEquals(-1, runTool(""-ns""));"
96956,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,164,,"    assertEquals(0, runTool(""-getServiceState"", ""nn1""));"
96957,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,296,,"    assertEquals(-1, runTool(""-failover"", ""nn1"", ""nn2""));"
96958,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdmin.java,323,,"    assertEquals(0, runTool(""-failover"", ""nn1"", ""nn2"", ""--forcefence""));"
96959,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,94,,"    assertEquals(0, runTool(""-getServiceState"", ""nn1""));"
96960,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,94,,"    assertEquals(0, runTool(""-getServiceState"", ""nn1""));"
96961,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,95,,"    assertEquals(0, runTool(""-getServiceState"", ""nn2""));"
96962,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,108,,"    assertEquals(0, runTool(""-transitionToActive"", ""nn1""));"
96963,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,110,,"    assertEquals(0, runTool(""-transitionToStandby"", ""nn1""));"
96964,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,119,,"    assertEquals(0, runTool(""-transitionToObserver"", ""nn2""));"
96965,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,172,,"    assertEquals(-1, runTool(""-failover"", ""nn2"", ""nn1""));"
96966,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSHAAdminMiniCluster.java,214,,"    assertEquals(0, runTool(""-failover"", ""nn1"", ""nn2"", ""--forcefence""));"
96967,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDFSZKFailoverController.java,105,,"            .addNN(new MiniDFSNNTopology.NNConf(""nn2"")"
96968,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDebugAdmin.java,106,,"    DFSTestUtil.createFile(fs, new Path(""/bar""), 1234, (short) 1, 0xdeadbeef);"
96969,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDebugAdmin.java,112,,"        new String[] {""verifyMeta"", ""-block"", blockFile.getAbsolutePath()}));"
96970,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestDebugAdmin.java,145,,"        runCmd(new String[] {""computeMeta""}));"
96971,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,103,,"    int ret = runCommandWithParams(""-verifyClusterSetup"");"
96972,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,104,,"    assertEquals(""Return value of the command is not successful"", 2, ret);"
96973,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,157,,"    assertEquals(""Return value of the command is successful"", 0, ret);"
96974,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,158,,"    assertTrue(""Result of cluster topology verify "" +"
96975,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,159,,"        ""should be logged correctly"", out.toString().contains("
96976,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,161,,"    assertTrue(""Error output should be empty"", err.toString().isEmpty());"
96977,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestECAdmin.java,184,,"    final int ret = runCommandWithParams(""-enablePolicy"", ""-policy"","
96978,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestGetConf.java,293,,"    verifyAddresses(conf, TestType.NAMENODE, false, ""localhost:1000"");"
96979,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestGetConf.java,297,,"    conf.set(DFS_NAMENODE_BACKUP_ADDRESS_KEY,""localhost:1001"");"
96980,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,77,,"    final Path foo = new Path(""/foo"");"
96981,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,94,,"        2, ""File/Directory does not exist: /fooz"");"
96982,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,105,,"        + ""/foo"", 0, ""The storage policy of "" + fs.getUri() + ""/foo:\n"""
96983,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,107,,"    DFSTestUtil.toolRun(admin, ""-getStoragePolicy -path /foo/bar"", 0,"
96984,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,108,,"        ""The storage policy of "" + bar.toString() + "":\n"" + cold);"
96985,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestStoragePolicyCommands.java,130,,"        ""The storage policy of "" + foo.toString() + "" is unspecified"");"
96986,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestViewFileSystemOverloadSchemeWithDFSAdmin.java,161,,"        new String[] {""-fs"", defaultFSURI.toString(), ""-safemode"", ""enter"" });"
96987,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestViewFileSystemOverloadSchemeWithDFSAdmin.java,161,,"        new String[] {""-fs"", defaultFSURI.toString(), ""-safemode"", ""enter"" });"
96988,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/TestViewFileSystemOverloadSchemeWithDFSAdmin.java,161,,"        new String[] {""-fs"", defaultFSURI.toString(), ""-safemode"", ""enter"" });"
96989,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/TestOfflineEditsViewer.java,113,,"    assertEquals(0, runOev(edits, editsParsedXml, ""xml"", false));"
96990,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineEditsViewer/TestOfflineEditsViewer.java,115,,"    assertEquals(0, runOev(editsParsedXml, editsReparsed, ""binary"", false));"
96991,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java,456,,"        originalFsimage.getAbsolutePath(), ""-o"", ""-"", ""-p"", ""FileDistribution"","
96992,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java,457,,"        ""-maxSize"", ""512"", ""-step"", ""8""});"
96993,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java,457,,"        ""-maxSize"", ""512"", ""-step"", ""8""});"
96994,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java,457,,"        ""-maxSize"", ""512"", ""-step"", ""8""});"
96995,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewer.java,597,,"      URL url = new URL(""http://localhost:"" + port +"
96996,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java,130,,"        NetUtils.createSocketAddr(""localhost:0""))) {"
96997,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java,133,,"      URL url = new URL(""http://localhost:"" + port"
96998,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java,136,,"      connection.setRequestMethod(""GET"");"
96999,./TargetProjects/hadoop/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOfflineImageViewerForContentSummary.java,140,,"      URI uri = new URI(""webhdfs://localhost:"" + String.valueOf(port));"

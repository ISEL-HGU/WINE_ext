103000,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java,858,,"        throw new FileNotFoundException(""File does not exist: "" + filename);"
103001,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSDirectory.java,1097,,"            +""failed to remove ""+src+"" because it does not exist"");"
103002,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSEditLogOp.java,198,,"        throw new IOException(""Incorrect data format. """
103003,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSImageSerialization.java,197,,"  @SuppressWarnings(""deprecation"")"
103004,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java,1047,,"          "" to "" + target);"
103005,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java,1483,,"            + src + "" on client "" + clientMachine);"
103006,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java,1617,,"            ""failed to create file "" + src + "" for "" + holder +"
103007,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java,2475,,"      final String message = ""DIR* NameSystem.internalReleaseLease: """
103008,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/FSNamesystem.java,2843,,"                                 ""BLOCK* NameSystem.registerDatanode: """
103009,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.java,91,,"    final String exclude = request.getParameter(""exclude"") != null"
103010,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.java,93,,"    final String filter = request.getParameter(""filter"") != null"
103011,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/ListPathsServlet.java,95,,"    final boolean recur = request.getParameter(""recursive"") != null"
103012,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java,811,,"                         +src+"" for ""+clientName+"" at ""+clientMachine);"
103013,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java,815,,"                            + MAX_PATH_LENGTH + "" characters, "" + MAX_PATH_DEPTH + "" levels."");"
103014,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java,815,,"                            + MAX_PATH_LENGTH + "" characters, "" + MAX_PATH_DEPTH + "" levels."");"
103015,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NameNode.java,1579,,"      StartupOption.BACKUP.getName() + ""] | ["" +"
103016,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeFsck.java,677,,"      if (totalBlocks > 0)        res.append("" ("" + ((float) (numMinReplicatedBlocks * 100) / (float) totalBlocks) + "" %)"");"
103017,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java,177,,"          + ""\""> "";"
103018,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java,255,,"        sorterField = ""name"";"
103019,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java,257,,"        sorterOrder = ""ASC"";"
103020,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/server/namenode/NamenodeJspHelper.java,622,,"                + ""> Configured <br>Capacity ("" + diskByteStr + "") <th """
103021,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,364,,"      printUsage(""-safemode"");"
103022,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,465,,"      ""\t["" + SetQuotaCommand.USAGE + ""]\n"" +"
103023,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,465,,"      ""\t["" + SetQuotaCommand.USAGE + ""]\n"" +"
103024,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,643,,"      printUsage(""-upgradeProgress"");"
103025,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,833,,"      System.err.println(""Usage: java DFSAdmin"""
103026,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,883,,"    } else if (""-deleteBlockPool"".equals(cmd)) {"
103027,./TargetProjects/hadoop-hdfs/src/java/org/apache/hadoop/hdfs/tools/DFSAdmin.java,902,,"      System.err.println(""           [""+SetQuotaCommand.USAGE+""]"");"
103028,./TargetProjects/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataTransferProtocol.java,97,,"    FiTestUtil.LOG.info(""Running "" + methodName + "" ..."");"
103029,./TargetProjects/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataTransferProtocol.java,97,,"    FiTestUtil.LOG.info(""Running "" + methodName + "" ..."");"
103030,./TargetProjects/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataTransferProtocol2.java,132,,"    FiTestUtil.LOG.info(""Running "" + methodName + "" ..."");"
103031,./TargetProjects/hadoop-hdfs/src/test/aop/org/apache/hadoop/hdfs/server/datanode/TestFiDataTransferProtocol2.java,132,,"    FiTestUtil.LOG.info(""Running "" + methodName + "" ..."");"
103032,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/TestFcHdfsSymlink.java,89,,"    Path link      = new Path(testBaseDir1(), ""linkToFile"");"
103033,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/TestFcHdfsSymlink.java,104,,"    Path file = new Path(testBaseDir1(), ""file"");"
103034,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/TestFcHdfsSymlink.java,153,,"    fc.setOwner(linkToFile, ""user"", ""group"");"
103035,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/TestFcHdfsSymlink.java,153,,"    fc.setOwner(linkToFile, ""user"", ""group"");"
103036,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/TestGlobPaths.java,68,,"      String[] files = new String[] { USER_DIR + ""/a"", USER_DIR + ""/a/b"" };"
103037,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/fs/permission/TestStickyBit.java,57,,"    Path file = new Path(p, ""foo"");"
103038,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/DFSTestUtil.java,433,,"          + "" Live = ""+live.size()+"" Expected = ""+expectedLive"
103039,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/MiniDFSCluster.java,519,,"      conf.set(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY, ""127.0.0.1:0"");"
103040,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/MiniDFSCluster.java,1280,,"      conf.set(""dfs.datanode.address"", addr.getAddress().getHostAddress() + "":"""
103041,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestCrcCorruption.java,78,,"      util.createFiles(fs, ""/srcdat"", replFactor);"
103042,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSClientRetries.java,333,,"      LOG.info(""Test 1 succeeded! Time spent: "" + (timestamp2-timestamp)/1000.0 + "" sec."");"
103043,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSFinalize.java,62,,"      assertTrue(new File(nameNodeDirs[i],""current"").isDirectory());"
103044,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSRollback.java,68,,"        assertTrue(new File(baseDirs[i],""current"").isDirectory());"
103045,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSRollback.java,85,,"      assertFalse(new File(baseDirs[i],""previous"").isDirectory());"
103046,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,63,,"    new Path(System.getProperty(""test.build.data"",""/tmp""))"
103047,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,100,,"    assertTrue(""Not a HDFS: ""+fs.getUri(),"
103048,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,189,,"      args[0] = ""-du"";"
103049,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,195,,"        System.err.println(""Exception raised from DFSShell.run "" +"
103050,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,315,,"      Path root = new Path(""/nonexistentfile"");"
103051,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,321,,"      argv[0] = ""-cat"";"
103052,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,329,,"      argv[0] = ""-rm"";"
103053,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,338,,"          (returned.lastIndexOf(""No such file or directory"") != -1));"
103054,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,361,,"      argv[0] = ""-ls"";"
103055,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,393,,"      Path testFile = new Path(""/testfile"");"
103056,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,488,,"      argv[2] = dstFs.getUri().toString() + ""/furi"";"
103057,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,512,,"      runCmd(shell, ""-chgrp"", ""-R"", ""herbivores"", dstFs.getUri().toString() +""/*"");"
103058,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,512,,"      runCmd(shell, ""-chgrp"", ""-R"", ""herbivores"", dstFs.getUri().toString() +""/*"");"
103059,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,514,,"      runCmd(shell, ""-chown"", ""-R"", "":reptiles"", dstFs.getUri().toString() + ""/"");"
103060,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,623,,"        assertTrue(""Copying failed."", f1.isFile());"
103061,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,628,,"        File sub = new File(localroot, ""sub"");"
103062,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSShell.java,757,,"      LOG.info(""RUN: ""+args[0]+"" exit="" + exitCode);"
103063,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSStorageStateRecovery.java,128,,"      UpgradeUtilities.createNameNodeStorageDirs(baseDirs, ""current"");"
103064,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSStorageStateRecovery.java,130,,"      UpgradeUtilities.createNameNodeStorageDirs(baseDirs, ""previous"");"
103065,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSUpgrade.java,71,,"      assertTrue(new File(baseDirs[i],""current"").isDirectory());"
103066,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSUpgradeFromImage.java,78,,"    String dataDir = System.getProperty(""test.build.data"", ""build/test/data"");"
103067,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDFSUtil.java,102,,"    assertEquals(""nn1"", it.next().toString());"
103068,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestDefaultNameNodePort.java,33,,"    assertEquals(NameNode.getAddress(""foo"").getPort(),"
103069,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestFSInputChecker.java,89,,"    checkAndEraseData(actual, 0, expected, ""Read Sanity Test"");"
103070,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestFileCreation.java,328,,"      System.out.println(""locations = "" + locations.locatedBlockCount());"
103071,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestFileCreation.java,362,,"      System.out.println(""testFileCreationError2: """
103072,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestFileCreation.java,431,,"      System.out.println(""testFileCreationNamenodeRestart: """
103073,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestFileCreation.java,432,,"                         + ""Created file "" + file1);"
103074,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestHDFSServerPorts.java,106,,"    FileSystem.setDefaultUri(config, ""hdfs://"" + THIS_HOST);"
103075,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,154,,"    AppendTestUtil.LOG.info(""filestr="" + filestr);"
103076,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,160,,"    AppendTestUtil.LOG.info(""size="" + size);"
103077,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,164,,"    AppendTestUtil.LOG.info(""hflush"");"
103078,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestLeaseRecovery2.java,168,,"      AppendTestUtil.LOG.info(""leasechecker.interruptAndJoin()"");"
103079,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestQuota.java,83,,"      String[] args = new String[]{""-setQuota"", ""3"", parent.toString()};"
103080,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestQuota.java,87,,"      runCommand(admin, false, ""-setSpaceQuota"", ""2t"", parent.toString());"
103081,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestQuota.java,140,,"      runCommand(admin, new String[]{""-clrQuota"", parent.toString()}, false);"
103082,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestQuota.java,168,,"      runCommand(admin, false, ""-clrSpaceQuota"", parent.toString());"
103083,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestQuota.java,377,,"      Path tempPath = new Path(quotaDir3, ""nqdir32"");"
103084,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,52,,"    conf.setInt(""ipc.client.connection.maxidletime"", MAX_IDLE_TIME);"
103085,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,56,,"    conf.setBoolean(""dfs.support.append"", true);"
103086,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,69,,"      Path file1 = new Path(dir1, ""file1"");"
103087,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,71,,"      System.out.println(""testFileCreationDeleteParent: """
103088,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,72,,"          + ""Created file "" + file1);"
103089,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRenameWhileOpen.java,77,,"      Path dir2 = new Path(""/user/dir2"");"
103090,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestReplication.java,159,,"    dfsClient = new DFSClient(new InetSocketAddress(""localhost"","
103091,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestRestartDFS.java,57,,"      fs.setOwner(rootpath, rootstatus.getOwner() + ""_XXX"", null);"
103092,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/TestSetTimes.java,122,,"      System.out.println(""atime on "" + file1 + "" is "" + adate + "
103093,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/UpgradeUtilities.java,155,,"        new File(namenodeStorage, ""current""));"
103094,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/UpgradeUtilities.java,288,,"      if (nodeType == DATA_NODE && list[i].getName().equals(""VERSION"")) {"
103095,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/security/TestDelegationToken.java,88,,"        ""SomeUser"", ""JobTracker"");"
103096,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java,596,,"      throw new ReplicaNotFoundException(""Block "" + b"
103097,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/SimulatedFSDataset.java,686,,"      throw new IOException(""No such Block "" + b );  "
103098,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestBlockReport.java,111,,"    Path filePath = new Path(""/"" + METHOD_NAME + "".dat"");"
103099,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java,90,,"      new File(dataDir, ""data""+(2*i+1)).setExecutable(true);"
103100,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java,132,,"    assertTrue(""Couldn't chmod local vol"", dn1Vol1.setExecutable(false));"
103101,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestDataNodeVolumeFailureReporting.java,151,,"    assertCounter(""VolumeFailures"", 1L, "
103102,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/datanode/TestSimulatedFSDataset.java,94,,"      assertTrue(""Expected an IO exception"", false);"
103103,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,314,,"      if(args.size() < 2 || ! args.get(0).startsWith(""-op""))"
103104,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,354,,"      LOG.info(""--- "" + getOpName() + "" stats  ---"");"
103105,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,468,,"      LOG.info(""--- "" + getOpName() + "" inputs ---"");"
103106,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,587,,"      ""-op "" + OP_OPEN_NAME + OP_USAGE_ARGS;"
103107,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/NNThroughputBenchmark.java,1198,,"        + "" | \n\t"" + CreateFileStats.OP_CREATE_USAGE"
103108,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestBackupNode.java,142,,"      LOG.error(""Error in TestBackupNode:"", e);"
103109,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestBlocksWithNotEnoughRacks.java,86,,"    final Path filePath = new Path(""/testFile"");"
103110,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestBlocksWithNotEnoughRacks.java,88,,"    String racks[] = {""/rack1"", ""/rack1"", ""/rack1""};"
103111,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestBlocksWithNotEnoughRacks.java,100,,"      String newRacks[] = {""/rack2""};"
103112,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,143,,"  @SuppressWarnings(""deprecation"")"
103113,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,545,,"    long fsimageLength = new File(new File(nameDirs.get(0).getPath(), ""current""), "
103114,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,583,,"                     new File(dir, ""lastcheckpoint.tmp""));"
103115,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCheckpoint.java,620,,"    conf.set(DFSConfigKeys.DFS_NAMENODE_HTTP_ADDRESS_KEY, ""0.0.0.0:0"");  "
103116,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestCorruptReplicaInfo.java,85,,"      assertEquals(""Number of corrupt blocks not returning correctly"","
103117,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestEditLogRace.java,265,,"        LOG.info(""Save "" + i + "": entering safe mode"");"
103118,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestEditLogRace.java,344,,"                new PermissionStatus(""test"",""test"", new FsPermission((short)00755)),"
103119,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestFsLimits.java,102,,"    addChildWithName(""333"", null);"
103120,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestFsLimits.java,103,,"    addChildWithName(""4444"", null);"
103121,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,89,,"    DFSTestUtil util = new DFSTestUtil(""TestFsck"", 20, 3, 8*1024);"
103122,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,99,,"      final String fileName = ""/srcdat"";"
103123,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestFsck.java,457,,"      util.createFiles(fs, ""/corruptData"", (short) 1);"
103124,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,72,,"      util.createFiles(fs, ""/srcdat10"");"
103125,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,78,,"      assertTrue(""Namenode has "" + badFiles.size()"
103126,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,89,,"        if (blocks[idx].getName().startsWith(""blk_"") &&"
103127,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,120,,"      LOG.info(""Namenode has bad files. "" + badFiles.size());"
103128,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,276,,"      util.createFiles(fs, ""/corruptData"");"
103129,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,343,,"      util.createFiles(fs, ""/goodData"");"
103130,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestListCorruptFileBlocks.java,455,,"      util.createFiles(fs, ""/srcdat2"", (short) 1);"
103131,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestNameNodeResourceChecker.java,44,,"    baseDir = new File(conf.get(""hadoop.tmp.dir""));"
103132,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestParallelImageWrite.java,81,,"      fs.setOwner(rootpath, rootstatus.getOwner() + ""_XXX"", null);"
103133,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,98,,"        fileAsURI(new File(hdfsDir, ""name"")).toString());"
103134,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,237,,"        LOG.info(""--image file "" + imf.getAbsolutePath() + ""; len = "" + imf.length() + ""; expected = "" + expectedImgSize);"
103135,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,264,,"        fileAsURI(new File(hdfsDir, ""chkpt"")).toString());"
103136,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestStartup.java,382,,"    namenode.getNamesystem().mkdirs(""/test"","
103137,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/TestStartupOptionUpgrade.java,97,,"    storage.setClusterID(""currentcid"");"
103138,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/server/namenode/metrics/TestNameNodeMetrics.java,245,,"    assertCounter(""GetBlockLocations"", 0L, getMetrics(NN_METRICS));"
103139,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/tools/TestGetConf.java,250,,"    verifyAddresses(conf, TestType.NAMENODE, false, ""localhost:1000"");"
103140,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/tools/TestGetConf.java,254,,"    conf.set(DFS_NAMENODE_BACKUP_ADDRESS_KEY,""localhost:1001"");"
103141,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/tools/offlineImageViewer/TestOIVCanReadOldVersions.java,123,,"    assertEquals(""Version "" + hadoopVersion + "": Same number of total blocks"", "
103142,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/util/TestGSet.java,51,,"        LightWeightGSet.LOG.info(""GOOD: getting "" + e, e);"
103143,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/hdfs/util/TestGSet.java,210,,"    println(""DONE "" + test.stat());"
103144,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/security/TestRefreshUserMappings.java,157,,"    config.set(userKeyHosts,""127.0.0.1"");"
103145,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/security/TestRefreshUserMappings.java,186,,"      System.err.println(""auth for "" + ugi1.getUserName() + "" failed"");"
103146,./TargetProjects/hadoop-hdfs/src/test/hdfs/org/apache/hadoop/tools/TestDelegationTokenFetcher.java,81,,"      DelegationTokenFetcher.main(new String[] { ""-fs"", uri.toString(),"
103147,./TargetProjects/hadoop-hdfs/src/test/unit/org/apache/hadoop/hdfs/server/datanode/TestBlockRecovery.java,175,,"      LOG.debug(""Running "" + GenericTestUtils.getMethodName());"
103148,./TargetProjects/hadoop-hdfs/src/test/unit/org/apache/hadoop/hdfs/server/namenode/TestNNLeaseRecovery.java,122,,"      LOG.debug(""Running "" + GenericTestUtils.getMethodName());    "
103149,./TargetProjects/hadoop-hdfs/src/test/unit/org/apache/hadoop/hdfs/server/namenode/TestNNLeaseRecovery.java,128,,"      new PermissionStatus(""test"", ""test"", new FsPermission((short)0777));"
103150,./TargetProjects/hadoop-hdfs/src/test/unit/org/apache/hadoop/hdfs/server/namenode/TestNNLeaseRecovery.java,150,,"      spy(new Path(""/"" + GenericTestUtils.getMethodName() + ""_test.dat""));    "
103151,./TargetProjects/hadoop-mapreduce/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapreduce/GridMixRunner.java,189,,"      sb.append("" org.apache.hadoop.mapreduce."" +"
103152,./TargetProjects/hadoop-mapreduce/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapreduce/GridMixRunner.java,196,,"      sb.append(""-indir "").append(indir).append("" "");"
103153,./TargetProjects/hadoop-mapreduce/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapreduce/GridMixRunner.java,197,,"      sb.append(""-outdir "").append(outdir).append("" "");"
103154,./TargetProjects/hadoop-mapreduce/src/benchmarks/gridmix2/src/java/org/apache/hadoop/mapreduce/GridMixRunner.java,198,,"      sb.append(""-r "").append(numReducers);"
103155,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,74,,"    conf.set(""mapred.queue.names"",""default"");"
103156,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,110,,"      JobStatus.PREP, 4, 4, ""default"", ""user"");"
103157,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,115,,"    expectedStrings.put(MAP, ""attempt_test_0001_m_000001_0 on tt1"");"
103158,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,116,,"    expectedStrings.put(REDUCE, ""attempt_test_0001_r_000001_0 on tt1"");"
103159,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,118,,"      taskTrackerManager, scheduler, ""tt1"", expectedStrings);"
103160,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,121,,"    expectedStrings.put(MAP, ""attempt_test_0001_m_000002_0 on tt2"");"
103161,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,122,,"    expectedStrings.put(REDUCE, ""attempt_test_0001_r_000002_0 on tt2"");"
103162,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,124,,"      taskTrackerManager, scheduler, ""tt2"", expectedStrings);"
103163,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,128,,"    List<Task> task3 = scheduler.assignTasks(tracker(""tt3""));"
103164,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,235,,"        + queueName + "" queue"","
103165,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,306,,"      ""attempt_test_0001_m_000002_0 on tt1"");"
103166,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,309,,"    taskTrackerManager.finishTask(""attempt_test_0001_m_000001_0"", j1);"
103167,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,321,,"      ""attempt_test_0002_m_000001_0 on tt1"");"
103168,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,331,,"      ""attempt_test_0002_m_000002_0 on tt1"");"
103169,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,413,,"    String[] qs = {""default"", ""qAZ1"", ""qAZ2"", ""qAZ3"", ""qAZ4""};"
103170,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,492,,"    taskTrackerManager.addTaskTracker(""tt4"");"
103171,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,500,,"    taskTrackerManager.addTaskTracker(""tt5"");"
103172,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,564,,"    taskTrackerManager.addQueues(new String[]{""defaultXYZM""});"
103173,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,629,,"    expectedStrings.put(REDUCE,""attempt_test_0002_r_000001_0 on tt2"");"
103174,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,693,,"    expectedStrings.put(REDUCE,""attempt_test_0002_r_000001_0 on tt1"");"
103175,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1010,,"        ""attempt_test_0001_m_00000"" + (i + 1) + ""_0 on tt1"");"
103176,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1105,,"    assertEquals(infoStrings[7], ""Used capacity: 0 (0.0% of Capacity)"");"
103177,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1106,,"    assertEquals(infoStrings[8], ""Running tasks: 0"");"
103178,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1174,,"    assertEquals(infoStrings[7], ""Used capacity: 1 (100.0% of Capacity)"");"
103179,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1175,,"    assertEquals(infoStrings[8], ""Running tasks: 1"");"
103180,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1176,,"    assertEquals(infoStrings[9], ""Active users:"");"
103181,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacityScheduler.java,1177,,"    assertEquals(infoStrings[10], ""User 'u1': 1 (100.0% of used capacity)"");"
103182,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestCapacitySchedulerConf.java,154,,"    conf.setProperties(""default"",prp);"
103183,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestContainerQueue.java,240,,"      new QueueSchedulingContext(""rt.sch"", a, -1, -1);"
103184,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestContainerQueue.java,242,,"      new QueueSchedulingContext(""rt.gta"", b, -1, -1);"
103185,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestContainerQueue.java,254,,"      new QueueSchedulingContext(""rt.sch.prod"", c, -1, -1);"
103186,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestContainerQueue.java,256,,"      new QueueSchedulingContext(""rt.sch.misc"", d, -1, -1);"
103187,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestRefreshOfQueues.java,218,,"        queues[1].getQueueName(), ""user"");"
103188,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestRefreshOfQueues.java,228,,"      taskTrackerManager, scheduler, ""tt1"","
103189,./TargetProjects/hadoop-mapreduce/src/contrib/capacity-scheduler/src/test/org/apache/hadoop/mapred/TestRefreshOfQueues.java,242,,"      taskTrackerManager, scheduler, ""tt2"","
103190,./TargetProjects/hadoop-mapreduce/src/contrib/dynamic-scheduler/src/test/org/apache/hadoop/mapred/TestDynamicScheduler.java,87,,"    setSpending(""queue1"", 1.0f);"
103191,./TargetProjects/hadoop-mapreduce/src/contrib/dynamic-scheduler/src/test/org/apache/hadoop/mapred/TestDynamicScheduler.java,88,,"    setSpending(""queue2"", 2.0f);"
103192,./TargetProjects/hadoop-mapreduce/src/contrib/dynamic-scheduler/src/test/org/apache/hadoop/mapred/TestPriorityScheduler.java,76,,"    setSpending(""queue1"", 1.0f);"
103193,./TargetProjects/hadoop-mapreduce/src/contrib/dynamic-scheduler/src/test/org/apache/hadoop/mapred/TestPriorityScheduler.java,77,,"    setSpending(""queue2"", 2.0f);"
103194,./TargetProjects/hadoop-mapreduce/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/servers/HadoopLocationWizard.java,339,,"              .equalsIgnoreCase(""yes"");"
103195,./TargetProjects/hadoop-mapreduce/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/servers/HadoopLocationWizard.java,362,,"                  String.format(""%s:%s"", jobTrackerHost, jobTrackerPort);"
103196,./TargetProjects/hadoop-mapreduce/src/contrib/eclipse-plugin/src/java/org/apache/hadoop/eclipse/servers/HadoopLocationWizard.java,502,,"    text.setData(""hProp"", prop);"
103197,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/FairScheduler.java,396,,"          eventLog.log(""INFO"", ""Can't assign another MAP to "" + trackerName);"
103198,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/FairSchedulerServlet.java,186,,"        out.printf(""<td>%d</td>"", pool.getJobs().size());"
103199,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/java/org/apache/hadoop/mapred/FairSchedulerServlet.java,259,,"          out.printf(""<td>%s</td>\n"", DATE_FORMAT.format("
103200,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,586,,"    out.println(""<?xml version=\""1.0\""?>"");"
103201,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,587,,"    out.println(""<allocations>""); "
103202,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,589,,"    out.println(""<pool name=\""poolA\"">"");"
103203,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,591,,"    out.println(""<minReduces>2</minReduces>"");"
103204,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,592,,"    out.println(""</pool>"");"
103205,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,594,,"    out.println(""<pool name=\""poolB\"">"");"
103206,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,595,,"    out.println(""<minMaps>2</minMaps>"");"
103207,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,608,,"    out.println(""<minSharePreemptionTimeout>60</minSharePreemptionTimeout>"");"
103208,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,617,,"    out.println(""</user>"");"
103209,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,623,,"    out.println(""</allocations>""); "
103210,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,634,,"    assertEquals(1, poolManager.getAllocation(""poolA"", TaskType.MAP));"
103211,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,636,,"    assertEquals(2, poolManager.getAllocation(""poolB"", TaskType.MAP));"
103212,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,638,,"    assertEquals(2, poolManager.getAllocation(""poolC"", TaskType.MAP));"
103213,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,640,,"    assertEquals(0, poolManager.getAllocation(""poolD"", TaskType.MAP));"
103214,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,642,,"    assertEquals(0, poolManager.getAllocation(""poolE"", TaskType.MAP));"
103215,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,650,,"    assertEquals(10, poolManager.getUserMaxJobs(""user1""));"
103216,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,651,,"    assertEquals(5, poolManager.getUserMaxJobs(""user2""));"
103217,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,664,,"    assertNull(scheduler.assignTasks(tracker(""tt1"")));"
103218,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,714,,"    checkAssignment(""tt1"", ""attempt_test_0001_m_000000_0 on tt1"");"
103219,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,715,,"    checkAssignment(""tt1"", ""attempt_test_0001_r_000000_0 on tt1"");"
103220,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,716,,"    checkAssignment(""tt1"", ""attempt_test_0002_m_000000_0 on tt1"");"
103221,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,717,,"    checkAssignment(""tt1"", ""attempt_test_0002_r_000000_0 on tt1"");"
103222,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,718,,"    checkAssignment(""tt2"", ""attempt_test_0001_m_000001_0 on tt2"");"
103223,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,718,,"    checkAssignment(""tt2"", ""attempt_test_0001_m_000001_0 on tt2"");"
103224,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,719,,"    checkAssignment(""tt2"", ""attempt_test_0002_r_000001_0 on tt2"");"
103225,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,839,,"    checkAssignment(""tt2"", ""attempt_test_0001_r_000001_0 on tt2"");"
103226,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,840,,"    checkAssignment(""tt2"", ""attempt_test_0002_m_000001_0 on tt2"");"
103227,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,867,,"    taskTrackerManager.finishTask(""tt2"", ""attempt_test_0001_m_000001_0"");"
103228,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,882,,"    checkAssignment(""tt2"", ""attempt_test_0001_m_000003_0 on tt2"");"
103229,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,883,,"    checkAssignment(""tt2"", ""attempt_test_0001_r_000003_0 on tt2"");"
103230,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,884,,"    checkAssignment(""tt2"", ""attempt_test_0002_m_000003_0 on tt2"");"
103231,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1057,,"    checkAssignment(""tt3"", ""attempt_test_0002_m_000002_0 on tt3"");"
103232,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1093,,"    Pool defaultPool = scheduler.getPoolManager().getPool(""default"");"
103233,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1136,,"    checkAssignment(""tt1"", ""attempt_test_0003_m_000000_0 on tt1"");"
103234,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1137,,"    checkAssignment(""tt1"", ""attempt_test_0003_r_000000_0 on tt1"");"
103235,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1348,,"    checkAssignment(""tt2"", ""attempt_test_0001_m_000002_0 on tt2"");"
103236,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1349,,"    checkAssignment(""tt2"", ""attempt_test_0001_r_000002_0 on tt2"");"
103237,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1771,,"    checkAssignment(""tt1"", ""attempt_test_0001_m_000001_0 on tt1"");"
103238,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1772,,"    checkAssignment(""tt1"", ""attempt_test_0001_r_000001_0 on tt1"");"
103239,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1811,,"    checkAssignment(""tt2"", ""attempt_test_0002_m_000000_0 on tt2"");"
103240,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1813,,"    checkAssignment(""tt2"", ""attempt_test_0002_r_000000_0 on tt2"");"
103241,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1910,,"    out.println(""<fairSharePreemptionTimeout>60</fairSharePreemptionTimeout>"");"
103242,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1916,,"    Pool pool1 = scheduler.getPoolManager().getPool(""pool1"");"
103243,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1917,,"    Pool pool2 = scheduler.getPoolManager().getPool(""pool2"");"
103244,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1918,,"    Pool pool3 = scheduler.getPoolManager().getPool(""pool3"");"
103245,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,1945,,"    checkAssignment(""tt4"", ""attempt_test_0002_m_000000_0 on tt4"");"
103246,./TargetProjects/hadoop-mapreduce/src/contrib/fairscheduler/src/test/org/apache/hadoop/mapred/TestFairScheduler.java,2288,,"          {""rack2.node2""}"
103247,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/JobSubmitter.java,87,,"          LOG.warn(""Failed to submit "" + job.getJob().getJobName() + "" as "" "
103248,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/java/org/apache/hadoop/mapred/gridmix/StressJobFactory.java,266,,"        LOG.debug(System.currentTimeMillis() + "" Overloaded is """
103249,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestCompressionEmulationUtils.java,113,,"        new Path(System.getProperty(""test.build.data"", ""/tmp"")).makeQualified("
103250,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestCompressionEmulationUtils.java,113,,"        new Path(System.getProperty(""test.build.data"", ""/tmp"")).makeQualified("
103251,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestDistCacheEmulation.java,447,,"                 + ""wrong."", sortedFileSizes.length,"
103252,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestGridmixSubmission.java,283,,"        assertTrue(""Mismatched "" + type + "" input bytes "" +"
103253,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/org/apache/hadoop/mapred/gridmix/TestUserResolve.java,141,,"    assertEquals(""user0"", rslv.getTargetUgi(ugi1).getUserName());"
103254,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/system/org/apache/hadoop/mapred/gridmix/TestEmulationOfHDFSAndLocalFSDCFiles.java,60,,"       ""-D"", MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN + ""=false"","
103255,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/system/org/apache/hadoop/mapred/gridmix/TestEmulationOfLocalFSDCFiles.java,58,,"       ""-D"", MRJobConfig.JOB_CANCEL_DELEGATION_TOKEN + ""=false"","
103256,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/system/org/apache/hadoop/mapred/gridmix/TestGridMixDataGeneration.java,95,,"        ""-D"", GridMixConfig.GRIDMIX_DISTCACHE_ENABLE + ""=false"", "
103257,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/system/org/apache/hadoop/mapred/gridmix/test/system/UtilsForGridmix.java,432,,"        LOG.error(""No traces found in "" + tracesPath.toString() + "" path."");"
103258,./TargetProjects/hadoop-mapreduce/src/contrib/gridmix/src/test/system/org/apache/hadoop/mapred/gridmix/test/system/UtilsForGridmix.java,432,,"        LOG.error(""No traces found in "" + tracesPath.toString() + "" path."");"
103259,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/java/org/apache/hadoop/raid/BlockFixer.java,114,,"      throw new ClassNotFoundException(""cannot construct blockfixer"", e);"
103260,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/java/org/apache/hadoop/raid/RaidNode.java,1576,,"      throw new ClassNotFoundException(""cannot construct blockfixer"", e);"
103261,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/java/org/apache/hadoop/raid/RaidShell.java,162,,"      System.err.println(""Usage: java RaidShell"" + "
103262,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/java/org/apache/hadoop/raid/RaidShell.java,365,,"                 blockNo + ""/"" + fileLengthInBlocks + "", stripe "" + stripe +"
103263,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/hdfs/TestRaidDfs.java,85,,"    conf.set(""xor"".equals(erasureCode) ? RaidNode.RAID_LOCATION_KEY :"
103264,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/hdfs/TestRaidDfs.java,86,,"             RaidNode.RAIDRS_LOCATION_KEY, ""/destraid"");"
103265,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/hdfs/server/namenode/TestBlockPlacementPolicyRaid.java,56,,"  String[] rack2 = {""/rack2""};"
103266,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,136,,"    Path file1 = new Path(""/user/dhruba/raidtest/file1"");"
103267,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,145,,"    localConf.set(RaidNode.RAID_LOCATION_KEY, ""/destraid"");"
103268,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,146,,"    localConf.setInt(""raid.blockfix.interval"", 1000);"
103269,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,148,,"      localConf.set(""raid.blockfix.classname"","
103270,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,149,,"                    ""org.apache.hadoop.raid.LocalBlockFixer"");"
103271,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,152,,"                    ""org.apache.hadoop.raid.DistBlockFixer"");"
103272,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,154,,"    localConf.setLong(""raid.blockfix.filespertask"", 2L);"
103273,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,167,,"      assertEquals(""no corrupt files expected"", 0, corruptFiles.length);"
103274,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,168,,"      assertEquals(""filesFixed() should return 0 before fixing files"","
103275,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,178,,"      assertEquals(""file not corrupted"", 1, corruptFiles.length);"
103276,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,179,,"      assertEquals(""wrong file corrupted"","
103277,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,192,,"      assertEquals(""file not fixed"", 1, cnode.blockFixer.filesFixed());"
103278,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,216,,"    LOG.info(""Test "" + testName + "" started."");"
103279,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,569,,"                        ""<property> "" +"
103280,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,573,,"                          ""</description> "" + "
103281,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixer.java,574,,"                        ""</property> "" +"
103282,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestBlockFixerDistConcurrency.java,126,,"      assertTrue(""file not fixed"","
103283,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidHar.java,117,,"                        ""<property> "" +"
103284,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidHar.java,121,,"                          ""</description> "" + "
103285,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidHar.java,122,,"                        ""</property> "" +"
103286,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,75,,"    conf.set(RaidNode.RAID_LOCATION_KEY, ""/destraid"");"
103287,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,122,,"        ""<srcPath prefix=\"""" + path + ""\""> "" +"
103288,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,136,,"             ""<property> "" +"
103289,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,138,,"               ""<value>"" + srcReplication + ""</value> "" +"
103290,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,138,,"               ""<value>"" + srcReplication + ""</value> "" +"
103291,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,140,,"               ""</description> "" +"
103292,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,141,,"             ""</property> "" +"
103293,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,272,,"    cb.addPolicy(""policy1"", ""/user/dhruba/raidtest"", (short)1, targetReplication, metaReplication, stripeLength);"
103294,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidNode.java,272,,"    cb.addPolicy(""policy1"", ""/user/dhruba/raidtest"", (short)1, targetReplication, metaReplication, stripeLength);"
103295,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidPurge.java,141,,"                        ""<property> "" +"
103296,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidPurge.java,143,,"                          ""<value>"" + targetReplication + ""</value> "" +"
103297,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidPurge.java,145,,"                          ""</description> "" + "
103298,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidPurge.java,146,,"                        ""</property> "" +"
103299,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidShell.java,207,,"                        ""<property> "" +"
103300,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidShell.java,211,,"                          ""</description> "" +"
103301,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidShell.java,212,,"                        ""</property> "" +"
103302,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidShellFsck.java,141,,"      ""      <property> "" +"
103303,./TargetProjects/hadoop-mapreduce/src/contrib/raid/src/test/org/apache/hadoop/raid/TestRaidShellFsck.java,460,,"    assertTrue(""fsck should return 0, but returns "" +"
103304,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/PipeMapRed.java,221,,"      LOG.error(""configuration exception"", e);"
103305,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java,405,,"                                             ""Optional."", ""spec"", 1, false);"
103306,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java,405,,"                                             ""Optional."", ""spec"", 1, false);"
103307,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/java/org/apache/hadoop/streaming/StreamJob.java,572,,"    System.out.println(""  -D "" + MRJobConfig.MAP_SPECULATIVE + ""=true"");"
103308,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestMultipleCachefiles.java,85,,"        ""-jobconf"", strNamenode,"
103309,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestRawBytesStreaming.java,59,,"      ""-jobconf"", ""mapreduce.task.files.preserve.failedtasks=true"","
103310,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamDataProtocol.java,73,,"      ""-jobconf"", ""stream.map.output.field.separator=."","
103311,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamJob.java,40,,"    dummyArgs.add(""-input""); dummyArgs.add(""dummy"");"
103312,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamXmlMultipleRecords.java,116,,"      LOG.warn(""No perl; skipping test."");"
103313,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingAsDifferentUser.java,76,,"            ""stream.tmpdir="" + System.getProperty(""test.build.data"", ""/tmp"") };"
103314,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingAsDifferentUser.java,76,,"            ""stream.tmpdir="" + System.getProperty(""test.build.data"", ""/tmp"") };"
103315,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingBadRecords.java,174,,"      ""-jobconf"", ""mapreduce.task.skip.start.attempts=""+attSkip,"
103316,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingExitStatus.java,58,,"      ""-jobconf"", ""mapreduce.task.files.preserve.failedtasks=true"","
103317,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingKeyValue.java,80,,"      ""-jobconf"", MRJobConfig.PRESERVE_FAILED_TASK_FILES + ""=true"", "
103318,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingOutputKeyValueTypes.java,95,,"    map = ""org.apache.hadoop.mapred.lib.IdentityMapper"";"
103319,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingOutputKeyValueTypes.java,105,,"    args.add(""-numReduceTasks"");"
103320,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingOutputKeyValueTypes.java,122,,"    reduce = ""cat"";"
103321,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingSeparator.java,77,,"      ""-jobconf"", ""mapreduce.task.files.preserve.failedtasks=true"","
103322,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingStatus.java,156,,"      ""-jobconf"", MRJobConfig.NUM_MAPS + ""=1"","
103323,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestStreamingTaskLog.java,55,,"      ""-jobconf"", ""mapred.job.tracker="" + ""localhost:"" + mr.getJobTrackerPort(),"
103324,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestSymLink.java,74,,"        ""-jobconf"", strNamenode,"
103325,./TargetProjects/hadoop-mapreduce/src/contrib/streaming/src/test/org/apache/hadoop/streaming/TestUlimit.java,61,,"      ""-jobconf"", MRJobConfig.NUM_MAPS + ""=1"","
103326,./TargetProjects/hadoop-mapreduce/src/contrib/vertica/src/java/org/apache/hadoop/vertica/VerticaRecord.java,190,,"          throw new ClassCastException(""Cannot cast """
103327,./TargetProjects/hadoop-mapreduce/src/contrib/vertica/src/java/org/apache/hadoop/vertica/VerticaRecord.java,267,,"        throw new RuntimeException(""Unknown type value "" + types.get(i));"
103328,./TargetProjects/hadoop-mapreduce/src/examples/org/apache/hadoop/examples/pi/math/ArithmeticProgression.java,53,,"            + this + "", that="" + that);"
103329,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/CompletedJobStatusStore.java,273,,"        LOG.warn(""Could not read ["" + jobId + ""] job status : "" + ex, ex);"
103330,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/IFile.java,206,,"                              "" for "" + key);"
103331,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/IsolationRunner.java,69,,"      LOG.info(""Task "" + taskid + "" reporting done."");"
103332,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JSPUtil.java,284,,"        sb.append(""<tr>"");"
103333,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JSPUtil.java,287,,"        sb.append(""<td>"");"
103334,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JSPUtil.java,348,,"            + refresh + ""\"">"" + jobid + ""</a></td>"" + ""<td id=\""priority_"""
103335,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JSPUtil.java,349,,"            + rowId + ""\"">"" + jobpri + ""</td>"" + ""<td id=\""user_"" + rowId"
103336,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JSPUtil.java,355,,"            + ""</td><td>"" + desiredMaps + ""</td><td>"" + completedMaps"
103337,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JobInProgress.java,1306,,"      LOG.info(""Cannot create task split for "" + profile.getJobID());"
103338,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JobInProgress.java,1897,,"               + ""Job details are missing."");"
103339,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/JobTracker.java,1676,,"        LOG.info(""Started plug-in "" + p + "" of type "" + p.getClass());"
103340,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/MapOutputFile.java,112,,"    return lDirAlloc.getLocalPathToRead(TaskTracker.OUTPUT + ""/spill"""
103341,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/MapTask.java,274,,"    @SuppressWarnings(""unchecked"")"
103342,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/ReduceTask.java,298,,"     @SuppressWarnings(""unchecked"")"
103343,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/Task.java,1303,,"  @SuppressWarnings(""unchecked"")"
103344,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/TaskGraphServlet.java,105,,"        , ymargin - 1, ""black"" );"
103345,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/TaskTracker.java,3306,,"      LOG.warn(""Error from unknown child task: ""+taskid+"". Ignored."");"
103346,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/TaskTracker.java,3772,,"      LOG.debug(""sendMapFile called for "" + mapId + "" to reduce "" + reduce);"
103347,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/join/CompositeRecordReader.java,73,,"  @SuppressWarnings(""unchecked"") // Generic array assignment"
103348,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/lib/MultipleInputs.java,79,,"    String mappers = conf.get(""mapreduce.input.multipleinputs.dir.mappers"");"
103349,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/lib/MultipleOutputs.java,458,,"    @SuppressWarnings({""unchecked""})"
103350,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/pipes/Submitter.java,404,,"                  ""class"");"
103351,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapred/tools/MRAdmin.java,117,,"      System.err.println(""Usage: java MRAdmin"" + "" [-refreshServiceAcl]"");"
103352,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/JobSubmitter.java,322,,"  @SuppressWarnings(""unchecked"")"
103353,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java,253,,"    taskSummary.append(""\t\t"").append(ts.numFailedSetups);"
103354,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java,299,,"    printAnalysis(avg.getMapTasks(), cMap, ""map"", avg.getAvgMapTime(), 10);"
103355,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/jobhistory/HistoryViewer.java,303,,"      printAnalysis(avg.getReduceTasks(), cShuffle, ""shuffle"", "
103356,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/chain/Chain.java,79,,"  @SuppressWarnings(""unchecked"")"
103357,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/BooleanSplitter.java,45,,"          colName + "" IS NULL"", colName + "" IS NULL""));"
103358,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/DateSplitter.java,72,,"          colName + "" IS NULL"", colName + "" IS NULL""));"
103359,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/FloatSplitter.java,59,,"          colName + "" IS NULL"", colName + "" IS NULL""));"
103360,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/IntegerSplitter.java,56,,"          colName + "" IS NULL"", colName + "" IS NULL""));"
103361,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/db/TextSplitter.java,88,,"          colName + "" IS NULL"", colName + "" IS NULL""));"
103362,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/MultipleInputs.java,54,,"  @SuppressWarnings(""unchecked"")"
103363,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/SequenceFileInputFilter.java,164,,"          ""Negative "" + FILTER_FREQUENCY + "": "" + frequency);"
103364,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/input/TaggedInputSplit.java,49,,"  @SuppressWarnings(""unchecked"")"
103365,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/join/CompositeRecordReader.java,57,,"  @SuppressWarnings(""unchecked"")"
103366,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/join/Parser.java,193,,"@SuppressWarnings(""unchecked"")"
103367,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/join/WrappedRecordReader.java,56,,"  @SuppressWarnings(""unchecked"")"
103368,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/output/MultipleOutputs.java,207,,"  @SuppressWarnings(""unchecked"")"
103369,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/lib/partition/InputSampler.java,126,,"    @SuppressWarnings(""unchecked"") // ArrayList::toArray doesn't preserve type"
103370,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/server/jobtracker/TaskTracker.java,129,,"        throw new RuntimeException(trackerName + "" already has "" + "
103371,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/server/jobtracker/TaskTracker.java,130,,"                                   ""slots reserved for "" + "
103372,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/server/jobtracker/TaskTracker.java,131,,"                                   jobForFallowMapSlot + ""; being""  +"
103373,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/task/JobContextImpl.java,166,,"  @SuppressWarnings(""unchecked"")"
103374,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/task/reduce/Fetcher.java,132,,"    setName(""fetcher#"" + id);"
103375,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/tools/CLI.java,151,,"      if (argv.length != 2 && !(argv.length == 3 && ""all"".equals(argv[1]))) {"
103376,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/tools/CLI.java,225,,"          System.out.println(""Could not find job "" + jobid);"
103377,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/util/LinuxResourceCalculatorPlugin.java,193,,"          LOG.warn(""Error closing the stream "" + in);"
103378,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/util/ProcfsBasedProcessTree.java,550,,"          LOG.warn(""Error closing the stream "" + in);"
103379,./TargetProjects/hadoop-mapreduce/src/java/org/apache/hadoop/mapreduce/util/ProcfsBasedProcessTree.java,685,,"      String ret = ""N/A"";"
103380,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/conf/TestJobConf.java,45,,"    configuration.setProfileParams(""test"");"
103381,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/conf/TestJobConf.java,69,,"    configuration.set(""mapred.task.maxvmem"" , String.valueOf(2*1024 * 1024));"
103382,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/examples/pi/math/TestModular.java,151,,"          assertEquals(""r="" + r + "", n="" + n + "", answer="" + answer + "" but s="" + s, answer, s);"
103383,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/examples/pi/math/TestModular.java,151,,"          assertEquals(""r="" + r + "", n="" + n + "", answer="" + answer + "" but s="" + s, answer, s);"
103384,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/examples/pi/math/TestModular.java,151,,"          assertEquals(""r="" + r + "", n="" + n + "", answer="" + answer + "" but s="" + s, answer, s);"
103385,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/AccumulatingReducer.java,70,,"    reporter.setStatus(""starting "" + field + "" ::host = "" + hostName);"
103386,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/DFSCIOTest.java,229,,"            String chmodCmd = new String(CHMOD + "" a+x "" + HDFS_SHLIB);"
103387,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/DFSCIOTest.java,233,,"              throw new IOException(chmodCmd + "": Failed with exitStatus: "" + exitStatus);"
103388,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/JHLogAnalyzer.java,322,,"                + "" expect "" + JOBID);"
103389,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/JHLogAnalyzer.java,411,,"            LOG.error(""Incorrect TASKID: """
103390,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/JHLogAnalyzer.java,724,,"              reporter.setStatus(""Processing "" + filePath + "" at "" + processed);"
103391,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/JHLogAnalyzer.java,872,,"          if(!""MAP"".equals(th.TASK_TYPE) && !""REDUCE"".equals(th.TASK_TYPE) &&"
103392,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/JHLogAnalyzer.java,872,,"          if(!""MAP"".equals(th.TASK_TYPE) && !""REDUCE"".equals(th.TASK_TYPE) &&"
103393,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/TestFileSystem.java,99,,"    assertEquals(cf.parse(new String[] {""-tail"",""fileName""}, 1).get(0),""fileName"");"
103394,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/TestFileSystem.java,169,,"      fastCheck = job.getBoolean(""fs.test.fastCheck"", false);"
103395,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/TestFileSystem.java,564,,"      new Path(""hftp://localhost:12345/"").getFileSystem(conf);"
103396,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/slive/ConfigExtractor.java,683,,"        read += cfg.getReadSize() + "" bytes"";"
103397,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/fs/slive/OperationOutput.java,139,,"              ""Unable to combine a type with a double "" + o1 + "" & "" + o2, e);"
103398,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/hdfs/NNBench.java,188,,"      ""This is not mandatory>\n"" +"
103399,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/hdfs/NNBench.java,704,,"          doCreateWriteOp(""file_"" + hostName + ""_"", reporter);"
103400,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/hdfs/NNBench.java,778,,"            reporter.setStatus(""Finish ""+ l + "" files"");"
103401,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/hdfs/NNBench.java,778,,"            reporter.setStatus(""Finish ""+ l + "" files"");"
103402,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/io/FileBench.java,108,,"    final String fn = conf.get(""test.filebench.name"", """");"
103403,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java,307,,"      LOG.info(""Signal type found : "" + signalType"
103404,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java,308,,"          + "" .Number of tasks to be finished by this signal : "" + noOfTasks"
103405,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java,309,,"          + "" . My id : "" + taskNumber);"
103406,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/ControlledMapReduceJob.java,310,,"      LOG.info(taskNumber + "" is still alive."");"
103407,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/JobClientUnitTest.java,31,,"  @SuppressWarnings(""deprecation"")"
103408,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/JobClientUnitTest.java,37,,"    JobID id = new JobID(""test"",0);"
103409,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/MRCaching.java,69,,"        String TEST_ROOT_DIR = jconf.get(""test.build.data"",""/tmp"");"
103410,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/MRCaching.java,73,,"          throw new IOException(""Mkdirs failed to create "" + file.toString());"
103411,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/MRCaching.java,75,,"        Path fileOut = new Path(file, ""test.txt"");"
103412,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestComparators.java,112,,"      out.collect(key, new Text(""success""));"
103413,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestComparators.java,351,,"      fail(""Oops! The job broke due to an unexpected error"");"
103414,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,79,,"    new Path(new Path(System.getProperty(""test.build.data"", ""/tmp"")),"
103415,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,183,,"    Path fnLocal = new Path(System.getProperty(""test.concat.data"", ""/tmp""), fn);"
103416,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,194,,"    assertEquals(""compressed splits == 2"", 2, splits.length);"
103417,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,208,,"    assertEquals(""splits[1][0]"", ""this is a test"","
103418,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,233,,"    assertEquals(""concat bytes available"", 148, in.available());"
103419,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,379,,"      jConf.setInt(""io.file.buffer.size"", bufferSize);"
103420,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,444,,"      ""Call me Ishmael. Some years ago--never mind how long precisely--having"","
103421,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestConcatenatedCompressedInput.java,447,,"      ""Tell me, does the magnetic virtue of the needles of the compasses of"","
103422,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestGetSplitHosts.java,37,,"    String [] block1Hosts = {""host1"",""host2"",""host3""};"
103423,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobCleanup.java,161,,"      assertFalse(""File "" + file + "" should not be present for successful job "" "
103424,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobCounters.java,184,,"    removeWordsFile(new Path(IN_DIR, ""input5_2k_4""), conf);"
103425,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobCounters.java,185,,"    removeWordsFile(new Path(IN_DIR, ""input5_2k_5""), conf);"
103426,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobCounters.java,351,,"  @SuppressWarnings({""deprecation"", ""unchecked""})"
103427,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,166,,"                 "" history file for task "" + tid, (status.equals(""SUCCEEDED"") ||"
103428,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,295,,"    assertTrue(""History file does not exist"", fileSys.exists(logFile));"
103429,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,337,,"               ""match the expected value"", jip.getStartTime() =="
103430,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,494,,"            "" obtained from "" +"
103431,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,495,,"            ""history file did not match the expected value"","
103432,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobHistory.java,631,,"        ""file:///"" + new File(System.getProperty(""hadoop.log.dir""))."
103433,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgressListener.java,233,,"        throw new RuntimeException(""Job "" + id + "" not seen in waiting queue"");"
103434,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobInProgressListener.java,310,,"    assertEquals(""Job failed!"", JobStatus.FAILED, rJob.getJobState());"
103435,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobQueueTaskScheduler.java,137,,"      TaskTracker tt1 = new TaskTracker(""tt1"");"
103436,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobQueueTaskScheduler.java,144,,"      TaskTracker tt2 = new TaskTracker(""tt2"");"
103437,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestJobRetire.java,348,,"      tip = new TaskInProgress(id, ""dummy"", JobSplit.EMPTY_TASK_SPLIT, "
103438,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestKillSubProcesses.java,93,,"        LOG.warn(""sleep is interrupted:"" + ie);"
103439,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestKillSubProcesses.java,200,,"                               scriptDirName + ""/childPidFile"" + 0);"
103440,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestLimitTasksPerJobTaskScheduler.java,65,,"        scheduler, TestJobQueueTaskScheduler.tracker(taskTrackerManager, ""tt1""), "
103441,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestLimitTasksPerJobTaskScheduler.java,77,,"        scheduler, TestJobQueueTaskScheduler.tracker(taskTrackerManager, ""tt2""), "
103442,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestLocalizationWithLinuxTaskController.java,113,,"                                ? ""drwxrws---"""
103443,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestLostTracker.java,118,,"    assertEquals(""Active tracker count mismatch"", "
103444,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMapRed.java,392,,"        throw new IOException(""Mkdirs failed to create "" + testdir.toString());"
103445,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,121,,"                                      ""/tmp"")).toString().replace(' ', '+');"
103446,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,217,,"        assertNotNull(JobConf.MAPRED_TASK_JAVA_OPTS + "" is null!"", "
103447,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,219,,"        assertEquals(JobConf.MAPRED_TASK_JAVA_OPTS + "" has value of: "" + "
103448,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,237,,"                 System.getenv(""LD_LIBRARY_PATH"").contains(pwd));"
103449,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,242,,"      checkEnv(""HOME"", ""/tmp"", ""noappend"");"
103450,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRChildTask.java,246,,"      checkEnv(""NEW_PATH"", "":/tmp"", ""noappend"");"
103451,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRLocalFS.java,336,,"    assertEquals(""------------------------------------------------\n"" +"
103452,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestMiniMRWithDFSWithDistinctUsers.java,84,,"    mkdir(fs, ""/user"", ""nobody"", ""nogroup"", (short)01777);"
103453,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestNodeHealthService.java,119,,"    assertTrue(""Node health status reported unhealthy"", healthStatus"
103454,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManager.java,101,,"        ""p1"" + NAME_SEPARATOR + ""p11""));"
103455,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManager.java,104,,"        ""p1"" + NAME_SEPARATOR + ""p12""));"
103456,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManager.java,214,,"      fail(""Should throw an exception as configuration is wrong "");"
103457,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManager.java,313,,"        assertEquals(p.getProperty(""capacity""), ""10"");"
103458,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManager.java,314,,"        assertEquals(p.getProperty(""maxCapacity""), ""35"");"
103459,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithDeprecatedConf.java,102,,"          ""default"", submitAcl), ugi.getUserName());"
103460,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithDeprecatedConf.java,120,,"      assertTrue(""User Job Submission failed."","
103461,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithJobTracker.java,126,,"    job = submitSleepJob(0, 0, 0, 0, true, ""u1,g1"", ""p1"" + NAME_SEPARATOR"
103462,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithJobTracker.java,127,,"        + ""p13"", conf);"
103463,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithJobTracker.java,149,,"          + ""p11"", conf);"
103464,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestQueueManagerWithJobTracker.java,209,,"      assertEquals(""job submitted for u1 and queue p1:p11 is not killed."","
103465,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestRecoveryManager.java,53,,"             ""test-recovery-manager"");"
103466,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestRecoveryManager.java,81,,"        new Path(TEST_DIR, ""input""), new Path(TEST_DIR, ""output1""), 2, 0, "
103467,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestRecoveryManager.java,86,,"    LOG.info(""Submitted job "" + rJob1.getID());"
103468,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestRecoveryManager.java,89,,"      LOG.info(""Waiting for job "" + rJob1.getID() + "" to be 50% done"");"
103469,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestReporter.java,61,,"  @SuppressWarnings(""deprecation"")"
103470,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSetupTaskScheduling.java,66,,"      setup[0] = new TaskInProgress(getJobID(), ""test"",  emptySplit,"
103471,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSetupWorkDir.java,95,,"    Path rootDir = new Path(System.getProperty(""test.build.data"",  ""/tmp""),"
103472,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSetupWorkDir.java,152,,"    createFile(fs, myTargetDir, ""cacheFile.txt"");"
103473,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSeveral.java,96,,"        TestMiniMRWithDFSWithDistinctUsers.mkdir(fs, ""/user"", ""mapred"", ""mapred"", (short)01777);"
103474,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,74,,"    assertEquals(0, outputRecord.getMetric(""shuffle_exceptions_caught"")"
103475,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,160,,"    stack[0] = new StackTraceElement(""sun.nio.ch.EPollArrayWrapper"","
103476,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,161,,"        ""interrupt"", """", -2);"
103477,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,164,,"    stack[2] = new StackTraceElement(""sun.nio.ch.EPollSelectorImpl"", ""wakeup"","
103478,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,168,,"        ""SelectorManager.java"", 831);"
103479,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,228,,"        ""org.mortbay.jetty.AbstractGenerator$Output"", ""blockForOutput"","
103480,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestShuffleExceptionCount.java,229,,"        ""AbstractGenerator.java"", 545);"
103481,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSpeculativeExecution.java,136,,"    assertEquals(""Total speculative maps"", 1, fakeInst.numSpeculativeMaps);"
103482,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSpeculativeExecution.java,137,,"    assertEquals(""Total speculative reduces"", 1,"
103483,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSpeculativeExecution.java,139,,"    LOG.info(""Total speculative maps = "" + fakeInst.numSpeculativeMaps);"
103484,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSpeculativeExecution.java,140,,"    LOG.info(""Total speculative reduces = "" + fakeInst.numSpeculativeReduces);"
103485,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestSubmitJob.java,209,,"      TestMiniMRWithDFSWithDistinctUsers.mkdir(fs, ""/user"", ""mapred"", ""mapred"", (short)01777);"
103486,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskLogServlet.java,89,,"    assertEquals(""text/html; charset=utf-8"", response.getHeader(""content-type""));"
103487,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskStatus.java,145,,"    assertEquals(""Status-update on state-string failed"", "
103488,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerBlacklisting.java,195,,"    TaskTrackerHealthStatus status = getUnhealthyNodeStatus(""ERROR"");"
103489,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerBlacklisting.java,225,,"      assertEquals(""Failure count updated wrongly for tracker : "" + tracker,"
103490,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerBlacklisting.java,272,,"    assertEquals(""All trackers not blacklisted"", 3,"
103491,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerBlacklisting.java,357,,"    assertEquals(""Tracker 1 not unreserved for the job 1"", 1, job"
103492,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerLocalization.java,433,,"      checkFilePermissions(userDir.getAbsolutePath(), ""drwx------"", task"
103493,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerMemoryManager.java,447,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"", ""500"", ""600"", ""700"" };"
103494,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerMemoryManager.java,447,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"", ""500"", ""600"", ""700"" };"
103495,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerMemoryManager.java,447,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"", ""500"", ""600"", ""700"" };"
103496,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTaskTrackerMemoryManager.java,493,,"                  test.isProcessTreeOverLimit(pTree, ""dummyId"", limit));"
103497,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTrackerReservation.java,129,,"    assertEquals(""reserved map slots do not match"","
103498,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestTrackerReservation.java,131,,"    assertEquals(""reserved reduce slots do not match"","
103499,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,109,,"    if (method.equals(""POST"")) {"
103500,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,263,,"        LOG.info(""Killing job "" + jobid + "" from finally block"");"
103501,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,263,,"        LOG.info(""Killing job "" + jobid + "" from finally block"");"
103502,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,265,,"            getHttpStatusCode(jobTrackerJSP + ""&killJobs=true&jobCheckBox="" +"
103503,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,266,,"            jobid.toString(), jobSubmitter, ""GET""));"
103504,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,281,,"    MyGroupsProvider.mapping.put(superGroupMember, Arrays.asList(""superGroup""));"
103505,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,307,,"    props.setProperty(""dfs.permissions.enabled"", ""false"");"
103506,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,353,,"    String jtURL = ""http://localhost:"" + infoPort;"
103507,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,394,,"        String stdoutURL = TaskLogServlet.getTaskLogUrl(""localhost"","
103508,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,396,,"            attempt.toString()) + ""&filter="" + TaskLog.LogName.STDOUT;"
103509,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,432,,"        assertEquals(""Incorrect return code for "" + unauthorizedUser,"
103510,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,515,,"    String jobTrackerJSP =  jtURL + ""/jobtracker.jsp?a=b"";"
103511,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/TestWebUIAuthorization.java,618,,"    url = url.concat(""&jobCheckBox="" + jobid.toString());"
103512,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/join/TestTupleWritable.java,72,,"      new BytesWritable(""dingo"".getBytes()),"
103513,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/join/TestTupleWritable.java,75,,"      new BytesWritable(""yak"".getBytes()),"
103514,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/join/TestTupleWritable.java,162,,"    assertTrue(""Failed to write/read tuple"", sTuple.equals(dTuple));"
103515,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/join/TestTupleWritable.java,181,,"    assertEquals(""All tuple data has not been read from the stream"",-1,in.read());"
103516,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestChainMapReduce.java,46,,"    fs.delete(getFlagDir(conf.getBoolean(""localFS"", true)), true);"
103517,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleInputs.java,41,,"    MultipleInputs.addInputPath(conf, new Path(""/foo""), TextInputFormat.class);"
103518,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleInputs.java,42,,"    MultipleInputs.addInputPath(conf, new Path(""/bar""),"
103519,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java,95,,"    file.writeBytes(""a\nb\n\nc\nd\ne"");"
103520,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java,122,,"    MultipleOutputs.addNamedOutput(conf, ""text"", TextOutputFormat.class,"
103521,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java,144,,"        status.getPath().getName().equals(""text-r-00000"")) {"
103522,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java,203,,"    MultipleOutputs.addMultiNamedOutput(conf, ""sequence"","
103523,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/TestMultipleOutputs.java,286,,"  @SuppressWarnings({""unchecked""})"
103524,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapred/lib/db/TestConstructQuery.java,38,,"    String actual = format.constructQuery(""hadoop_output"", fieldNames);"
103525,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestChild.java,59,,"        assertNotNull(JobConf.MAPRED_TASK_JAVA_OPTS + "" is null!"", "
103526,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestChild.java,61,,"        assertEquals(JobConf.MAPRED_TASK_JAVA_OPTS + "" has value of: "" + "
103527,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,201,,"      @SuppressWarnings(""null"")"
103528,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,209,,"          fail(""Exception .."" + e);"
103529,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,212,,"        assertNotNull(""Job "" + jobId + "" is not known to the JobTracker!"","
103530,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,212,,"        assertNotNull(""Job "" + jobId + "" is not known to the JobTracker!"","
103531,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,219,,"          fail(""Unexpected.. exception.. "" + ioe);"
103532,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,258,,"          fail(""AccessControlException expected.."");"
103533,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,261,,"              "" cannot perform operation "" + JobACL.VIEW_JOB));"
103534,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestJobACLs.java,263,,"          fail(""Exception .. interrupted.."" + e);"
103535,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapCollection.java,131,,"      disableRead = conf.getBoolean(""test.disable.key.read"", false);"
103536,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapCollection.java,141,,"      disableRead = conf.getBoolean(""test.disable.val.read"", false);"
103537,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapCollection.java,189,,"      expected = job.getConfiguration().getInt(""test.spillmap.records"", 100);"
103538,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapCollection.java,270,,"              conf.getClass(""test.mapcollection.class"","
103539,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapReduceLocal.java,129,,"    localFs.delete(new Path(TEST_ROOT_DIR + ""/in""), true);"
103540,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestMapReduceLocal.java,130,,"    localFs.delete(new Path(TEST_ROOT_DIR + ""/out""), true);    "
103541,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestTaskContext.java,89,,"                new Path(test, ""in""), new Path(test, ""out""), numMaps, 0);"
103542,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestTaskContext.java,92,,"    assertTrue(""Job failed"", job.isSuccessful());"
103543,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/TestValueIterReset.java,160,,"            "", Got: "" + i);"
103544,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestTrackerDistributedCacheManager.java,178,,"    File workDir = new File(new Path(TEST_ROOT_DIR, ""workdir"").toString());"
103545,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestTrackerDistributedCacheManager.java,630,,"    checkCacheDeletion(localfs, secondLocalCache, ""DistributedCache failed "" +"
103546,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,41,,"        new URI(""file://foo/bar/myCacheFile1.txt#file""),"
103547,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,45,,"        new URI(""file://foo/bar/myCacheArchive2.txt#archive"") }));"
103548,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,61,,"        new URI(""file://foo/bar/myCacheFile1.txt#file1""),"
103549,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,62,,"        new URI(""file://foo/bar/myCacheFile2.txt#file2"") }, new URI[] {"
103550,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,68,,"        new URI(""file://foo/bar/myCacheArchive1.txt#archive1""),"
103551,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/filecache/TestURIFragments.java,69,,"        new URI(""file://foo/bar/myCacheArchive2.txt#archive2"") }));"
103552,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/jobhistory/TestJobHistoryEvents.java,49,,"    TaskAttemptID fakeId = new TaskAttemptID(""1234"", 1, TaskType.MAP, 1, 1);"
103553,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/chain/TestChainErrors.java,59,,"    job.setJobName(""chain"");"
103554,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/db/TestDBOutputFormat.java,40,,"    String actual = format.constructQuery(""hadoop_output"", fieldNames);"
103555,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/db/TestDataDrivenDBInputFormat.java,185,,"    s.executeUpdate(""INSERT INTO "" + DATE_TABLE + "" VALUES('2010-04-01')"");"
103556,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/input/TestCombineFileInputFormat.java,64,,"    ""host3.rack3.com"""
103557,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/input/TestMultipleInputs.java,145,,"    MultipleInputs.addInputPath(conf, new Path(""/foo""), TextInputFormat.class);"
103558,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/input/TestMultipleInputs.java,146,,"    MultipleInputs.addInputPath(conf, new Path(""/bar""),"
103559,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/join/TestJoinProperties.java,209,,"    assertTrue(""not all keys present"", count == expectedCount);"
103560,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/join/TestJoinTupleWritable.java,69,,"      new BytesWritable(""dingo"".getBytes()),"
103561,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/join/TestJoinTupleWritable.java,72,,"      new BytesWritable(""yak"".getBytes()),"
103562,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/join/TestJoinTupleWritable.java,159,,"    assertTrue(""Failed to write/read tuple"", sTuple.equals(dTuple));"
103563,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/output/TestFileOutputCommitter.java,53,,"  @SuppressWarnings(""unchecked"")"
103564,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/output/TestJobOutputCommitter.java,157,,"      assertFalse(""File "" + file + "" should not be present for successful job """
103565,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/output/TestMRMultipleOutputs.java,112,,"          fileName.equals(""text-r-00000"")) {"
103566,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestKeyFieldHelper.java,37,,"    assertEquals(""KeyFieldHelper's parsing is garbled"", eKeySpecs, actKeySpecs);"
103567,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestKeyFieldHelper.java,48,,"    eKeySpecs = ""-k1.2,3.4nr"";"
103568,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestKeyFieldHelper.java,55,,"    eKeySpecs = ""-k1.2,3.4n"";"
103569,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestKeyFieldHelper.java,62,,"    eKeySpecs = ""-k1.2,3.4r"";"
103570,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestMRKeyFieldBasedPartitioner.java,47,,"    assertEquals(""Partitioner doesnt work as expected"", expectedPartition, "
103571,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/lib/partition/TestTotalOrderPartitioner.java,66,,"    testStrings.add(new Check<Text>(new Text(""aaaaa""), 0));"
103572,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,312,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"" };"
103573,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,312,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"" };"
103574,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,312,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"" };"
103575,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,312,,"    String[] pids = { ""100"", ""200"", ""300"", ""400"" };"
103576,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,314,,"    File procfsRootDir = new File(TEST_ROOT_DIR, ""proc"");"
103577,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,324,,"          {""100"", ""proc1"", ""1"", ""100"", ""100"", ""100000"", ""100"", ""1000"", ""200""});"
103578,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,324,,"          {""100"", ""proc1"", ""1"", ""100"", ""100"", ""100000"", ""100"", ""1000"", ""200""});"
103579,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,326,,"          {""200"", ""proc2"", ""100"", ""100"", ""100"", ""200000"", ""200"", ""2000"", ""400""});"
103580,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,326,,"          {""200"", ""proc2"", ""100"", ""100"", ""100"", ""200000"", ""200"", ""2000"", ""400""});"
103581,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,328,,"          {""300"", ""proc3"", ""200"", ""100"", ""100"", ""300000"", ""300"", ""3000"", ""600""});"
103582,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,330,,"          {""400"", ""proc4"", ""1"", ""400"", ""400"", ""400000"", ""400"", ""4000"", ""800""});"
103583,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,330,,"          {""400"", ""proc4"", ""1"", ""400"", ""400"", ""400000"", ""400"", ""4000"", ""800""});"
103584,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,330,,"          {""400"", ""proc4"", ""1"", ""400"", ""400"", ""400000"", ""400"", ""4000"", ""800""});"
103585,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/mapreduce/util/TestProcfsBasedProcessTree.java,361,,"          {""200"", ""proc2"", ""100"", ""100"", ""100"", ""200000"", ""200"", ""3000"", ""500""});"
103586,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/security/TestMapredGroupMappingServiceRefresh.java,185,,"    config.set(userKeyHosts,""127.0.0.1"");"
103587,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/security/TestMapredGroupMappingServiceRefresh.java,214,,"      System.err.println(""auth for "" + ugi1.getUserName() + "" failed"");"
103588,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,68,,"  static final URI LOCAL_FS = URI.create(""file:///"");"
103589,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,267,,"    MyFile[] files = createFiles(LOCAL_FS, TEST_ROOT_DIR+""/srcdat"");"
103590,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,270,,"                                         ""file:///""+TEST_ROOT_DIR+""/destdat""});"
103591,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,271,,"    assertTrue(""Source and destination directories do not match."","
103592,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,286,,"      if (namenode.startsWith(""hdfs://"")) {"
103593,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,289,,"                                         ""-log"","
103594,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,290,,"                                         namenode+""/logs"","
103595,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,296,,"        assertTrue(""Log directory does not exist."","
103596,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,423,,"                                         ""-update"","
103597,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,570,,"          new String[] {""file:///""+TEST_ROOT_DIR+""/srcdat/""+fname,"
103598,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,571,,"                        ""file:///""+TEST_ROOT_DIR+""/dest2/""+fname});"
103599,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,573,,"          checkFiles(fs, TEST_ROOT_DIR+""/dest2"", files));     "
103600,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestCopyFiles.java,764,,"      System.out.println(execCmd(shell, ""-lsr"", logdir));"
103601,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,62,,"    inputPath = new Path(fs.getHomeDirectory(), ""test""); "
103602,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,67,,"    filec = new Path(inputPath,""c c"");"
103603,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,128,,"    assertTrue(""strings are equal "", (b[0] == ""a"".getBytes()[0]));"
103604,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,181,,"      args[0] = ""-archiveName"";"
103605,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,188,,"      assertTrue(""failed test"", ret == 0);"
103606,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,193,,"      Path harPath = new Path(""har://"" + filePath.toUri().getPath());"
103607,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,221,,"      args[3] = ""foo.har"";"
103608,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/TestHarFileSystem.java,380,,"    args[3] = ""foo bar.har"";"
103609,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestHistograms.java,68,,"      if (fileName.startsWith(""input"")) {"
103610,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestParsedLine.java,73,,"    testOneLine(""REC1"", ""A"", ""x"", ""B"", ""abc=de"", ""C"", ""f"");"
103611,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestParsedLine.java,74,,"    testOneLine(""REC2"", ""B"", ""=abcde"", ""C"", ""f"");"
103612,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestParsedLine.java,75,,"    testOneLine(""REC3"", ""A"", ""x"", ""B"", ""abcde="");"
103613,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestPiecewiseLinearInterpolation.java,78,,"      System.out.println(""element "" + i + "", got "" + result[i] + "", expected """
103614,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestPiecewiseLinearInterpolation.java,78,,"      System.out.println(""element "" + i + "", got "" + result[i] + "", expected """
103615,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestPiecewiseLinearInterpolation.java,78,,"      System.out.println(""element "" + i + "", got "" + result[i] + "", expected """
103616,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestPiecewiseLinearInterpolation.java,79,,"          + (10000L * i + 100000L) + "", error = "" + error);"
103617,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRandomSeedGenerator.java,32,,"        getSeed(""stream1"", masterSeed1) == getSeed(""stream1"", masterSeed1));"
103618,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenFolder.java,45,,"    @SuppressWarnings(""deprecation"")"
103619,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,78,,"        new Path(System.getProperty(""test.tools.input.dir"", """")).makeQualified("
103620,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,81,,"        new Path(System.getProperty(""test.build.data"", ""/tmp"")).makeQualified("
103621,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,81,,"        new Path(System.getProperty(""test.build.data"", ""/tmp"")).makeQualified("
103622,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,84,,"    final Path rootInputFile = new Path(rootInputDir, ""rumen/small-trace-test"");"
103623,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,625,,"      assertEquals(""New config property "" + MRJobConfig.MAP_JAVA_OPTS"
103624,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,627,,"          ""-server -Xmx640m -Djava.net.preferIPv4Stack=true"","
103625,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestRumenJobTraces.java,860,,"        .valueOf(""MAP""), ""STATUS"", 1234567890L,"
103626,./TargetProjects/hadoop-mapreduce/src/test/mapred/org/apache/hadoop/tools/rumen/TestZombieJob.java,81,,"          System.out.println(""   "" + ranking.getRelativeRanking() + "":"""
103627,./TargetProjects/hadoop-mapreduce/src/test/system/test/org/apache/hadoop/mapred/TestFileOwner.java,157,,"              Assert.assertTrue(""FilePermission failed for "" + filename, fsPerm"
103628,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java,784,,"        String finishTime = line.get(""FINISH_TIME"");"
103629,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/HadoopLogsAnalyzer.java,1042,,"        LOG.error(""A task status you don't know about is \"""" + status + ""\""."","
103630,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/Job20LineHistoryEventEmitter.java,125,,"      String status = line.get(""JOB_STATUS"");"
103631,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/LoggedJob.java,417,,"      throw new DeepInequalityException(eltname + "" miscompared"", new TreePath("
103632,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/LoggedTask.java,285,,"      throw new DeepInequalityException(eltname + "" miscompared"", new TreePath("
103633,./TargetProjects/hadoop-mapreduce/src/tools/org/apache/hadoop/tools/rumen/LoggedTaskAttempt.java,446,,"      throw new DeepInequalityException(eltname + "" miscompared"", new TreePath("
103634,./TargetProjects/hadoop-ozone/hadoop-hdds/client/src/main/java/org/apache/hadoop/hdds/scm/XceiverClientGrpc.java,244,,"      LOG.error(""Command execution was interrupted."");"
103635,./TargetProjects/hadoop-ozone/hadoop-hdds/client/src/test/java/org/apache/hadoop/hdds/scm/storage/TestBlockInputStream.java,156,,"    Assert.assertEquals(""ChunkIndex is incorrect"", 0,"
103636,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/HddsConfigKeys.java,32,,"      ""60s"";"
103637,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/scm/ScmConfigKeys.java,167,,"      ""0.0.0.0"";"
103638,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/scm/net/NodeSchemaLoader.java,331,,"              "" in network topology schema configuration file"");"
103639,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/hdds/utils/VersionInfo.java,57,,"    return info.getProperty(""release"", ""Unknown"");"
103640,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/common/IncrementalChunkBuffer.java,85,,"        assertInt(getBufferCapacityAtIndex(i), ith.capacity(), ""capacity"", i);"
103641,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/container/common/helpers/ContainerCommandRequestPBHelper.java,50,,"      auditParams.put(""containerID"", containerID);"
103642,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/main/java/org/apache/hadoop/ozone/container/common/helpers/ContainerCommandRequestPBHelper.java,79,,"        auditParams.put(""blockData"","
103643,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/TestHddsUtils.java,98,,"    conf.setStrings(ScmConfigKeys.OZONE_SCM_NAMES, ""scm1"");"
103644,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,71,,"      appendProperty(out, ""hadoop.tags.custom"", ""MYCUSTOMTAG"");"
103645,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,76,,"      appendPropertyByTag(out, ""dfs.random.key"", ""XYZ"", ""MYCUSTOMTAG"");"
103646,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,110,,"    ozoneConfig.set(""test.scm.client.address"", ""address"");"
103647,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,111,,"    ozoneConfig.set(""test.scm.client.bind.host"", ""host"");"
103648,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,112,,"    ozoneConfig.setBoolean(""test.scm.client.enabled"", true);"
103649,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,113,,"    ozoneConfig.setInt(""test.scm.client.port"", 5555);"
103650,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/conf/TestOzoneConfiguration.java,114,,"    ozoneConfig.setTimeDuration(""test.scm.client.wait"", 10, TimeUnit.MINUTES);"
103651,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestRatisHelper.java,36,,"        "".request.timeout"", ""30s"");"
103652,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestRatisHelper.java,59,,"        ""30MB"");"
103653,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestRatisHelper.java,61,,"        "".window"", ""1MB"");"
103654,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestRatisHelper.java,62,,"    ozoneConfiguration.set(""hdds.ratis.raft.grpc.tls.enabled"", ""true"");"
103655,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestServerNotLeaderException.java,40,,"    String message = ""Server:7fdd7170-75cc-4e11-b343-c2657c2f2f39 is not the "" +"
103656,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestServerNotLeaderException.java,42,,"        ""at org.apache.hadoop.hdds.ratis.ServerNotLeaderException"" +"
103657,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/ratis/TestServerNotLeaderException.java,43,,"        "".convertToNotLeaderException(ServerNotLeaderException.java:96)"";"
103658,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMNodeInfo.java,66,,"          scmServiceId, nodeId), ""localhost"");"
103659,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMNodeInfo.java,68,,"          scmServiceId, nodeId), ""localhost:"" + ++port);"
103660,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,82,,"                createDatanode(""1.1.1.1"", ""/""),"
103661,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,83,,"                createDatanode(""2.2.2.2"", ""/""),"
103662,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,84,,"                createDatanode(""3.3.3.3"", ""/""),"
103663,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,85,,"                createDatanode(""4.4.4.4"", ""/""),"
103664,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,86,,"                createDatanode(""5.5.5.5"", ""/""),"
103665,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,87,,"                createDatanode(""6.6.6.6"", ""/""),"
103666,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,88,,"                createDatanode(""7.7.7.7"", ""/""),"
103667,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,89,,"                createDatanode(""8.8.8.8"", ""/""),"
103668,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,95,,"                createDatanode(""3.3.3.3"", ""/r2""),"
103669,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,107,,"                createDatanode(""3.3.3.3"", ""/d1/r2""),"
103670,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,141,,"                createDatanode(""1.1.1.1"", ""/d1/rg1/r1/ng1""),"
103671,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,143,,"                createDatanode(""3.3.3.3"", ""/d1/rg1/r1/ng2""),"
103672,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,151,,"                createDatanode(""11.11.11.11"", ""/d1/rg1/r2/ng1""),"
103673,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,156,,"                createDatanode(""16.16.16.16"", ""/d1/rg1/r2/ng2""),"
103674,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/hdds/scm/net/TestNetworkTopologyImpl.java,305,,"      assertTrue(e.getMessage().startsWith(""Invalid level""));"
103675,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,80,,"    LeaseManager<DummyResource> manager = new LeaseManager<>(""Test"", 5000);"
103676,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,82,,"    DummyResource resourceOne = new DummyResource(""one"");"
103677,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,83,,"    DummyResource resourceTwo = new DummyResource(""two"");"
103678,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,84,,"    DummyResource resourceThree = new DummyResource(""three"");"
103679,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,116,,"    exception.expectMessage(""Resource: "" + resourceOne);"
103680,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,196,,"    leaseStatus.put(resourceOne, ""lease in use"");"
103681,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,198,,"      leaseStatus.put(resourceOne, ""lease expired"");"
103682,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lease/TestLeaseManager.java,231,,"    leaseStatus.put(resourceOne, ""lease released"");"
103683,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lock/TestLockManager.java,38,,"    manager.writeLock(""/resourceOne"");"
103684,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/lock/TestLockManager.java,40,,"    manager.writeLock(""/resourceTwo"");"
103685,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/upgrade/TestLayoutVersionInstanceFactory.java,46,,"    assertTrue(factory.register(lvm, getKey(""key"", 0), m1));"
103686,./TargetProjects/hadoop-ozone/hadoop-hdds/common/src/test/java/org/apache/hadoop/ozone/upgrade/TestLayoutVersionInstanceFactory.java,62,,"        () -> factory.register(lvm, getKey(""key2"", 4), new MockClassV2()));"
103687,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/common/volume/AbstractFuture.java,173,,"  @SuppressWarnings(""visibilitymodifier"")"
103688,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/TestHddsSecureDatanodeInit.java,154,,"            "" initialization failed"","
103689,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/TestHddsSecureDatanodeInit.java,159,,"    Assert.assertTrue(dnLogs.getOutput().contains(""Init response: FAILURE""));"
103690,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/TestContainerCache.java,92,,"    ReferenceCountedDB db1 = cache.getDB(1, ""RocksDB"","
103691,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/impl/TestContainerPersistence.java,189,,"    data.addMetadata(""VOLUME"", ""shire"");"
103692,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/impl/TestContainerPersistence.java,708,,"    newMetadata.put(""owner"", ""bilbo_new"");"
103693,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/report/TestReportPublisher.java,112,,"                .setNameFormat(""Unit test ReportManager Thread - %d"").build());"
103694,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/statemachine/TestStateContext.java,78,,"    InetSocketAddress scm1 = new InetSocketAddress(""scm1"", 9001);"
103695,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/common/statemachine/TestStateContext.java,80,,"    InetSocketAddress scm2 = new InetSocketAddress(""scm2"", 9001);"
103696,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/keyvalue/impl/CommonChunkManagerTestCases.java,58,,"          String.format(""%d.data.%d"", blockID.getLocalID(), 0),"
103697,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/stream/TestDirstreamClientHandler.java,61,,"    Assert.assertEquals(""xxxx"", getContent(""asd.txt""));"
103698,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/stream/TestDirstreamClientHandler.java,61,,"    Assert.assertEquals(""xxxx"", getContent(""asd.txt""));"
103699,./TargetProjects/hadoop-ozone/hadoop-hdds/container-service/src/test/java/org/apache/hadoop/ozone/container/stream/TestStreamingServer.java,53,,"    Files.write(sourceDir.resolve(SUBDIR).resolve(""file1""), CONTENT);"
103700,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/scm/protocolPB/StorageContainerLocationProtocolClientSideTranslatorPB.java,215,,"        ""Container ID cannot be negative"");"
103701,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/security/x509/certificate/client/DefaultCertificateClient.java,379,,"      getLogger().error(""Error while signing the stream"", e);"
103702,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/server/http/HttpServer2.java,654,,"        .put(""acceptRanges"", ""true"")"
103703,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/main/java/org/apache/hadoop/hdds/server/http/HttpServer2.java,750,,"        @SuppressWarnings(""unchecked"")"
103704,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/token/TestOzoneBlockTokenIdentifier.java,86,,"        .generateCertificate(""CN=OzoneMaster"", keyPair, 30, ""SHA256withRSA"");"
103705,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/token/TokenVerifierTests.java,89,,"    subject.verify(""anyUser"", anyToken(), verifiedRequest(newTokenId()));"
103706,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultCAServer.java,95,,"    CertificateServer testCA = new DefaultCAServer(""testCA"","
103707,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultCAServer.java,172,,"        .addDnsName(""hadoop.apache.org"")"
103708,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultCAServer.java,173,,"        .addIpAddress(""8.8.8.8"")"
103709,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultProfile.java,112,,"        .addDnsName(""hadoop.apache.org"")"
103710,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultProfile.java,116,,"        .setClusterID(""ClusterID"")"
103711,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultProfile.java,117,,"        .setScmID(""SCMID"")"
103712,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/authority/TestDefaultProfile.java,118,,"        .setSubject(""Ozone Cluster"")"
103713,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificate/client/TestDefaultCertificateClient.java,254,,"        ""abc"".getBytes(UTF_8), x509Certificate));"
103714,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/security/x509/certificates/TestCertificateSignRequest.java,79,,"    String subject = ""DN001"";"
103715,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/server/http/TestRatisNameRewrite.java,52,,"            new String[] {""instance"", ""group"", ""follower""},"
103716,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/server/http/TestRatisNameRewrite.java,52,,"            new String[] {""instance"", ""group"", ""follower""},"
103717,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/server/http/TestRatisNameRewrite.java,52,,"            new String[] {""instance"", ""group"", ""follower""},"
103718,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestDBStoreBuilder.java,64,,"        .setName(""Test.db"")"
103719,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestDBStoreBuilder.java,136,,"        .addTable(""First"")"
103720,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestDBStoreBuilder.java,137,,"        .addTable(""Second"")"
103721,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestRDBStore.java,108,,"      Assert.assertNotNull(""DB Store cannot be null"", newStore);"
103722,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestRDBTableStore.java,54,,"          ""Fourth"", ""Fifth"","
103723,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestRDBTableStore.java,55,,"          ""Sixth"", ""Seventh"","
103724,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestTypedRDBTableStore.java,59,,"          ""Fourth"", ""Fifth"","
103725,./TargetProjects/hadoop-ozone/hadoop-hdds/framework/src/test/java/org/apache/hadoop/hdds/utils/db/TestTypedRDBTableStore.java,60,,"          ""Sixth"", ""Seven"", ""Eighth"","
103726,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/placement/metrics/ContainerStat.java,79,,"        ""Container size cannot be "" + ""negative."");"
103727,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/container/placement/metrics/SCMNodeStat.java,42,,"        ""negative."");"
103728,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateManagerV2Impl.java,292,,"    throw new IOException(""Not supported."");"
103729,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateMap.java,94,,"        ""Pipeline Id cannot be null"");"
103730,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/pipeline/PipelineStateMap.java,121,,"          String.format(""%s not found"", pipelineID));"
103731,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/main/java/org/apache/hadoop/hdds/scm/server/SCMClientProtocolServer.java,213,,"    auditMap.put(""containerID"", String.valueOf(containerID));"
103732,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestHddsServerUtil.java,59,,"    conf.set(ScmConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, ""1.2.3.4"");"
103733,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestHddsServerUtil.java,68,,"    conf.set(ScmConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, ""1.2.3.4:100"");"
103734,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestHddsServerUtil.java,80,,"    conf.set(ScmConfigKeys.OZONE_SCM_DATANODE_ADDRESS_KEY, ""5.6.7.8"");"
103735,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestHddsServerUtil.java,112,,"    assertThat(addr.getHostString(), is(""0.0.0.0""));"
103736,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestHddsServerUtil.java,119,,"    conf.set(ScmConfigKeys.OZONE_SCM_DATANODE_ADDRESS_KEY, ""1.2.3.4:200"");"
103737,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/TestUtils.java,608,,"    conf.set(ScmConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, ""127.0.0.1:0"");"
103738,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/block/TestBlockManager.java,269,,"      Assert.fail(""testAllocateBlockInParallel failed"");"
103739,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/placement/algorithms/TestContainerPlacementFactory.java,101,,"          datanodeInfo.getUuid(), ""/data1-"" + datanodeInfo.getUuidString(),"
103740,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/placement/algorithms/TestSCMContainerPlacementCapacity.java,67,,"          datanodeInfo.getUuid(), ""/data1-"" + datanodeInfo.getUuidString(),"
103741,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/placement/algorithms/TestSCMContainerPlacementRackAware.java,120,,"          datanodeInfo.getUuid(), ""/data1-"" + datanodeInfo.getUuidString(),"
103742,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/states/TestContainerAttribute.java,75,,"    List<String> keyslist = Arrays.asList(""Key1"", ""Key2"", ""Key3"");"
103743,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/states/TestContainerAttribute.java,75,,"    List<String> keyslist = Arrays.asList(""Key1"", ""Key2"", ""Key3"");"
103744,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/container/states/TestContainerAttribute.java,75,,"    List<String> keyslist = Arrays.asList(""Key1"", ""Key2"", ""Key3"");"
103745,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMHAConfiguration.java,91,,"    String[] nodes = new String[] {""scm1"", ""scm2"", ""scm3""};"
103746,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMHAConfiguration.java,100,,"          scmServiceId, nodeId), ""localhost:""+port++);"
103747,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMHAConfiguration.java,104,,"          scmServiceId, nodeId), ""172.28.9.1"");"
103748,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMHAConfiguration.java,245,,"        NetUtils.createSocketAddr(""0.0.0.0"","
103749,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSCMRatisRequest.java,42,,"    String operation = ""test"";"
103750,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSequenceIDGenerator.java,46,,"    Assert.assertEquals(1L, sequenceIdGen.getNextId(""someKey""));"
103751,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/ha/TestSequenceIDGenerator.java,50,,"    Assert.assertEquals(1L, sequenceIdGen.getNextId(""otherKey""));"
103752,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestNodeDecommissionManager.java,71,,"        new NodeDecommissionManager.HostDefinition(""foobar"");"
103753,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestNodeDecommissionManager.java,103,,"      fail(""InvalidHostStringException expected"");"
103754,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestSCMNodeManager.java,700,,"      assertEquals(""Expected to find 1 stale node"","
103755,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestSCMNodeManager.java,1667,,"    String[] hostNames = {""host1"", ""host2"", ""host3"", ""host4""};"
103756,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestSCMNodeManager.java,1667,,"    String[] hostNames = {""host1"", ""host2"", ""host3"", ""host4""};"
103757,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestSCMNodeManager.java,1668,,"    String[] ipAddress = {""1.2.3.4"", ""2.3.4.5"", ""3.4.5.6"", ""4.5.6.7""};"
103758,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/node/TestSCMNodeManager.java,1668,,"    String[] ipAddress = {""1.2.3.4"", ""2.3.4.5"", ""3.4.5.6"", ""4.5.6.7""};"
103759,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java,425,,"        .createDatanodeDetails(""host1"", ""/rack1""));"
103760,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestPipelinePlacementPolicy.java,429,,"        .createDatanodeDetails(""host3"", ""/rack2""));"
103761,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestSCMPipelineManager.java,293,,"    long numPipelineAllocated = getLongCounter(""NumPipelineAllocated"","
103762,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/pipeline/TestSCMPipelineManager.java,311,,"        ""NumPipelineCreationFailed"", metrics);"
103763,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/server/TestSCMBlockProtocolServer.java,99,,"    System.out.println(""client = "" + client);"
103764,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/server/TestStorageContainerManagerStarter.java,80,,"    executeCommand(""--invalid"");"
103765,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/server/TestStorageContainerManagerStarter.java,86,,"    executeCommand(""--init"");"
103766,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/hdds/scm/update/server/TestSCMUpdateServiceGrpcServer.java,91,,"        new SCMUpdateServiceGrpcClient(""localhost"", conf, clientCRLStore);"
103767,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/ozone/container/testutils/ReplicationNodeManagerMock.java,239,,"    throw new UnsupportedOperationException(""Not yet implemented"");"
103768,./TargetProjects/hadoop-ozone/hadoop-hdds/server-scm/src/test/java/org/apache/hadoop/ozone/scm/node/TestSCMNodeMetrics.java,73,,"        new SCMStorageConfig(NodeType.DATANODE, new File(""/tmp""), ""storage"");"
103769,./TargetProjects/hadoop-ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/OzoneBucket.java,155,,"  @SuppressWarnings(""parameternumber"")"
103770,./TargetProjects/hadoop-ozone/hadoop-ozone/client/src/main/java/org/apache/hadoop/ozone/client/OzoneVolume.java,109,,"  @SuppressWarnings(""parameternumber"")"
103771,./TargetProjects/hadoop-ozone/hadoop-ozone/client/src/test/java/org/apache/hadoop/ozone/client/TestHddsClientUtils.java,90,,"    conf.set(OZONE_SCM_CLIENT_ADDRESS_KEY, ""1.2.3.4"");"
103772,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/TestOzoneAcls.java,132,,"    assertEquals(acl.getName(), ""bilbo"");"
103773,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/TestOzoneAcls.java,164,,"    assertEquals(acl.getName(), ""WORLD"");"
103774,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/helpers/TestOmKeyInfo.java,49,,"        .setKeyName(""key1"")"
103775,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/helpers/TestOmVolumeArgs.java,47,,"            new OzoneAcl(IAccessAuthorizer.ACLIdentityType.USER, ""user1"","
103776,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java,197,,"      lock.releaseWriteLock(OzoneManagerLock.Resource.USER_LOCK, ""user3"");"
103777,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java,241,,"    lock.acquireMultiUserLock(""user1"", ""user2"");"
103778,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/om/lock/TestOzoneManagerLock.java,241,,"    lock.acquireMultiUserLock(""user1"", ""user2"");"
103779,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/util/TestRadixTree.java,39,,"    assertEquals(""/"", ROOT.getLongestPrefix(""/a/b/c""));"
103780,./TargetProjects/hadoop-ozone/hadoop-ozone/common/src/test/java/org/apache/hadoop/ozone/util/TestRadixTree.java,54,,"    ROOT.insert(""/a/b/c/d"");"
103781,./TargetProjects/hadoop-ozone/hadoop-ozone/insight/src/main/java/org/apache/hadoop/ozone/insight/datanode/DatanodeDispatcherInsight.java,45,,"  private static final String DATANODE_FILTER = ""datanode"";"
103782,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFSWithObjectStoreCreate.java,169,,"      String fileName = parentDir.concat(""/file"" + i + ""/"");"
103783,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileInterfaces.java,329,,"    assertTrue(""Makedirs returned with false for the path "" + leaf,"
103784,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,243,,"    Path file1 = new Path(parent, ""key1"");"
103785,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,356,,"    Path child = new Path(parent, ""child"");"
103786,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,448,,"      Path level1 = new Path(level0, ""level"" +i);"
103787,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,450,,"      Path level1File = new Path(level1, ""file1"");"
103788,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,697,,"    Path dir1 = new Path(""/dir1"");"
103789,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,702,,"    Path dir2 = new Path(""/dir2"");"
103790,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,812,,"    final String root = ""/root"";"
103791,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,863,,"    Path file1 = new Path(fs.getUri().toString() + dir2 + ""/file1"");"
103792,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,891,,"    assertTrue(""Rename failed"", fs.rename(aSourcePath, bDestinPath));"
103793,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystem.java,1260,,"        LOG.error(""Delete from Trash Failed"");"
103794,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,125,,"    Path key1 = new Path(""/key1"");"
103795,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,131,,"    Path d1 = new Path(""/d1"");"
103796,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,132,,"    Path dir1Key1 = new Path(d1, ""key1"");"
103797,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,134,,"      assertNotNull(""Should be able to create file: "" + dir1Key1,"
103798,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,143,,"    Path dir1Dir2 = new Path(""/d1/d2/"");"
103799,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,167,,"    assertEquals(""FileStatus should return files and directories"","
103800,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,170,,"    expectedPaths.add(""o3fs://"" + bucketName + ""."" + volumeName + ""/d1"");"
103801,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,176,,"    assertEquals(""Failed to return the filestatus[]"" + expectedPaths,"
103802,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,184,,"    expectedPaths.add(""o3fs://"" + bucketName + ""."" + volumeName + ""/d1/d2"");"
103803,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFileSystemWithFSO.java,282,,"    assertEquals(""Failed to get all the files: "" + expectedPaths,"
103804,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFsHAURLs.java,131,,"    rootPath = String.format(""%s://%s.%s.%s/"", OzoneConsts.OZONE_URI_SCHEME,"
103805,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestOzoneFsHAURLs.java,215,,"      res = ToolRunner.run(shell, new String[] {""-ls"", ""/""});"
103806,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,227,,"    Path child = new Path(parent, ""child"");"
103807,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,354,,"    String bucketNameLocal = ""bucket-"" + RandomStringUtils.randomNumeric(5);"
103808,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,356,,"    Path dir1 = new Path(root, ""dir1"");"
103809,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,358,,"    Path dir2 = new Path(root, ""dir2"");"
103810,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,565,,"    Path leafInsideInterimPath = new Path(interimPath, ""leaf"");"
103811,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,1287,,"        LOG.error(""Delete from Trash Failed"", e);"
103812,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystem.java,1440,,"    assertTrue(""Rename failed"", getFs().rename(dir2SourcePath, destRootPath));"
103813,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/fs/ozone/TestRootedOzoneFileSystemWithFSO.java,65,,"  @Ignore(""HDDS-2939"")"
103814,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/hdds/upgrade/TestHDDSUpgrade.java,408,,"    StatusAndMessages status = scm.finalizeUpgrade(""xyz"");"
103815,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/MiniOzoneClusterImpl.java,860,,"      conf.set(ScmConfigKeys.OZONE_SCM_CLIENT_ADDRESS_KEY, ""127.0.0.1:0"");"
103816,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/MiniOzoneClusterImpl.java,900,,"      conf.set(ScmConfigKeys.HDDS_REST_HTTP_ADDRESS_KEY, ""0.0.0.0:0"");"
103817,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/MiniOzoneHAClusterImpl.java,616,,"        conf.set(scmHttpAddrKey, ""127.0.0.1:"" + (port + 2));"
103818,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/TestDelegationToken.java,297,,"          ""Auth successful for "" + username + "" (auth:KERBEROS)""));"
103819,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/TestSecureOzoneCluster.java,141,,"  private static final String COMPONENT = ""test"";"
103820,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/TestStorageContainerManager.java,188,,"        fail(""Operation should fail, expecting an IOException here."");"
103821,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/TestStorageContainerManager.java,482,,"    Path scmPath = Paths.get(path, ""scm-meta"");"
103822,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestContainerStateMachine.java,143,,"            .createKey(""ratis"", 1024, ReplicationType.RATIS,"
103823,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestContainerStateMachineFailures.java,173,,"                    .createKey(""ratis"", 1024, ReplicationType.RATIS,"
103824,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneAtRestEncryption.java,247,,"        .addMetadata(OzoneConsts.GDPR_FLAG, ""true"").build();"
103825,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneClientMultipartUploadWithFSO.java,331,,"            ""data"".getBytes(UTF_8));"
103826,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneClientMultipartUploadWithFSO.java,410,,"    partsMap.put(3, ""random"");"
103827,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneClientMultipartUploadWithFSO.java,420,,"    String parentDir = ""a/b/c/d/"";"
103828,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,300,,"    String value = ""sample value"";"
103829,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,306,,"        ""10GB"", ""10000""));"
103830,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,316,,"        OzoneQuota.parseQuota(""1GB"", ""1000""));"
103831,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,373,,"        ""Invalid values for space quota"","
103832,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,387,,"        ""Invalid values for quota"","
103833,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,389,,"            OzoneQuota.parseQuota(""1TEST"", ""100"")));"
103834,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,423,,"        .addMetadata(""key1"", ""val1"")"
103835,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,597,,"    OzoneAcl userAcl = new OzoneAcl(USER, ""test"","
103836,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,885,,"      GenericTestUtils.assertExceptionContains(""QUOTA_EXCEEDED"", ex);"
103837,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,2065,,"        volAbucketA.listKeys(""key-"");"
103838,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,2200,,"    String sampleData = ""sample Value"";"
103839,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,2362,,"    String uploadID = ""random"";"
103840,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,2520,,"        ""data"".getBytes(UTF_8));"
103841,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,3028,,"    assertTrue(""Current acls:"" + StringUtils.join("","", acls) +"
103842,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientAbstract.java,3449,,"        .addMetadata(OzoneConsts.GDPR_FLAG, ""true"").build();"
103843,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestOzoneRpcClientForAclAuditLog.java,86,,"      ""johndoe"", IAccessAuthorizer.ACLType.ALL, ACCESS);"
103844,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/client/rpc/TestValidateBCSIDOnRestart.java,152,,"                    .createKey(""ratis"", 1024, ReplicationType.RATIS,"
103845,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/container/common/statemachine/commandhandler/TestCloseContainerByPipeline.java,94,,"    objectStore.createVolume(""test"");"
103846,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/container/common/statemachine/commandhandler/TestCloseContainerHandler.java,96,,"    objectStore.createVolume(""test"");"
103847,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/freon/TestHadoopDirTreeGenerator.java,105,,"      verifyDirTree(""vol1"", ""bucket1"", 1,"
103848,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/freon/TestHadoopNestedDirGenerator.java,101,,"              ""bucket1"", 1, 1);"
103849,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerImpl.java,153,,"  private static final String BUCKET_NAME = ""bucket1"";"
103850,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerImpl.java,154,,"  private static final String VOLUME_NAME = ""vol1"";"
103851,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerImpl.java,195,,"            mockScmContainerClient, metadataManager, conf, ""om1"", null);"
103852,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerImpl.java,607,,"    exception.expectMessage(""Invalid prefix name"");"
103853,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOMStartupWithLayout.java,153,,"      Assert.fail(""Should fail OM startup in "" + clusterLayout + "" layout"");"
103854,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOMStartupWithLayout.java,153,,"      Assert.fail(""Should fail OM startup in "" + clusterLayout + "" layout"");"
103855,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOMStartupWithLayout.java,156,,"          ""Failed to start OM in "" + clusterLayout + "" layout format"","
103856,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOMStartupWithLayout.java,156,,"          ""Failed to start OM in "" + clusterLayout + "" layout format"","
103857,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,117,,"    MetricsRecordBuilder omMetrics = getMetrics(""OMMetrics"");"
103858,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,125,,"    assertCounter(""NumVolumes"", 1L, omMetrics);"
103859,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,180,,"            ozoneManager, ""bucketManager"");"
103860,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,201,,"    assertCounter(""NumBuckets"", 0L, omMetrics);"
103861,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,277,,"    assertCounter(""NumKeys"", 0L, omMetrics);"
103862,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,336,,"      cluster.getClient().getObjectStore().createVolume(""volumeacl"");"
103863,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOmMetrics.java,374,,"    objectStore.getVolume(""volumeacl"").createBucket(""bucketacl"");"
103864,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerConfiguration.java,127,,"    String omNode1Id = ""omNode1"";"
103865,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerConfiguration.java,128,,"    String omNode2Id = ""omNode2"";"
103866,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerConfiguration.java,196,,"    final String omNode3Id = ""omNode3"";"
103867,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerHAMetadataOnly.java,99,,"    String volumeName = ""volume"" + RandomStringUtils.randomNumeric(5);"
103868,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerHAWithACL.java,46,,"    String remoteUserName = ""remoteUser"";"
103869,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerHAWithData.java,119,,"    String data = ""random data"";"
103870,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,65,,"      UserGroupInformation.createUserForTesting(""user1"", new String[]{""test""});"
103871,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,108,,"    createVolumeWithOwnerAndAcl(objectStore, ""volume1"", ""user1"", aclUser1All);"
103872,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,109,,"    createVolumeWithOwnerAndAcl(objectStore, ""volume2"", ""user2"", aclUser2All);"
103873,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,110,,"    createVolumeWithOwnerAndAcl(objectStore, ""volume3"", ""user1"", aclUser2All);"
103874,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,111,,"    createVolumeWithOwnerAndAcl(objectStore, ""volume4"", ""user2"", aclUser1All);"
103875,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,112,,"    createVolumeWithOwnerAndAcl(objectStore, ""volume5"", ""user1"", aclWorldAll);"
103876,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerListVolumes.java,209,,"        ""volume4"", ""volume5"", ""s3v""), true);"
103877,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestRecursiveAclWithFSO.java,107,,"    volume.createBucket(""bucket1"", omBucketArgs);"
103878,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestRecursiveAclWithFSO.java,179,,"      Assert.fail(""Should throw permission denied !"");"
103879,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/om/TestRecursiveAclWithFSO.java,182,,"      Assert.assertEquals(""Permission check failed"","
103880,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/scm/TestContainerSmallFile.java,103,,"        ""data123"".getBytes(UTF_8), null);"
103881,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/scm/node/TestDecommissionAndMaintenance.java,148,,"    generateData(20, ""key"", ReplicationFactor.THREE, ReplicationType.RATIS);"
103882,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,307,,"        ""volume"", ""create"", ""o3://"" + omServiceId + volumeName};"
103883,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,307,,"        ""volume"", ""create"", ""o3://"" + omServiceId + volumeName};"
103884,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,307,,"        ""volume"", ""create"", ""o3://"" + omServiceId + volumeName};"
103885,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,311,,"        ""bucket"", ""create"", ""o3://"" + omServiceId + volumeName + bucketName};"
103886,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,315,,"        OzoneConsts.OZONE_URI_DELIMITER + ""key"";"
103887,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,424,,"    String[] args = new String[] {""key"", ""list"", destinationBucket};"
103888,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,549,,"      res = ToolRunner.run(shell, new String[]{""-rm"", strKey1});"
103889,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,665,,"    String[] args = new String[]{""volume"", ""create"", ""vol""};"
103890,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,681,,"    args = new String[]{""volume"", ""create"", ""vol1"", ""--quota"", ""100B""};"
103891,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,698,,"    args = new String[]{""volume"", ""create"", ""vol2"", ""--space-quota"","
103892,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,698,,"    args = new String[]{""volume"", ""create"", ""vol2"", ""--space-quota"","
103893,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,717,,"        new String[]{""volume"", ""create"", ""vol3"", ""--namespace-quota"", ""100""};"
103894,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,717,,"        new String[]{""volume"", ""create"", ""vol3"", ""--namespace-quota"", ""100""};"
103895,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,717,,"        new String[]{""volume"", ""create"", ""vol3"", ""--namespace-quota"", ""100""};"
103896,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,734,,"    args = new String[]{""volume"", ""create"", ""vol4"", ""--space-quota"","
103897,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,742,,"    args = new String[]{""bucket"", ""create"", ""vol4/buck4"","
103898,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,746,,"        objectStore.getVolume(""vol4"").getBucket(""buck4"").getQuotaInBytes());"
103899,./TargetProjects/hadoop-ozone/hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/shell/TestOzoneShellHA.java,771,,"    String[] volumeArgs1 = new String[]{""volume"", ""setquota"", ""vol4"","
103900,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java,412,,"      throw new IllegalArgumentException(""Unexpected argument passed to "" +"
103901,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java,413,,"          ""BucketManager. OzoneObj type:"" + obj.getResourceType());"
103902,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java,424,,"        LOG.debug(""Bucket:{}/{} does not exist"", volume, bucket);"
103903,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java,425,,"        throw new OMException(""Bucket "" + bucket + "" is not found"","
103904,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/BucketManagerImpl.java,425,,"        throw new OMException(""Bucket "" + bucket + "" is not found"","
103905,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/KeyManagerImpl.java,208,,"  @SuppressWarnings(""parameternumber"")"
103906,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/KeyManagerImpl.java,1265,,"            volumeName + ""bucket: "" + bucketName + ""key: "" + keyName,"
103907,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/KeyManagerImpl.java,1265,,"            volumeName + ""bucket: "" + bucketName + ""key: "" + keyName,"
103908,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/KeyManagerImpl.java,1585,,"        throw new OMException(""Key not found. Key:"" + objectKey, KEY_NOT_FOUND);"
103909,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/KeyManagerImpl.java,1896,,"    Preconditions.checkNotNull(args, ""Key args can not be null"");"
103910,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java,1057,,"      LOG.error(""OM security initialization failed."");"
103911,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java,1949,,"    throw new UnsupportedOperationException(""OzoneManager does not require "" +"
103912,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OzoneManager.java,3198,,"        throw new OMException(""Unexpected resource type: "" +"
103913,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/VolumeManagerImpl.java,215,,"        throw new OMException(""Volume "" + volume + "" is not found"","
103914,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/VolumeManagerImpl.java,215,,"        throw new OMException(""Volume "" + volume + "" is not found"","
103915,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/VolumeManagerImpl.java,288,,"        LOG.debug(""volume:{} does not exist"", volume);"
103916,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/VolumeManagerImpl.java,416,,"      throw new IllegalArgumentException(""Unexpected argument passed to "" +"
103917,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/VolumeManagerImpl.java,417,,"          ""VolumeManager. OzoneObj type:"" + obj.getResourceType());"
103918,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/request/key/OMKeyRequest.java,113,,"  @SuppressWarnings(""parameternumber"")"
103919,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestBucketManagerImpl.java,69,,"    String volumeKey = metaMgr.getVolumeKey(""sampleVol"");"
103920,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestBucketManagerImpl.java,92,,"          .setBucketName(""bucketOne"")"
103921,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,125,,"    createBucket(metadataManager, ""vol1"", ""bucket1"");"
103922,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,125,,"    createBucket(metadataManager, ""vol1"", ""bucket1"");"
103923,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,128,,"        initMultipartUpload(keyManager, ""vol1"", ""bucket1"", ""dir/key1"");"
103924,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,144,,"    createBucket(metadataManager, ""vol1"", ""bucket2"");"
103925,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,147,,"    initMultipartUpload(keyManager, ""vol1"", ""bucket1"", ""dir/key2"");"
103926,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,202,,"    addinitMultipartUploadToCache(volume, bucket, ""dir/ozonekey1"");"
103927,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,204,,"    initMultipartUpload(keyManager, volume, bucket, ""dir/ozonekey2"");"
103928,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,207,,"        bucket, ""dir/ozonekey3"");"
103929,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestKeyManagerUnit.java,375,,"        .setVolume(""volumeOne"")"
103930,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/TestOzoneManagerStarter.java,89,,"    executeCommand(""--init"");"
103931,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/TestNormalizePaths.java,42,,"    Assert.assertEquals(""a/b/c/d"","
103932,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/TestOMRequestUtils.java,104,,"  @SuppressWarnings(""parameterNumber"")"
103933,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMDirectoryCreateRequest.java,106,,"    String volumeName = ""vol1"";"
103934,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMDirectoryCreateRequest.java,107,,"    String bucketName = ""bucket1"";"
103935,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMDirectoryCreateRequestWithFSO.java,113,,"    String volumeName = ""vol1"";"
103936,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMDirectoryCreateRequestWithFSO.java,114,,"    String bucketName = ""bucket1"";"
103937,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/file/TestOMFileCreateRequest.java,247,,"        ""c/d/e/f"", 0L,  HddsProtos.ReplicationType.RATIS,"
103938,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeyDeleteRequestWithFSO.java,105,,"    verifyPath(ozonePrefixPath, ""c/d/e"", ""c/d/e/file1"");"
103939,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/key/TestOMKeysRenameRequest.java,65,,"              parentDir.concat(""/key"" + i)));"
103940,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/volume/TestOMVolumeCreateRequest.java,64,,"    String adminName = ""user1"";"
103941,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/request/volume/TestOMVolumeSetOwnerRequest.java,44,,"    String newOwner = ""user1"";"
103942,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/response/key/TestOMKeysRenameResponse.java,68,,"      String key = parentDir.concat(""/key"" + i);"
103943,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/upgrade/TestOMUpgradeFinalizer.java,88,,"    Iterable<OMLayoutFeature> lfs = mockFeatures(3, ""feature-3"", ""feature-4"");"
103944,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/om/upgrade/TestOMUpgradeFinalizer.java,88,,"    Iterable<OMLayoutFeature> lfs = mockFeatures(3, ""feature-3"", ""feature-4"");"
103945,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneBlockTokenSecretManager.java,158,,"        ""testUser"", blockID, EnumSet.allOf(AccessModeProto.class), 100);"
103946,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneBlockTokenSecretManager.java,227,,"  @SuppressWarnings(""java:S2699"")"
103947,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneDelegationTokenSecretManager.java,340,,"    identifier.setStrToSign(""AWS4-HMAC-SHA256\n"" +"
103948,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneDelegationTokenSecretManager.java,341,,"        ""20190221T002037Z\n"" +"
103949,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneDelegationTokenSecretManager.java,342,,"        ""20190221/us-west-1/s3/aws4_request\n"" +"
103950,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneDelegationTokenSecretManager.java,343,,"        ""c297c080cce4e0927779823d3fd1f5cae71481a8f7dfc7e18d91851294efc47d"");"
103951,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneManagerBlockToken.java,83,,"        .generateCertificate(""CN=OzoneMaster"", keyPair, 30, ""SHA256withRSA"");"
103952,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneTokenIdentifier.java,126,,"        .generateCertificate(""CN=OzoneMaster"", keyPair, 30, ""SHA256withRSA"");"
103953,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/TestOzoneTokenIdentifier.java,138,,"    tokenId.setOmCertSerialId(""123"");"
103954,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/acl/TestOzoneAdministrators.java,47,,"    RequestContext context = getUserRequestContext(""testuser"","
103955,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/acl/TestRequestContext.java,52,,"    Assert.assertFalse(""Wrongly sets recursive flag value"","
103956,./TargetProjects/hadoop-ozone/hadoop-ozone/ozone-manager/src/test/java/org/apache/hadoop/ozone/security/acl/TestVolumeOwner.java,166,,"        ""operations"", nativeAuthorizer.checkAccess(vol0, nonOwnerContext));"
103957,./TargetProjects/hadoop-ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestOFSPath.java,36,,"    Assert.assertEquals(""volume1"", ofsPath.getVolumeName());"
103958,./TargetProjects/hadoop-ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestOFSPath.java,37,,"    Assert.assertEquals(""bucket2"", ofsPath.getBucketName());"
103959,./TargetProjects/hadoop-ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestOFSPath.java,39,,"    Assert.assertEquals(""/volume1/bucket2"", ofsPath.getNonKeyPath());"
103960,./TargetProjects/hadoop-ozone/hadoop-ozone/ozonefs-common/src/test/java/org/apache/hadoop/fs/ozone/TestOFSPath.java,83,,"    OFSPath ofsPath = new OFSPath(""/volume1/"");"
103961,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/OMMetadataManagerTestUtils.java,76,,"    String volumeKey = omMetadataManager.getVolumeKey(""sampleVol"");"
103962,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,436,,"    final UUID u1 = newDatanode(""host1"", ""127.0.0.1"");"
103963,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,436,,"    final UUID u1 = newDatanode(""host1"", ""127.0.0.1"");"
103964,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,437,,"    final UUID u2 = newDatanode(""host2"", ""127.0.0.2"");"
103965,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,437,,"    final UUID u2 = newDatanode(""host2"", ""127.0.0.2"");"
103966,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,438,,"    final UUID u3 = newDatanode(""host3"", ""127.0.0.3"");"
103967,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,438,,"    final UUID u3 = newDatanode(""host3"", ""127.0.0.3"");"
103968,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,439,,"    final UUID u4 = newDatanode(""host4"", ""127.0.0.4"");"
103969,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestContainerEndpoint.java,439,,"    final UUID u4 = newDatanode(""host4"", ""127.0.0.4"");"
103970,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java,609,,"    given(omKeyInfo1.getVolumeName()).willReturn(""vol1"");"
103971,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestEndpoints.java,610,,"    given(omKeyInfo1.getBucketName()).willReturn(""bucket1"");"
103972,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/api/TestOpenContainerCount.java,145,,"              .setOwner(""test"")"
103973,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/fsck/TestContainerHealthTask.java,148,,"    assertEquals(""MISSING"", rec.getContainerState());"
103974,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/persistence/TestReconInternalSchemaDefinition.java,87,,"    newRecord.setTaskName(""HelloWorldTask"");"
103975,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/persistence/TestStatsSchemaDefinition.java,86,,"    newRecord.setKey(""key1"");"
103976,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/persistence/TestStatsSchemaDefinition.java,93,,"    newRecord2.setKey(""key2"");"
103977,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/recovery/TestReconOmMetadataManagerImpl.java,81,,"        .get(""/sampleVol/bucketOne/key_one""));"
103978,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/recovery/TestReconOmMetadataManagerImpl.java,83,,"        .get(""/sampleVol/bucketOne/key_two""));"
103979,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/recovery/TestReconOmMetadataManagerImpl.java,149,,"    String volumeKey = omMetadataManager.getVolumeKey(""sampleVol"");"
103980,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/scm/AbstractReconContainerManagerTest.java,157,,"            .setOwner(""test"")"
103981,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java,78,,"    given(omKeyInfo1.getVolumeName()).willReturn(""vol1"");"
103982,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java,79,,"    given(omKeyInfo1.getBucketName()).willReturn(""bucket1"");"
103983,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java,162,,"    given(toBeUpdatedKey.getKeyName()).willReturn(""updatedKey"");"
103984,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestFileSizeCountTask.java,255,,"          given(omKeyInfo.getKeyName()).willReturn(""key"" + keyIndex);"
103985,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestOMDBUpdatesHandler.java,79,,"    String volumeKey = metaMgr.getVolumeKey(""sampleVol"");"
103986,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestOMDBUpdatesHandler.java,83,,"            .setAdminName(""bilbo"")"
103987,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestOMDBUpdatesHandler.java,89,,"    metaMgr.getKeyTable().put(""/sampleVol/bucketOne/key_one"", firstKey);"
103988,./TargetProjects/hadoop-ozone/hadoop-ozone/recon/src/test/java/org/apache/hadoop/ozone/recon/tasks/TestOMDBUpdatesHandler.java,92,,"    metaMgr.getKeyTable().put(""/sampleVol/bucketOne/key_two"", secondKey);"
103989,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/BucketEndpoint.java,91,,"      @PathParam(""bucket"") String bucketName,"
103990,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java,150,,"      @PathParam(""bucket"") String bucketName,"
103991,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java,151,,"      @PathParam(""path"") String keyPath,"
103992,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/main/java/org/apache/hadoop/ozone/s3/endpoint/ObjectEndpoint.java,154,,"      @QueryParam(""uploadId"") @DefaultValue("""") String uploadID,"
103993,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestSignedChunksInputStream.java,45,,"        ""=23abb2bd920ddeeaac78a63ed808bc59fa6e7d3ef0e356474b82cdc2f8c93c40\r"""
103994,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestSignedChunksInputStream.java,54,,"    InputStream is = fileContent(""0A;chunk-signature"""
103995,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestSignedChunksInputStream.java,59,,"    Assert.assertEquals(""1234567890"", result);"
103996,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestVirtualHostStyleFilter.java,63,,"    URI baseUri = new URI(""http://"" + s3HttpAddr);"
103997,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestVirtualHostStyleFilter.java,105,,"    ContainerRequest containerRequest = createContainerRequest(""mybucket"" +"
103998,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/TestVirtualHostStyleFilter.java,106,,"            "".localhost:9878"", ""/myfile"", null, true);"
103999,./TargetProjects/hadoop-ozone/hadoop-ozone/s3gateway/src/test/java/org/apache/hadoop/ozone/s3/endpoint/TestBucketAcl.java,97,,"        .thenReturn(S3Acl.ACLIdentityType.GROUP.getHeaderType() + ""=root"");"
